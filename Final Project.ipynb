{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clf type\n",
    "Logistic Regression/ ANN/ Random Forest/ SVM/ Boosting/ Knn\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupance = pd.read_table('occupancy_data/datatraining.txt',delimiter=',')\n",
    "Stu_Eva = pd.read_csv('turkiye-student-evaluation_generic.csv',delimiter=',',header=0)\n",
    "Activity = pd.read_csv('Activity_Recognition/1.csv',delimiter=',',header=None)\n",
    "Parking = pd.read_csv('Parking_Birminghan_Data.csv',delimiter=',',header=0)\n",
    "Whole = pd.read_csv('Wholesale_customers.csv',delimiter=',',header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "Whole.drop(columns=['Region'], inplace=True)\n",
    "Whole_x = Whole.iloc[:,1:]\n",
    "Whole_y = Whole.iloc[:,0]\n",
    "#Whole_y = np.reshape(Whole_y, (Whole_y.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on activity dataset\n",
    "# drop the time series column\n",
    "Activity.columns=['sequential','x','y','z','activity_type']\n",
    "Activity.drop(columns=['sequential'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# manually divide 7 kinds of activity into 2 categories\n",
    "# first one is going up\n",
    "# second one is the remaining\n",
    "Activity['activity_type'].replace([0,1,2,3,4,5,6,7],[0,0,1,0,0,1,0,0],inplace=True)\n",
    "\n",
    "Act_x = Activity.iloc[:,:3]\n",
    "Act_y = Activity.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on occupance dataset\n",
    "occupance.drop(columns=['date'],inplace=True)\n",
    "occ_x = occupance.iloc[:,:-1]\n",
    "occ_y = occupance.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on student evaluation dataset\n",
    "Stu_Eva = pd.concat([Stu_Eva,pd.get_dummies(Stu_Eva['instr'])],axis=1)\n",
    "Instr = Stu_Eva.iloc[:,0]\n",
    "Stu_Eva.drop(columns=['instr'],inplace=True)\n",
    "eva_x = Stu_Eva.iloc[:,0:-3]\n",
    "eva_y = Stu_Eva.iloc[:,-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process parking dataset\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "Parking.drop(columns=['LastUpdated'],inplace=True)\n",
    "Parking['parking_label'] = le.fit_transform(Parking['SystemCodeNumber'])\n",
    "parking_label = Parking['parking_label']\n",
    "Parking.drop(columns=['parking_label'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parking = pd.concat([Parking,pd.get_dummies(Parking['SystemCodeNumber'])],axis=1)\n",
    "Parking.drop(columns=['SystemCodeNumber'],inplace=True)\n",
    "parking_x = Parking.iloc[:,:2]\n",
    "parking_y = Parking.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "sc = StandardScaler()\n",
    "# different test size\n",
    "test_size=[0.2,0.5,0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9053030303030303, 0.9015151515151515, 0.8778409090909092]\n",
      "[0.9043560606060606, 0.9212121212121213, 0.9280303030303031]\n"
     ]
    }
   ],
   "source": [
    "ave_acc_whole_log = []\n",
    "ave_acc_whole_log_train = []\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(Whole_x, Whole_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_whole_log.append(score2/3.0)\n",
    "    ave_acc_whole_log_train.append(score1/3.0)\n",
    "print ave_acc_whole_log\n",
    "print ave_acc_whole_log_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97463667784581, 0.9743223673144535, 0.9742130188742139]\n",
      "[0.974197435897436, 0.9742605128205128, 0.9746564102564103]\n"
     ]
    }
   ],
   "source": [
    "ave_acc_activity_log = []\n",
    "ave_acc_activity_log_train = []\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(Act_x, Act_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_activity_log.append(score2/3.0)\n",
    "    ave_acc_activity_log_train.append(score1/3.0)\n",
    "print ave_acc_activity_log \n",
    "print ave_acc_activity_log_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9873132801309596, 0.9871480026195153, 0.9859810693271936]\n",
      "[0.9856718861938388, 0.9850978465569474, 0.9864864864864865]\n"
     ]
    }
   ],
   "source": [
    "ave_acc_occ_log = []\n",
    "ave_acc_occ_log_train = []\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(occ_x, occ_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf = LogisticRegression(random_state=0, solver='saga',multi_class='multinomial').fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_occ_log.append(score2/3.0)\n",
    "    ave_acc_occ_log_train.append(score1/3.0)\n",
    "print ave_acc_occ_log\n",
    "print ave_acc_occ_log_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6056701030927836, 0.618327605956472, 0.6106099656357389]\n",
      "[0.6241408934707904, 0.6217640320733104, 0.6222794959908362]\n"
     ]
    }
   ],
   "source": [
    "ave_acc_eva_log=[]\n",
    "ave_acc_eva_log_train=[]\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(eva_x, Instr, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf = LogisticRegression(random_state=0, solver='saga',multi_class='multinomial').fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_eva_log.append(score2/3.0)\n",
    "    ave_acc_eva_log_train.append(score1/3.0)\n",
    "print ave_acc_eva_log\n",
    "print ave_acc_eva_log_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6312523329600597, 0.5826007428560763, 0.5377149389888243]\n",
      "[0.6289854058026808, 0.585750550640236, 0.5486023612861076]\n"
     ]
    }
   ],
   "source": [
    "ave_acc_parking_log=[]\n",
    "ave_acc_parking_log_train=[]\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(parking_x, parking_label, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf = LogisticRegression(random_state=0, solver='saga',multi_class='multinomial').fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_parking_log.append(score2/3.0)\n",
    "    ave_acc_parking_log_train.append(score1/3.0)\n",
    "print ave_acc_parking_log\n",
    "print ave_acc_parking_log_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 50, 'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Use Grid Search\n",
    "clf = RandomForestClassifier()\n",
    "parameter = [{'n_estimators':[20,50,100],'max_depth':[5,10,50]}]\n",
    "search = GridSearchCV(clf,parameter,cv=3)\n",
    "search.fit(Act_x,Act_y)\n",
    "print search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=search.best_params_['n_estimators'],max_depth=search.best_params_['max_depth'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  if __name__ == '__main__':\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "ave_acc_activity_rf = []\n",
    "ave_acc_activity_rf_train = []\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(Act_x, Act_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1,y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_activity_rf.append(score2/3.0)\n",
    "    ave_acc_activity_rf_train.append(score1/3.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9757340799770263, 0.9760126029218101, 0.9757463404127661]\n",
      "[0.976428205128205, 0.9766728205128206, 0.9768820512820513]\n"
     ]
    }
   ],
   "source": [
    "print ave_acc_activity_rf\n",
    "print ave_acc_activity_rf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 20, 'max_depth': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:12: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "search.fit(Whole_x,Whole_y)\n",
    "print search.best_params_\n",
    "clf = RandomForestClassifier(n_estimators=search.best_params_['n_estimators'],max_depth=search.best_params_['max_depth'])\n",
    "ave_acc_whole_rf = []\n",
    "ave_acc_whole_rf_train = []\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(Whole_x, Whole_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_whole_rf.append(score2/3.0)\n",
    "    ave_acc_whole_rf_train.append(score1/3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9015151515151515, 0.8984848484848484, 0.9043560606060606]\n",
      "[0.9981060606060606, 0.9984848484848485, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print ave_acc_whole_rf\n",
    "print ave_acc_whole_rf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "search.fit(occ_x,occ_y)\n",
    "print search.best_params_\n",
    "clf = RandomForestClassifier(n_estimators=search.best_params_['n_estimators'],max_depth=search.best_params_['max_depth'])\n",
    "ave_acc_occ_rf = []\n",
    "ave_acc_occ_rf_train = []\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(occ_x, occ_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_occ_rf.append(score2/3.0)\n",
    "    ave_acc_occ_rf_train.append(score1/3.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9914057704112954, 0.989603798297315, 0.9884369403939627]\n",
      "[0.9914031317163033, 0.9918938835666914, 0.9948812448812449]\n"
     ]
    }
   ],
   "source": [
    "print ave_acc_occ_rf\n",
    "print ave_acc_occ_rf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 50, 'max_depth': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:12: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "search.fit(eva_x,eva_y)\n",
    "print search.best_params_\n",
    "clf = RandomForestClassifier(n_estimators=search.best_params_['n_estimators'],max_depth=search.best_params_['max_depth'])\n",
    "ave_acc_eva_rf=[]\n",
    "ave_acc_eva_rf_train=[]\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(eva_x, eva_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_eva_rf.append(score2/3.0)\n",
    "    ave_acc_eva_rf_train.append(score1/3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8473654066437573, 0.8355097365406644, 0.8011884306987399]\n",
      "[0.9944873997709051, 0.9949599083619702, 0.9959908361970218]\n"
     ]
    }
   ],
   "source": [
    "print ave_acc_eva_rf\n",
    "print ave_acc_eva_rf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'max_depth': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:12: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "search.fit(parking_x,parking_y)\n",
    "print search.best_params_\n",
    "clf = RandomForestClassifier(n_estimators=search.best_params_['n_estimators'],max_depth=search.best_params_['max_depth'])\n",
    "ave_acc_parking_rf=[]\n",
    "ave_acc_parking_rf_train=[]\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(parking_x, parking_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_parking_rf.append(score2/3.0)\n",
    "    ave_acc_parking_rf_train.append(score1/3.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9962206047032475, 0.9911342553707746, 0.9793751895662725]\n",
      "[1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print ave_acc_parking_rf\n",
    "print ave_acc_parking_rf_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(gamma='scale')\n",
    "C_list = [{'kernel':['rbf'],'C':[0.001,0.1]}]\n",
    "search = GridSearchCV(clf, C_list,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'C': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:16: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9751699947693918, 0.9747859513523935, 0.9745719904718682]\n",
      "[0.9745230769230769, 0.9745189743589743, 0.974974358974359]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "search.fit(Act_x,Act_y)\n",
    "\n",
    "clf=SVC(kernel=search.best_params_['kernel'],C=search.best_params_['C'])\n",
    "print search.best_params_\n",
    "\n",
    "ave_acc_activity_svm = []\n",
    "ave_acc_activity_svm_train = []\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        \n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(Act_x, Act_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1,y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_activity_svm.append(score2/3.0)\n",
    "    ave_acc_activity_svm_train.append(score1/3.0)\n",
    "print ave_acc_activity_svm\n",
    "print ave_acc_activity_svm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'C': 0.001}\n",
      "[0.6969696969696969, 0.6696969696969696, 0.6761363636363636]\n",
      "[0.6723484848484849, 0.6848484848484849, 0.6818181818181818]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:14: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "search.fit(Whole_x,Whole_y)\n",
    "\n",
    "clf=SVC(kernel=search.best_params_['kernel'],C=search.best_params_['C'])\n",
    "print search.best_params_\n",
    "ave_acc_whole_svm = []\n",
    "ave_acc_whole_svm_train = []\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        \n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(Whole_x, Whole_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1,y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_whole_svm.append(score2/3.0)\n",
    "    ave_acc_whole_svm_train.append(score1/3.0)\n",
    "print ave_acc_whole_svm\n",
    "print ave_acc_whole_svm_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'C': 0.1}\n",
      "[0.9895641497851443, 0.988867059593975, 0.9884881043745204]\n",
      "[0.9884863371200492, 0.9885368050438058, 0.9864864864864865]\n"
     ]
    }
   ],
   "source": [
    "search.fit(occ_x,occ_y)\n",
    "clf=SVC(kernel=search.best_params_['kernel'],C=search.best_params_['C'])\n",
    "print search.best_params_\n",
    "#clf=SVC(kernel='rbf',C=0.01)\n",
    "ave_acc_occ_svm = []\n",
    "ave_acc_occ_svm_train = []\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        \n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(occ_x, occ_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_occ_svm.append(score2/3.0)\n",
    "    ave_acc_occ_svm_train.append(score1/3.0)\n",
    "\n",
    "print ave_acc_occ_svm\n",
    "print ave_acc_occ_svm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'C': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:14: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6257159221076747, 0.6158075601374571, 0.6148339060710195]\n",
      "[0.6169816723940436, 0.6216494845360825, 0.6343069873997709]\n"
     ]
    }
   ],
   "source": [
    "search.fit(eva_x,Instr)\n",
    "clf=SVC(kernel=search.best_params_['kernel'],C=search.best_params_['C'])\n",
    "print search.best_params_\n",
    "#clf=SVC(kernel='rbf',C=0.1)\n",
    "ave_acc_eva_svm=[]\n",
    "ave_acc_eva_svm_train=[]\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "       \n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(eva_x, Instr, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_eva_svm.append(score2/3.0)\n",
    "    ave_acc_eva_svm_train.append(score1/3.0)\n",
    "\n",
    "print ave_acc_eva_svm\n",
    "print ave_acc_eva_svm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'C': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:14: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.611748786860769, 0.5523638874890345, 0.4305079209537808]\n",
      "[0.6144495386087099, 0.5597304662709524, 0.44211115777684445]\n"
     ]
    }
   ],
   "source": [
    "search.fit(parking_x,parking_label)\n",
    "clf = SVC(kernel=search.best_params_['kernel'],C=0.1)\n",
    "print search.best_params_\n",
    "#clf=SVC(kernel='linear',C=0.1)\n",
    "ave_acc_parking_svm=[]\n",
    "ave_acc_parking_svm_train=[]\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "       \n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(parking_x, parking_label, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_parking_svm.append(score2/3.0)\n",
    "    ave_acc_parking_svm_train.append(score1/3.0)\n",
    "\n",
    "print ave_acc_parking_svm\n",
    "print ave_acc_parking_svm_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(in_num,out_num):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32,activation='relu',input_dim=in_num))\n",
    "    model.add(Dense(units = 32, activation = 'relu'))\n",
    "    model.add(Dense(units = out_num, activation = 'softmax'))\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:13: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 352 samples, validate on 352 samples\n",
      "Epoch 1/200\n",
      "352/352 [==============================] - 4s 12ms/step - loss: 0.9701 - acc: 0.3949 - val_loss: 0.9085 - val_acc: 0.4744\n",
      "Epoch 2/200\n",
      "352/352 [==============================] - 0s 337us/step - loss: 0.8583 - acc: 0.5057 - val_loss: 0.8060 - val_acc: 0.5767\n",
      "Epoch 3/200\n",
      "352/352 [==============================] - 0s 310us/step - loss: 0.7609 - acc: 0.5966 - val_loss: 0.7111 - val_acc: 0.6080\n",
      "Epoch 4/200\n",
      "352/352 [==============================] - 0s 323us/step - loss: 0.6715 - acc: 0.6222 - val_loss: 0.6259 - val_acc: 0.6307\n",
      "Epoch 5/200\n",
      "352/352 [==============================] - 0s 326us/step - loss: 0.5889 - acc: 0.6392 - val_loss: 0.5473 - val_acc: 0.6477\n",
      "Epoch 6/200\n",
      "352/352 [==============================] - 0s 375us/step - loss: 0.5107 - acc: 0.6562 - val_loss: 0.4713 - val_acc: 0.6591\n",
      "Epoch 7/200\n",
      "352/352 [==============================] - 0s 439us/step - loss: 0.4348 - acc: 0.6619 - val_loss: 0.3970 - val_acc: 0.6676\n",
      "Epoch 8/200\n",
      "352/352 [==============================] - 0s 379us/step - loss: 0.3619 - acc: 0.6676 - val_loss: 0.3229 - val_acc: 0.6705\n",
      "Epoch 9/200\n",
      "352/352 [==============================] - 0s 384us/step - loss: 0.2892 - acc: 0.6733 - val_loss: 0.2511 - val_acc: 0.6733\n",
      "Epoch 10/200\n",
      "352/352 [==============================] - 0s 321us/step - loss: 0.2196 - acc: 0.6761 - val_loss: 0.1811 - val_acc: 0.6761\n",
      "Epoch 11/200\n",
      "352/352 [==============================] - 0s 322us/step - loss: 0.1494 - acc: 0.6761 - val_loss: 0.1153 - val_acc: 0.6761\n",
      "Epoch 12/200\n",
      "352/352 [==============================] - 0s 436us/step - loss: 0.0827 - acc: 0.6761 - val_loss: 0.0466 - val_acc: 0.6761\n",
      "Epoch 13/200\n",
      "352/352 [==============================] - 0s 416us/step - loss: 0.0142 - acc: 0.6761 - val_loss: -0.0217 - val_acc: 0.6761\n",
      "Epoch 14/200\n",
      "352/352 [==============================] - 0s 339us/step - loss: -0.0539 - acc: 0.6761 - val_loss: -0.0917 - val_acc: 0.6761\n",
      "Epoch 15/200\n",
      "352/352 [==============================] - 0s 361us/step - loss: -0.1247 - acc: 0.6790 - val_loss: -0.1589 - val_acc: 0.6790\n",
      "Epoch 16/200\n",
      "352/352 [==============================] - 0s 283us/step - loss: -0.1930 - acc: 0.6790 - val_loss: -0.2316 - val_acc: 0.6790\n",
      "Epoch 17/200\n",
      "352/352 [==============================] - 0s 318us/step - loss: -0.2646 - acc: 0.6790 - val_loss: -0.3052 - val_acc: 0.6790\n",
      "Epoch 18/200\n",
      "352/352 [==============================] - 0s 381us/step - loss: -0.3390 - acc: 0.6790 - val_loss: -0.3787 - val_acc: 0.6790\n",
      "Epoch 19/200\n",
      "352/352 [==============================] - 0s 461us/step - loss: -0.4146 - acc: 0.6790 - val_loss: -0.4547 - val_acc: 0.6790\n",
      "Epoch 20/200\n",
      "352/352 [==============================] - 0s 341us/step - loss: -0.4919 - acc: 0.6790 - val_loss: -0.5332 - val_acc: 0.6790\n",
      "Epoch 21/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -0.5722 - acc: 0.6790 - val_loss: -0.6147 - val_acc: 0.6790\n",
      "Epoch 22/200\n",
      "352/352 [==============================] - 0s 276us/step - loss: -0.6567 - acc: 0.6790 - val_loss: -0.7051 - val_acc: 0.6790\n",
      "Epoch 23/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -0.7500 - acc: 0.6790 - val_loss: -0.8021 - val_acc: 0.6790\n",
      "Epoch 24/200\n",
      "352/352 [==============================] - 0s 276us/step - loss: -0.8490 - acc: 0.6790 - val_loss: -0.9058 - val_acc: 0.6790\n",
      "Epoch 25/200\n",
      "352/352 [==============================] - 0s 277us/step - loss: -0.9524 - acc: 0.6790 - val_loss: -1.0162 - val_acc: 0.6790\n",
      "Epoch 26/200\n",
      "352/352 [==============================] - 0s 311us/step - loss: -1.0664 - acc: 0.6790 - val_loss: -1.1249 - val_acc: 0.6790\n",
      "Epoch 27/200\n",
      "352/352 [==============================] - 0s 299us/step - loss: -1.1817 - acc: 0.6790 - val_loss: -1.2467 - val_acc: 0.6790\n",
      "Epoch 28/200\n",
      "352/352 [==============================] - 0s 350us/step - loss: -1.3104 - acc: 0.6790 - val_loss: -1.3759 - val_acc: 0.6790\n",
      "Epoch 29/200\n",
      "352/352 [==============================] - 0s 338us/step - loss: -1.4428 - acc: 0.6790 - val_loss: -1.5212 - val_acc: 0.6790\n",
      "Epoch 30/200\n",
      "352/352 [==============================] - 0s 331us/step - loss: -1.5847 - acc: 0.6790 - val_loss: -1.6565 - val_acc: 0.6790\n",
      "Epoch 31/200\n",
      "352/352 [==============================] - 0s 321us/step - loss: -1.7209 - acc: 0.6790 - val_loss: -1.7990 - val_acc: 0.6790\n",
      "Epoch 32/200\n",
      "352/352 [==============================] - 0s 310us/step - loss: -1.8634 - acc: 0.6790 - val_loss: -1.9432 - val_acc: 0.6790\n",
      "Epoch 33/200\n",
      "352/352 [==============================] - 0s 315us/step - loss: -2.0077 - acc: 0.6790 - val_loss: -2.0792 - val_acc: 0.6790\n",
      "Epoch 34/200\n",
      "352/352 [==============================] - 0s 324us/step - loss: -2.1413 - acc: 0.6790 - val_loss: -2.2177 - val_acc: 0.6790\n",
      "Epoch 35/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -2.2804 - acc: 0.6790 - val_loss: -2.3513 - val_acc: 0.6790\n",
      "Epoch 36/200\n",
      "352/352 [==============================] - 0s 312us/step - loss: -2.4136 - acc: 0.6790 - val_loss: -2.4965 - val_acc: 0.6790\n",
      "Epoch 37/200\n",
      "352/352 [==============================] - 0s 278us/step - loss: -2.5561 - acc: 0.6790 - val_loss: -2.6234 - val_acc: 0.6790\n",
      "Epoch 38/200\n",
      "352/352 [==============================] - 0s 300us/step - loss: -2.6883 - acc: 0.6790 - val_loss: -2.7557 - val_acc: 0.6790\n",
      "Epoch 39/200\n",
      "352/352 [==============================] - 0s 325us/step - loss: -2.8189 - acc: 0.6790 - val_loss: -2.8862 - val_acc: 0.6790\n",
      "Epoch 40/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -2.9500 - acc: 0.6790 - val_loss: -3.0202 - val_acc: 0.6790\n",
      "Epoch 41/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -3.0896 - acc: 0.6790 - val_loss: -3.1573 - val_acc: 0.6790\n",
      "Epoch 42/200\n",
      "352/352 [==============================] - 0s 281us/step - loss: -3.2344 - acc: 0.6790 - val_loss: -3.3105 - val_acc: 0.6790\n",
      "Epoch 43/200\n",
      "352/352 [==============================] - 0s 313us/step - loss: -3.3849 - acc: 0.6790 - val_loss: -3.4589 - val_acc: 0.6790\n",
      "Epoch 44/200\n",
      "352/352 [==============================] - 0s 304us/step - loss: -3.5148 - acc: 0.6790 - val_loss: -3.5856 - val_acc: 0.6790\n",
      "Epoch 45/200\n",
      "352/352 [==============================] - 0s 289us/step - loss: -3.6310 - acc: 0.6790 - val_loss: -3.6830 - val_acc: 0.6790\n",
      "Epoch 46/200\n",
      "352/352 [==============================] - 0s 316us/step - loss: -3.7268 - acc: 0.6790 - val_loss: -3.7743 - val_acc: 0.6790\n",
      "Epoch 47/200\n",
      "352/352 [==============================] - 0s 414us/step - loss: -3.8108 - acc: 0.6790 - val_loss: -3.8532 - val_acc: 0.6790\n",
      "Epoch 48/200\n",
      "352/352 [==============================] - 0s 425us/step - loss: -3.8905 - acc: 0.6790 - val_loss: -3.9328 - val_acc: 0.6790\n",
      "Epoch 49/200\n",
      "352/352 [==============================] - 0s 331us/step - loss: -3.9628 - acc: 0.6790 - val_loss: -4.0029 - val_acc: 0.6790\n",
      "Epoch 50/200\n",
      "352/352 [==============================] - 0s 303us/step - loss: -4.0300 - acc: 0.6790 - val_loss: -4.0680 - val_acc: 0.6790\n",
      "Epoch 51/200\n",
      "352/352 [==============================] - 0s 286us/step - loss: -4.0987 - acc: 0.6790 - val_loss: -4.1284 - val_acc: 0.6790\n",
      "Epoch 52/200\n",
      "352/352 [==============================] - 0s 333us/step - loss: -4.1524 - acc: 0.6790 - val_loss: -4.1817 - val_acc: 0.6790\n",
      "Epoch 53/200\n",
      "352/352 [==============================] - 0s 328us/step - loss: -4.2039 - acc: 0.6790 - val_loss: -4.2338 - val_acc: 0.6790\n",
      "Epoch 54/200\n",
      "352/352 [==============================] - 0s 399us/step - loss: -4.2557 - acc: 0.6790 - val_loss: -4.2822 - val_acc: 0.6790\n",
      "Epoch 55/200\n",
      "352/352 [==============================] - 0s 334us/step - loss: -4.3010 - acc: 0.6790 - val_loss: -4.3234 - val_acc: 0.6790\n",
      "Epoch 56/200\n",
      "352/352 [==============================] - 0s 337us/step - loss: -4.3418 - acc: 0.6790 - val_loss: -4.3681 - val_acc: 0.6790\n",
      "Epoch 57/200\n",
      "352/352 [==============================] - 0s 304us/step - loss: -4.3840 - acc: 0.6790 - val_loss: -4.4061 - val_acc: 0.6790\n",
      "Epoch 58/200\n",
      "352/352 [==============================] - 0s 308us/step - loss: -4.4212 - acc: 0.6790 - val_loss: -4.4450 - val_acc: 0.6790\n",
      "Epoch 59/200\n",
      "352/352 [==============================] - 0s 329us/step - loss: -4.4598 - acc: 0.6790 - val_loss: -4.4794 - val_acc: 0.6790\n",
      "Epoch 60/200\n",
      "352/352 [==============================] - 0s 330us/step - loss: -4.4982 - acc: 0.6790 - val_loss: -4.5189 - val_acc: 0.6790\n",
      "Epoch 61/200\n",
      "352/352 [==============================] - 0s 343us/step - loss: -4.5357 - acc: 0.6790 - val_loss: -4.5580 - val_acc: 0.6790\n",
      "Epoch 62/200\n",
      "352/352 [==============================] - 0s 363us/step - loss: -4.5751 - acc: 0.6790 - val_loss: -4.5973 - val_acc: 0.6790\n",
      "Epoch 63/200\n",
      "352/352 [==============================] - 0s 301us/step - loss: -4.6127 - acc: 0.6790 - val_loss: -4.6319 - val_acc: 0.6790\n",
      "Epoch 64/200\n",
      "352/352 [==============================] - 0s 324us/step - loss: -4.6495 - acc: 0.6790 - val_loss: -4.6694 - val_acc: 0.6790\n",
      "Epoch 65/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -4.6798 - acc: 0.6790 - val_loss: -4.7011 - val_acc: 0.6790\n",
      "Epoch 66/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -4.7124 - acc: 0.6790 - val_loss: -4.7275 - val_acc: 0.6790\n",
      "Epoch 67/200\n",
      "352/352 [==============================] - 0s 291us/step - loss: -4.7384 - acc: 0.6790 - val_loss: -4.7490 - val_acc: 0.6790\n",
      "Epoch 68/200\n",
      "352/352 [==============================] - 0s 342us/step - loss: -4.7666 - acc: 0.6790 - val_loss: -4.7817 - val_acc: 0.6790\n",
      "Epoch 69/200\n",
      "352/352 [==============================] - 0s 304us/step - loss: -4.7897 - acc: 0.6790 - val_loss: -4.8044 - val_acc: 0.6790\n",
      "Epoch 70/200\n",
      "352/352 [==============================] - 0s 286us/step - loss: -4.8143 - acc: 0.6790 - val_loss: -4.8269 - val_acc: 0.6790\n",
      "Epoch 71/200\n",
      "352/352 [==============================] - 0s 300us/step - loss: -4.8349 - acc: 0.6790 - val_loss: -4.8492 - val_acc: 0.6790\n",
      "Epoch 72/200\n",
      "352/352 [==============================] - 0s 285us/step - loss: -4.8603 - acc: 0.6790 - val_loss: -4.8686 - val_acc: 0.6790\n",
      "Epoch 73/200\n",
      "352/352 [==============================] - 0s 291us/step - loss: -4.8760 - acc: 0.6790 - val_loss: -4.8900 - val_acc: 0.6790\n",
      "Epoch 74/200\n",
      "352/352 [==============================] - 0s 301us/step - loss: -4.8970 - acc: 0.6790 - val_loss: -4.9018 - val_acc: 0.6790\n",
      "Epoch 75/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -4.9100 - acc: 0.6790 - val_loss: -4.9169 - val_acc: 0.6790\n",
      "Epoch 76/200\n",
      "352/352 [==============================] - 0s 279us/step - loss: -4.9247 - acc: 0.6790 - val_loss: -4.9332 - val_acc: 0.6790\n",
      "Epoch 77/200\n",
      "352/352 [==============================] - 0s 302us/step - loss: -4.9395 - acc: 0.6790 - val_loss: -4.9461 - val_acc: 0.6790\n",
      "Epoch 78/200\n",
      "352/352 [==============================] - 0s 269us/step - loss: -4.9508 - acc: 0.6790 - val_loss: -4.9554 - val_acc: 0.6790\n",
      "Epoch 79/200\n",
      "352/352 [==============================] - 0s 291us/step - loss: -4.9612 - acc: 0.6790 - val_loss: -4.9679 - val_acc: 0.6790\n",
      "Epoch 80/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -4.9701 - acc: 0.6790 - val_loss: -4.9740 - val_acc: 0.6790\n",
      "Epoch 81/200\n",
      "352/352 [==============================] - 0s 294us/step - loss: -4.9793 - acc: 0.6790 - val_loss: -4.9847 - val_acc: 0.6790\n",
      "Epoch 82/200\n",
      "352/352 [==============================] - 0s 282us/step - loss: -4.9867 - acc: 0.6790 - val_loss: -4.9892 - val_acc: 0.6790\n",
      "Epoch 83/200\n",
      "352/352 [==============================] - 0s 312us/step - loss: -4.9923 - acc: 0.6790 - val_loss: -4.9964 - val_acc: 0.6790\n",
      "Epoch 84/200\n",
      "352/352 [==============================] - 0s 320us/step - loss: -4.9985 - acc: 0.6790 - val_loss: -5.0011 - val_acc: 0.6790\n",
      "Epoch 85/200\n",
      "352/352 [==============================] - 0s 282us/step - loss: -5.0027 - acc: 0.6790 - val_loss: -5.0040 - val_acc: 0.6790\n",
      "Epoch 86/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.0056 - acc: 0.6790 - val_loss: -5.0108 - val_acc: 0.6790\n",
      "Epoch 87/200\n",
      "352/352 [==============================] - 0s 286us/step - loss: -5.0114 - acc: 0.6790 - val_loss: -5.0156 - val_acc: 0.6790\n",
      "Epoch 88/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -5.0163 - acc: 0.6790 - val_loss: -5.0174 - val_acc: 0.6790\n",
      "Epoch 89/200\n",
      "352/352 [==============================] - 0s 282us/step - loss: -5.0180 - acc: 0.6790 - val_loss: -5.0196 - val_acc: 0.6790\n",
      "Epoch 90/200\n",
      "352/352 [==============================] - 0s 277us/step - loss: -5.0225 - acc: 0.6790 - val_loss: -5.0257 - val_acc: 0.6790\n",
      "Epoch 91/200\n",
      "352/352 [==============================] - 0s 302us/step - loss: -5.0264 - acc: 0.6790 - val_loss: -5.0284 - val_acc: 0.6790\n",
      "Epoch 92/200\n",
      "352/352 [==============================] - 0s 300us/step - loss: -5.0292 - acc: 0.6790 - val_loss: -5.0303 - val_acc: 0.6790\n",
      "Epoch 93/200\n",
      "352/352 [==============================] - 0s 380us/step - loss: -5.0311 - acc: 0.6790 - val_loss: -5.0331 - val_acc: 0.6790\n",
      "Epoch 94/200\n",
      "352/352 [==============================] - 0s 296us/step - loss: -5.0339 - acc: 0.6790 - val_loss: -5.0374 - val_acc: 0.6790\n",
      "Epoch 95/200\n",
      "352/352 [==============================] - 0s 298us/step - loss: -5.0381 - acc: 0.6790 - val_loss: -5.0389 - val_acc: 0.6790\n",
      "Epoch 96/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.0404 - acc: 0.6790 - val_loss: -5.0411 - val_acc: 0.6790\n",
      "Epoch 97/200\n",
      "352/352 [==============================] - 0s 274us/step - loss: -5.0439 - acc: 0.6790 - val_loss: -5.0448 - val_acc: 0.6790\n",
      "Epoch 98/200\n",
      "352/352 [==============================] - 0s 289us/step - loss: -5.0476 - acc: 0.6790 - val_loss: -5.0491 - val_acc: 0.6790\n",
      "Epoch 99/200\n",
      "352/352 [==============================] - 0s 325us/step - loss: -5.0499 - acc: 0.6790 - val_loss: -5.0507 - val_acc: 0.6790\n",
      "Epoch 100/200\n",
      "352/352 [==============================] - 0s 406us/step - loss: -5.0514 - acc: 0.6790 - val_loss: -5.0525 - val_acc: 0.6790\n",
      "Epoch 101/200\n",
      "352/352 [==============================] - 0s 325us/step - loss: -5.0531 - acc: 0.6790 - val_loss: -5.0551 - val_acc: 0.6790\n",
      "Epoch 102/200\n",
      "352/352 [==============================] - 0s 303us/step - loss: -5.0557 - acc: 0.6790 - val_loss: -5.0568 - val_acc: 0.6790\n",
      "Epoch 103/200\n",
      "352/352 [==============================] - 0s 342us/step - loss: -5.0574 - acc: 0.6790 - val_loss: -5.0586 - val_acc: 0.6790\n",
      "Epoch 104/200\n",
      "352/352 [==============================] - 0s 303us/step - loss: -5.0593 - acc: 0.6790 - val_loss: -5.0600 - val_acc: 0.6790\n",
      "Epoch 105/200\n",
      "352/352 [==============================] - 0s 307us/step - loss: -5.0608 - acc: 0.6790 - val_loss: -5.0616 - val_acc: 0.6790\n",
      "Epoch 106/200\n",
      "352/352 [==============================] - 0s 280us/step - loss: -5.0624 - acc: 0.6790 - val_loss: -5.0653 - val_acc: 0.6790\n",
      "Epoch 107/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.0659 - acc: 0.6790 - val_loss: -5.0666 - val_acc: 0.6790\n",
      "Epoch 108/200\n",
      "352/352 [==============================] - 0s 285us/step - loss: -5.0672 - acc: 0.6790 - val_loss: -5.0681 - val_acc: 0.6790\n",
      "Epoch 109/200\n",
      "352/352 [==============================] - 0s 291us/step - loss: -5.0688 - acc: 0.6790 - val_loss: -5.0697 - val_acc: 0.6790\n",
      "Epoch 110/200\n",
      "352/352 [==============================] - 0s 321us/step - loss: -5.0703 - acc: 0.6790 - val_loss: -5.0712 - val_acc: 0.6790\n",
      "Epoch 111/200\n",
      "352/352 [==============================] - 0s 271us/step - loss: -5.0717 - acc: 0.6790 - val_loss: -5.0727 - val_acc: 0.6790\n",
      "Epoch 112/200\n",
      "352/352 [==============================] - 0s 304us/step - loss: -5.0731 - acc: 0.6790 - val_loss: -5.0745 - val_acc: 0.6790\n",
      "Epoch 113/200\n",
      "352/352 [==============================] - 0s 297us/step - loss: -5.0752 - acc: 0.6790 - val_loss: -5.0759 - val_acc: 0.6790\n",
      "Epoch 114/200\n",
      "352/352 [==============================] - 0s 301us/step - loss: -5.0765 - acc: 0.6790 - val_loss: -5.0778 - val_acc: 0.6790\n",
      "Epoch 115/200\n",
      "352/352 [==============================] - 0s 310us/step - loss: -5.0780 - acc: 0.6790 - val_loss: -5.0792 - val_acc: 0.6790\n",
      "Epoch 116/200\n",
      "352/352 [==============================] - 0s 296us/step - loss: -5.0800 - acc: 0.6790 - val_loss: -5.0806 - val_acc: 0.6790\n",
      "Epoch 117/200\n",
      "352/352 [==============================] - 0s 280us/step - loss: -5.0815 - acc: 0.6790 - val_loss: -5.0819 - val_acc: 0.6790\n",
      "Epoch 118/200\n",
      "352/352 [==============================] - 0s 331us/step - loss: -5.0830 - acc: 0.6790 - val_loss: -5.0838 - val_acc: 0.6790\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 0s 295us/step - loss: -5.0838 - acc: 0.6790 - val_loss: -5.0855 - val_acc: 0.6790\n",
      "Epoch 120/200\n",
      "352/352 [==============================] - 0s 278us/step - loss: -5.0857 - acc: 0.6790 - val_loss: -5.0869 - val_acc: 0.6790\n",
      "Epoch 121/200\n",
      "352/352 [==============================] - ETA: 0s - loss: -5.2767 - acc: 0.66 - 0s 282us/step - loss: -5.0873 - acc: 0.6790 - val_loss: -5.0882 - val_acc: 0.6790\n",
      "Epoch 122/200\n",
      "352/352 [==============================] - 0s 271us/step - loss: -5.0890 - acc: 0.6790 - val_loss: -5.0901 - val_acc: 0.6790\n",
      "Epoch 123/200\n",
      "352/352 [==============================] - 0s 274us/step - loss: -5.0903 - acc: 0.6790 - val_loss: -5.0916 - val_acc: 0.6790\n",
      "Epoch 124/200\n",
      "352/352 [==============================] - 0s 308us/step - loss: -5.0926 - acc: 0.6790 - val_loss: -5.0928 - val_acc: 0.6790\n",
      "Epoch 125/200\n",
      "352/352 [==============================] - 0s 327us/step - loss: -5.0931 - acc: 0.6790 - val_loss: -5.0949 - val_acc: 0.6790\n",
      "Epoch 126/200\n",
      "352/352 [==============================] - 0s 292us/step - loss: -5.0951 - acc: 0.6790 - val_loss: -5.0965 - val_acc: 0.6790\n",
      "Epoch 127/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.0967 - acc: 0.6790 - val_loss: -5.0969 - val_acc: 0.6790\n",
      "Epoch 128/200\n",
      "352/352 [==============================] - 0s 281us/step - loss: -5.0973 - acc: 0.6790 - val_loss: -5.1000 - val_acc: 0.6790\n",
      "Epoch 129/200\n",
      "352/352 [==============================] - 0s 309us/step - loss: -5.1001 - acc: 0.6790 - val_loss: -5.1019 - val_acc: 0.6790\n",
      "Epoch 130/200\n",
      "352/352 [==============================] - 0s 416us/step - loss: -5.1019 - acc: 0.6790 - val_loss: -5.1027 - val_acc: 0.6790\n",
      "Epoch 131/200\n",
      "352/352 [==============================] - 0s 316us/step - loss: -5.1027 - acc: 0.6790 - val_loss: -5.1035 - val_acc: 0.6790\n",
      "Epoch 132/200\n",
      "352/352 [==============================] - 0s 298us/step - loss: -5.1037 - acc: 0.6790 - val_loss: -5.1043 - val_acc: 0.6790\n",
      "Epoch 133/200\n",
      "352/352 [==============================] - 0s 298us/step - loss: -5.1048 - acc: 0.6790 - val_loss: -5.1048 - val_acc: 0.6790\n",
      "Epoch 134/200\n",
      "352/352 [==============================] - 0s 316us/step - loss: -5.1051 - acc: 0.6790 - val_loss: -5.1077 - val_acc: 0.6790\n",
      "Epoch 135/200\n",
      "352/352 [==============================] - 0s 275us/step - loss: -5.1080 - acc: 0.6790 - val_loss: -5.1080 - val_acc: 0.6790\n",
      "Epoch 136/200\n",
      "352/352 [==============================] - 0s 344us/step - loss: -5.1084 - acc: 0.6790 - val_loss: -5.1092 - val_acc: 0.6790\n",
      "Epoch 137/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.1092 - acc: 0.6790 - val_loss: -5.1097 - val_acc: 0.6790\n",
      "Epoch 138/200\n",
      "352/352 [==============================] - 0s 332us/step - loss: -5.1097 - acc: 0.6790 - val_loss: -5.1097 - val_acc: 0.6790\n",
      "Epoch 139/200\n",
      "352/352 [==============================] - 0s 321us/step - loss: -5.1102 - acc: 0.6790 - val_loss: -5.1113 - val_acc: 0.6790\n",
      "Epoch 140/200\n",
      "352/352 [==============================] - 0s 343us/step - loss: -5.1113 - acc: 0.6790 - val_loss: -5.1113 - val_acc: 0.6790\n",
      "Epoch 141/200\n",
      "352/352 [==============================] - 0s 395us/step - loss: -5.1120 - acc: 0.6790 - val_loss: -5.1120 - val_acc: 0.6790\n",
      "Epoch 142/200\n",
      "352/352 [==============================] - 0s 450us/step - loss: -5.1120 - acc: 0.6790 - val_loss: -5.1120 - val_acc: 0.6790\n",
      "Epoch 143/200\n",
      "352/352 [==============================] - 0s 306us/step - loss: -5.1120 - acc: 0.6790 - val_loss: -5.1128 - val_acc: 0.6790\n",
      "Epoch 144/200\n",
      "352/352 [==============================] - 0s 294us/step - loss: -5.1128 - acc: 0.6790 - val_loss: -5.1147 - val_acc: 0.6790\n",
      "Epoch 145/200\n",
      "352/352 [==============================] - 0s 309us/step - loss: -5.1147 - acc: 0.6790 - val_loss: -5.1147 - val_acc: 0.6790\n",
      "Epoch 146/200\n",
      "352/352 [==============================] - 0s 279us/step - loss: -5.1147 - acc: 0.6790 - val_loss: -5.1159 - val_acc: 0.6790\n",
      "Epoch 147/200\n",
      "352/352 [==============================] - 0s 287us/step - loss: -5.1159 - acc: 0.6790 - val_loss: -5.1159 - val_acc: 0.6790\n",
      "Epoch 148/200\n",
      "352/352 [==============================] - 0s 305us/step - loss: -5.1159 - acc: 0.6790 - val_loss: -5.1159 - val_acc: 0.6790\n",
      "Epoch 149/200\n",
      "352/352 [==============================] - 0s 348us/step - loss: -5.1159 - acc: 0.6790 - val_loss: -5.1159 - val_acc: 0.6790\n",
      "Epoch 150/200\n",
      "352/352 [==============================] - 0s 319us/step - loss: -5.1159 - acc: 0.6790 - val_loss: -5.1159 - val_acc: 0.6790\n",
      "Epoch 151/200\n",
      "352/352 [==============================] - 0s 299us/step - loss: -5.1159 - acc: 0.6790 - val_loss: -5.1159 - val_acc: 0.6790\n",
      "Epoch 152/200\n",
      "352/352 [==============================] - 0s 301us/step - loss: -5.1159 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 153/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 154/200\n",
      "352/352 [==============================] - 0s 349us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 155/200\n",
      "352/352 [==============================] - 0s 364us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 156/200\n",
      "352/352 [==============================] - 0s 372us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 157/200\n",
      "352/352 [==============================] - 0s 296us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 158/200\n",
      "352/352 [==============================] - 0s 281us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 159/200\n",
      "352/352 [==============================] - 0s 294us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 160/200\n",
      "352/352 [==============================] - 0s 284us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 161/200\n",
      "352/352 [==============================] - 0s 340us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 162/200\n",
      "352/352 [==============================] - 0s 327us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 163/200\n",
      "352/352 [==============================] - 0s 309us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 164/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 165/200\n",
      "352/352 [==============================] - 0s 287us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 166/200\n",
      "352/352 [==============================] - 0s 282us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 167/200\n",
      "352/352 [==============================] - 0s 300us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 168/200\n",
      "352/352 [==============================] - 0s 289us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 169/200\n",
      "352/352 [==============================] - 0s 305us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 170/200\n",
      "352/352 [==============================] - 0s 267us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 171/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 172/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 173/200\n",
      "352/352 [==============================] - 0s 284us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 174/200\n",
      "352/352 [==============================] - 0s 286us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 175/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 176/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 177/200\n",
      "352/352 [==============================] - 0s 292us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/200\n",
      "352/352 [==============================] - 0s 308us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 179/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 180/200\n",
      "352/352 [==============================] - 0s 278us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 181/200\n",
      "352/352 [==============================] - 0s 300us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 182/200\n",
      "352/352 [==============================] - 0s 276us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 183/200\n",
      "352/352 [==============================] - 0s 285us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 184/200\n",
      "352/352 [==============================] - 0s 304us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 185/200\n",
      "352/352 [==============================] - 0s 284us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 186/200\n",
      "352/352 [==============================] - 0s 278us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 187/200\n",
      "352/352 [==============================] - 0s 287us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 188/200\n",
      "352/352 [==============================] - 0s 300us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 189/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 190/200\n",
      "352/352 [==============================] - 0s 242us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 191/200\n",
      "352/352 [==============================] - 0s 250us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 192/200\n",
      "352/352 [==============================] - 0s 283us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 193/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 194/200\n",
      "352/352 [==============================] - 0s 305us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 195/200\n",
      "352/352 [==============================] - 0s 291us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 196/200\n",
      "352/352 [==============================] - 0s 291us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 197/200\n",
      "352/352 [==============================] - 0s 284us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 198/200\n",
      "352/352 [==============================] - ETA: 0s - loss: -5.2311 - acc: 0.67 - 0s 271us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 199/200\n",
      "352/352 [==============================] - 0s 284us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "Epoch 200/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.1179 - acc: 0.6790 - val_loss: -5.1179 - val_acc: 0.6790\n",
      "88/88 [==============================] - 0s 165us/step\n",
      "352/352 [==============================] - 0s 70us/step\n",
      "Train on 352 samples, validate on 352 samples\n",
      "Epoch 1/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 2/200\n",
      "352/352 [==============================] - 0s 303us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 3/200\n",
      "352/352 [==============================] - 0s 294us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 4/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 5/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 6/200\n",
      "352/352 [==============================] - 0s 292us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 7/200\n",
      "352/352 [==============================] - 0s 283us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 8/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 9/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 10/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 11/200\n",
      "352/352 [==============================] - 0s 281us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 12/200\n",
      "352/352 [==============================] - 0s 286us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 13/200\n",
      "352/352 [==============================] - 0s 279us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 14/200\n",
      "352/352 [==============================] - 0s 286us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 15/200\n",
      "352/352 [==============================] - 0s 271us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 16/200\n",
      "352/352 [==============================] - 0s 310us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 17/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 18/200\n",
      "352/352 [==============================] - 0s 289us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 19/200\n",
      "352/352 [==============================] - 0s 285us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 20/200\n",
      "352/352 [==============================] - 0s 296us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 21/200\n",
      "352/352 [==============================] - 0s 296us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 22/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 23/200\n",
      "352/352 [==============================] - 0s 286us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 24/200\n",
      "352/352 [==============================] - 0s 301us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 25/200\n",
      "352/352 [==============================] - 0s 280us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 26/200\n",
      "352/352 [==============================] - 0s 302us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 27/200\n",
      "352/352 [==============================] - 0s 282us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 28/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 29/200\n",
      "352/352 [==============================] - 0s 285us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 30/200\n",
      "352/352 [==============================] - 0s 311us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 31/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 32/200\n",
      "352/352 [==============================] - 0s 319us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 33/200\n",
      "352/352 [==============================] - 0s 416us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 34/200\n",
      "352/352 [==============================] - 0s 411us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 35/200\n",
      "352/352 [==============================] - 0s 301us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200\n",
      "352/352 [==============================] - 0s 319us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 37/200\n",
      "352/352 [==============================] - 0s 306us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 38/200\n",
      "352/352 [==============================] - 0s 317us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 39/200\n",
      "352/352 [==============================] - 0s 302us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 40/200\n",
      "352/352 [==============================] - 0s 281us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 41/200\n",
      "352/352 [==============================] - 0s 280us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 42/200\n",
      "352/352 [==============================] - 0s 276us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 43/200\n",
      "352/352 [==============================] - 0s 310us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 44/200\n",
      "352/352 [==============================] - 0s 282us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 45/200\n",
      "352/352 [==============================] - 0s 284us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 46/200\n",
      "352/352 [==============================] - 0s 281us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 47/200\n",
      "352/352 [==============================] - 0s 278us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 48/200\n",
      "352/352 [==============================] - 0s 282us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 49/200\n",
      "352/352 [==============================] - 0s 317us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 50/200\n",
      "352/352 [==============================] - 0s 282us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 51/200\n",
      "352/352 [==============================] - 0s 272us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 52/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 53/200\n",
      "352/352 [==============================] - 0s 320us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 54/200\n",
      "352/352 [==============================] - 0s 301us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 55/200\n",
      "352/352 [==============================] - 0s 284us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 56/200\n",
      "352/352 [==============================] - 0s 285us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 57/200\n",
      "352/352 [==============================] - ETA: 0s - loss: -5.0318 - acc: 0.68 - 0s 274us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 58/200\n",
      "352/352 [==============================] - 0s 297us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 59/200\n",
      "352/352 [==============================] - 0s 283us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 60/200\n",
      "352/352 [==============================] - 0s 280us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 61/200\n",
      "352/352 [==============================] - 0s 292us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 62/200\n",
      "352/352 [==============================] - 0s 291us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 63/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 64/200\n",
      "352/352 [==============================] - 0s 315us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 65/200\n",
      "352/352 [==============================] - 0s 276us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 66/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 67/200\n",
      "352/352 [==============================] - 0s 292us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 68/200\n",
      "352/352 [==============================] - 0s 296us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 69/200\n",
      "352/352 [==============================] - 0s 287us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 70/200\n",
      "352/352 [==============================] - 0s 274us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 71/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 72/200\n",
      "352/352 [==============================] - 0s 321us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 73/200\n",
      "352/352 [==============================] - 0s 296us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 74/200\n",
      "352/352 [==============================] - 0s 292us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 75/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 76/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 77/200\n",
      "352/352 [==============================] - 0s 285us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 78/200\n",
      "352/352 [==============================] - 0s 291us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 79/200\n",
      "352/352 [==============================] - 0s 280us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 80/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 81/200\n",
      "352/352 [==============================] - 0s 316us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 82/200\n",
      "352/352 [==============================] - 0s 300us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 83/200\n",
      "352/352 [==============================] - 0s 312us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 84/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 85/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 86/200\n",
      "352/352 [==============================] - 0s 289us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 87/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 88/200\n",
      "352/352 [==============================] - 0s 311us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 89/200\n",
      "352/352 [==============================] - 0s 346us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 90/200\n",
      "352/352 [==============================] - 0s 277us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 91/200\n",
      "352/352 [==============================] - 0s 302us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 92/200\n",
      "352/352 [==============================] - 0s 300us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 93/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 94/200\n",
      "352/352 [==============================] - 0s 309us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 0s 290us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 96/200\n",
      "352/352 [==============================] - 0s 287us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 97/200\n",
      "352/352 [==============================] - 0s 287us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 98/200\n",
      "352/352 [==============================] - 0s 284us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 99/200\n",
      "352/352 [==============================] - 0s 269us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 100/200\n",
      "352/352 [==============================] - 0s 294us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 101/200\n",
      "352/352 [==============================] - 0s 283us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 102/200\n",
      "352/352 [==============================] - 0s 298us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 103/200\n",
      "352/352 [==============================] - 0s 289us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 104/200\n",
      "352/352 [==============================] - 0s 285us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 105/200\n",
      "352/352 [==============================] - 0s 279us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 106/200\n",
      "352/352 [==============================] - 0s 282us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 107/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 108/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 109/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 110/200\n",
      "352/352 [==============================] - 0s 306us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 111/200\n",
      "352/352 [==============================] - 0s 282us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 112/200\n",
      "352/352 [==============================] - 0s 314us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 113/200\n",
      "352/352 [==============================] - 0s 300us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 114/200\n",
      "352/352 [==============================] - 0s 289us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 115/200\n",
      "352/352 [==============================] - 0s 291us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 116/200\n",
      "352/352 [==============================] - 0s 289us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 117/200\n",
      "352/352 [==============================] - 0s 284us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 118/200\n",
      "352/352 [==============================] - 0s 299us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 119/200\n",
      "352/352 [==============================] - 0s 383us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 120/200\n",
      "352/352 [==============================] - 0s 549us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 121/200\n",
      "352/352 [==============================] - 0s 545us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 122/200\n",
      "352/352 [==============================] - 0s 553us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 123/200\n",
      "352/352 [==============================] - 0s 414us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 124/200\n",
      "352/352 [==============================] - 0s 399us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 125/200\n",
      "352/352 [==============================] - 0s 393us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 126/200\n",
      "352/352 [==============================] - 0s 372us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 127/200\n",
      "352/352 [==============================] - 0s 418us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 128/200\n",
      "352/352 [==============================] - 0s 411us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 129/200\n",
      "352/352 [==============================] - 0s 406us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 130/200\n",
      "352/352 [==============================] - 0s 380us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 131/200\n",
      "352/352 [==============================] - 0s 398us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 132/200\n",
      "352/352 [==============================] - 0s 395us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 133/200\n",
      "352/352 [==============================] - 0s 381us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 134/200\n",
      "352/352 [==============================] - 0s 274us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 135/200\n",
      "352/352 [==============================] - 0s 307us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 136/200\n",
      "352/352 [==============================] - 0s 400us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 137/200\n",
      "352/352 [==============================] - 0s 306us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 138/200\n",
      "352/352 [==============================] - 0s 307us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 139/200\n",
      "352/352 [==============================] - 0s 299us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 140/200\n",
      "352/352 [==============================] - 0s 379us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 141/200\n",
      "352/352 [==============================] - 0s 319us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 142/200\n",
      "352/352 [==============================] - 0s 471us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 143/200\n",
      "352/352 [==============================] - 0s 367us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 144/200\n",
      "352/352 [==============================] - 0s 374us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 145/200\n",
      "352/352 [==============================] - 0s 360us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 146/200\n",
      "352/352 [==============================] - 0s 287us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 147/200\n",
      "352/352 [==============================] - 0s 294us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 148/200\n",
      "352/352 [==============================] - 0s 282us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 149/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 150/200\n",
      "352/352 [==============================] - 0s 313us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 151/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 152/200\n",
      "352/352 [==============================] - 0s 303us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 153/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 0s 297us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 155/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 156/200\n",
      "352/352 [==============================] - 0s 289us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 157/200\n",
      "352/352 [==============================] - 0s 280us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 158/200\n",
      "352/352 [==============================] - 0s 278us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 159/200\n",
      "352/352 [==============================] - 0s 287us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 160/200\n",
      "352/352 [==============================] - 0s 280us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 161/200\n",
      "352/352 [==============================] - 0s 297us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 162/200\n",
      "352/352 [==============================] - 0s 279us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 163/200\n",
      "352/352 [==============================] - 0s 283us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 164/200\n",
      "352/352 [==============================] - 0s 297us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 165/200\n",
      "352/352 [==============================] - 0s 291us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 166/200\n",
      "352/352 [==============================] - 0s 271us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 167/200\n",
      "352/352 [==============================] - 0s 275us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 168/200\n",
      "352/352 [==============================] - 0s 286us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 169/200\n",
      "352/352 [==============================] - 0s 270us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 170/200\n",
      "352/352 [==============================] - 0s 291us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 171/200\n",
      "352/352 [==============================] - 0s 298us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 172/200\n",
      "352/352 [==============================] - 0s 285us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 173/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 174/200\n",
      "352/352 [==============================] - 0s 296us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 175/200\n",
      "352/352 [==============================] - 0s 285us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 176/200\n",
      "352/352 [==============================] - 0s 291us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 177/200\n",
      "352/352 [==============================] - 0s 281us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 178/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 179/200\n",
      "352/352 [==============================] - 0s 296us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 180/200\n",
      "352/352 [==============================] - 0s 357us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 181/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 182/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 183/200\n",
      "352/352 [==============================] - 0s 303us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 184/200\n",
      "352/352 [==============================] - 0s 282us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 185/200\n",
      "352/352 [==============================] - 0s 292us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 186/200\n",
      "352/352 [==============================] - 0s 281us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 187/200\n",
      "352/352 [==============================] - 0s 271us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 188/200\n",
      "352/352 [==============================] - 0s 287us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 189/200\n",
      "352/352 [==============================] - 0s 298us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 190/200\n",
      "352/352 [==============================] - 0s 363us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 191/200\n",
      "352/352 [==============================] - 0s 367us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 192/200\n",
      "352/352 [==============================] - 0s 329us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 193/200\n",
      "352/352 [==============================] - 0s 320us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 194/200\n",
      "352/352 [==============================] - 0s 349us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 195/200\n",
      "352/352 [==============================] - 0s 309us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 196/200\n",
      "352/352 [==============================] - 0s 341us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 197/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 198/200\n",
      "352/352 [==============================] - 0s 303us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 199/200\n",
      "352/352 [==============================] - 0s 284us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "Epoch 200/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.0273 - acc: 0.6847 - val_loss: -5.0273 - val_acc: 0.6847\n",
      "88/88 [==============================] - 0s 101us/step\n",
      "352/352 [==============================] - 0s 65us/step\n",
      "Train on 352 samples, validate on 352 samples\n",
      "Epoch 1/200\n",
      "352/352 [==============================] - 0s 304us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 2/200\n",
      "352/352 [==============================] - 0s 303us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 3/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 4/200\n",
      "352/352 [==============================] - 0s 326us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 5/200\n",
      "352/352 [==============================] - 0s 303us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 6/200\n",
      "352/352 [==============================] - 0s 294us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 7/200\n",
      "352/352 [==============================] - 0s 316us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 8/200\n",
      "352/352 [==============================] - 0s 298us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 9/200\n",
      "352/352 [==============================] - 0s 294us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 10/200\n",
      "352/352 [==============================] - 0s 301us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 11/200\n",
      "352/352 [==============================] - 0s 300us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 0s 310us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 13/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 14/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 15/200\n",
      "352/352 [==============================] - 0s 284us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 16/200\n",
      "352/352 [==============================] - 0s 381us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 17/200\n",
      "352/352 [==============================] - 0s 360us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 18/200\n",
      "352/352 [==============================] - 0s 386us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 19/200\n",
      "352/352 [==============================] - 0s 312us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 20/200\n",
      "352/352 [==============================] - 0s 289us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 21/200\n",
      "352/352 [==============================] - 0s 282us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 22/200\n",
      "352/352 [==============================] - 0s 306us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 23/200\n",
      "352/352 [==============================] - 0s 304us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 24/200\n",
      "352/352 [==============================] - 0s 283us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 25/200\n",
      "352/352 [==============================] - 0s 312us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 26/200\n",
      "352/352 [==============================] - 0s 310us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 27/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 28/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 29/200\n",
      "352/352 [==============================] - 0s 278us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 30/200\n",
      "352/352 [==============================] - 0s 294us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 31/200\n",
      "352/352 [==============================] - 0s 291us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 32/200\n",
      "352/352 [==============================] - 0s 292us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 33/200\n",
      "352/352 [==============================] - 0s 285us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 34/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 35/200\n",
      "352/352 [==============================] - 0s 283us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 36/200\n",
      "352/352 [==============================] - 0s 297us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 37/200\n",
      "352/352 [==============================] - 0s 284us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 38/200\n",
      "352/352 [==============================] - 0s 277us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 39/200\n",
      "352/352 [==============================] - 0s 344us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 40/200\n",
      "352/352 [==============================] - 0s 314us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 41/200\n",
      "352/352 [==============================] - 0s 310us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 42/200\n",
      "352/352 [==============================] - 0s 279us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 43/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 44/200\n",
      "352/352 [==============================] - 0s 294us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 45/200\n",
      "352/352 [==============================] - 0s 296us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 46/200\n",
      "352/352 [==============================] - 0s 289us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 47/200\n",
      "352/352 [==============================] - 0s 302us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 48/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 49/200\n",
      "352/352 [==============================] - 0s 294us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 50/200\n",
      "352/352 [==============================] - 0s 287us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 51/200\n",
      "352/352 [==============================] - 0s 304us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 52/200\n",
      "352/352 [==============================] - 0s 289us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 53/200\n",
      "352/352 [==============================] - 0s 352us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 54/200\n",
      "352/352 [==============================] - 0s 319us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 55/200\n",
      "352/352 [==============================] - 0s 298us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 56/200\n",
      "352/352 [==============================] - 0s 296us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 57/200\n",
      "352/352 [==============================] - 0s 287us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 58/200\n",
      "352/352 [==============================] - 0s 301us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 59/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 60/200\n",
      "352/352 [==============================] - 0s 285us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 61/200\n",
      "352/352 [==============================] - 0s 336us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 62/200\n",
      "352/352 [==============================] - 0s 307us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 63/200\n",
      "352/352 [==============================] - 0s 286us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 64/200\n",
      "352/352 [==============================] - 0s 309us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 65/200\n",
      "352/352 [==============================] - 0s 298us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 66/200\n",
      "352/352 [==============================] - 0s 292us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 67/200\n",
      "352/352 [==============================] - 0s 289us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 68/200\n",
      "352/352 [==============================] - 0s 297us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 69/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 70/200\n",
      "352/352 [==============================] - 0s 307us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 71/200\n",
      "352/352 [==============================] - 0s 302us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 72/200\n",
      "352/352 [==============================] - 0s 309us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 73/200\n",
      "352/352 [==============================] - 0s 292us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 74/200\n",
      "352/352 [==============================] - 0s 297us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 75/200\n",
      "352/352 [==============================] - 0s 285us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 76/200\n",
      "352/352 [==============================] - 0s 283us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 77/200\n",
      "352/352 [==============================] - 0s 294us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 78/200\n",
      "352/352 [==============================] - 0s 286us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 79/200\n",
      "352/352 [==============================] - 0s 304us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 80/200\n",
      "352/352 [==============================] - 0s 277us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 81/200\n",
      "352/352 [==============================] - 0s 296us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 82/200\n",
      "352/352 [==============================] - 0s 292us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 83/200\n",
      "352/352 [==============================] - 0s 280us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 84/200\n",
      "352/352 [==============================] - 0s 275us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 85/200\n",
      "352/352 [==============================] - 0s 298us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 86/200\n",
      "352/352 [==============================] - 0s 279us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 87/200\n",
      "352/352 [==============================] - 0s 294us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 88/200\n",
      "352/352 [==============================] - 0s 298us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 89/200\n",
      "352/352 [==============================] - 0s 312us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 90/200\n",
      "352/352 [==============================] - 0s 278us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 91/200\n",
      "352/352 [==============================] - 0s 316us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 92/200\n",
      "352/352 [==============================] - 0s 277us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 93/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 94/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 95/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 96/200\n",
      "352/352 [==============================] - 0s 289us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 97/200\n",
      "352/352 [==============================] - 0s 294us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 98/200\n",
      "352/352 [==============================] - 0s 297us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 99/200\n",
      "352/352 [==============================] - 0s 352us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 100/200\n",
      "352/352 [==============================] - 0s 445us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 101/200\n",
      "352/352 [==============================] - 0s 342us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 102/200\n",
      "352/352 [==============================] - 0s 308us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 103/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 104/200\n",
      "352/352 [==============================] - 0s 296us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 105/200\n",
      "352/352 [==============================] - 0s 276us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 106/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 107/200\n",
      "352/352 [==============================] - 0s 282us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 108/200\n",
      "352/352 [==============================] - 0s 296us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 109/200\n",
      "352/352 [==============================] - 0s 308us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 110/200\n",
      "352/352 [==============================] - 0s 282us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 111/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 112/200\n",
      "352/352 [==============================] - 0s 299us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 113/200\n",
      "352/352 [==============================] - 0s 285us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 114/200\n",
      "352/352 [==============================] - 0s 289us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 115/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 116/200\n",
      "352/352 [==============================] - 0s 328us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 117/200\n",
      "352/352 [==============================] - 0s 297us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 118/200\n",
      "352/352 [==============================] - 0s 297us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 119/200\n",
      "352/352 [==============================] - 0s 289us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 120/200\n",
      "352/352 [==============================] - 0s 277us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 121/200\n",
      "352/352 [==============================] - 0s 303us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 122/200\n",
      "352/352 [==============================] - 0s 280us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 123/200\n",
      "352/352 [==============================] - 0s 305us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 124/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 125/200\n",
      "352/352 [==============================] - 0s 297us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 126/200\n",
      "352/352 [==============================] - 0s 307us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 127/200\n",
      "352/352 [==============================] - 0s 294us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 128/200\n",
      "352/352 [==============================] - 0s 306us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 129/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 0s 330us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 131/200\n",
      "352/352 [==============================] - 0s 334us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 132/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 133/200\n",
      "352/352 [==============================] - 0s 285us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 134/200\n",
      "352/352 [==============================] - 0s 289us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 135/200\n",
      "352/352 [==============================] - 0s 287us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 136/200\n",
      "352/352 [==============================] - 0s 286us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 137/200\n",
      "352/352 [==============================] - 0s 294us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 138/200\n",
      "352/352 [==============================] - 0s 286us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 139/200\n",
      "352/352 [==============================] - 0s 265us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 140/200\n",
      "352/352 [==============================] - 0s 300us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 141/200\n",
      "352/352 [==============================] - 0s 291us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 142/200\n",
      "352/352 [==============================] - 0s 277us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 143/200\n",
      "352/352 [==============================] - 0s 282us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 144/200\n",
      "352/352 [==============================] - 0s 291us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 145/200\n",
      "352/352 [==============================] - 0s 309us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 146/200\n",
      "352/352 [==============================] - 0s 265us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 147/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 148/200\n",
      "352/352 [==============================] - 0s 285us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 149/200\n",
      "352/352 [==============================] - 0s 296us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 150/200\n",
      "352/352 [==============================] - 0s 286us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 151/200\n",
      "352/352 [==============================] - 0s 281us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 152/200\n",
      "352/352 [==============================] - 0s 296us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 153/200\n",
      "352/352 [==============================] - 0s 297us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 154/200\n",
      "352/352 [==============================] - 0s 289us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 155/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 156/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 157/200\n",
      "352/352 [==============================] - 0s 275us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 158/200\n",
      "352/352 [==============================] - 0s 297us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 159/200\n",
      "352/352 [==============================] - 0s 297us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 160/200\n",
      "352/352 [==============================] - 0s 327us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 161/200\n",
      "352/352 [==============================] - 0s 363us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 162/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 163/200\n",
      "352/352 [==============================] - 0s 299us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 164/200\n",
      "352/352 [==============================] - 0s 301us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 165/200\n",
      "352/352 [==============================] - 0s 311us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 166/200\n",
      "352/352 [==============================] - 0s 297us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 167/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 168/200\n",
      "352/352 [==============================] - 0s 296us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 169/200\n",
      "352/352 [==============================] - 0s 291us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 170/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 171/200\n",
      "352/352 [==============================] - 0s 281us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 172/200\n",
      "352/352 [==============================] - 0s 286us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 173/200\n",
      "352/352 [==============================] - 0s 297us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 174/200\n",
      "352/352 [==============================] - 0s 296us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 175/200\n",
      "352/352 [==============================] - 0s 305us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 176/200\n",
      "352/352 [==============================] - 0s 288us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 177/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 178/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 179/200\n",
      "352/352 [==============================] - 0s 292us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 180/200\n",
      "352/352 [==============================] - 0s 300us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 181/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 182/200\n",
      "352/352 [==============================] - 0s 313us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 183/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 184/200\n",
      "352/352 [==============================] - 0s 309us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 185/200\n",
      "352/352 [==============================] - 0s 281us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 186/200\n",
      "352/352 [==============================] - 0s 293us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 187/200\n",
      "352/352 [==============================] - 0s 305us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 188/200\n",
      "352/352 [==============================] - 0s 307us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 0s 297us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 190/200\n",
      "352/352 [==============================] - 0s 290us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 191/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 192/200\n",
      "352/352 [==============================] - 0s 295us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 193/200\n",
      "352/352 [==============================] - 0s 282us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 194/200\n",
      "352/352 [==============================] - 0s 284us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 195/200\n",
      "352/352 [==============================] - 0s 271us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 196/200\n",
      "352/352 [==============================] - 0s 282us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 197/200\n",
      "352/352 [==============================] - 0s 310us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 198/200\n",
      "352/352 [==============================] - 0s 369us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 199/200\n",
      "352/352 [==============================] - 0s 410us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 200/200\n",
      "352/352 [==============================] - 0s 390us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "88/88 [==============================] - 0s 127us/step\n",
      "352/352 [==============================] - 0s 79us/step\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/200\n",
      "220/220 [==============================] - 0s 330us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 2/200\n",
      "220/220 [==============================] - 0s 284us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 3/200\n",
      "220/220 [==============================] - 0s 292us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 4/200\n",
      "220/220 [==============================] - 0s 271us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 5/200\n",
      "220/220 [==============================] - 0s 311us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 6/200\n",
      "220/220 [==============================] - 0s 298us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 7/200\n",
      "220/220 [==============================] - 0s 298us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 8/200\n",
      "220/220 [==============================] - 0s 293us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 9/200\n",
      "220/220 [==============================] - 0s 309us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 10/200\n",
      "220/220 [==============================] - 0s 300us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 11/200\n",
      "220/220 [==============================] - 0s 291us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 12/200\n",
      "220/220 [==============================] - 0s 323us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 13/200\n",
      "220/220 [==============================] - 0s 300us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 14/200\n",
      "220/220 [==============================] - 0s 282us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 15/200\n",
      "220/220 [==============================] - 0s 295us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 16/200\n",
      "220/220 [==============================] - 0s 321us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 17/200\n",
      "220/220 [==============================] - 0s 286us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 18/200\n",
      "220/220 [==============================] - 0s 297us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 19/200\n",
      "220/220 [==============================] - 0s 281us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 20/200\n",
      "220/220 [==============================] - 0s 286us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 21/200\n",
      "220/220 [==============================] - 0s 278us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 22/200\n",
      "220/220 [==============================] - 0s 301us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 23/200\n",
      "220/220 [==============================] - 0s 307us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 24/200\n",
      "220/220 [==============================] - 0s 298us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 25/200\n",
      "220/220 [==============================] - 0s 268us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 26/200\n",
      "220/220 [==============================] - 0s 302us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 27/200\n",
      "220/220 [==============================] - 0s 280us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 28/200\n",
      "220/220 [==============================] - 0s 294us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 29/200\n",
      "220/220 [==============================] - 0s 327us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 30/200\n",
      "220/220 [==============================] - 0s 302us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 31/200\n",
      "220/220 [==============================] - 0s 299us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 32/200\n",
      "220/220 [==============================] - 0s 307us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 33/200\n",
      "220/220 [==============================] - 0s 288us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 34/200\n",
      "220/220 [==============================] - 0s 310us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 35/200\n",
      "220/220 [==============================] - 0s 308us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 36/200\n",
      "220/220 [==============================] - 0s 316us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 37/200\n",
      "220/220 [==============================] - 0s 303us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 38/200\n",
      "220/220 [==============================] - 0s 296us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 39/200\n",
      "220/220 [==============================] - 0s 294us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 40/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 41/200\n",
      "220/220 [==============================] - 0s 313us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 42/200\n",
      "220/220 [==============================] - 0s 299us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 43/200\n",
      "220/220 [==============================] - 0s 303us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 44/200\n",
      "220/220 [==============================] - 0s 301us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 45/200\n",
      "220/220 [==============================] - 0s 308us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 46/200\n",
      "220/220 [==============================] - 0s 296us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 47/200\n",
      "220/220 [==============================] - 0s 300us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 48/200\n",
      "220/220 [==============================] - 0s 300us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 49/200\n",
      "220/220 [==============================] - 0s 289us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 50/200\n",
      "220/220 [==============================] - 0s 305us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 51/200\n",
      "220/220 [==============================] - 0s 294us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 52/200\n",
      "220/220 [==============================] - 0s 278us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 53/200\n",
      "220/220 [==============================] - 0s 299us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 54/200\n",
      "220/220 [==============================] - 0s 287us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 55/200\n",
      "220/220 [==============================] - 0s 276us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 56/200\n",
      "220/220 [==============================] - 0s 278us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 57/200\n",
      "220/220 [==============================] - 0s 290us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 58/200\n",
      "220/220 [==============================] - 0s 279us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 59/200\n",
      "220/220 [==============================] - 0s 311us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 60/200\n",
      "220/220 [==============================] - 0s 272us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 61/200\n",
      "220/220 [==============================] - 0s 295us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 62/200\n",
      "220/220 [==============================] - 0s 361us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 63/200\n",
      "220/220 [==============================] - 0s 281us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 64/200\n",
      "220/220 [==============================] - 0s 303us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 65/200\n",
      "220/220 [==============================] - 0s 313us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 66/200\n",
      "220/220 [==============================] - 0s 290us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 67/200\n",
      "220/220 [==============================] - 0s 317us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 68/200\n",
      "220/220 [==============================] - 0s 283us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 69/200\n",
      "220/220 [==============================] - 0s 301us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 70/200\n",
      "220/220 [==============================] - 0s 296us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 71/200\n",
      "220/220 [==============================] - 0s 272us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 72/200\n",
      "220/220 [==============================] - 0s 286us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 73/200\n",
      "220/220 [==============================] - 0s 320us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 74/200\n",
      "220/220 [==============================] - 0s 278us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 75/200\n",
      "220/220 [==============================] - 0s 270us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 76/200\n",
      "220/220 [==============================] - 0s 341us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 77/200\n",
      "220/220 [==============================] - 0s 293us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 78/200\n",
      "220/220 [==============================] - 0s 308us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 79/200\n",
      "220/220 [==============================] - 0s 324us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 80/200\n",
      "220/220 [==============================] - 0s 328us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 81/200\n",
      "220/220 [==============================] - 0s 315us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 82/200\n",
      "220/220 [==============================] - 0s 329us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 83/200\n",
      "220/220 [==============================] - 0s 313us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 84/200\n",
      "220/220 [==============================] - 0s 307us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 85/200\n",
      "220/220 [==============================] - 0s 327us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 86/200\n",
      "220/220 [==============================] - 0s 308us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 87/200\n",
      "220/220 [==============================] - 0s 340us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 88/200\n",
      "220/220 [==============================] - 0s 371us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 89/200\n",
      "220/220 [==============================] - 0s 398us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 90/200\n",
      "220/220 [==============================] - 0s 432us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 91/200\n",
      "220/220 [==============================] - 0s 364us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 92/200\n",
      "220/220 [==============================] - 0s 365us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 93/200\n",
      "220/220 [==============================] - 0s 358us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 94/200\n",
      "220/220 [==============================] - 0s 321us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 95/200\n",
      "220/220 [==============================] - 0s 352us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 96/200\n",
      "220/220 [==============================] - 0s 336us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 97/200\n",
      "220/220 [==============================] - 0s 335us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 98/200\n",
      "220/220 [==============================] - 0s 383us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 99/200\n",
      "220/220 [==============================] - 0s 345us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 100/200\n",
      "220/220 [==============================] - 0s 358us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 101/200\n",
      "220/220 [==============================] - 0s 384us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 102/200\n",
      "220/220 [==============================] - 0s 351us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 103/200\n",
      "220/220 [==============================] - 0s 344us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 104/200\n",
      "220/220 [==============================] - 0s 351us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 105/200\n",
      "220/220 [==============================] - 0s 343us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 106/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 378us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 107/200\n",
      "220/220 [==============================] - 0s 333us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 108/200\n",
      "220/220 [==============================] - 0s 337us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 109/200\n",
      "220/220 [==============================] - 0s 338us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 110/200\n",
      "220/220 [==============================] - 0s 319us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 111/200\n",
      "220/220 [==============================] - 0s 302us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 112/200\n",
      "220/220 [==============================] - 0s 349us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 113/200\n",
      "220/220 [==============================] - 0s 295us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 114/200\n",
      "220/220 [==============================] - 0s 362us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 115/200\n",
      "220/220 [==============================] - 0s 349us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 116/200\n",
      "220/220 [==============================] - 0s 310us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 117/200\n",
      "220/220 [==============================] - 0s 329us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 118/200\n",
      "220/220 [==============================] - 0s 348us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 119/200\n",
      "220/220 [==============================] - 0s 337us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 120/200\n",
      "220/220 [==============================] - 0s 315us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 121/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 122/200\n",
      "220/220 [==============================] - 0s 341us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 123/200\n",
      "220/220 [==============================] - 0s 307us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 124/200\n",
      "220/220 [==============================] - 0s 344us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 125/200\n",
      "220/220 [==============================] - 0s 320us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 126/200\n",
      "220/220 [==============================] - 0s 337us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 127/200\n",
      "220/220 [==============================] - 0s 331us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 128/200\n",
      "220/220 [==============================] - 0s 332us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 129/200\n",
      "220/220 [==============================] - 0s 323us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 130/200\n",
      "220/220 [==============================] - 0s 322us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 131/200\n",
      "220/220 [==============================] - 0s 319us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 132/200\n",
      "220/220 [==============================] - 0s 351us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 133/200\n",
      "220/220 [==============================] - 0s 318us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 134/200\n",
      "220/220 [==============================] - 0s 364us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 135/200\n",
      "220/220 [==============================] - 0s 379us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 136/200\n",
      "220/220 [==============================] - 0s 339us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 137/200\n",
      "220/220 [==============================] - 0s 487us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 138/200\n",
      "220/220 [==============================] - 0s 413us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 139/200\n",
      "220/220 [==============================] - 0s 482us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 140/200\n",
      "220/220 [==============================] - 0s 455us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 141/200\n",
      "220/220 [==============================] - 0s 382us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 142/200\n",
      "220/220 [==============================] - 0s 401us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 143/200\n",
      "220/220 [==============================] - 0s 390us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 144/200\n",
      "220/220 [==============================] - 0s 373us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 145/200\n",
      "220/220 [==============================] - 0s 371us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 146/200\n",
      "220/220 [==============================] - 0s 346us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 147/200\n",
      "220/220 [==============================] - 0s 309us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 148/200\n",
      "220/220 [==============================] - 0s 398us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 149/200\n",
      "220/220 [==============================] - 0s 332us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 150/200\n",
      "220/220 [==============================] - 0s 343us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 151/200\n",
      "220/220 [==============================] - 0s 313us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 152/200\n",
      "220/220 [==============================] - 0s 315us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 153/200\n",
      "220/220 [==============================] - 0s 317us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 154/200\n",
      "220/220 [==============================] - 0s 354us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 155/200\n",
      "220/220 [==============================] - 0s 331us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 156/200\n",
      "220/220 [==============================] - 0s 363us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 157/200\n",
      "220/220 [==============================] - 0s 359us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 158/200\n",
      "220/220 [==============================] - 0s 307us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 159/200\n",
      "220/220 [==============================] - 0s 322us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 160/200\n",
      "220/220 [==============================] - 0s 351us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 161/200\n",
      "220/220 [==============================] - 0s 392us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 162/200\n",
      "220/220 [==============================] - 0s 356us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 163/200\n",
      "220/220 [==============================] - 0s 356us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 164/200\n",
      "220/220 [==============================] - 0s 351us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 333us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 166/200\n",
      "220/220 [==============================] - 0s 369us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 167/200\n",
      "220/220 [==============================] - 0s 363us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 168/200\n",
      "220/220 [==============================] - 0s 326us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 169/200\n",
      "220/220 [==============================] - 0s 327us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 170/200\n",
      "220/220 [==============================] - 0s 321us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 171/200\n",
      "220/220 [==============================] - 0s 323us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 172/200\n",
      "220/220 [==============================] - 0s 331us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 173/200\n",
      "220/220 [==============================] - 0s 295us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 174/200\n",
      "220/220 [==============================] - 0s 303us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 175/200\n",
      "220/220 [==============================] - 0s 297us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 176/200\n",
      "220/220 [==============================] - 0s 279us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 177/200\n",
      "220/220 [==============================] - 0s 300us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 178/200\n",
      "220/220 [==============================] - 0s 305us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 179/200\n",
      "220/220 [==============================] - 0s 273us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 180/200\n",
      "220/220 [==============================] - 0s 287us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 181/200\n",
      "220/220 [==============================] - 0s 311us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 182/200\n",
      "220/220 [==============================] - 0s 272us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 183/200\n",
      "220/220 [==============================] - 0s 309us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 184/200\n",
      "220/220 [==============================] - 0s 298us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 185/200\n",
      "220/220 [==============================] - 0s 279us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 186/200\n",
      "220/220 [==============================] - 0s 327us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 187/200\n",
      "220/220 [==============================] - 0s 316us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 188/200\n",
      "220/220 [==============================] - 0s 294us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 189/200\n",
      "220/220 [==============================] - 0s 308us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 190/200\n",
      "220/220 [==============================] - 0s 288us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 191/200\n",
      "220/220 [==============================] - 0s 291us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 192/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 193/200\n",
      "220/220 [==============================] - 0s 292us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 194/200\n",
      "220/220 [==============================] - 0s 323us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 195/200\n",
      "220/220 [==============================] - 0s 284us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 196/200\n",
      "220/220 [==============================] - 0s 285us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 197/200\n",
      "220/220 [==============================] - 0s 305us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 198/200\n",
      "220/220 [==============================] - 0s 296us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 199/200\n",
      "220/220 [==============================] - 0s 297us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "Epoch 200/200\n",
      "220/220 [==============================] - 0s 300us/step - loss: -5.0001 - acc: 0.6864 - val_loss: -5.0001 - val_acc: 0.6864\n",
      "220/220 [==============================] - 0s 75us/step\n",
      "220/220 [==============================] - 0s 71us/step\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/200\n",
      "220/220 [==============================] - 0s 302us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 2/200\n",
      "220/220 [==============================] - 0s 267us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 3/200\n",
      "220/220 [==============================] - 0s 312us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 4/200\n",
      "220/220 [==============================] - 0s 327us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 5/200\n",
      "220/220 [==============================] - 0s 312us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 6/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 7/200\n",
      "220/220 [==============================] - 0s 345us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 8/200\n",
      "220/220 [==============================] - 0s 298us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 9/200\n",
      "220/220 [==============================] - 0s 288us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 10/200\n",
      "220/220 [==============================] - 0s 266us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 11/200\n",
      "220/220 [==============================] - 0s 277us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 12/200\n",
      "220/220 [==============================] - 0s 302us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 13/200\n",
      "220/220 [==============================] - 0s 343us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 14/200\n",
      "220/220 [==============================] - 0s 335us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 15/200\n",
      "220/220 [==============================] - 0s 336us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 16/200\n",
      "220/220 [==============================] - 0s 297us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 17/200\n",
      "220/220 [==============================] - 0s 317us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 18/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 19/200\n",
      "220/220 [==============================] - 0s 470us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 20/200\n",
      "220/220 [==============================] - 0s 349us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 21/200\n",
      "220/220 [==============================] - 0s 284us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 22/200\n",
      "220/220 [==============================] - 0s 302us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 23/200\n",
      "220/220 [==============================] - 0s 301us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 24/200\n",
      "220/220 [==============================] - 0s 280us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 25/200\n",
      "220/220 [==============================] - 0s 275us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 26/200\n",
      "220/220 [==============================] - 0s 286us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 27/200\n",
      "220/220 [==============================] - 0s 284us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 28/200\n",
      "220/220 [==============================] - 0s 301us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 29/200\n",
      "220/220 [==============================] - 0s 287us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 30/200\n",
      "220/220 [==============================] - 0s 316us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 31/200\n",
      "220/220 [==============================] - 0s 293us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 32/200\n",
      "220/220 [==============================] - 0s 334us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 33/200\n",
      "220/220 [==============================] - 0s 295us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 34/200\n",
      "220/220 [==============================] - 0s 287us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 35/200\n",
      "220/220 [==============================] - 0s 290us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 36/200\n",
      "220/220 [==============================] - 0s 302us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 37/200\n",
      "220/220 [==============================] - 0s 327us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 38/200\n",
      "220/220 [==============================] - 0s 286us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 39/200\n",
      "220/220 [==============================] - 0s 271us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 40/200\n",
      "220/220 [==============================] - 0s 303us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 41/200\n",
      "220/220 [==============================] - 0s 324us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 42/200\n",
      "220/220 [==============================] - 0s 289us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 43/200\n",
      "220/220 [==============================] - 0s 272us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 44/200\n",
      "220/220 [==============================] - 0s 288us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 45/200\n",
      "220/220 [==============================] - 0s 328us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 46/200\n",
      "220/220 [==============================] - 0s 327us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 47/200\n",
      "220/220 [==============================] - 0s 284us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 48/200\n",
      "220/220 [==============================] - 0s 303us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 49/200\n",
      "220/220 [==============================] - 0s 326us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 50/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 51/200\n",
      "220/220 [==============================] - 0s 283us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 52/200\n",
      "220/220 [==============================] - 0s 282us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 53/200\n",
      "220/220 [==============================] - 0s 287us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 54/200\n",
      "220/220 [==============================] - 0s 283us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 55/200\n",
      "220/220 [==============================] - 0s 311us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 56/200\n",
      "220/220 [==============================] - 0s 272us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 57/200\n",
      "220/220 [==============================] - 0s 286us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 58/200\n",
      "220/220 [==============================] - 0s 300us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 59/200\n",
      "220/220 [==============================] - 0s 316us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 60/200\n",
      "220/220 [==============================] - 0s 277us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 61/200\n",
      "220/220 [==============================] - 0s 342us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 62/200\n",
      "220/220 [==============================] - 0s 324us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 63/200\n",
      "220/220 [==============================] - 0s 297us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 64/200\n",
      "220/220 [==============================] - 0s 278us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 65/200\n",
      "220/220 [==============================] - 0s 281us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 66/200\n",
      "220/220 [==============================] - 0s 352us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 67/200\n",
      "220/220 [==============================] - 0s 300us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 68/200\n",
      "220/220 [==============================] - 0s 324us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 69/200\n",
      "220/220 [==============================] - 0s 281us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 70/200\n",
      "220/220 [==============================] - 0s 315us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 71/200\n",
      "220/220 [==============================] - 0s 289us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 72/200\n",
      "220/220 [==============================] - 0s 275us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 73/200\n",
      "220/220 [==============================] - 0s 348us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 74/200\n",
      "220/220 [==============================] - 0s 295us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 75/200\n",
      "220/220 [==============================] - 0s 312us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 76/200\n",
      "220/220 [==============================] - 0s 317us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 77/200\n",
      "220/220 [==============================] - 0s 306us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 78/200\n",
      "220/220 [==============================] - 0s 339us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 79/200\n",
      "220/220 [==============================] - 0s 428us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 80/200\n",
      "220/220 [==============================] - 0s 317us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 81/200\n",
      "220/220 [==============================] - 0s 335us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 313us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 83/200\n",
      "220/220 [==============================] - 0s 330us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 84/200\n",
      "220/220 [==============================] - 0s 324us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 85/200\n",
      "220/220 [==============================] - 0s 403us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 86/200\n",
      "220/220 [==============================] - 0s 407us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 87/200\n",
      "220/220 [==============================] - 0s 382us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 88/200\n",
      "220/220 [==============================] - 0s 360us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 89/200\n",
      "220/220 [==============================] - 0s 323us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 90/200\n",
      "220/220 [==============================] - 0s 269us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 91/200\n",
      "220/220 [==============================] - 0s 277us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 92/200\n",
      "220/220 [==============================] - 0s 300us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 93/200\n",
      "220/220 [==============================] - 0s 286us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 94/200\n",
      "220/220 [==============================] - 0s 292us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 95/200\n",
      "220/220 [==============================] - 0s 281us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 96/200\n",
      "220/220 [==============================] - 0s 315us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 97/200\n",
      "220/220 [==============================] - 0s 302us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 98/200\n",
      "220/220 [==============================] - 0s 308us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 99/200\n",
      "220/220 [==============================] - 0s 279us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 100/200\n",
      "220/220 [==============================] - 0s 293us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 101/200\n",
      "220/220 [==============================] - 0s 289us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 102/200\n",
      "220/220 [==============================] - 0s 310us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 103/200\n",
      "220/220 [==============================] - 0s 317us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 104/200\n",
      "220/220 [==============================] - 0s 286us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 105/200\n",
      "220/220 [==============================] - 0s 320us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 106/200\n",
      "220/220 [==============================] - 0s 326us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 107/200\n",
      "220/220 [==============================] - 0s 398us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 108/200\n",
      "220/220 [==============================] - 0s 297us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 109/200\n",
      "220/220 [==============================] - 0s 289us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 110/200\n",
      "220/220 [==============================] - 0s 292us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 111/200\n",
      "220/220 [==============================] - 0s 286us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 112/200\n",
      "220/220 [==============================] - 0s 288us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 113/200\n",
      "220/220 [==============================] - 0s 327us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 114/200\n",
      "220/220 [==============================] - 0s 320us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 115/200\n",
      "220/220 [==============================] - 0s 296us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 116/200\n",
      "220/220 [==============================] - 0s 285us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 117/200\n",
      "220/220 [==============================] - 0s 319us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 118/200\n",
      "220/220 [==============================] - 0s 320us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 119/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 120/200\n",
      "220/220 [==============================] - 0s 295us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 121/200\n",
      "220/220 [==============================] - 0s 321us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 122/200\n",
      "220/220 [==============================] - 0s 280us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 123/200\n",
      "220/220 [==============================] - 0s 299us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 124/200\n",
      "220/220 [==============================] - 0s 294us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 125/200\n",
      "220/220 [==============================] - 0s 318us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 126/200\n",
      "220/220 [==============================] - 0s 325us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 127/200\n",
      "220/220 [==============================] - 0s 297us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 128/200\n",
      "220/220 [==============================] - 0s 298us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 129/200\n",
      "220/220 [==============================] - 0s 307us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 130/200\n",
      "220/220 [==============================] - 0s 307us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 131/200\n",
      "220/220 [==============================] - 0s 333us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 132/200\n",
      "220/220 [==============================] - 0s 302us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 133/200\n",
      "220/220 [==============================] - 0s 312us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 134/200\n",
      "220/220 [==============================] - 0s 307us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 135/200\n",
      "220/220 [==============================] - 0s 333us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 136/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 137/200\n",
      "220/220 [==============================] - 0s 281us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 138/200\n",
      "220/220 [==============================] - 0s 280us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 139/200\n",
      "220/220 [==============================] - 0s 289us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 140/200\n",
      "220/220 [==============================] - 0s 312us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 141/200\n",
      "220/220 [==============================] - 0s 298us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 142/200\n",
      "220/220 [==============================] - 0s 295us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 143/200\n",
      "220/220 [==============================] - 0s 272us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 144/200\n",
      "220/220 [==============================] - 0s 302us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 145/200\n",
      "220/220 [==============================] - 0s 269us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 146/200\n",
      "220/220 [==============================] - 0s 303us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 147/200\n",
      "220/220 [==============================] - 0s 270us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 148/200\n",
      "220/220 [==============================] - 0s 284us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 149/200\n",
      "220/220 [==============================] - 0s 293us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 150/200\n",
      "220/220 [==============================] - 0s 293us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 151/200\n",
      "220/220 [==============================] - 0s 342us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 152/200\n",
      "220/220 [==============================] - 0s 274us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 153/200\n",
      "220/220 [==============================] - 0s 284us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 154/200\n",
      "220/220 [==============================] - 0s 277us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 155/200\n",
      "220/220 [==============================] - 0s 284us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 156/200\n",
      "220/220 [==============================] - 0s 296us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 157/200\n",
      "220/220 [==============================] - 0s 330us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 158/200\n",
      "220/220 [==============================] - 0s 331us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 159/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 160/200\n",
      "220/220 [==============================] - 0s 284us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 161/200\n",
      "220/220 [==============================] - 0s 294us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 162/200\n",
      "220/220 [==============================] - 0s 322us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 163/200\n",
      "220/220 [==============================] - 0s 286us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 164/200\n",
      "220/220 [==============================] - 0s 270us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 165/200\n",
      "220/220 [==============================] - 0s 349us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 166/200\n",
      "220/220 [==============================] - 0s 305us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 167/200\n",
      "220/220 [==============================] - 0s 292us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 168/200\n",
      "220/220 [==============================] - 0s 299us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 169/200\n",
      "220/220 [==============================] - ETA: 0s - loss: -1.9928 - acc: 0.87 - 0s 292us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 170/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 171/200\n",
      "220/220 [==============================] - 0s 321us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 172/200\n",
      "220/220 [==============================] - 0s 289us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 173/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 174/200\n",
      "220/220 [==============================] - 0s 346us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 175/200\n",
      "220/220 [==============================] - 0s 260us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 176/200\n",
      "220/220 [==============================] - 0s 303us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 177/200\n",
      "220/220 [==============================] - 0s 283us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 178/200\n",
      "220/220 [==============================] - 0s 267us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 179/200\n",
      "220/220 [==============================] - 0s 353us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 180/200\n",
      "220/220 [==============================] - 0s 346us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 181/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 182/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 183/200\n",
      "220/220 [==============================] - 0s 294us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 184/200\n",
      "220/220 [==============================] - 0s 324us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 185/200\n",
      "220/220 [==============================] - 0s 282us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 186/200\n",
      "220/220 [==============================] - 0s 326us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 187/200\n",
      "220/220 [==============================] - 0s 365us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 188/200\n",
      "220/220 [==============================] - 0s 313us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 189/200\n",
      "220/220 [==============================] - 0s 342us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 190/200\n",
      "220/220 [==============================] - 0s 315us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 191/200\n",
      "220/220 [==============================] - 0s 310us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 192/200\n",
      "220/220 [==============================] - 0s 311us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 193/200\n",
      "220/220 [==============================] - 0s 307us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 194/200\n",
      "220/220 [==============================] - 0s 298us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 195/200\n",
      "220/220 [==============================] - 0s 309us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 196/200\n",
      "220/220 [==============================] - 0s 292us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 197/200\n",
      "220/220 [==============================] - 0s 308us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 198/200\n",
      "220/220 [==============================] - 0s 320us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "Epoch 199/200\n",
      "220/220 [==============================] - 0s 303us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200\n",
      "220/220 [==============================] - 0s 309us/step - loss: -4.7103 - acc: 0.7045 - val_loss: -4.7103 - val_acc: 0.7045\n",
      "220/220 [==============================] - 0s 73us/step\n",
      "220/220 [==============================] - 0s 77us/step\n",
      "Train on 220 samples, validate on 220 samples\n",
      "Epoch 1/200\n",
      "220/220 [==============================] - 0s 279us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 2/200\n",
      "220/220 [==============================] - 0s 290us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 3/200\n",
      "220/220 [==============================] - 0s 311us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 4/200\n",
      "220/220 [==============================] - 0s 275us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 5/200\n",
      "220/220 [==============================] - 0s 293us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 6/200\n",
      "220/220 [==============================] - 0s 275us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 7/200\n",
      "220/220 [==============================] - 0s 317us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 8/200\n",
      "220/220 [==============================] - 0s 322us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 9/200\n",
      "220/220 [==============================] - 0s 271us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 10/200\n",
      "220/220 [==============================] - 0s 319us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 11/200\n",
      "220/220 [==============================] - 0s 283us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 12/200\n",
      "220/220 [==============================] - 0s 326us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 13/200\n",
      "220/220 [==============================] - 0s 294us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 14/200\n",
      "220/220 [==============================] - 0s 301us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 15/200\n",
      "220/220 [==============================] - 0s 297us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 16/200\n",
      "220/220 [==============================] - 0s 297us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 17/200\n",
      "220/220 [==============================] - 0s 335us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 18/200\n",
      "220/220 [==============================] - 0s 313us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 19/200\n",
      "220/220 [==============================] - 0s 311us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 20/200\n",
      "220/220 [==============================] - 0s 359us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 21/200\n",
      "220/220 [==============================] - 0s 377us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 22/200\n",
      "220/220 [==============================] - 0s 417us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 23/200\n",
      "220/220 [==============================] - 0s 423us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 24/200\n",
      "220/220 [==============================] - 0s 279us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 25/200\n",
      "220/220 [==============================] - 0s 293us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 26/200\n",
      "220/220 [==============================] - 0s 305us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 27/200\n",
      "220/220 [==============================] - 0s 321us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 28/200\n",
      "220/220 [==============================] - 0s 331us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 29/200\n",
      "220/220 [==============================] - 0s 317us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 30/200\n",
      "220/220 [==============================] - 0s 307us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 31/200\n",
      "220/220 [==============================] - 0s 373us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 32/200\n",
      "220/220 [==============================] - 0s 301us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 33/200\n",
      "220/220 [==============================] - 0s 278us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 34/200\n",
      "220/220 [==============================] - 0s 287us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 35/200\n",
      "220/220 [==============================] - 0s 307us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 36/200\n",
      "220/220 [==============================] - 0s 306us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 37/200\n",
      "220/220 [==============================] - 0s 310us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 38/200\n",
      "220/220 [==============================] - 0s 289us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 39/200\n",
      "220/220 [==============================] - 0s 302us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 40/200\n",
      "220/220 [==============================] - 0s 303us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 41/200\n",
      "220/220 [==============================] - 0s 297us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 42/200\n",
      "220/220 [==============================] - 0s 294us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 43/200\n",
      "220/220 [==============================] - 0s 278us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 44/200\n",
      "220/220 [==============================] - 0s 297us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 45/200\n",
      "220/220 [==============================] - 0s 357us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 46/200\n",
      "220/220 [==============================] - 0s 305us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 47/200\n",
      "220/220 [==============================] - 0s 303us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 48/200\n",
      "220/220 [==============================] - 0s 301us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 49/200\n",
      "220/220 [==============================] - 0s 279us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 50/200\n",
      "220/220 [==============================] - 0s 299us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 51/200\n",
      "220/220 [==============================] - 0s 288us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 52/200\n",
      "220/220 [==============================] - 0s 300us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 53/200\n",
      "220/220 [==============================] - 0s 270us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 54/200\n",
      "220/220 [==============================] - 0s 315us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 55/200\n",
      "220/220 [==============================] - 0s 286us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 56/200\n",
      "220/220 [==============================] - 0s 283us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 57/200\n",
      "220/220 [==============================] - 0s 297us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 58/200\n",
      "220/220 [==============================] - 0s 305us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 59/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 60/200\n",
      "220/220 [==============================] - 0s 289us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 61/200\n",
      "220/220 [==============================] - 0s 292us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 62/200\n",
      "220/220 [==============================] - 0s 268us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 63/200\n",
      "220/220 [==============================] - 0s 264us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 64/200\n",
      "220/220 [==============================] - 0s 281us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 65/200\n",
      "220/220 [==============================] - 0s 283us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 66/200\n",
      "220/220 [==============================] - 0s 266us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 67/200\n",
      "220/220 [==============================] - 0s 318us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 68/200\n",
      "220/220 [==============================] - 0s 277us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 69/200\n",
      "220/220 [==============================] - 0s 318us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 70/200\n",
      "220/220 [==============================] - 0s 301us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 71/200\n",
      "220/220 [==============================] - 0s 261us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 72/200\n",
      "220/220 [==============================] - 0s 303us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 73/200\n",
      "220/220 [==============================] - 0s 274us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 74/200\n",
      "220/220 [==============================] - 0s 297us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 75/200\n",
      "220/220 [==============================] - 0s 306us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 76/200\n",
      "220/220 [==============================] - 0s 342us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 77/200\n",
      "220/220 [==============================] - 0s 291us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 78/200\n",
      "220/220 [==============================] - 0s 290us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 79/200\n",
      "220/220 [==============================] - 0s 312us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 80/200\n",
      "220/220 [==============================] - 0s 265us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 81/200\n",
      "220/220 [==============================] - 0s 314us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 82/200\n",
      "220/220 [==============================] - 0s 363us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 83/200\n",
      "220/220 [==============================] - 0s 310us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 84/200\n",
      "220/220 [==============================] - 0s 318us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 85/200\n",
      "220/220 [==============================] - 0s 303us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 86/200\n",
      "220/220 [==============================] - 0s 297us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 87/200\n",
      "220/220 [==============================] - 0s 295us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 88/200\n",
      "220/220 [==============================] - 0s 289us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 89/200\n",
      "220/220 [==============================] - 0s 300us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 90/200\n",
      "220/220 [==============================] - 0s 291us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 91/200\n",
      "220/220 [==============================] - 0s 290us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 92/200\n",
      "220/220 [==============================] - 0s 300us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 93/200\n",
      "220/220 [==============================] - 0s 285us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 94/200\n",
      "220/220 [==============================] - 0s 323us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 95/200\n",
      "220/220 [==============================] - 0s 384us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 96/200\n",
      "220/220 [==============================] - 0s 301us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 97/200\n",
      "220/220 [==============================] - 0s 289us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 98/200\n",
      "220/220 [==============================] - 0s 305us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 99/200\n",
      "220/220 [==============================] - 0s 296us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 100/200\n",
      "220/220 [==============================] - 0s 296us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 101/200\n",
      "220/220 [==============================] - 0s 302us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 102/200\n",
      "220/220 [==============================] - 0s 294us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 103/200\n",
      "220/220 [==============================] - 0s 301us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 104/200\n",
      "220/220 [==============================] - 0s 356us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 105/200\n",
      "220/220 [==============================] - 0s 328us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 106/200\n",
      "220/220 [==============================] - 0s 298us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 107/200\n",
      "220/220 [==============================] - 0s 269us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 108/200\n",
      "220/220 [==============================] - 0s 311us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 109/200\n",
      "220/220 [==============================] - 0s 306us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 110/200\n",
      "220/220 [==============================] - 0s 290us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 111/200\n",
      "220/220 [==============================] - 0s 286us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 112/200\n",
      "220/220 [==============================] - 0s 312us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 113/200\n",
      "220/220 [==============================] - 0s 336us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 114/200\n",
      "220/220 [==============================] - 0s 295us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 115/200\n",
      "220/220 [==============================] - 0s 296us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 116/200\n",
      "220/220 [==============================] - 0s 270us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 291us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 118/200\n",
      "220/220 [==============================] - 0s 317us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 119/200\n",
      "220/220 [==============================] - 0s 302us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 120/200\n",
      "220/220 [==============================] - 0s 285us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 121/200\n",
      "220/220 [==============================] - 0s 291us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 122/200\n",
      "220/220 [==============================] - 0s 283us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 123/200\n",
      "220/220 [==============================] - 0s 302us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 124/200\n",
      "220/220 [==============================] - 0s 271us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 125/200\n",
      "220/220 [==============================] - 0s 301us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 126/200\n",
      "220/220 [==============================] - 0s 314us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 127/200\n",
      "220/220 [==============================] - 0s 330us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 128/200\n",
      "220/220 [==============================] - 0s 291us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 129/200\n",
      "220/220 [==============================] - 0s 285us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 130/200\n",
      "220/220 [==============================] - 0s 269us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 131/200\n",
      "220/220 [==============================] - 0s 286us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 132/200\n",
      "220/220 [==============================] - 0s 285us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 133/200\n",
      "220/220 [==============================] - 0s 289us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 134/200\n",
      "220/220 [==============================] - 0s 281us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 135/200\n",
      "220/220 [==============================] - 0s 317us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 136/200\n",
      "220/220 [==============================] - 0s 297us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 137/200\n",
      "220/220 [==============================] - 0s 287us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 138/200\n",
      "220/220 [==============================] - ETA: 0s - loss: -6.9748 - acc: 0.56 - 0s 287us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 139/200\n",
      "220/220 [==============================] - 0s 309us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 140/200\n",
      "220/220 [==============================] - 0s 336us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 141/200\n",
      "220/220 [==============================] - 0s 286us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 142/200\n",
      "220/220 [==============================] - 0s 299us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 143/200\n",
      "220/220 [==============================] - 0s 284us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 144/200\n",
      "220/220 [==============================] - 0s 309us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 145/200\n",
      "220/220 [==============================] - 0s 276us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 146/200\n",
      "220/220 [==============================] - 0s 294us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 147/200\n",
      "220/220 [==============================] - ETA: 0s - loss: -3.9856 - acc: 0.75 - 0s 318us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 148/200\n",
      "220/220 [==============================] - 0s 299us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 149/200\n",
      "220/220 [==============================] - 0s 300us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 150/200\n",
      "220/220 [==============================] - 0s 305us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 151/200\n",
      "220/220 [==============================] - 0s 286us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 152/200\n",
      "220/220 [==============================] - 0s 293us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 153/200\n",
      "220/220 [==============================] - 0s 315us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 154/200\n",
      "220/220 [==============================] - 0s 282us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 155/200\n",
      "220/220 [==============================] - 0s 297us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 156/200\n",
      "220/220 [==============================] - 0s 313us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 157/200\n",
      "220/220 [==============================] - 0s 305us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 158/200\n",
      "220/220 [==============================] - 0s 305us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 159/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 160/200\n",
      "220/220 [==============================] - 0s 306us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 161/200\n",
      "220/220 [==============================] - 0s 343us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 162/200\n",
      "220/220 [==============================] - 0s 273us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 163/200\n",
      "220/220 [==============================] - 0s 311us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 164/200\n",
      "220/220 [==============================] - 0s 301us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 165/200\n",
      "220/220 [==============================] - 0s 294us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 166/200\n",
      "220/220 [==============================] - 0s 284us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 167/200\n",
      "220/220 [==============================] - 0s 345us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 168/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 169/200\n",
      "220/220 [==============================] - 0s 300us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 170/200\n",
      "220/220 [==============================] - 0s 298us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 171/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 172/200\n",
      "220/220 [==============================] - 0s 305us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 173/200\n",
      "220/220 [==============================] - 0s 312us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 174/200\n",
      "220/220 [==============================] - 0s 288us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 175/200\n",
      "220/220 [==============================] - 0s 290us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 176/200\n",
      "220/220 [==============================] - 0s 336us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 177/200\n",
      "220/220 [==============================] - 0s 288us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 178/200\n",
      "220/220 [==============================] - 0s 282us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 179/200\n",
      "220/220 [==============================] - 0s 278us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 180/200\n",
      "220/220 [==============================] - 0s 285us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 181/200\n",
      "220/220 [==============================] - 0s 297us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 182/200\n",
      "220/220 [==============================] - 0s 302us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 183/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 184/200\n",
      "220/220 [==============================] - 0s 273us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 185/200\n",
      "220/220 [==============================] - 0s 293us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 186/200\n",
      "220/220 [==============================] - 0s 301us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 187/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 188/200\n",
      "220/220 [==============================] - 0s 353us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 189/200\n",
      "220/220 [==============================] - 0s 304us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 190/200\n",
      "220/220 [==============================] - 0s 302us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 191/200\n",
      "220/220 [==============================] - 0s 324us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 192/200\n",
      "220/220 [==============================] - 0s 269us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 193/200\n",
      "220/220 [==============================] - 0s 301us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 194/200\n",
      "220/220 [==============================] - 0s 331us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 195/200\n",
      "220/220 [==============================] - 0s 283us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 196/200\n",
      "220/220 [==============================] - 0s 309us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 197/200\n",
      "220/220 [==============================] - 0s 316us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 198/200\n",
      "220/220 [==============================] - 0s 283us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 199/200\n",
      "220/220 [==============================] - 0s 282us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "Epoch 200/200\n",
      "220/220 [==============================] - 0s 299us/step - loss: -5.1450 - acc: 0.6773 - val_loss: -5.1450 - val_acc: 0.6773\n",
      "220/220 [==============================] - 0s 73us/step\n",
      "220/220 [==============================] - 0s 83us/step\n",
      "Train on 88 samples, validate on 88 samples\n",
      "Epoch 1/200\n",
      "88/88 [==============================] - 0s 381us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 2/200\n",
      "88/88 [==============================] - 0s 362us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 3/200\n",
      "88/88 [==============================] - 0s 374us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 4/200\n",
      "88/88 [==============================] - 0s 339us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 5/200\n",
      "88/88 [==============================] - 0s 368us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 6/200\n",
      "88/88 [==============================] - 0s 357us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 7/200\n",
      "88/88 [==============================] - 0s 369us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 8/200\n",
      "88/88 [==============================] - 0s 341us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 9/200\n",
      "88/88 [==============================] - 0s 379us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 10/200\n",
      "88/88 [==============================] - 0s 447us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 11/200\n",
      "88/88 [==============================] - 0s 340us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 12/200\n",
      "88/88 [==============================] - 0s 382us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 13/200\n",
      "88/88 [==============================] - 0s 345us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 14/200\n",
      "88/88 [==============================] - 0s 372us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 15/200\n",
      "88/88 [==============================] - 0s 449us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 16/200\n",
      "88/88 [==============================] - 0s 381us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 17/200\n",
      "88/88 [==============================] - 0s 367us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 18/200\n",
      "88/88 [==============================] - 0s 356us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 19/200\n",
      "88/88 [==============================] - 0s 353us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 20/200\n",
      "88/88 [==============================] - 0s 359us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 21/200\n",
      "88/88 [==============================] - 0s 349us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 22/200\n",
      "88/88 [==============================] - 0s 336us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 23/200\n",
      "88/88 [==============================] - 0s 354us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 24/200\n",
      "88/88 [==============================] - 0s 372us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 25/200\n",
      "88/88 [==============================] - 0s 365us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 26/200\n",
      "88/88 [==============================] - 0s 378us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 27/200\n",
      "88/88 [==============================] - 0s 336us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 28/200\n",
      "88/88 [==============================] - 0s 325us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 29/200\n",
      "88/88 [==============================] - 0s 341us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 30/200\n",
      "88/88 [==============================] - 0s 327us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 31/200\n",
      "88/88 [==============================] - 0s 327us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 32/200\n",
      "88/88 [==============================] - 0s 366us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 33/200\n",
      "88/88 [==============================] - 0s 406us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200\n",
      "88/88 [==============================] - 0s 356us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 35/200\n",
      "88/88 [==============================] - 0s 383us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 36/200\n",
      "88/88 [==============================] - 0s 361us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 37/200\n",
      "88/88 [==============================] - 0s 368us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 38/200\n",
      "88/88 [==============================] - 0s 355us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 39/200\n",
      "88/88 [==============================] - 0s 401us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 40/200\n",
      "88/88 [==============================] - 0s 359us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 41/200\n",
      "88/88 [==============================] - 0s 375us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 42/200\n",
      "88/88 [==============================] - 0s 369us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 43/200\n",
      "88/88 [==============================] - 0s 369us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 44/200\n",
      "88/88 [==============================] - 0s 344us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 45/200\n",
      "88/88 [==============================] - 0s 412us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 46/200\n",
      "88/88 [==============================] - 0s 358us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 47/200\n",
      "88/88 [==============================] - 0s 356us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 48/200\n",
      "88/88 [==============================] - 0s 390us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 49/200\n",
      "88/88 [==============================] - 0s 397us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 50/200\n",
      "88/88 [==============================] - 0s 450us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 51/200\n",
      "88/88 [==============================] - 0s 379us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 52/200\n",
      "88/88 [==============================] - 0s 369us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 53/200\n",
      "88/88 [==============================] - 0s 367us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 54/200\n",
      "88/88 [==============================] - 0s 333us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 55/200\n",
      "88/88 [==============================] - 0s 390us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 56/200\n",
      "88/88 [==============================] - 0s 358us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 57/200\n",
      "88/88 [==============================] - 0s 403us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 58/200\n",
      "88/88 [==============================] - 0s 334us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 59/200\n",
      "88/88 [==============================] - 0s 349us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 60/200\n",
      "88/88 [==============================] - 0s 359us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 61/200\n",
      "88/88 [==============================] - 0s 355us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 62/200\n",
      "88/88 [==============================] - 0s 337us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 63/200\n",
      "88/88 [==============================] - 0s 355us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 64/200\n",
      "88/88 [==============================] - 0s 374us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 65/200\n",
      "88/88 [==============================] - 0s 365us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 66/200\n",
      "88/88 [==============================] - 0s 354us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 67/200\n",
      "88/88 [==============================] - 0s 352us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 68/200\n",
      "88/88 [==============================] - 0s 381us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 69/200\n",
      "88/88 [==============================] - 0s 370us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 70/200\n",
      "88/88 [==============================] - 0s 363us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 71/200\n",
      "88/88 [==============================] - 0s 346us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 72/200\n",
      "88/88 [==============================] - 0s 381us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 73/200\n",
      "88/88 [==============================] - 0s 362us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 74/200\n",
      "88/88 [==============================] - 0s 394us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 75/200\n",
      "88/88 [==============================] - 0s 407us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 76/200\n",
      "88/88 [==============================] - 0s 403us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 77/200\n",
      "88/88 [==============================] - 0s 369us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 78/200\n",
      "88/88 [==============================] - 0s 367us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 79/200\n",
      "88/88 [==============================] - 0s 408us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 80/200\n",
      "88/88 [==============================] - 0s 377us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 81/200\n",
      "88/88 [==============================] - 0s 339us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 82/200\n",
      "88/88 [==============================] - 0s 402us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 83/200\n",
      "88/88 [==============================] - 0s 323us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 84/200\n",
      "88/88 [==============================] - 0s 340us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 85/200\n",
      "88/88 [==============================] - 0s 360us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 86/200\n",
      "88/88 [==============================] - 0s 377us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 87/200\n",
      "88/88 [==============================] - 0s 349us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 88/200\n",
      "88/88 [==============================] - 0s 353us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 89/200\n",
      "88/88 [==============================] - 0s 358us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 90/200\n",
      "88/88 [==============================] - 0s 350us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 91/200\n",
      "88/88 [==============================] - 0s 360us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 92/200\n",
      "88/88 [==============================] - 0s 354us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 93/200\n",
      "88/88 [==============================] - 0s 340us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 94/200\n",
      "88/88 [==============================] - 0s 356us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 95/200\n",
      "88/88 [==============================] - 0s 358us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 96/200\n",
      "88/88 [==============================] - 0s 357us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 97/200\n",
      "88/88 [==============================] - 0s 387us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 98/200\n",
      "88/88 [==============================] - 0s 384us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 99/200\n",
      "88/88 [==============================] - 0s 524us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 100/200\n",
      "88/88 [==============================] - 0s 447us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 101/200\n",
      "88/88 [==============================] - 0s 387us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 102/200\n",
      "88/88 [==============================] - 0s 368us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 103/200\n",
      "88/88 [==============================] - 0s 406us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 104/200\n",
      "88/88 [==============================] - 0s 417us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 105/200\n",
      "88/88 [==============================] - 0s 390us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 106/200\n",
      "88/88 [==============================] - 0s 379us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 107/200\n",
      "88/88 [==============================] - 0s 409us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 108/200\n",
      "88/88 [==============================] - 0s 413us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 109/200\n",
      "88/88 [==============================] - 0s 387us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 110/200\n",
      "88/88 [==============================] - 0s 391us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 111/200\n",
      "88/88 [==============================] - 0s 384us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 112/200\n",
      "88/88 [==============================] - 0s 409us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 113/200\n",
      "88/88 [==============================] - 0s 397us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 114/200\n",
      "88/88 [==============================] - 0s 398us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 115/200\n",
      "88/88 [==============================] - 0s 404us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 116/200\n",
      "88/88 [==============================] - 0s 438us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 117/200\n",
      "88/88 [==============================] - 0s 408us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 118/200\n",
      "88/88 [==============================] - 0s 347us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 119/200\n",
      "88/88 [==============================] - 0s 396us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 120/200\n",
      "88/88 [==============================] - 0s 437us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 121/200\n",
      "88/88 [==============================] - 0s 412us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 122/200\n",
      "88/88 [==============================] - 0s 380us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 123/200\n",
      "88/88 [==============================] - 0s 470us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 124/200\n",
      "88/88 [==============================] - 0s 405us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 125/200\n",
      "88/88 [==============================] - 0s 440us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 126/200\n",
      "88/88 [==============================] - 0s 410us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 127/200\n",
      "88/88 [==============================] - 0s 371us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 128/200\n",
      "88/88 [==============================] - 0s 447us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 129/200\n",
      "88/88 [==============================] - 0s 418us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 130/200\n",
      "88/88 [==============================] - 0s 423us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 131/200\n",
      "88/88 [==============================] - 0s 362us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 132/200\n",
      "88/88 [==============================] - 0s 407us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 133/200\n",
      "88/88 [==============================] - 0s 409us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 134/200\n",
      "88/88 [==============================] - 0s 361us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 135/200\n",
      "88/88 [==============================] - 0s 371us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 136/200\n",
      "88/88 [==============================] - 0s 423us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 137/200\n",
      "88/88 [==============================] - 0s 403us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 138/200\n",
      "88/88 [==============================] - 0s 328us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 139/200\n",
      "88/88 [==============================] - 0s 373us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 140/200\n",
      "88/88 [==============================] - 0s 420us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 141/200\n",
      "88/88 [==============================] - 0s 414us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 142/200\n",
      "88/88 [==============================] - 0s 353us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 143/200\n",
      "88/88 [==============================] - 0s 395us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 144/200\n",
      "88/88 [==============================] - 0s 399us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 145/200\n",
      "88/88 [==============================] - 0s 355us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 146/200\n",
      "88/88 [==============================] - 0s 353us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 147/200\n",
      "88/88 [==============================] - 0s 411us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 148/200\n",
      "88/88 [==============================] - 0s 394us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 149/200\n",
      "88/88 [==============================] - 0s 348us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 150/200\n",
      "88/88 [==============================] - 0s 407us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 151/200\n",
      "88/88 [==============================] - 0s 427us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 152/200\n",
      "88/88 [==============================] - 0s 384us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 153/200\n",
      "88/88 [==============================] - 0s 351us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/200\n",
      "88/88 [==============================] - 0s 388us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 155/200\n",
      "88/88 [==============================] - 0s 422us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 156/200\n",
      "88/88 [==============================] - 0s 391us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 157/200\n",
      "88/88 [==============================] - 0s 354us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 158/200\n",
      "88/88 [==============================] - 0s 362us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 159/200\n",
      "88/88 [==============================] - 0s 417us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 160/200\n",
      "88/88 [==============================] - 0s 389us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 161/200\n",
      "88/88 [==============================] - 0s 400us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 162/200\n",
      "88/88 [==============================] - ETA: 0s - loss: -4.9820 - acc: 0.68 - 0s 575us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 163/200\n",
      "88/88 [==============================] - 0s 448us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 164/200\n",
      "88/88 [==============================] - 0s 514us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 165/200\n",
      "88/88 [==============================] - 0s 703us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 166/200\n",
      "88/88 [==============================] - 0s 543us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 167/200\n",
      "88/88 [==============================] - 0s 486us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 168/200\n",
      "88/88 [==============================] - 0s 471us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 169/200\n",
      "88/88 [==============================] - 0s 463us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 170/200\n",
      "88/88 [==============================] - 0s 481us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 171/200\n",
      "88/88 [==============================] - 0s 430us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 172/200\n",
      "88/88 [==============================] - 0s 392us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 173/200\n",
      "88/88 [==============================] - 0s 378us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 174/200\n",
      "88/88 [==============================] - 0s 404us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 175/200\n",
      "88/88 [==============================] - 0s 458us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 176/200\n",
      "88/88 [==============================] - 0s 424us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 177/200\n",
      "88/88 [==============================] - 0s 458us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 178/200\n",
      "88/88 [==============================] - 0s 359us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 179/200\n",
      "88/88 [==============================] - 0s 427us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 180/200\n",
      "88/88 [==============================] - 0s 371us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 181/200\n",
      "88/88 [==============================] - 0s 385us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 182/200\n",
      "88/88 [==============================] - 0s 362us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 183/200\n",
      "88/88 [==============================] - 0s 359us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 184/200\n",
      "88/88 [==============================] - 0s 360us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 185/200\n",
      "88/88 [==============================] - 0s 367us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 186/200\n",
      "88/88 [==============================] - 0s 331us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 187/200\n",
      "88/88 [==============================] - 0s 350us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 188/200\n",
      "88/88 [==============================] - 0s 350us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 189/200\n",
      "88/88 [==============================] - 0s 357us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 190/200\n",
      "88/88 [==============================] - 0s 348us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 191/200\n",
      "88/88 [==============================] - 0s 428us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 192/200\n",
      "88/88 [==============================] - 0s 343us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 193/200\n",
      "88/88 [==============================] - 0s 367us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 194/200\n",
      "88/88 [==============================] - 0s 398us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 195/200\n",
      "88/88 [==============================] - 0s 371us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 196/200\n",
      "88/88 [==============================] - 0s 355us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 197/200\n",
      "88/88 [==============================] - 0s 334us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 198/200\n",
      "88/88 [==============================] - 0s 342us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 199/200\n",
      "88/88 [==============================] - 0s 356us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "Epoch 200/200\n",
      "88/88 [==============================] - 0s 336us/step - loss: -4.3479 - acc: 0.7273 - val_loss: -4.3479 - val_acc: 0.7273\n",
      "352/352 [==============================] - 0s 62us/step\n",
      "88/88 [==============================] - 0s 98us/step\n",
      "Train on 88 samples, validate on 88 samples\n",
      "Epoch 1/200\n",
      "88/88 [==============================] - 0s 333us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 2/200\n",
      "88/88 [==============================] - 0s 424us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 3/200\n",
      "88/88 [==============================] - 0s 425us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 4/200\n",
      "88/88 [==============================] - 0s 385us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 5/200\n",
      "88/88 [==============================] - 0s 359us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 6/200\n",
      "88/88 [==============================] - 0s 418us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 7/200\n",
      "88/88 [==============================] - 0s 406us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 8/200\n",
      "88/88 [==============================] - 0s 366us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 9/200\n",
      "88/88 [==============================] - 0s 374us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 10/200\n",
      "88/88 [==============================] - 0s 424us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 11/200\n",
      "88/88 [==============================] - 0s 337us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 12/200\n",
      "88/88 [==============================] - 0s 376us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 13/200\n",
      "88/88 [==============================] - 0s 399us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 14/200\n",
      "88/88 [==============================] - 0s 395us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 15/200\n",
      "88/88 [==============================] - 0s 364us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 16/200\n",
      "88/88 [==============================] - 0s 377us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 17/200\n",
      "88/88 [==============================] - 0s 413us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 18/200\n",
      "88/88 [==============================] - 0s 439us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 19/200\n",
      "88/88 [==============================] - 0s 342us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 20/200\n",
      "88/88 [==============================] - 0s 377us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 21/200\n",
      "88/88 [==============================] - 0s 411us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 22/200\n",
      "88/88 [==============================] - 0s 429us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 23/200\n",
      "88/88 [==============================] - 0s 341us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 24/200\n",
      "88/88 [==============================] - 0s 415us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 25/200\n",
      "88/88 [==============================] - 0s 445us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 26/200\n",
      "88/88 [==============================] - 0s 429us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 27/200\n",
      "88/88 [==============================] - 0s 410us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 28/200\n",
      "88/88 [==============================] - 0s 431us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 29/200\n",
      "88/88 [==============================] - 0s 417us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 30/200\n",
      "88/88 [==============================] - 0s 457us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 31/200\n",
      "88/88 [==============================] - 0s 441us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 32/200\n",
      "88/88 [==============================] - 0s 407us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 33/200\n",
      "88/88 [==============================] - 0s 404us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 34/200\n",
      "88/88 [==============================] - 0s 415us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 35/200\n",
      "88/88 [==============================] - 0s 405us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 36/200\n",
      "88/88 [==============================] - 0s 473us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 37/200\n",
      "88/88 [==============================] - 0s 380us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 38/200\n",
      "88/88 [==============================] - 0s 388us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 39/200\n",
      "88/88 [==============================] - 0s 395us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 40/200\n",
      "88/88 [==============================] - 0s 402us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 41/200\n",
      "88/88 [==============================] - 0s 361us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 42/200\n",
      "88/88 [==============================] - 0s 427us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 43/200\n",
      "88/88 [==============================] - 0s 409us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 44/200\n",
      "88/88 [==============================] - 0s 434us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 45/200\n",
      "88/88 [==============================] - 0s 361us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 46/200\n",
      "88/88 [==============================] - 0s 384us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 47/200\n",
      "88/88 [==============================] - 0s 398us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 48/200\n",
      "88/88 [==============================] - 0s 421us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 49/200\n",
      "88/88 [==============================] - 0s 357us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 50/200\n",
      "88/88 [==============================] - 0s 360us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 51/200\n",
      "88/88 [==============================] - 0s 417us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 52/200\n",
      "88/88 [==============================] - 0s 363us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 53/200\n",
      "88/88 [==============================] - 0s 358us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 54/200\n",
      "88/88 [==============================] - 0s 399us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 55/200\n",
      "88/88 [==============================] - 0s 410us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 56/200\n",
      "88/88 [==============================] - 0s 345us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 57/200\n",
      "88/88 [==============================] - 0s 372us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 58/200\n",
      "88/88 [==============================] - 0s 399us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 59/200\n",
      "88/88 [==============================] - 0s 398us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 60/200\n",
      "88/88 [==============================] - 0s 343us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 61/200\n",
      "88/88 [==============================] - 0s 394us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 62/200\n",
      "88/88 [==============================] - 0s 468us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 63/200\n",
      "88/88 [==============================] - 0s 358us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 64/200\n",
      "88/88 [==============================] - 0s 359us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 65/200\n",
      "88/88 [==============================] - 0s 389us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 66/200\n",
      "88/88 [==============================] - 0s 392us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 67/200\n",
      "88/88 [==============================] - 0s 349us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 68/200\n",
      "88/88 [==============================] - 0s 382us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 69/200\n",
      "88/88 [==============================] - 0s 409us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 70/200\n",
      "88/88 [==============================] - 0s 393us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 71/200\n",
      "88/88 [==============================] - 0s 346us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 72/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 392us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 73/200\n",
      "88/88 [==============================] - 0s 409us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 74/200\n",
      "88/88 [==============================] - 0s 395us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 75/200\n",
      "88/88 [==============================] - 0s 394us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 76/200\n",
      "88/88 [==============================] - 0s 405us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 77/200\n",
      "88/88 [==============================] - 0s 436us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 78/200\n",
      "88/88 [==============================] - 0s 354us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 79/200\n",
      "88/88 [==============================] - 0s 393us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 80/200\n",
      "88/88 [==============================] - 0s 410us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 81/200\n",
      "88/88 [==============================] - 0s 459us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 82/200\n",
      "88/88 [==============================] - 0s 392us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 83/200\n",
      "88/88 [==============================] - 0s 365us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 84/200\n",
      "88/88 [==============================] - 0s 422us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 85/200\n",
      "88/88 [==============================] - 0s 457us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 86/200\n",
      "88/88 [==============================] - 0s 421us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 87/200\n",
      "88/88 [==============================] - 0s 415us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 88/200\n",
      "88/88 [==============================] - 0s 406us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 89/200\n",
      "88/88 [==============================] - 0s 462us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 90/200\n",
      "88/88 [==============================] - 0s 397us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 91/200\n",
      "88/88 [==============================] - 0s 392us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 92/200\n",
      "88/88 [==============================] - 0s 413us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 93/200\n",
      "88/88 [==============================] - 0s 368us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 94/200\n",
      "88/88 [==============================] - 0s 420us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 95/200\n",
      "88/88 [==============================] - 0s 411us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 96/200\n",
      "88/88 [==============================] - 0s 358us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 97/200\n",
      "88/88 [==============================] - 0s 386us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 98/200\n",
      "88/88 [==============================] - 0s 423us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 99/200\n",
      "88/88 [==============================] - 0s 408us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 100/200\n",
      "88/88 [==============================] - 0s 348us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 101/200\n",
      "88/88 [==============================] - 0s 395us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 102/200\n",
      "88/88 [==============================] - 0s 389us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 103/200\n",
      "88/88 [==============================] - 0s 393us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 104/200\n",
      "88/88 [==============================] - 0s 365us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 105/200\n",
      "88/88 [==============================] - 0s 395us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 106/200\n",
      "88/88 [==============================] - 0s 403us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 107/200\n",
      "88/88 [==============================] - 0s 343us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 108/200\n",
      "88/88 [==============================] - 0s 382us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 109/200\n",
      "88/88 [==============================] - 0s 404us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 110/200\n",
      "88/88 [==============================] - 0s 412us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 111/200\n",
      "88/88 [==============================] - 0s 364us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 112/200\n",
      "88/88 [==============================] - 0s 380us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 113/200\n",
      "88/88 [==============================] - 0s 406us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 114/200\n",
      "88/88 [==============================] - 0s 415us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 115/200\n",
      "88/88 [==============================] - 0s 443us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 116/200\n",
      "88/88 [==============================] - 0s 399us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 117/200\n",
      "88/88 [==============================] - 0s 385us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 118/200\n",
      "88/88 [==============================] - 0s 404us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 119/200\n",
      "88/88 [==============================] - 0s 341us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 120/200\n",
      "88/88 [==============================] - 0s 363us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 121/200\n",
      "88/88 [==============================] - 0s 402us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 122/200\n",
      "88/88 [==============================] - 0s 361us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 123/200\n",
      "88/88 [==============================] - 0s 385us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 124/200\n",
      "88/88 [==============================] - 0s 391us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 125/200\n",
      "88/88 [==============================] - 0s 436us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 126/200\n",
      "88/88 [==============================] - 0s 352us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 127/200\n",
      "88/88 [==============================] - 0s 384us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 128/200\n",
      "88/88 [==============================] - 0s 389us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 129/200\n",
      "88/88 [==============================] - 0s 403us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 130/200\n",
      "88/88 [==============================] - 0s 344us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 131/200\n",
      "88/88 [==============================] - 0s 376us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 132/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 396us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 133/200\n",
      "88/88 [==============================] - 0s 361us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 134/200\n",
      "88/88 [==============================] - 0s 369us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 135/200\n",
      "88/88 [==============================] - 0s 421us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 136/200\n",
      "88/88 [==============================] - 0s 403us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 137/200\n",
      "88/88 [==============================] - 0s 390us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 138/200\n",
      "88/88 [==============================] - 0s 357us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 139/200\n",
      "88/88 [==============================] - 0s 410us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 140/200\n",
      "88/88 [==============================] - 0s 379us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 141/200\n",
      "88/88 [==============================] - 0s 368us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 142/200\n",
      "88/88 [==============================] - 0s 368us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 143/200\n",
      "88/88 [==============================] - 0s 503us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 144/200\n",
      "88/88 [==============================] - 0s 424us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 145/200\n",
      "88/88 [==============================] - 0s 355us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 146/200\n",
      "88/88 [==============================] - 0s 381us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 147/200\n",
      "88/88 [==============================] - 0s 380us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 148/200\n",
      "88/88 [==============================] - 0s 408us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 149/200\n",
      "88/88 [==============================] - 0s 340us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 150/200\n",
      "88/88 [==============================] - 0s 390us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 151/200\n",
      "88/88 [==============================] - 0s 409us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 152/200\n",
      "88/88 [==============================] - 0s 381us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 153/200\n",
      "88/88 [==============================] - 0s 359us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 154/200\n",
      "88/88 [==============================] - 0s 383us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 155/200\n",
      "88/88 [==============================] - 0s 417us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 156/200\n",
      "88/88 [==============================] - 0s 452us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 157/200\n",
      "88/88 [==============================] - 0s 556us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 158/200\n",
      "88/88 [==============================] - 0s 494us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 159/200\n",
      "88/88 [==============================] - 0s 355us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 160/200\n",
      "88/88 [==============================] - 0s 383us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 161/200\n",
      "88/88 [==============================] - 0s 410us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 162/200\n",
      "88/88 [==============================] - 0s 352us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 163/200\n",
      "88/88 [==============================] - 0s 380us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 164/200\n",
      "88/88 [==============================] - 0s 408us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 165/200\n",
      "88/88 [==============================] - 0s 438us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 166/200\n",
      "88/88 [==============================] - 0s 394us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 167/200\n",
      "88/88 [==============================] - 0s 403us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 168/200\n",
      "88/88 [==============================] - 0s 391us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 169/200\n",
      "88/88 [==============================] - 0s 462us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 170/200\n",
      "88/88 [==============================] - 0s 437us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 171/200\n",
      "88/88 [==============================] - 0s 477us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 172/200\n",
      "88/88 [==============================] - 0s 361us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 173/200\n",
      "88/88 [==============================] - 0s 411us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 174/200\n",
      "88/88 [==============================] - 0s 405us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 175/200\n",
      "88/88 [==============================] - 0s 413us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 176/200\n",
      "88/88 [==============================] - 0s 363us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 177/200\n",
      "88/88 [==============================] - 0s 396us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 178/200\n",
      "88/88 [==============================] - 0s 422us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 179/200\n",
      "88/88 [==============================] - 0s 414us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 180/200\n",
      "88/88 [==============================] - 0s 351us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 181/200\n",
      "88/88 [==============================] - 0s 396us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 182/200\n",
      "88/88 [==============================] - 0s 413us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 183/200\n",
      "88/88 [==============================] - 0s 383us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 184/200\n",
      "88/88 [==============================] - 0s 351us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 185/200\n",
      "88/88 [==============================] - 0s 397us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 186/200\n",
      "88/88 [==============================] - 0s 410us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 187/200\n",
      "88/88 [==============================] - 0s 349us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 188/200\n",
      "88/88 [==============================] - 0s 382us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 189/200\n",
      "88/88 [==============================] - 0s 407us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 190/200\n",
      "88/88 [==============================] - 0s 408us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 191/200\n",
      "88/88 [==============================] - 0s 385us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/200\n",
      "88/88 [==============================] - 0s 362us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 193/200\n",
      "88/88 [==============================] - 0s 387us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 194/200\n",
      "88/88 [==============================] - 0s 417us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 195/200\n",
      "88/88 [==============================] - 0s 499us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 196/200\n",
      "88/88 [==============================] - 0s 356us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 197/200\n",
      "88/88 [==============================] - 0s 392us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 198/200\n",
      "88/88 [==============================] - 0s 413us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 199/200\n",
      "88/88 [==============================] - 0s 374us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "Epoch 200/200\n",
      "88/88 [==============================] - 0s 350us/step - loss: -5.2537 - acc: 0.6705 - val_loss: -5.2537 - val_acc: 0.6705\n",
      "352/352 [==============================] - 0s 78us/step\n",
      "88/88 [==============================] - 0s 110us/step\n",
      "Train on 88 samples, validate on 88 samples\n",
      "Epoch 1/200\n",
      "88/88 [==============================] - 0s 427us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 2/200\n",
      "88/88 [==============================] - 0s 430us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 3/200\n",
      "88/88 [==============================] - 0s 416us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 4/200\n",
      "88/88 [==============================] - 0s 388us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 5/200\n",
      "88/88 [==============================] - 0s 487us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 6/200\n",
      "88/88 [==============================] - 0s 420us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 7/200\n",
      "88/88 [==============================] - 0s 418us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 8/200\n",
      "88/88 [==============================] - 0s 392us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 9/200\n",
      "88/88 [==============================] - 0s 396us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 10/200\n",
      "88/88 [==============================] - 0s 413us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 11/200\n",
      "88/88 [==============================] - 0s 423us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 12/200\n",
      "88/88 [==============================] - 0s 370us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 13/200\n",
      "88/88 [==============================] - 0s 460us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 14/200\n",
      "88/88 [==============================] - 0s 430us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 15/200\n",
      "88/88 [==============================] - 0s 410us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 16/200\n",
      "88/88 [==============================] - 0s 421us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 17/200\n",
      "88/88 [==============================] - 0s 368us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 18/200\n",
      "88/88 [==============================] - 0s 398us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 19/200\n",
      "88/88 [==============================] - 0s 400us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 20/200\n",
      "88/88 [==============================] - 0s 380us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 21/200\n",
      "88/88 [==============================] - 0s 451us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 22/200\n",
      "88/88 [==============================] - 0s 384us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 23/200\n",
      "88/88 [==============================] - 0s 385us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 24/200\n",
      "88/88 [==============================] - 0s 426us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 25/200\n",
      "88/88 [==============================] - 0s 357us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 26/200\n",
      "88/88 [==============================] - 0s 376us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 27/200\n",
      "88/88 [==============================] - 0s 402us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 28/200\n",
      "88/88 [==============================] - 0s 401us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 29/200\n",
      "88/88 [==============================] - 0s 370us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 30/200\n",
      "88/88 [==============================] - 0s 392us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 31/200\n",
      "88/88 [==============================] - 0s 408us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 32/200\n",
      "88/88 [==============================] - 0s 390us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 33/200\n",
      "88/88 [==============================] - 0s 363us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 34/200\n",
      "88/88 [==============================] - 0s 375us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 35/200\n",
      "88/88 [==============================] - 0s 402us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 36/200\n",
      "88/88 [==============================] - 0s 373us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 37/200\n",
      "88/88 [==============================] - 0s 339us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 38/200\n",
      "88/88 [==============================] - 0s 470us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 39/200\n",
      "88/88 [==============================] - 0s 460us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 40/200\n",
      "88/88 [==============================] - 0s 428us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 41/200\n",
      "88/88 [==============================] - 0s 433us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 42/200\n",
      "88/88 [==============================] - 0s 556us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 43/200\n",
      "88/88 [==============================] - 0s 444us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 44/200\n",
      "88/88 [==============================] - 0s 459us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 45/200\n",
      "88/88 [==============================] - 0s 437us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 46/200\n",
      "88/88 [==============================] - 0s 540us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 47/200\n",
      "88/88 [==============================] - 0s 527us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 48/200\n",
      "88/88 [==============================] - 0s 474us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 49/200\n",
      "88/88 [==============================] - 0s 493us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 50/200\n",
      "88/88 [==============================] - 0s 536us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 51/200\n",
      "88/88 [==============================] - 0s 488us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 52/200\n",
      "88/88 [==============================] - 0s 345us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 53/200\n",
      "88/88 [==============================] - 0s 386us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 54/200\n",
      "88/88 [==============================] - 0s 427us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 55/200\n",
      "88/88 [==============================] - 0s 492us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 56/200\n",
      "88/88 [==============================] - 0s 414us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 57/200\n",
      "88/88 [==============================] - 0s 375us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 58/200\n",
      "88/88 [==============================] - 0s 416us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 59/200\n",
      "88/88 [==============================] - 0s 436us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 60/200\n",
      "88/88 [==============================] - 0s 444us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 61/200\n",
      "88/88 [==============================] - 0s 364us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 62/200\n",
      "88/88 [==============================] - 0s 375us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 63/200\n",
      "88/88 [==============================] - 0s 423us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 64/200\n",
      "88/88 [==============================] - 0s 455us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 65/200\n",
      "88/88 [==============================] - 0s 404us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 66/200\n",
      "88/88 [==============================] - 0s 378us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 67/200\n",
      "88/88 [==============================] - 0s 410us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 68/200\n",
      "88/88 [==============================] - 0s 429us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 69/200\n",
      "88/88 [==============================] - 0s 469us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 70/200\n",
      "88/88 [==============================] - 0s 393us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 71/200\n",
      "88/88 [==============================] - 0s 374us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 72/200\n",
      "88/88 [==============================] - 0s 395us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 73/200\n",
      "88/88 [==============================] - 0s 497us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 74/200\n",
      "88/88 [==============================] - 0s 422us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 75/200\n",
      "88/88 [==============================] - 0s 408us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 76/200\n",
      "88/88 [==============================] - 0s 393us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 77/200\n",
      "88/88 [==============================] - 0s 378us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 78/200\n",
      "88/88 [==============================] - 0s 372us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 79/200\n",
      "88/88 [==============================] - 0s 387us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 80/200\n",
      "88/88 [==============================] - 0s 361us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 81/200\n",
      "88/88 [==============================] - 0s 395us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 82/200\n",
      "88/88 [==============================] - 0s 392us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 83/200\n",
      "88/88 [==============================] - 0s 335us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 84/200\n",
      "88/88 [==============================] - 0s 342us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 85/200\n",
      "88/88 [==============================] - 0s 349us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 86/200\n",
      "88/88 [==============================] - 0s 379us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 87/200\n",
      "88/88 [==============================] - 0s 363us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 88/200\n",
      "88/88 [==============================] - 0s 382us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 89/200\n",
      "88/88 [==============================] - 0s 332us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 90/200\n",
      "88/88 [==============================] - 0s 511us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 91/200\n",
      "88/88 [==============================] - 0s 372us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 92/200\n",
      "88/88 [==============================] - 0s 368us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 93/200\n",
      "88/88 [==============================] - 0s 377us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 94/200\n",
      "88/88 [==============================] - 0s 388us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 95/200\n",
      "88/88 [==============================] - 0s 368us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 96/200\n",
      "88/88 [==============================] - 0s 354us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 97/200\n",
      "88/88 [==============================] - 0s 351us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 98/200\n",
      "88/88 [==============================] - 0s 393us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 99/200\n",
      "88/88 [==============================] - 0s 387us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 100/200\n",
      "88/88 [==============================] - 0s 355us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 101/200\n",
      "88/88 [==============================] - 0s 360us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 102/200\n",
      "88/88 [==============================] - 0s 412us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 103/200\n",
      "88/88 [==============================] - 0s 408us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 104/200\n",
      "88/88 [==============================] - 0s 351us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 105/200\n",
      "88/88 [==============================] - 0s 411us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 106/200\n",
      "88/88 [==============================] - 0s 397us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 107/200\n",
      "88/88 [==============================] - 0s 398us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 108/200\n",
      "88/88 [==============================] - 0s 349us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 109/200\n",
      "88/88 [==============================] - 0s 387us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 110/200\n",
      "88/88 [==============================] - 0s 412us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 349us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 112/200\n",
      "88/88 [==============================] - 0s 365us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 113/200\n",
      "88/88 [==============================] - 0s 422us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 114/200\n",
      "88/88 [==============================] - 0s 397us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 115/200\n",
      "88/88 [==============================] - 0s 335us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 116/200\n",
      "88/88 [==============================] - 0s 407us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 117/200\n",
      "88/88 [==============================] - 0s 456us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 118/200\n",
      "88/88 [==============================] - 0s 401us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 119/200\n",
      "88/88 [==============================] - 0s 369us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 120/200\n",
      "88/88 [==============================] - 0s 382us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 121/200\n",
      "88/88 [==============================] - 0s 443us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 122/200\n",
      "88/88 [==============================] - 0s 463us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 123/200\n",
      "88/88 [==============================] - 0s 367us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 124/200\n",
      "88/88 [==============================] - 0s 364us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 125/200\n",
      "88/88 [==============================] - 0s 395us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 126/200\n",
      "88/88 [==============================] - 0s 395us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 127/200\n",
      "88/88 [==============================] - 0s 348us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 128/200\n",
      "88/88 [==============================] - 0s 377us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 129/200\n",
      "88/88 [==============================] - 0s 388us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 130/200\n",
      "88/88 [==============================] - 0s 470us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 131/200\n",
      "88/88 [==============================] - 0s 351us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 132/200\n",
      "88/88 [==============================] - 0s 388us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 133/200\n",
      "88/88 [==============================] - 0s 410us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 134/200\n",
      "88/88 [==============================] - 0s 429us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 135/200\n",
      "88/88 [==============================] - 0s 367us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 136/200\n",
      "88/88 [==============================] - 0s 373us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 137/200\n",
      "88/88 [==============================] - 0s 408us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 138/200\n",
      "88/88 [==============================] - 0s 388us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 139/200\n",
      "88/88 [==============================] - 0s 336us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 140/200\n",
      "88/88 [==============================] - 0s 407us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 141/200\n",
      "88/88 [==============================] - 0s 444us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 142/200\n",
      "88/88 [==============================] - 0s 356us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 143/200\n",
      "88/88 [==============================] - 0s 362us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 144/200\n",
      "88/88 [==============================] - 0s 400us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 145/200\n",
      "88/88 [==============================] - 0s 442us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 146/200\n",
      "88/88 [==============================] - 0s 356us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 147/200\n",
      "88/88 [==============================] - 0s 393us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 148/200\n",
      "88/88 [==============================] - 0s 400us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 149/200\n",
      "88/88 [==============================] - 0s 396us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 150/200\n",
      "88/88 [==============================] - 0s 367us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 151/200\n",
      "88/88 [==============================] - 0s 384us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 152/200\n",
      "88/88 [==============================] - 0s 407us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 153/200\n",
      "88/88 [==============================] - 0s 333us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 154/200\n",
      "88/88 [==============================] - 0s 364us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 155/200\n",
      "88/88 [==============================] - 0s 400us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 156/200\n",
      "88/88 [==============================] - 0s 399us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 157/200\n",
      "88/88 [==============================] - 0s 362us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 158/200\n",
      "88/88 [==============================] - 0s 382us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 159/200\n",
      "88/88 [==============================] - 0s 394us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 160/200\n",
      "88/88 [==============================] - 0s 369us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 161/200\n",
      "88/88 [==============================] - 0s 367us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 162/200\n",
      "88/88 [==============================] - 0s 398us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 163/200\n",
      "88/88 [==============================] - 0s 440us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 164/200\n",
      "88/88 [==============================] - 0s 391us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 165/200\n",
      "88/88 [==============================] - 0s 352us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 166/200\n",
      "88/88 [==============================] - 0s 398us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 167/200\n",
      "88/88 [==============================] - 0s 362us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 168/200\n",
      "88/88 [==============================] - 0s 358us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 169/200\n",
      "88/88 [==============================] - 0s 381us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 170/200\n",
      "88/88 [==============================] - 0s 407us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200\n",
      "88/88 [==============================] - 0s 366us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 172/200\n",
      "88/88 [==============================] - 0s 380us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 173/200\n",
      "88/88 [==============================] - 0s 429us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 174/200\n",
      "88/88 [==============================] - 0s 411us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 175/200\n",
      "88/88 [==============================] - 0s 371us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 176/200\n",
      "88/88 [==============================] - 0s 368us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 177/200\n",
      "88/88 [==============================] - 0s 399us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 178/200\n",
      "88/88 [==============================] - 0s 394us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 179/200\n",
      "88/88 [==============================] - 0s 382us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 180/200\n",
      "88/88 [==============================] - 0s 378us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 181/200\n",
      "88/88 [==============================] - 0s 402us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 182/200\n",
      "88/88 [==============================] - 0s 444us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 183/200\n",
      "88/88 [==============================] - 0s 354us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 184/200\n",
      "88/88 [==============================] - 0s 400us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 185/200\n",
      "88/88 [==============================] - 0s 415us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 186/200\n",
      "88/88 [==============================] - 0s 394us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 187/200\n",
      "88/88 [==============================] - 0s 361us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 188/200\n",
      "88/88 [==============================] - 0s 386us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 189/200\n",
      "88/88 [==============================] - 0s 443us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 190/200\n",
      "88/88 [==============================] - 0s 379us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 191/200\n",
      "88/88 [==============================] - 0s 362us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 192/200\n",
      "88/88 [==============================] - 0s 404us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 193/200\n",
      "88/88 [==============================] - 0s 404us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 194/200\n",
      "88/88 [==============================] - 0s 360us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 195/200\n",
      "88/88 [==============================] - 0s 400us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 196/200\n",
      "88/88 [==============================] - 0s 401us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 197/200\n",
      "88/88 [==============================] - 0s 438us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 198/200\n",
      "88/88 [==============================] - 0s 369us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 199/200\n",
      "88/88 [==============================] - 0s 394us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "Epoch 200/200\n",
      "88/88 [==============================] - 0s 399us/step - loss: -4.5291 - acc: 0.7159 - val_loss: -4.5291 - val_acc: 0.7159\n",
      "352/352 [==============================] - 0s 75us/step\n",
      "88/88 [==============================] - 0s 115us/step\n",
      "[0.6742424206300215, 0.6651515158739957, 0.6704545454545454]\n",
      "[0.6780303030303031, 0.6893939383102184, 0.7045454545454545]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8,activation='relu',input_dim=6))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics=['accuracy'])\n",
    "ave_acc_whole_ann=[]\n",
    "ave_acc_whole_ann_train=[]\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(Whole_x, Whole_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        history = model.fit(X_train1, y_train1,validation_data=(X_train1,y_train1),batch_size=16,epochs=200)\n",
    "        score2 += model.evaluate(X_test1,y_test1,verbose=1)[1]\n",
    "        score1 += model.evaluate(X_train1,y_train1,verbose=1)[1]\n",
    "    ave_acc_whole_ann.append(score2/3.0)\n",
    "    ave_acc_whole_ann_train.append(score1/3.0)\n",
    "    \n",
    "print ave_acc_whole_ann\n",
    "print ave_acc_whole_ann_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4656 samples, validate on 4656 samples\n",
      "Epoch 1/200\n",
      "4656/4656 [==============================] - 3s 617us/step - loss: 0.9474 - acc: 0.5831 - val_loss: 0.9022 - val_acc: 0.6143\n",
      "Epoch 2/200\n",
      "4656/4656 [==============================] - 0s 56us/step - loss: 0.8874 - acc: 0.6177 - val_loss: 0.8714 - val_acc: 0.6196\n",
      "Epoch 3/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.8662 - acc: 0.6233 - val_loss: 0.8592 - val_acc: 0.6198\n",
      "Epoch 4/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.8547 - acc: 0.6213 - val_loss: 0.8437 - val_acc: 0.6252\n",
      "Epoch 5/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.8428 - acc: 0.6269 - val_loss: 0.8340 - val_acc: 0.6274\n",
      "Epoch 6/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.8344 - acc: 0.6280 - val_loss: 0.8257 - val_acc: 0.6293\n",
      "Epoch 7/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.8264 - acc: 0.6291 - val_loss: 0.8190 - val_acc: 0.6342\n",
      "Epoch 8/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.8176 - acc: 0.6334 - val_loss: 0.8126 - val_acc: 0.6312\n",
      "Epoch 9/200\n",
      "4656/4656 [==============================] - 0s 56us/step - loss: 0.8123 - acc: 0.6362 - val_loss: 0.8040 - val_acc: 0.6370\n",
      "Epoch 10/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.8064 - acc: 0.6396 - val_loss: 0.7972 - val_acc: 0.6441\n",
      "Epoch 11/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.7991 - acc: 0.6437 - val_loss: 0.7894 - val_acc: 0.6482\n",
      "Epoch 12/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.7905 - acc: 0.6516 - val_loss: 0.7874 - val_acc: 0.6557\n",
      "Epoch 13/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.7877 - acc: 0.6450 - val_loss: 0.7792 - val_acc: 0.6553\n",
      "Epoch 14/200\n",
      "4656/4656 [==============================] - 0s 47us/step - loss: 0.7781 - acc: 0.6529 - val_loss: 0.7747 - val_acc: 0.6574\n",
      "Epoch 15/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.7723 - acc: 0.6570 - val_loss: 0.7638 - val_acc: 0.6619\n",
      "Epoch 16/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.7652 - acc: 0.6652 - val_loss: 0.7584 - val_acc: 0.6639\n",
      "Epoch 17/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.7610 - acc: 0.6602 - val_loss: 0.7497 - val_acc: 0.6690\n",
      "Epoch 18/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.7515 - acc: 0.6677 - val_loss: 0.7432 - val_acc: 0.6768\n",
      "Epoch 19/200\n",
      "4656/4656 [==============================] - 0s 47us/step - loss: 0.7459 - acc: 0.6710 - val_loss: 0.7376 - val_acc: 0.6763\n",
      "Epoch 20/200\n",
      "4656/4656 [==============================] - 0s 46us/step - loss: 0.7430 - acc: 0.6712 - val_loss: 0.7333 - val_acc: 0.6783\n",
      "Epoch 21/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.7353 - acc: 0.6776 - val_loss: 0.7268 - val_acc: 0.6828\n",
      "Epoch 22/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.7295 - acc: 0.6832 - val_loss: 0.7223 - val_acc: 0.6843\n",
      "Epoch 23/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.7232 - acc: 0.6860 - val_loss: 0.7132 - val_acc: 0.6881\n",
      "Epoch 24/200\n",
      "4656/4656 [==============================] - 0s 47us/step - loss: 0.7167 - acc: 0.6918 - val_loss: 0.7061 - val_acc: 0.6905\n",
      "Epoch 25/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.7093 - acc: 0.6954 - val_loss: 0.7001 - val_acc: 0.6997\n",
      "Epoch 26/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.7031 - acc: 0.6918 - val_loss: 0.6944 - val_acc: 0.7017\n",
      "Epoch 27/200\n",
      "4656/4656 [==============================] - 0s 47us/step - loss: 0.6982 - acc: 0.7038 - val_loss: 0.6898 - val_acc: 0.7064\n",
      "Epoch 28/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.6915 - acc: 0.7062 - val_loss: 0.6815 - val_acc: 0.7131\n",
      "Epoch 29/200\n",
      "4656/4656 [==============================] - 0s 46us/step - loss: 0.6860 - acc: 0.7098 - val_loss: 0.6762 - val_acc: 0.7206\n",
      "Epoch 30/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.6799 - acc: 0.7124 - val_loss: 0.6718 - val_acc: 0.7214\n",
      "Epoch 31/200\n",
      "4656/4656 [==============================] - 0s 47us/step - loss: 0.6710 - acc: 0.7191 - val_loss: 0.6598 - val_acc: 0.7272\n",
      "Epoch 32/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.6624 - acc: 0.7300 - val_loss: 0.6561 - val_acc: 0.7356\n",
      "Epoch 33/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.6582 - acc: 0.7292 - val_loss: 0.6533 - val_acc: 0.7313\n",
      "Epoch 34/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.6539 - acc: 0.7335 - val_loss: 0.6431 - val_acc: 0.7324\n",
      "Epoch 35/200\n",
      "4656/4656 [==============================] - 0s 46us/step - loss: 0.6452 - acc: 0.7380 - val_loss: 0.6368 - val_acc: 0.7498\n",
      "Epoch 36/200\n",
      "4656/4656 [==============================] - 0s 46us/step - loss: 0.6412 - acc: 0.7446 - val_loss: 0.6341 - val_acc: 0.7479\n",
      "Epoch 37/200\n",
      "4656/4656 [==============================] - 0s 45us/step - loss: 0.6362 - acc: 0.7410 - val_loss: 0.6286 - val_acc: 0.7455\n",
      "Epoch 38/200\n",
      "4656/4656 [==============================] - 0s 46us/step - loss: 0.6300 - acc: 0.7530 - val_loss: 0.6181 - val_acc: 0.7595\n",
      "Epoch 39/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.6209 - acc: 0.7629 - val_loss: 0.6128 - val_acc: 0.7702\n",
      "Epoch 40/200\n",
      "4656/4656 [==============================] - 0s 44us/step - loss: 0.6155 - acc: 0.7616 - val_loss: 0.6081 - val_acc: 0.7715\n",
      "Epoch 41/200\n",
      "4656/4656 [==============================] - 0s 46us/step - loss: 0.6090 - acc: 0.7687 - val_loss: 0.5966 - val_acc: 0.7758\n",
      "Epoch 42/200\n",
      "4656/4656 [==============================] - 0s 45us/step - loss: 0.6022 - acc: 0.7680 - val_loss: 0.5921 - val_acc: 0.7687\n",
      "Epoch 43/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.5947 - acc: 0.7751 - val_loss: 0.5826 - val_acc: 0.7822\n",
      "Epoch 44/200\n",
      "4656/4656 [==============================] - 0s 59us/step - loss: 0.5883 - acc: 0.7758 - val_loss: 0.5762 - val_acc: 0.7859\n",
      "Epoch 45/200\n",
      "4656/4656 [==============================] - 0s 45us/step - loss: 0.5778 - acc: 0.7824 - val_loss: 0.5663 - val_acc: 0.7869\n",
      "Epoch 46/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.5680 - acc: 0.7863 - val_loss: 0.5563 - val_acc: 0.7934\n",
      "Epoch 47/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.5604 - acc: 0.7932 - val_loss: 0.5513 - val_acc: 0.7953\n",
      "Epoch 48/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.5536 - acc: 0.7925 - val_loss: 0.5415 - val_acc: 0.7985\n",
      "Epoch 49/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.5405 - acc: 0.8005 - val_loss: 0.5263 - val_acc: 0.8091\n",
      "Epoch 50/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.5292 - acc: 0.8035 - val_loss: 0.5153 - val_acc: 0.8110\n",
      "Epoch 51/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.5163 - acc: 0.8116 - val_loss: 0.5080 - val_acc: 0.8146\n",
      "Epoch 52/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.5056 - acc: 0.8170 - val_loss: 0.4935 - val_acc: 0.8224\n",
      "Epoch 53/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.4936 - acc: 0.8230 - val_loss: 0.4787 - val_acc: 0.8275\n",
      "Epoch 54/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.4793 - acc: 0.8241 - val_loss: 0.4663 - val_acc: 0.8295\n",
      "Epoch 55/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.4718 - acc: 0.8262 - val_loss: 0.4566 - val_acc: 0.8303\n",
      "Epoch 56/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.4558 - acc: 0.8329 - val_loss: 0.4403 - val_acc: 0.8346\n",
      "Epoch 57/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.4432 - acc: 0.8357 - val_loss: 0.4321 - val_acc: 0.8381\n",
      "Epoch 58/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.4331 - acc: 0.8419 - val_loss: 0.4213 - val_acc: 0.8439\n",
      "Epoch 59/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.4210 - acc: 0.8482 - val_loss: 0.4069 - val_acc: 0.8537\n",
      "Epoch 60/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.4061 - acc: 0.8514 - val_loss: 0.3896 - val_acc: 0.8619\n",
      "Epoch 61/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.3935 - acc: 0.8600 - val_loss: 0.3804 - val_acc: 0.8690\n",
      "Epoch 62/200\n",
      "4656/4656 [==============================] - 0s 47us/step - loss: 0.3815 - acc: 0.8623 - val_loss: 0.3754 - val_acc: 0.8688\n",
      "Epoch 63/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.3716 - acc: 0.8675 - val_loss: 0.3558 - val_acc: 0.8793\n",
      "Epoch 64/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.3591 - acc: 0.8739 - val_loss: 0.3468 - val_acc: 0.8698\n",
      "Epoch 65/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.3457 - acc: 0.8817 - val_loss: 0.3348 - val_acc: 0.8836\n",
      "Epoch 66/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.3373 - acc: 0.8845 - val_loss: 0.3278 - val_acc: 0.8834\n",
      "Epoch 67/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.3263 - acc: 0.8956 - val_loss: 0.3195 - val_acc: 0.8892\n",
      "Epoch 68/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.3197 - acc: 0.8954 - val_loss: 0.3035 - val_acc: 0.9029\n",
      "Epoch 69/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.3052 - acc: 0.9025 - val_loss: 0.2976 - val_acc: 0.9034\n",
      "Epoch 70/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.2951 - acc: 0.9044 - val_loss: 0.2855 - val_acc: 0.9102\n",
      "Epoch 71/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.2868 - acc: 0.9083 - val_loss: 0.2738 - val_acc: 0.9152\n",
      "Epoch 72/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.2764 - acc: 0.9143 - val_loss: 0.2638 - val_acc: 0.9190\n",
      "Epoch 73/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.2665 - acc: 0.9137 - val_loss: 0.2578 - val_acc: 0.9248\n",
      "Epoch 74/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.2616 - acc: 0.9175 - val_loss: 0.2496 - val_acc: 0.9233\n",
      "Epoch 75/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.2492 - acc: 0.9225 - val_loss: 0.2405 - val_acc: 0.9272\n",
      "Epoch 76/200\n",
      "4656/4656 [==============================] - 0s 47us/step - loss: 0.2417 - acc: 0.9250 - val_loss: 0.2325 - val_acc: 0.9265\n",
      "Epoch 77/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.2352 - acc: 0.9255 - val_loss: 0.2228 - val_acc: 0.9338\n",
      "Epoch 78/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.2269 - acc: 0.9296 - val_loss: 0.2170 - val_acc: 0.9330\n",
      "Epoch 79/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.2194 - acc: 0.9328 - val_loss: 0.2096 - val_acc: 0.9360\n",
      "Epoch 80/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.2116 - acc: 0.9358 - val_loss: 0.2116 - val_acc: 0.9358\n",
      "Epoch 81/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.2044 - acc: 0.9373 - val_loss: 0.1965 - val_acc: 0.9409\n",
      "Epoch 82/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.2002 - acc: 0.9369 - val_loss: 0.1878 - val_acc: 0.9429\n",
      "Epoch 83/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.1913 - acc: 0.9407 - val_loss: 0.1851 - val_acc: 0.9405\n",
      "Epoch 84/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.1868 - acc: 0.9418 - val_loss: 0.1776 - val_acc: 0.9500\n",
      "Epoch 85/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.1803 - acc: 0.9452 - val_loss: 0.1723 - val_acc: 0.9472\n",
      "Epoch 86/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.1757 - acc: 0.9467 - val_loss: 0.1677 - val_acc: 0.9536\n",
      "Epoch 87/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.1716 - acc: 0.9476 - val_loss: 0.1659 - val_acc: 0.9480\n",
      "Epoch 88/200\n",
      "4656/4656 [==============================] - 0s 60us/step - loss: 0.1681 - acc: 0.9489 - val_loss: 0.1586 - val_acc: 0.9502\n",
      "Epoch 89/200\n",
      "4656/4656 [==============================] - 0s 62us/step - loss: 0.1612 - acc: 0.9517 - val_loss: 0.1527 - val_acc: 0.9568\n",
      "Epoch 90/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.1581 - acc: 0.9547 - val_loss: 0.1540 - val_acc: 0.9598\n",
      "Epoch 91/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.1532 - acc: 0.9512 - val_loss: 0.1482 - val_acc: 0.9577\n",
      "Epoch 92/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.1518 - acc: 0.9547 - val_loss: 0.1441 - val_acc: 0.9562\n",
      "Epoch 93/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.1478 - acc: 0.9573 - val_loss: 0.1394 - val_acc: 0.9633\n",
      "Epoch 94/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.1427 - acc: 0.9577 - val_loss: 0.1405 - val_acc: 0.9659\n",
      "Epoch 95/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.1414 - acc: 0.9605 - val_loss: 0.1338 - val_acc: 0.9626\n",
      "Epoch 96/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.1381 - acc: 0.9626 - val_loss: 0.1313 - val_acc: 0.9637\n",
      "Epoch 97/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.1348 - acc: 0.9605 - val_loss: 0.1286 - val_acc: 0.9622\n",
      "Epoch 98/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.1304 - acc: 0.9652 - val_loss: 0.1250 - val_acc: 0.9635\n",
      "Epoch 99/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.1279 - acc: 0.9646 - val_loss: 0.1239 - val_acc: 0.9656\n",
      "Epoch 100/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.1244 - acc: 0.9671 - val_loss: 0.1217 - val_acc: 0.9650\n",
      "Epoch 101/200\n",
      "4656/4656 [==============================] - 0s 47us/step - loss: 0.1233 - acc: 0.9648 - val_loss: 0.1215 - val_acc: 0.9704\n",
      "Epoch 102/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.1224 - acc: 0.9665 - val_loss: 0.1159 - val_acc: 0.9697\n",
      "Epoch 103/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.1195 - acc: 0.9682 - val_loss: 0.1138 - val_acc: 0.9701\n",
      "Epoch 104/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.1160 - acc: 0.9695 - val_loss: 0.1160 - val_acc: 0.9682\n",
      "Epoch 105/200\n",
      "4656/4656 [==============================] - 0s 61us/step - loss: 0.1145 - acc: 0.9704 - val_loss: 0.1075 - val_acc: 0.9738\n",
      "Epoch 106/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.1125 - acc: 0.9725 - val_loss: 0.1087 - val_acc: 0.9732\n",
      "Epoch 107/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.1126 - acc: 0.9725 - val_loss: 0.1133 - val_acc: 0.9674\n",
      "Epoch 108/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.1097 - acc: 0.9697 - val_loss: 0.1044 - val_acc: 0.9723\n",
      "Epoch 109/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.1075 - acc: 0.9734 - val_loss: 0.1010 - val_acc: 0.9751\n",
      "Epoch 110/200\n",
      "4656/4656 [==============================] - 0s 58us/step - loss: 0.1046 - acc: 0.9734 - val_loss: 0.1063 - val_acc: 0.9704\n",
      "Epoch 111/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.1032 - acc: 0.9742 - val_loss: 0.0993 - val_acc: 0.9721\n",
      "Epoch 112/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0992 - acc: 0.9734 - val_loss: 0.0988 - val_acc: 0.9779\n",
      "Epoch 113/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0993 - acc: 0.9753 - val_loss: 0.0946 - val_acc: 0.9768\n",
      "Epoch 114/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0972 - acc: 0.9753 - val_loss: 0.0926 - val_acc: 0.9768\n",
      "Epoch 115/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0956 - acc: 0.9766 - val_loss: 0.0930 - val_acc: 0.9772\n",
      "Epoch 116/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0957 - acc: 0.9764 - val_loss: 0.0922 - val_acc: 0.9774\n",
      "Epoch 117/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.0963 - acc: 0.9755 - val_loss: 0.0877 - val_acc: 0.9787\n",
      "Epoch 118/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0923 - acc: 0.9774 - val_loss: 0.0892 - val_acc: 0.9781\n",
      "Epoch 119/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0901 - acc: 0.9768 - val_loss: 0.0869 - val_acc: 0.9792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0893 - acc: 0.9779 - val_loss: 0.0907 - val_acc: 0.9794\n",
      "Epoch 121/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0904 - acc: 0.9792 - val_loss: 0.0836 - val_acc: 0.9794\n",
      "Epoch 122/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0875 - acc: 0.9781 - val_loss: 0.0820 - val_acc: 0.9802\n",
      "Epoch 123/200\n",
      "4656/4656 [==============================] - 0s 46us/step - loss: 0.0869 - acc: 0.9762 - val_loss: 0.0863 - val_acc: 0.9792\n",
      "Epoch 124/200\n",
      "4656/4656 [==============================] - 0s 47us/step - loss: 0.0821 - acc: 0.9800 - val_loss: 0.0790 - val_acc: 0.9796\n",
      "Epoch 125/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0825 - acc: 0.9790 - val_loss: 0.0774 - val_acc: 0.9811\n",
      "Epoch 126/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0813 - acc: 0.9790 - val_loss: 0.0794 - val_acc: 0.9809\n",
      "Epoch 127/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0802 - acc: 0.9805 - val_loss: 0.0766 - val_acc: 0.9800\n",
      "Epoch 128/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0807 - acc: 0.9798 - val_loss: 0.0798 - val_acc: 0.9822\n",
      "Epoch 129/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.0803 - acc: 0.9787 - val_loss: 0.0773 - val_acc: 0.9798\n",
      "Epoch 130/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0769 - acc: 0.9805 - val_loss: 0.0805 - val_acc: 0.9768\n",
      "Epoch 131/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0764 - acc: 0.9802 - val_loss: 0.0752 - val_acc: 0.9822\n",
      "Epoch 132/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.0770 - acc: 0.9807 - val_loss: 0.0703 - val_acc: 0.9815\n",
      "Epoch 133/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0748 - acc: 0.9811 - val_loss: 0.0709 - val_acc: 0.9826\n",
      "Epoch 134/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0725 - acc: 0.9820 - val_loss: 0.0714 - val_acc: 0.9805\n",
      "Epoch 135/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0734 - acc: 0.9824 - val_loss: 0.0709 - val_acc: 0.9817\n",
      "Epoch 136/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.0719 - acc: 0.9824 - val_loss: 0.0693 - val_acc: 0.9820\n",
      "Epoch 137/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0716 - acc: 0.9822 - val_loss: 0.0677 - val_acc: 0.9839\n",
      "Epoch 138/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0698 - acc: 0.9822 - val_loss: 0.0662 - val_acc: 0.9845\n",
      "Epoch 139/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0682 - acc: 0.9826 - val_loss: 0.0664 - val_acc: 0.9830\n",
      "Epoch 140/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0690 - acc: 0.9820 - val_loss: 0.0741 - val_acc: 0.9824\n",
      "Epoch 141/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0693 - acc: 0.9824 - val_loss: 0.0637 - val_acc: 0.9837\n",
      "Epoch 142/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0693 - acc: 0.9807 - val_loss: 0.0641 - val_acc: 0.9826\n",
      "Epoch 143/200\n",
      "4656/4656 [==============================] - 0s 47us/step - loss: 0.0663 - acc: 0.9820 - val_loss: 0.0637 - val_acc: 0.9835\n",
      "Epoch 144/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0649 - acc: 0.9841 - val_loss: 0.0647 - val_acc: 0.9850\n",
      "Epoch 145/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0656 - acc: 0.9832 - val_loss: 0.0597 - val_acc: 0.9848\n",
      "Epoch 146/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0642 - acc: 0.9811 - val_loss: 0.0664 - val_acc: 0.9837\n",
      "Epoch 147/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.0659 - acc: 0.9830 - val_loss: 0.0599 - val_acc: 0.9852\n",
      "Epoch 148/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0646 - acc: 0.9832 - val_loss: 0.0599 - val_acc: 0.9845\n",
      "Epoch 149/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0624 - acc: 0.9843 - val_loss: 0.0607 - val_acc: 0.9843\n",
      "Epoch 150/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0618 - acc: 0.9839 - val_loss: 0.0570 - val_acc: 0.9858\n",
      "Epoch 151/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.0613 - acc: 0.9837 - val_loss: 0.0585 - val_acc: 0.9852\n",
      "Epoch 152/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0630 - acc: 0.9841 - val_loss: 0.0580 - val_acc: 0.9843\n",
      "Epoch 153/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0606 - acc: 0.9845 - val_loss: 0.0598 - val_acc: 0.9828\n",
      "Epoch 154/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0584 - acc: 0.9865 - val_loss: 0.0636 - val_acc: 0.9815\n",
      "Epoch 155/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.0629 - acc: 0.9839 - val_loss: 0.0559 - val_acc: 0.9865\n",
      "Epoch 156/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0577 - acc: 0.9854 - val_loss: 0.0547 - val_acc: 0.9867\n",
      "Epoch 157/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0563 - acc: 0.9860 - val_loss: 0.0546 - val_acc: 0.9867\n",
      "Epoch 158/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0569 - acc: 0.9854 - val_loss: 0.0545 - val_acc: 0.9865\n",
      "Epoch 159/200\n",
      "4656/4656 [==============================] - 0s 47us/step - loss: 0.0554 - acc: 0.9863 - val_loss: 0.0528 - val_acc: 0.9867\n",
      "Epoch 160/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0553 - acc: 0.9860 - val_loss: 0.0542 - val_acc: 0.9871\n",
      "Epoch 161/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0593 - acc: 0.9852 - val_loss: 0.0554 - val_acc: 0.9860\n",
      "Epoch 162/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0561 - acc: 0.9848 - val_loss: 0.0552 - val_acc: 0.9841\n",
      "Epoch 163/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0541 - acc: 0.9863 - val_loss: 0.0522 - val_acc: 0.9858\n",
      "Epoch 164/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0558 - acc: 0.9850 - val_loss: 0.0574 - val_acc: 0.9854\n",
      "Epoch 165/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0551 - acc: 0.9858 - val_loss: 0.0524 - val_acc: 0.9873\n",
      "Epoch 166/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.0517 - acc: 0.9873 - val_loss: 0.0490 - val_acc: 0.9875\n",
      "Epoch 167/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0537 - acc: 0.9850 - val_loss: 0.0506 - val_acc: 0.9873\n",
      "Epoch 168/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0515 - acc: 0.9875 - val_loss: 0.0509 - val_acc: 0.9860\n",
      "Epoch 169/200\n",
      "4656/4656 [==============================] - 0s 63us/step - loss: 0.0530 - acc: 0.9869 - val_loss: 0.0494 - val_acc: 0.9863\n",
      "Epoch 170/200\n",
      "4656/4656 [==============================] - 0s 60us/step - loss: 0.0512 - acc: 0.9869 - val_loss: 0.0473 - val_acc: 0.9873\n",
      "Epoch 171/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0509 - acc: 0.9869 - val_loss: 0.0486 - val_acc: 0.9873\n",
      "Epoch 172/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.0509 - acc: 0.9871 - val_loss: 0.0469 - val_acc: 0.9886\n",
      "Epoch 173/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.0502 - acc: 0.9875 - val_loss: 0.0475 - val_acc: 0.9873\n",
      "Epoch 174/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0494 - acc: 0.9860 - val_loss: 0.0477 - val_acc: 0.9873\n",
      "Epoch 175/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0492 - acc: 0.9875 - val_loss: 0.0471 - val_acc: 0.9888\n",
      "Epoch 176/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0493 - acc: 0.9873 - val_loss: 0.0498 - val_acc: 0.9873\n",
      "Epoch 177/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0505 - acc: 0.9875 - val_loss: 0.0466 - val_acc: 0.9873\n",
      "Epoch 178/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0491 - acc: 0.9875 - val_loss: 0.0519 - val_acc: 0.9871\n",
      "Epoch 179/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0476 - acc: 0.9880 - val_loss: 0.0535 - val_acc: 0.9787\n",
      "Epoch 180/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0496 - acc: 0.9871 - val_loss: 0.0450 - val_acc: 0.9878\n",
      "Epoch 181/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0476 - acc: 0.9875 - val_loss: 0.0451 - val_acc: 0.9882\n",
      "Epoch 182/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0466 - acc: 0.9873 - val_loss: 0.0435 - val_acc: 0.9886\n",
      "Epoch 183/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0470 - acc: 0.9873 - val_loss: 0.0469 - val_acc: 0.9875\n",
      "Epoch 184/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0464 - acc: 0.9875 - val_loss: 0.0433 - val_acc: 0.9888\n",
      "Epoch 185/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0488 - acc: 0.9869 - val_loss: 0.0423 - val_acc: 0.9890\n",
      "Epoch 186/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0459 - acc: 0.9878 - val_loss: 0.0410 - val_acc: 0.9890\n",
      "Epoch 187/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0453 - acc: 0.9875 - val_loss: 0.0454 - val_acc: 0.9893\n",
      "Epoch 188/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0470 - acc: 0.9873 - val_loss: 0.0421 - val_acc: 0.9888\n",
      "Epoch 189/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0461 - acc: 0.9878 - val_loss: 0.0433 - val_acc: 0.9893\n",
      "Epoch 190/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0459 - acc: 0.9888 - val_loss: 0.0421 - val_acc: 0.9880\n",
      "Epoch 191/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0440 - acc: 0.9878 - val_loss: 0.0409 - val_acc: 0.9882\n",
      "Epoch 192/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0435 - acc: 0.9880 - val_loss: 0.0401 - val_acc: 0.9893\n",
      "Epoch 193/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0436 - acc: 0.9890 - val_loss: 0.0409 - val_acc: 0.9886\n",
      "Epoch 194/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0423 - acc: 0.9878 - val_loss: 0.0407 - val_acc: 0.9886\n",
      "Epoch 195/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0433 - acc: 0.9886 - val_loss: 0.0405 - val_acc: 0.9895\n",
      "Epoch 196/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0446 - acc: 0.9873 - val_loss: 0.0406 - val_acc: 0.9899\n",
      "Epoch 197/200\n",
      "4656/4656 [==============================] - 0s 57us/step - loss: 0.0429 - acc: 0.9886 - val_loss: 0.0422 - val_acc: 0.9878\n",
      "Epoch 198/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.0418 - acc: 0.9886 - val_loss: 0.0386 - val_acc: 0.9901\n",
      "Epoch 199/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0418 - acc: 0.9893 - val_loss: 0.0387 - val_acc: 0.9884\n",
      "Epoch 200/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0409 - acc: 0.9882 - val_loss: 0.0421 - val_acc: 0.9886\n",
      "1164/1164 [==============================] - 0s 73us/step\n",
      "4656/4656 [==============================] - 0s 59us/step\n",
      "Train on 4656 samples, validate on 4656 samples\n",
      "Epoch 1/200\n",
      "4656/4656 [==============================] - 3s 598us/step - loss: 0.9895 - acc: 0.5586 - val_loss: 0.9238 - val_acc: 0.6091\n",
      "Epoch 2/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.9056 - acc: 0.6110 - val_loss: 0.8883 - val_acc: 0.6136\n",
      "Epoch 3/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.8785 - acc: 0.6125 - val_loss: 0.8675 - val_acc: 0.6145\n",
      "Epoch 4/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.8637 - acc: 0.6145 - val_loss: 0.8549 - val_acc: 0.6162\n",
      "Epoch 5/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.8548 - acc: 0.6166 - val_loss: 0.8472 - val_acc: 0.6211\n",
      "Epoch 6/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.8487 - acc: 0.6196 - val_loss: 0.8394 - val_acc: 0.6194\n",
      "Epoch 7/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.8398 - acc: 0.6222 - val_loss: 0.8323 - val_acc: 0.6235\n",
      "Epoch 8/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.8325 - acc: 0.6213 - val_loss: 0.8287 - val_acc: 0.6259\n",
      "Epoch 9/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.8257 - acc: 0.6280 - val_loss: 0.8201 - val_acc: 0.6256\n",
      "Epoch 10/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.8202 - acc: 0.6291 - val_loss: 0.8114 - val_acc: 0.6329\n",
      "Epoch 11/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.8136 - acc: 0.6304 - val_loss: 0.8080 - val_acc: 0.6379\n",
      "Epoch 12/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.8092 - acc: 0.6304 - val_loss: 0.8027 - val_acc: 0.6334\n",
      "Epoch 13/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.8018 - acc: 0.6362 - val_loss: 0.7930 - val_acc: 0.6411\n",
      "Epoch 14/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.7954 - acc: 0.6439 - val_loss: 0.7871 - val_acc: 0.6430\n",
      "Epoch 15/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.7880 - acc: 0.6418 - val_loss: 0.7789 - val_acc: 0.6435\n",
      "Epoch 16/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.7806 - acc: 0.6448 - val_loss: 0.7739 - val_acc: 0.6460\n",
      "Epoch 17/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.7738 - acc: 0.6516 - val_loss: 0.7662 - val_acc: 0.6617\n",
      "Epoch 18/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.7680 - acc: 0.6523 - val_loss: 0.7603 - val_acc: 0.6626\n",
      "Epoch 19/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.7605 - acc: 0.6538 - val_loss: 0.7520 - val_acc: 0.6553\n",
      "Epoch 20/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.7553 - acc: 0.6576 - val_loss: 0.7418 - val_acc: 0.6656\n",
      "Epoch 21/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.7441 - acc: 0.6585 - val_loss: 0.7350 - val_acc: 0.6622\n",
      "Epoch 22/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.7369 - acc: 0.6619 - val_loss: 0.7303 - val_acc: 0.6628\n",
      "Epoch 23/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.7298 - acc: 0.6641 - val_loss: 0.7220 - val_acc: 0.6692\n",
      "Epoch 24/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.7236 - acc: 0.6718 - val_loss: 0.7142 - val_acc: 0.6768\n",
      "Epoch 25/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.7166 - acc: 0.6727 - val_loss: 0.7077 - val_acc: 0.6838\n",
      "Epoch 26/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.7101 - acc: 0.6798 - val_loss: 0.6986 - val_acc: 0.6871\n",
      "Epoch 27/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.7023 - acc: 0.6862 - val_loss: 0.6901 - val_acc: 0.6950\n",
      "Epoch 28/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.6942 - acc: 0.6854 - val_loss: 0.6848 - val_acc: 0.6970\n",
      "Epoch 29/200\n",
      "4656/4656 [==============================] - 0s 47us/step - loss: 0.6855 - acc: 0.6991 - val_loss: 0.6770 - val_acc: 0.6931\n",
      "Epoch 30/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.6805 - acc: 0.6995 - val_loss: 0.6692 - val_acc: 0.7032\n",
      "Epoch 31/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.6745 - acc: 0.6987 - val_loss: 0.6644 - val_acc: 0.7148\n",
      "Epoch 32/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.6671 - acc: 0.7088 - val_loss: 0.6662 - val_acc: 0.6993\n",
      "Epoch 33/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.6632 - acc: 0.7068 - val_loss: 0.6530 - val_acc: 0.7083\n",
      "Epoch 34/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.6552 - acc: 0.7163 - val_loss: 0.6454 - val_acc: 0.7236\n",
      "Epoch 35/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.6482 - acc: 0.7201 - val_loss: 0.6391 - val_acc: 0.7313\n",
      "Epoch 36/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.6433 - acc: 0.7251 - val_loss: 0.6331 - val_acc: 0.7322\n",
      "Epoch 37/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.6383 - acc: 0.7277 - val_loss: 0.6266 - val_acc: 0.7356\n",
      "Epoch 38/200\n",
      "4656/4656 [==============================] - 0s 61us/step - loss: 0.6302 - acc: 0.7352 - val_loss: 0.6306 - val_acc: 0.7339\n",
      "Epoch 39/200\n",
      "4656/4656 [==============================] - 0s 65us/step - loss: 0.6268 - acc: 0.7371 - val_loss: 0.6171 - val_acc: 0.7403\n",
      "Epoch 40/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.6174 - acc: 0.7386 - val_loss: 0.6114 - val_acc: 0.7418\n",
      "Epoch 41/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.6124 - acc: 0.7386 - val_loss: 0.6031 - val_acc: 0.7513\n",
      "Epoch 42/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.6093 - acc: 0.7436 - val_loss: 0.6019 - val_acc: 0.7461\n",
      "Epoch 43/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.6024 - acc: 0.7453 - val_loss: 0.5948 - val_acc: 0.7453\n",
      "Epoch 44/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.5970 - acc: 0.7481 - val_loss: 0.5864 - val_acc: 0.7582\n",
      "Epoch 45/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.5904 - acc: 0.7547 - val_loss: 0.5835 - val_acc: 0.7610\n",
      "Epoch 46/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.5860 - acc: 0.7554 - val_loss: 0.5733 - val_acc: 0.7676\n",
      "Epoch 47/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.5786 - acc: 0.7633 - val_loss: 0.5749 - val_acc: 0.7620\n",
      "Epoch 48/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.5759 - acc: 0.7616 - val_loss: 0.5649 - val_acc: 0.7672\n",
      "Epoch 49/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.5688 - acc: 0.7646 - val_loss: 0.5637 - val_acc: 0.7674\n",
      "Epoch 50/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.5631 - acc: 0.7689 - val_loss: 0.5560 - val_acc: 0.7732\n",
      "Epoch 51/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.5601 - acc: 0.7674 - val_loss: 0.5528 - val_acc: 0.7777\n",
      "Epoch 52/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.5539 - acc: 0.7706 - val_loss: 0.5455 - val_acc: 0.7833\n",
      "Epoch 53/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.5467 - acc: 0.7820 - val_loss: 0.5352 - val_acc: 0.7869\n",
      "Epoch 54/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.5414 - acc: 0.7837 - val_loss: 0.5324 - val_acc: 0.7816\n",
      "Epoch 55/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.5344 - acc: 0.7869 - val_loss: 0.5262 - val_acc: 0.7891\n",
      "Epoch 56/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.5297 - acc: 0.7878 - val_loss: 0.5269 - val_acc: 0.7878\n",
      "Epoch 57/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.5267 - acc: 0.7889 - val_loss: 0.5141 - val_acc: 0.7992\n",
      "Epoch 58/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.5207 - acc: 0.7876 - val_loss: 0.5117 - val_acc: 0.7917\n",
      "Epoch 59/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.5162 - acc: 0.7938 - val_loss: 0.5059 - val_acc: 0.7953\n",
      "Epoch 60/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.5089 - acc: 0.7994 - val_loss: 0.5039 - val_acc: 0.7955\n",
      "Epoch 61/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.5043 - acc: 0.7990 - val_loss: 0.4995 - val_acc: 0.8024\n",
      "Epoch 62/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.4990 - acc: 0.8020 - val_loss: 0.4910 - val_acc: 0.8052\n",
      "Epoch 63/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.4949 - acc: 0.8043 - val_loss: 0.4819 - val_acc: 0.8091\n",
      "Epoch 64/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.4862 - acc: 0.8080 - val_loss: 0.4879 - val_acc: 0.8058\n",
      "Epoch 65/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.4887 - acc: 0.8080 - val_loss: 0.4721 - val_acc: 0.8183\n",
      "Epoch 66/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.4761 - acc: 0.8151 - val_loss: 0.4664 - val_acc: 0.8187\n",
      "Epoch 67/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.4684 - acc: 0.8164 - val_loss: 0.4620 - val_acc: 0.8127\n",
      "Epoch 68/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.4631 - acc: 0.8194 - val_loss: 0.4519 - val_acc: 0.8230\n",
      "Epoch 69/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.4591 - acc: 0.8194 - val_loss: 0.4507 - val_acc: 0.8271\n",
      "Epoch 70/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.4515 - acc: 0.8243 - val_loss: 0.4408 - val_acc: 0.8357\n",
      "Epoch 71/200\n",
      "4656/4656 [==============================] - 0s 58us/step - loss: 0.4433 - acc: 0.8329 - val_loss: 0.4414 - val_acc: 0.8314\n",
      "Epoch 72/200\n",
      "4656/4656 [==============================] - 0s 59us/step - loss: 0.4395 - acc: 0.8355 - val_loss: 0.4260 - val_acc: 0.8374\n",
      "Epoch 73/200\n",
      "4656/4656 [==============================] - 0s 56us/step - loss: 0.4303 - acc: 0.8385 - val_loss: 0.4244 - val_acc: 0.8432\n",
      "Epoch 74/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.4273 - acc: 0.8419 - val_loss: 0.4179 - val_acc: 0.8507\n",
      "Epoch 75/200\n",
      "4656/4656 [==============================] - 0s 59us/step - loss: 0.4157 - acc: 0.8477 - val_loss: 0.4071 - val_acc: 0.8509\n",
      "Epoch 76/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.4109 - acc: 0.8497 - val_loss: 0.3984 - val_acc: 0.8537\n",
      "Epoch 77/200\n",
      "4656/4656 [==============================] - 0s 58us/step - loss: 0.4010 - acc: 0.8540 - val_loss: 0.3909 - val_acc: 0.8610\n",
      "Epoch 78/200\n",
      "4656/4656 [==============================] - 0s 57us/step - loss: 0.3943 - acc: 0.8563 - val_loss: 0.3815 - val_acc: 0.8619\n",
      "Epoch 79/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.3924 - acc: 0.8570 - val_loss: 0.3847 - val_acc: 0.8658\n",
      "Epoch 80/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.3801 - acc: 0.8636 - val_loss: 0.3707 - val_acc: 0.8638\n",
      "Epoch 81/200\n",
      "4656/4656 [==============================] - 0s 68us/step - loss: 0.3736 - acc: 0.8713 - val_loss: 0.3609 - val_acc: 0.8784\n",
      "Epoch 82/200\n",
      "4656/4656 [==============================] - 0s 56us/step - loss: 0.3632 - acc: 0.8731 - val_loss: 0.3550 - val_acc: 0.8763\n",
      "Epoch 83/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.3555 - acc: 0.8741 - val_loss: 0.3452 - val_acc: 0.8845\n",
      "Epoch 84/200\n",
      "4656/4656 [==============================] - 0s 62us/step - loss: 0.3480 - acc: 0.8789 - val_loss: 0.3316 - val_acc: 0.8840\n",
      "Epoch 85/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.3377 - acc: 0.8847 - val_loss: 0.3275 - val_acc: 0.8808\n",
      "Epoch 86/200\n",
      "4656/4656 [==============================] - 0s 58us/step - loss: 0.3285 - acc: 0.8857 - val_loss: 0.3141 - val_acc: 0.8909\n",
      "Epoch 87/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.3178 - acc: 0.8898 - val_loss: 0.3066 - val_acc: 0.8978\n",
      "Epoch 88/200\n",
      "4656/4656 [==============================] - 0s 57us/step - loss: 0.3076 - acc: 0.8948 - val_loss: 0.2981 - val_acc: 0.9034\n",
      "Epoch 89/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.3006 - acc: 0.8988 - val_loss: 0.2905 - val_acc: 0.9087\n",
      "Epoch 90/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.2885 - acc: 0.9094 - val_loss: 0.2775 - val_acc: 0.9137\n",
      "Epoch 91/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.2804 - acc: 0.9098 - val_loss: 0.2713 - val_acc: 0.9212\n",
      "Epoch 92/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.2699 - acc: 0.9158 - val_loss: 0.2624 - val_acc: 0.9184\n",
      "Epoch 93/200\n",
      "4656/4656 [==============================] - 0s 59us/step - loss: 0.2607 - acc: 0.9175 - val_loss: 0.2491 - val_acc: 0.9300\n",
      "Epoch 94/200\n",
      "4656/4656 [==============================] - 0s 56us/step - loss: 0.2512 - acc: 0.9229 - val_loss: 0.2395 - val_acc: 0.9300\n",
      "Epoch 95/200\n",
      "4656/4656 [==============================] - 0s 59us/step - loss: 0.2430 - acc: 0.9259 - val_loss: 0.2340 - val_acc: 0.9319\n",
      "Epoch 96/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.2372 - acc: 0.9283 - val_loss: 0.2279 - val_acc: 0.9270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.2270 - acc: 0.9319 - val_loss: 0.2198 - val_acc: 0.9272\n",
      "Epoch 98/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.2166 - acc: 0.9351 - val_loss: 0.2078 - val_acc: 0.9390\n",
      "Epoch 99/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.2071 - acc: 0.9379 - val_loss: 0.2092 - val_acc: 0.9381\n",
      "Epoch 100/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.2073 - acc: 0.9371 - val_loss: 0.1952 - val_acc: 0.9448\n",
      "Epoch 101/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.1959 - acc: 0.9405 - val_loss: 0.1890 - val_acc: 0.9448\n",
      "Epoch 102/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.1906 - acc: 0.9386 - val_loss: 0.1857 - val_acc: 0.9433\n",
      "Epoch 103/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.1851 - acc: 0.9444 - val_loss: 0.1771 - val_acc: 0.9480\n",
      "Epoch 104/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.1796 - acc: 0.9480 - val_loss: 0.1691 - val_acc: 0.9502\n",
      "Epoch 105/200\n",
      "4656/4656 [==============================] - 0s 57us/step - loss: 0.1728 - acc: 0.9482 - val_loss: 0.1637 - val_acc: 0.9523\n",
      "Epoch 106/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.1682 - acc: 0.9497 - val_loss: 0.1687 - val_acc: 0.9543\n",
      "Epoch 107/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.1653 - acc: 0.9493 - val_loss: 0.1557 - val_acc: 0.9534\n",
      "Epoch 108/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.1590 - acc: 0.9523 - val_loss: 0.1531 - val_acc: 0.9558\n",
      "Epoch 109/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.1556 - acc: 0.9532 - val_loss: 0.1476 - val_acc: 0.9549\n",
      "Epoch 110/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.1520 - acc: 0.9543 - val_loss: 0.1470 - val_acc: 0.9577\n",
      "Epoch 111/200\n",
      "4656/4656 [==============================] - 0s 56us/step - loss: 0.1471 - acc: 0.9560 - val_loss: 0.1385 - val_acc: 0.9605\n",
      "Epoch 112/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.1429 - acc: 0.9560 - val_loss: 0.1391 - val_acc: 0.9609\n",
      "Epoch 113/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.1375 - acc: 0.9607 - val_loss: 0.1330 - val_acc: 0.9622\n",
      "Epoch 114/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.1353 - acc: 0.9611 - val_loss: 0.1301 - val_acc: 0.9639\n",
      "Epoch 115/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.1312 - acc: 0.9633 - val_loss: 0.1289 - val_acc: 0.9622\n",
      "Epoch 116/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.1292 - acc: 0.9622 - val_loss: 0.1287 - val_acc: 0.9598\n",
      "Epoch 117/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.1262 - acc: 0.9631 - val_loss: 0.1209 - val_acc: 0.9669\n",
      "Epoch 118/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.1244 - acc: 0.9654 - val_loss: 0.1176 - val_acc: 0.9689\n",
      "Epoch 119/200\n",
      "4656/4656 [==============================] - 0s 69us/step - loss: 0.1214 - acc: 0.9641 - val_loss: 0.1155 - val_acc: 0.9686\n",
      "Epoch 120/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.1208 - acc: 0.9652 - val_loss: 0.1166 - val_acc: 0.9682\n",
      "Epoch 121/200\n",
      "4656/4656 [==============================] - 0s 56us/step - loss: 0.1153 - acc: 0.9671 - val_loss: 0.1107 - val_acc: 0.9719\n",
      "Epoch 122/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.1127 - acc: 0.9708 - val_loss: 0.1099 - val_acc: 0.9706\n",
      "Epoch 123/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.1126 - acc: 0.9684 - val_loss: 0.1076 - val_acc: 0.9719\n",
      "Epoch 124/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.1089 - acc: 0.9701 - val_loss: 0.1071 - val_acc: 0.9671\n",
      "Epoch 125/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.1060 - acc: 0.9708 - val_loss: 0.1043 - val_acc: 0.9721\n",
      "Epoch 126/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.1050 - acc: 0.9714 - val_loss: 0.0993 - val_acc: 0.9729\n",
      "Epoch 127/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.1023 - acc: 0.9729 - val_loss: 0.0988 - val_acc: 0.9762\n",
      "Epoch 128/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.1036 - acc: 0.9710 - val_loss: 0.0953 - val_acc: 0.9794\n",
      "Epoch 129/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.0982 - acc: 0.9753 - val_loss: 0.0957 - val_acc: 0.9719\n",
      "Epoch 130/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0975 - acc: 0.9744 - val_loss: 0.0936 - val_acc: 0.9757\n",
      "Epoch 131/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0951 - acc: 0.9744 - val_loss: 0.0897 - val_acc: 0.9779\n",
      "Epoch 132/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.0942 - acc: 0.9774 - val_loss: 0.0903 - val_acc: 0.9762\n",
      "Epoch 133/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0926 - acc: 0.9768 - val_loss: 0.0896 - val_acc: 0.9781\n",
      "Epoch 134/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0916 - acc: 0.9759 - val_loss: 0.0907 - val_acc: 0.9732\n",
      "Epoch 135/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0896 - acc: 0.9774 - val_loss: 0.0849 - val_acc: 0.9796\n",
      "Epoch 136/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0865 - acc: 0.9783 - val_loss: 0.0829 - val_acc: 0.9790\n",
      "Epoch 137/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0875 - acc: 0.9792 - val_loss: 0.0953 - val_acc: 0.9736\n",
      "Epoch 138/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0867 - acc: 0.9785 - val_loss: 0.0807 - val_acc: 0.9805\n",
      "Epoch 139/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0841 - acc: 0.9798 - val_loss: 0.0788 - val_acc: 0.9822\n",
      "Epoch 140/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0814 - acc: 0.9794 - val_loss: 0.0781 - val_acc: 0.9824\n",
      "Epoch 141/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0820 - acc: 0.9796 - val_loss: 0.0760 - val_acc: 0.9824\n",
      "Epoch 142/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0814 - acc: 0.9800 - val_loss: 0.0765 - val_acc: 0.9830\n",
      "Epoch 143/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0781 - acc: 0.9813 - val_loss: 0.0733 - val_acc: 0.9828\n",
      "Epoch 144/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.0763 - acc: 0.9826 - val_loss: 0.0734 - val_acc: 0.9809\n",
      "Epoch 145/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0764 - acc: 0.9815 - val_loss: 0.0745 - val_acc: 0.9824\n",
      "Epoch 146/200\n",
      "4656/4656 [==============================] - 0s 57us/step - loss: 0.0764 - acc: 0.9815 - val_loss: 0.0741 - val_acc: 0.9824\n",
      "Epoch 147/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.0736 - acc: 0.9817 - val_loss: 0.0692 - val_acc: 0.9837\n",
      "Epoch 148/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0735 - acc: 0.9824 - val_loss: 0.0698 - val_acc: 0.9832\n",
      "Epoch 149/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0723 - acc: 0.9832 - val_loss: 0.0689 - val_acc: 0.9848\n",
      "Epoch 150/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0731 - acc: 0.9822 - val_loss: 0.0697 - val_acc: 0.9832\n",
      "Epoch 151/200\n",
      "4656/4656 [==============================] - 0s 56us/step - loss: 0.0707 - acc: 0.9828 - val_loss: 0.0654 - val_acc: 0.9852\n",
      "Epoch 152/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0695 - acc: 0.9837 - val_loss: 0.0641 - val_acc: 0.9854\n",
      "Epoch 153/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0663 - acc: 0.9854 - val_loss: 0.0638 - val_acc: 0.9837\n",
      "Epoch 154/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0688 - acc: 0.9826 - val_loss: 0.0625 - val_acc: 0.9869\n",
      "Epoch 155/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0645 - acc: 0.9845 - val_loss: 0.0676 - val_acc: 0.9828\n",
      "Epoch 156/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0645 - acc: 0.9826 - val_loss: 0.0668 - val_acc: 0.9828\n",
      "Epoch 157/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0635 - acc: 0.9850 - val_loss: 0.0619 - val_acc: 0.9850\n",
      "Epoch 158/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0646 - acc: 0.9841 - val_loss: 0.0590 - val_acc: 0.9867\n",
      "Epoch 159/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0624 - acc: 0.9848 - val_loss: 0.0672 - val_acc: 0.9802\n",
      "Epoch 160/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0621 - acc: 0.9845 - val_loss: 0.0573 - val_acc: 0.9852\n",
      "Epoch 161/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0600 - acc: 0.9848 - val_loss: 0.0608 - val_acc: 0.9845\n",
      "Epoch 162/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0575 - acc: 0.9856 - val_loss: 0.0573 - val_acc: 0.9869\n",
      "Epoch 163/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0579 - acc: 0.9852 - val_loss: 0.0568 - val_acc: 0.9869\n",
      "Epoch 164/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0584 - acc: 0.9854 - val_loss: 0.0544 - val_acc: 0.9854\n",
      "Epoch 165/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.0556 - acc: 0.9856 - val_loss: 0.0590 - val_acc: 0.9854\n",
      "Epoch 166/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0596 - acc: 0.9856 - val_loss: 0.0551 - val_acc: 0.9867\n",
      "Epoch 167/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0558 - acc: 0.9867 - val_loss: 0.0560 - val_acc: 0.9852\n",
      "Epoch 168/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0547 - acc: 0.9860 - val_loss: 0.0515 - val_acc: 0.9875\n",
      "Epoch 169/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0536 - acc: 0.9873 - val_loss: 0.0518 - val_acc: 0.9871\n",
      "Epoch 170/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0536 - acc: 0.9871 - val_loss: 0.0501 - val_acc: 0.9878\n",
      "Epoch 171/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0527 - acc: 0.9867 - val_loss: 0.0518 - val_acc: 0.9865\n",
      "Epoch 172/200\n",
      "4656/4656 [==============================] - 0s 46us/step - loss: 0.0530 - acc: 0.9873 - val_loss: 0.0518 - val_acc: 0.9858\n",
      "Epoch 173/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0527 - acc: 0.9869 - val_loss: 0.0485 - val_acc: 0.9880\n",
      "Epoch 174/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0512 - acc: 0.9869 - val_loss: 0.0488 - val_acc: 0.9880\n",
      "Epoch 175/200\n",
      "4656/4656 [==============================] - 0s 62us/step - loss: 0.0514 - acc: 0.9865 - val_loss: 0.0502 - val_acc: 0.9865\n",
      "Epoch 176/200\n",
      "4656/4656 [==============================] - 0s 65us/step - loss: 0.0513 - acc: 0.9869 - val_loss: 0.0496 - val_acc: 0.9871\n",
      "Epoch 177/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0515 - acc: 0.9873 - val_loss: 0.0474 - val_acc: 0.9884\n",
      "Epoch 178/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0482 - acc: 0.9884 - val_loss: 0.0478 - val_acc: 0.9873\n",
      "Epoch 179/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0489 - acc: 0.9865 - val_loss: 0.0467 - val_acc: 0.9895\n",
      "Epoch 180/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0504 - acc: 0.9863 - val_loss: 0.0472 - val_acc: 0.9882\n",
      "Epoch 181/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0488 - acc: 0.9884 - val_loss: 0.0494 - val_acc: 0.9880\n",
      "Epoch 182/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0487 - acc: 0.9869 - val_loss: 0.0454 - val_acc: 0.9886\n",
      "Epoch 183/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0470 - acc: 0.9886 - val_loss: 0.0429 - val_acc: 0.9893\n",
      "Epoch 184/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0485 - acc: 0.9867 - val_loss: 0.0479 - val_acc: 0.9884\n",
      "Epoch 185/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0477 - acc: 0.9890 - val_loss: 0.0469 - val_acc: 0.9865\n",
      "Epoch 186/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0467 - acc: 0.9882 - val_loss: 0.0436 - val_acc: 0.9893\n",
      "Epoch 187/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0455 - acc: 0.9882 - val_loss: 0.0458 - val_acc: 0.9878\n",
      "Epoch 188/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.0464 - acc: 0.9880 - val_loss: 0.0415 - val_acc: 0.9897\n",
      "Epoch 189/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0435 - acc: 0.9882 - val_loss: 0.0431 - val_acc: 0.9884\n",
      "Epoch 190/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0442 - acc: 0.9884 - val_loss: 0.0442 - val_acc: 0.9880\n",
      "Epoch 191/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0455 - acc: 0.9880 - val_loss: 0.0412 - val_acc: 0.9901\n",
      "Epoch 192/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0436 - acc: 0.9882 - val_loss: 0.0431 - val_acc: 0.9888\n",
      "Epoch 193/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0435 - acc: 0.9884 - val_loss: 0.0406 - val_acc: 0.9897\n",
      "Epoch 194/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0426 - acc: 0.9886 - val_loss: 0.0396 - val_acc: 0.9897\n",
      "Epoch 195/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0427 - acc: 0.9882 - val_loss: 0.0395 - val_acc: 0.9886\n",
      "Epoch 196/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.0425 - acc: 0.9886 - val_loss: 0.0408 - val_acc: 0.9886\n",
      "Epoch 197/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0427 - acc: 0.9882 - val_loss: 0.0410 - val_acc: 0.9901\n",
      "Epoch 198/200\n",
      "4656/4656 [==============================] - 0s 60us/step - loss: 0.0432 - acc: 0.9888 - val_loss: 0.0397 - val_acc: 0.9905\n",
      "Epoch 199/200\n",
      "4656/4656 [==============================] - 0s 61us/step - loss: 0.0440 - acc: 0.9873 - val_loss: 0.0392 - val_acc: 0.9897\n",
      "Epoch 200/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0407 - acc: 0.9899 - val_loss: 0.0387 - val_acc: 0.9895\n",
      "1164/1164 [==============================] - 0s 78us/step\n",
      "4656/4656 [==============================] - 0s 65us/step\n",
      "Train on 4656 samples, validate on 4656 samples\n",
      "Epoch 1/200\n",
      "4656/4656 [==============================] - 3s 595us/step - loss: 1.0038 - acc: 0.5348 - val_loss: 0.9146 - val_acc: 0.6158\n",
      "Epoch 2/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.9002 - acc: 0.6175 - val_loss: 0.8831 - val_acc: 0.6194\n",
      "Epoch 3/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.8773 - acc: 0.6181 - val_loss: 0.8683 - val_acc: 0.6190\n",
      "Epoch 4/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.8672 - acc: 0.6198 - val_loss: 0.8585 - val_acc: 0.6190\n",
      "Epoch 5/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.8570 - acc: 0.6186 - val_loss: 0.8529 - val_acc: 0.6196\n",
      "Epoch 6/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.8524 - acc: 0.6177 - val_loss: 0.8453 - val_acc: 0.6198\n",
      "Epoch 7/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.8459 - acc: 0.6213 - val_loss: 0.8392 - val_acc: 0.6239\n",
      "Epoch 8/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.8398 - acc: 0.6239 - val_loss: 0.8331 - val_acc: 0.6259\n",
      "Epoch 9/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.8351 - acc: 0.6244 - val_loss: 0.8284 - val_acc: 0.6280\n",
      "Epoch 10/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.8292 - acc: 0.6254 - val_loss: 0.8235 - val_acc: 0.6250\n",
      "Epoch 11/200\n",
      "4656/4656 [==============================] - 0s 56us/step - loss: 0.8245 - acc: 0.6265 - val_loss: 0.8184 - val_acc: 0.6347\n",
      "Epoch 12/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.8185 - acc: 0.6271 - val_loss: 0.8114 - val_acc: 0.6351\n",
      "Epoch 13/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.8164 - acc: 0.6312 - val_loss: 0.8062 - val_acc: 0.6368\n",
      "Epoch 14/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.8082 - acc: 0.6336 - val_loss: 0.8005 - val_acc: 0.6439\n",
      "Epoch 15/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.8002 - acc: 0.6411 - val_loss: 0.7966 - val_acc: 0.6387\n",
      "Epoch 16/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.7956 - acc: 0.6430 - val_loss: 0.7917 - val_acc: 0.6452\n",
      "Epoch 17/200\n",
      "4656/4656 [==============================] - 0s 47us/step - loss: 0.7896 - acc: 0.6460 - val_loss: 0.7837 - val_acc: 0.6508\n",
      "Epoch 18/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.7840 - acc: 0.6497 - val_loss: 0.7760 - val_acc: 0.6553\n",
      "Epoch 19/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.7806 - acc: 0.6529 - val_loss: 0.7712 - val_acc: 0.6523\n",
      "Epoch 20/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.7718 - acc: 0.6553 - val_loss: 0.7653 - val_acc: 0.6607\n",
      "Epoch 21/200\n",
      "4656/4656 [==============================] - 0s 62us/step - loss: 0.7662 - acc: 0.6527 - val_loss: 0.7565 - val_acc: 0.6596\n",
      "Epoch 22/200\n",
      "4656/4656 [==============================] - 0s 59us/step - loss: 0.7597 - acc: 0.6596 - val_loss: 0.7497 - val_acc: 0.6628\n",
      "Epoch 23/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.7540 - acc: 0.6645 - val_loss: 0.7452 - val_acc: 0.6684\n",
      "Epoch 24/200\n",
      "4656/4656 [==============================] - 0s 56us/step - loss: 0.7472 - acc: 0.6652 - val_loss: 0.7368 - val_acc: 0.6680\n",
      "Epoch 25/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.7400 - acc: 0.6677 - val_loss: 0.7324 - val_acc: 0.6740\n",
      "Epoch 26/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.7351 - acc: 0.6731 - val_loss: 0.7262 - val_acc: 0.6821\n",
      "Epoch 27/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.7278 - acc: 0.6738 - val_loss: 0.7198 - val_acc: 0.6759\n",
      "Epoch 28/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.7234 - acc: 0.6804 - val_loss: 0.7166 - val_acc: 0.6765\n",
      "Epoch 29/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.7144 - acc: 0.6817 - val_loss: 0.7064 - val_acc: 0.6866\n",
      "Epoch 30/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.7065 - acc: 0.6877 - val_loss: 0.6982 - val_acc: 0.6972\n",
      "Epoch 31/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.6996 - acc: 0.6935 - val_loss: 0.6914 - val_acc: 0.7000\n",
      "Epoch 32/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.6944 - acc: 0.6978 - val_loss: 0.6888 - val_acc: 0.6963\n",
      "Epoch 33/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.6899 - acc: 0.7006 - val_loss: 0.6799 - val_acc: 0.6991\n",
      "Epoch 34/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.6814 - acc: 0.7062 - val_loss: 0.6716 - val_acc: 0.7081\n",
      "Epoch 35/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.6776 - acc: 0.7062 - val_loss: 0.6650 - val_acc: 0.7214\n",
      "Epoch 36/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.6687 - acc: 0.7184 - val_loss: 0.6615 - val_acc: 0.7092\n",
      "Epoch 37/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.6641 - acc: 0.7216 - val_loss: 0.6508 - val_acc: 0.7320\n",
      "Epoch 38/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.6551 - acc: 0.7292 - val_loss: 0.6455 - val_acc: 0.7472\n",
      "Epoch 39/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.6534 - acc: 0.7294 - val_loss: 0.6392 - val_acc: 0.7461\n",
      "Epoch 40/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.6441 - acc: 0.7352 - val_loss: 0.6365 - val_acc: 0.7448\n",
      "Epoch 41/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.6357 - acc: 0.7436 - val_loss: 0.6261 - val_acc: 0.7448\n",
      "Epoch 42/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.6273 - acc: 0.7483 - val_loss: 0.6189 - val_acc: 0.7558\n",
      "Epoch 43/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.6217 - acc: 0.7517 - val_loss: 0.6145 - val_acc: 0.7588\n",
      "Epoch 44/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.6146 - acc: 0.7614 - val_loss: 0.6072 - val_acc: 0.7567\n",
      "Epoch 45/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.6056 - acc: 0.7610 - val_loss: 0.5958 - val_acc: 0.7702\n",
      "Epoch 46/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.5975 - acc: 0.7668 - val_loss: 0.5881 - val_acc: 0.7683\n",
      "Epoch 47/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.5896 - acc: 0.7751 - val_loss: 0.5816 - val_acc: 0.7706\n",
      "Epoch 48/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.5817 - acc: 0.7784 - val_loss: 0.5680 - val_acc: 0.7878\n",
      "Epoch 49/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.5715 - acc: 0.7786 - val_loss: 0.5600 - val_acc: 0.7951\n",
      "Epoch 50/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.5627 - acc: 0.7902 - val_loss: 0.5555 - val_acc: 0.7921\n",
      "Epoch 51/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.5504 - acc: 0.7938 - val_loss: 0.5343 - val_acc: 0.8030\n",
      "Epoch 52/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.5387 - acc: 0.7964 - val_loss: 0.5255 - val_acc: 0.8009\n",
      "Epoch 53/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.5272 - acc: 0.8007 - val_loss: 0.5151 - val_acc: 0.8054\n",
      "Epoch 54/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.5170 - acc: 0.8065 - val_loss: 0.5071 - val_acc: 0.8116\n",
      "Epoch 55/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.5054 - acc: 0.8112 - val_loss: 0.4954 - val_acc: 0.8121\n",
      "Epoch 56/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.4971 - acc: 0.8127 - val_loss: 0.4805 - val_acc: 0.8220\n",
      "Epoch 57/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.4825 - acc: 0.8200 - val_loss: 0.4665 - val_acc: 0.8256\n",
      "Epoch 58/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.4712 - acc: 0.8204 - val_loss: 0.4652 - val_acc: 0.8207\n",
      "Epoch 59/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.4609 - acc: 0.8239 - val_loss: 0.4436 - val_acc: 0.8288\n",
      "Epoch 60/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.4461 - acc: 0.8331 - val_loss: 0.4349 - val_acc: 0.8404\n",
      "Epoch 61/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.4368 - acc: 0.8348 - val_loss: 0.4221 - val_acc: 0.8432\n",
      "Epoch 62/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.4227 - acc: 0.8426 - val_loss: 0.4134 - val_acc: 0.8421\n",
      "Epoch 63/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.4100 - acc: 0.8475 - val_loss: 0.3952 - val_acc: 0.8548\n",
      "Epoch 64/200\n",
      "4656/4656 [==============================] - 0s 62us/step - loss: 0.3987 - acc: 0.8552 - val_loss: 0.3834 - val_acc: 0.8709\n",
      "Epoch 65/200\n",
      "4656/4656 [==============================] - 0s 61us/step - loss: 0.3857 - acc: 0.8660 - val_loss: 0.3740 - val_acc: 0.8683\n",
      "Epoch 66/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.3729 - acc: 0.8711 - val_loss: 0.3654 - val_acc: 0.8761\n",
      "Epoch 67/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.3639 - acc: 0.8799 - val_loss: 0.3497 - val_acc: 0.8847\n",
      "Epoch 68/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.3522 - acc: 0.8842 - val_loss: 0.3455 - val_acc: 0.8870\n",
      "Epoch 69/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.3412 - acc: 0.8860 - val_loss: 0.3313 - val_acc: 0.9016\n",
      "Epoch 70/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.3323 - acc: 0.8930 - val_loss: 0.3225 - val_acc: 0.8950\n",
      "Epoch 71/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.3254 - acc: 0.8926 - val_loss: 0.3132 - val_acc: 0.8954\n",
      "Epoch 72/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.3104 - acc: 0.8980 - val_loss: 0.3049 - val_acc: 0.8976\n",
      "Epoch 73/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.3028 - acc: 0.9049 - val_loss: 0.2913 - val_acc: 0.9051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.2937 - acc: 0.9038 - val_loss: 0.2812 - val_acc: 0.9096\n",
      "Epoch 75/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.2840 - acc: 0.9074 - val_loss: 0.2790 - val_acc: 0.9139\n",
      "Epoch 76/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.2761 - acc: 0.9152 - val_loss: 0.2660 - val_acc: 0.9158\n",
      "Epoch 77/200\n",
      "4656/4656 [==============================] - 0s 47us/step - loss: 0.2670 - acc: 0.9124 - val_loss: 0.2606 - val_acc: 0.9186\n",
      "Epoch 78/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.2614 - acc: 0.9169 - val_loss: 0.2520 - val_acc: 0.9235\n",
      "Epoch 79/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.2519 - acc: 0.9199 - val_loss: 0.2426 - val_acc: 0.9235\n",
      "Epoch 80/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.2433 - acc: 0.9238 - val_loss: 0.2344 - val_acc: 0.9257\n",
      "Epoch 81/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.2384 - acc: 0.9257 - val_loss: 0.2313 - val_acc: 0.9311\n",
      "Epoch 82/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.2305 - acc: 0.9300 - val_loss: 0.2188 - val_acc: 0.9334\n",
      "Epoch 83/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.2228 - acc: 0.9336 - val_loss: 0.2173 - val_acc: 0.9345\n",
      "Epoch 84/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.2198 - acc: 0.9341 - val_loss: 0.2085 - val_acc: 0.9377\n",
      "Epoch 85/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.2110 - acc: 0.9377 - val_loss: 0.1988 - val_acc: 0.9407\n",
      "Epoch 86/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.2006 - acc: 0.9399 - val_loss: 0.1942 - val_acc: 0.9412\n",
      "Epoch 87/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.1932 - acc: 0.9459 - val_loss: 0.1883 - val_acc: 0.9506\n",
      "Epoch 88/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.1885 - acc: 0.9476 - val_loss: 0.1778 - val_acc: 0.9540\n",
      "Epoch 89/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.1811 - acc: 0.9495 - val_loss: 0.1797 - val_acc: 0.9521\n",
      "Epoch 90/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.1763 - acc: 0.9517 - val_loss: 0.1669 - val_acc: 0.9564\n",
      "Epoch 91/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.1687 - acc: 0.9536 - val_loss: 0.1629 - val_acc: 0.9523\n",
      "Epoch 92/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.1633 - acc: 0.9553 - val_loss: 0.1582 - val_acc: 0.9590\n",
      "Epoch 93/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.1578 - acc: 0.9551 - val_loss: 0.1490 - val_acc: 0.9609\n",
      "Epoch 94/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.1523 - acc: 0.9607 - val_loss: 0.1445 - val_acc: 0.9626\n",
      "Epoch 95/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.1486 - acc: 0.9603 - val_loss: 0.1430 - val_acc: 0.9661\n",
      "Epoch 96/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.1433 - acc: 0.9654 - val_loss: 0.1346 - val_acc: 0.9650\n",
      "Epoch 97/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.1374 - acc: 0.9635 - val_loss: 0.1333 - val_acc: 0.9714\n",
      "Epoch 98/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.1343 - acc: 0.9646 - val_loss: 0.1271 - val_acc: 0.9699\n",
      "Epoch 99/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.1294 - acc: 0.9676 - val_loss: 0.1217 - val_acc: 0.9704\n",
      "Epoch 100/200\n",
      "4656/4656 [==============================] - 0s 66us/step - loss: 0.1245 - acc: 0.9689 - val_loss: 0.1191 - val_acc: 0.9701\n",
      "Epoch 101/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.1221 - acc: 0.9706 - val_loss: 0.1175 - val_acc: 0.9727\n",
      "Epoch 102/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.1173 - acc: 0.9716 - val_loss: 0.1138 - val_acc: 0.9710\n",
      "Epoch 103/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.1158 - acc: 0.9701 - val_loss: 0.1098 - val_acc: 0.9727\n",
      "Epoch 104/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.1111 - acc: 0.9721 - val_loss: 0.1144 - val_acc: 0.9738\n",
      "Epoch 105/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.1100 - acc: 0.9762 - val_loss: 0.1056 - val_acc: 0.9738\n",
      "Epoch 106/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.1076 - acc: 0.9744 - val_loss: 0.1045 - val_acc: 0.9732\n",
      "Epoch 107/200\n",
      "4656/4656 [==============================] - 0s 64us/step - loss: 0.1050 - acc: 0.9738 - val_loss: 0.1047 - val_acc: 0.9753\n",
      "Epoch 108/200\n",
      "4656/4656 [==============================] - 0s 61us/step - loss: 0.1048 - acc: 0.9747 - val_loss: 0.1000 - val_acc: 0.9759\n",
      "Epoch 109/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0987 - acc: 0.9770 - val_loss: 0.1008 - val_acc: 0.9779\n",
      "Epoch 110/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.0993 - acc: 0.9759 - val_loss: 0.0938 - val_acc: 0.9787\n",
      "Epoch 111/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0938 - acc: 0.9764 - val_loss: 0.0916 - val_acc: 0.9802\n",
      "Epoch 112/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0930 - acc: 0.9770 - val_loss: 0.0918 - val_acc: 0.9781\n",
      "Epoch 113/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0913 - acc: 0.9777 - val_loss: 0.0880 - val_acc: 0.9800\n",
      "Epoch 114/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0902 - acc: 0.9783 - val_loss: 0.0880 - val_acc: 0.9785\n",
      "Epoch 115/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0908 - acc: 0.9762 - val_loss: 0.0927 - val_acc: 0.9759\n",
      "Epoch 116/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0903 - acc: 0.9781 - val_loss: 0.0917 - val_acc: 0.9783\n",
      "Epoch 117/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0869 - acc: 0.9798 - val_loss: 0.0809 - val_acc: 0.9798\n",
      "Epoch 118/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0843 - acc: 0.9790 - val_loss: 0.0808 - val_acc: 0.9807\n",
      "Epoch 119/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0823 - acc: 0.9792 - val_loss: 0.0816 - val_acc: 0.9774\n",
      "Epoch 120/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0812 - acc: 0.9790 - val_loss: 0.0792 - val_acc: 0.9811\n",
      "Epoch 121/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0797 - acc: 0.9817 - val_loss: 0.0745 - val_acc: 0.9826\n",
      "Epoch 122/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0779 - acc: 0.9809 - val_loss: 0.0750 - val_acc: 0.9822\n",
      "Epoch 123/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0785 - acc: 0.9822 - val_loss: 0.0802 - val_acc: 0.9826\n",
      "Epoch 124/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0764 - acc: 0.9820 - val_loss: 0.0728 - val_acc: 0.9839\n",
      "Epoch 125/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.0760 - acc: 0.9813 - val_loss: 0.0714 - val_acc: 0.9843\n",
      "Epoch 126/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.0768 - acc: 0.9790 - val_loss: 0.0721 - val_acc: 0.9817\n",
      "Epoch 127/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0725 - acc: 0.9813 - val_loss: 0.0707 - val_acc: 0.9822\n",
      "Epoch 128/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0727 - acc: 0.9820 - val_loss: 0.0760 - val_acc: 0.9809\n",
      "Epoch 129/200\n",
      "4656/4656 [==============================] - 0s 67us/step - loss: 0.0732 - acc: 0.9822 - val_loss: 0.0697 - val_acc: 0.9837\n",
      "Epoch 130/200\n",
      "4656/4656 [==============================] - 0s 72us/step - loss: 0.0705 - acc: 0.9828 - val_loss: 0.0673 - val_acc: 0.9837\n",
      "Epoch 131/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0689 - acc: 0.9837 - val_loss: 0.0648 - val_acc: 0.9830\n",
      "Epoch 132/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0664 - acc: 0.9850 - val_loss: 0.0663 - val_acc: 0.9848\n",
      "Epoch 133/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0675 - acc: 0.9841 - val_loss: 0.0629 - val_acc: 0.9854\n",
      "Epoch 134/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.0661 - acc: 0.9845 - val_loss: 0.0617 - val_acc: 0.9863\n",
      "Epoch 135/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0689 - acc: 0.9820 - val_loss: 0.0658 - val_acc: 0.9845\n",
      "Epoch 136/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0629 - acc: 0.9845 - val_loss: 0.0612 - val_acc: 0.9850\n",
      "Epoch 137/200\n",
      "4656/4656 [==============================] - 0s 47us/step - loss: 0.0632 - acc: 0.9845 - val_loss: 0.0621 - val_acc: 0.9839\n",
      "Epoch 138/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0625 - acc: 0.9837 - val_loss: 0.0594 - val_acc: 0.9860\n",
      "Epoch 139/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0623 - acc: 0.9830 - val_loss: 0.0581 - val_acc: 0.9860\n",
      "Epoch 140/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0603 - acc: 0.9858 - val_loss: 0.0571 - val_acc: 0.9871\n",
      "Epoch 141/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0598 - acc: 0.9856 - val_loss: 0.0560 - val_acc: 0.9860\n",
      "Epoch 142/200\n",
      "4656/4656 [==============================] - 0s 56us/step - loss: 0.0586 - acc: 0.9850 - val_loss: 0.0601 - val_acc: 0.9830\n",
      "Epoch 143/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0582 - acc: 0.9852 - val_loss: 0.0551 - val_acc: 0.9858\n",
      "Epoch 144/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0576 - acc: 0.9858 - val_loss: 0.0551 - val_acc: 0.9858\n",
      "Epoch 145/200\n",
      "4656/4656 [==============================] - 0s 56us/step - loss: 0.0571 - acc: 0.9856 - val_loss: 0.0595 - val_acc: 0.9858\n",
      "Epoch 146/200\n",
      "4656/4656 [==============================] - 0s 59us/step - loss: 0.0573 - acc: 0.9863 - val_loss: 0.0567 - val_acc: 0.9856\n",
      "Epoch 147/200\n",
      "4656/4656 [==============================] - 0s 65us/step - loss: 0.0575 - acc: 0.9835 - val_loss: 0.0566 - val_acc: 0.9852\n",
      "Epoch 148/200\n",
      "4656/4656 [==============================] - 0s 58us/step - loss: 0.0565 - acc: 0.9863 - val_loss: 0.0535 - val_acc: 0.9860\n",
      "Epoch 149/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.0558 - acc: 0.9867 - val_loss: 0.0532 - val_acc: 0.9871\n",
      "Epoch 150/200\n",
      "4656/4656 [==============================] - 0s 56us/step - loss: 0.0554 - acc: 0.9858 - val_loss: 0.0517 - val_acc: 0.9860\n",
      "Epoch 151/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.0528 - acc: 0.9863 - val_loss: 0.0510 - val_acc: 0.9865\n",
      "Epoch 152/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0542 - acc: 0.9858 - val_loss: 0.0613 - val_acc: 0.9848\n",
      "Epoch 153/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0544 - acc: 0.9863 - val_loss: 0.0504 - val_acc: 0.9873\n",
      "Epoch 154/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.0522 - acc: 0.9867 - val_loss: 0.0501 - val_acc: 0.9878\n",
      "Epoch 155/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0519 - acc: 0.9875 - val_loss: 0.0495 - val_acc: 0.9880\n",
      "Epoch 156/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0513 - acc: 0.9873 - val_loss: 0.0513 - val_acc: 0.9867\n",
      "Epoch 157/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0505 - acc: 0.9878 - val_loss: 0.0499 - val_acc: 0.9875\n",
      "Epoch 158/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.0485 - acc: 0.9873 - val_loss: 0.0472 - val_acc: 0.9886\n",
      "Epoch 159/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0517 - acc: 0.9869 - val_loss: 0.0462 - val_acc: 0.9882\n",
      "Epoch 160/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0499 - acc: 0.9873 - val_loss: 0.0461 - val_acc: 0.9882\n",
      "Epoch 161/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.0472 - acc: 0.9873 - val_loss: 0.0461 - val_acc: 0.9882\n",
      "Epoch 162/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0499 - acc: 0.9867 - val_loss: 0.0462 - val_acc: 0.9882\n",
      "Epoch 163/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0469 - acc: 0.9882 - val_loss: 0.0446 - val_acc: 0.9886\n",
      "Epoch 164/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0497 - acc: 0.9858 - val_loss: 0.0485 - val_acc: 0.9871\n",
      "Epoch 165/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0474 - acc: 0.9867 - val_loss: 0.0431 - val_acc: 0.9886\n",
      "Epoch 166/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0455 - acc: 0.9886 - val_loss: 0.0463 - val_acc: 0.9871\n",
      "Epoch 167/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0468 - acc: 0.9871 - val_loss: 0.0423 - val_acc: 0.9882\n",
      "Epoch 168/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0441 - acc: 0.9882 - val_loss: 0.0466 - val_acc: 0.9878\n",
      "Epoch 169/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.0457 - acc: 0.9880 - val_loss: 0.0430 - val_acc: 0.9882\n",
      "Epoch 170/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.0457 - acc: 0.9880 - val_loss: 0.0423 - val_acc: 0.9884\n",
      "Epoch 171/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0441 - acc: 0.9886 - val_loss: 0.0416 - val_acc: 0.9888\n",
      "Epoch 172/200\n",
      "4656/4656 [==============================] - 0s 54us/step - loss: 0.0442 - acc: 0.9869 - val_loss: 0.0409 - val_acc: 0.9886\n",
      "Epoch 173/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0437 - acc: 0.9893 - val_loss: 0.0414 - val_acc: 0.9893\n",
      "Epoch 174/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0434 - acc: 0.9893 - val_loss: 0.0426 - val_acc: 0.9882\n",
      "Epoch 175/200\n",
      "4656/4656 [==============================] - 0s 56us/step - loss: 0.0436 - acc: 0.9884 - val_loss: 0.0446 - val_acc: 0.9865\n",
      "Epoch 176/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0431 - acc: 0.9882 - val_loss: 0.0437 - val_acc: 0.9895\n",
      "Epoch 177/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0439 - acc: 0.9882 - val_loss: 0.0396 - val_acc: 0.9884\n",
      "Epoch 178/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0411 - acc: 0.9882 - val_loss: 0.0403 - val_acc: 0.9888\n",
      "Epoch 179/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0413 - acc: 0.9890 - val_loss: 0.0402 - val_acc: 0.9890\n",
      "Epoch 180/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0457 - acc: 0.9878 - val_loss: 0.0406 - val_acc: 0.9886\n",
      "Epoch 181/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0434 - acc: 0.9882 - val_loss: 0.0380 - val_acc: 0.9893\n",
      "Epoch 182/200\n",
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0409 - acc: 0.9888 - val_loss: 0.0380 - val_acc: 0.9890\n",
      "Epoch 183/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.0412 - acc: 0.9875 - val_loss: 0.0383 - val_acc: 0.9890\n",
      "Epoch 184/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0417 - acc: 0.9884 - val_loss: 0.0380 - val_acc: 0.9888\n",
      "Epoch 185/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0407 - acc: 0.9886 - val_loss: 0.0381 - val_acc: 0.9895\n",
      "Epoch 186/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0408 - acc: 0.9884 - val_loss: 0.0370 - val_acc: 0.9890\n",
      "Epoch 187/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0394 - acc: 0.9888 - val_loss: 0.0393 - val_acc: 0.9888\n",
      "Epoch 188/200\n",
      "4656/4656 [==============================] - 0s 52us/step - loss: 0.0404 - acc: 0.9880 - val_loss: 0.0403 - val_acc: 0.9893\n",
      "Epoch 189/200\n",
      "4656/4656 [==============================] - 0s 57us/step - loss: 0.0406 - acc: 0.9884 - val_loss: 0.0375 - val_acc: 0.9895\n",
      "Epoch 190/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.0397 - acc: 0.9888 - val_loss: 0.0409 - val_acc: 0.9897\n",
      "Epoch 191/200\n",
      "4656/4656 [==============================] - 0s 55us/step - loss: 0.0386 - acc: 0.9890 - val_loss: 0.0379 - val_acc: 0.9903\n",
      "Epoch 192/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4656/4656 [==============================] - 0s 49us/step - loss: 0.0383 - acc: 0.9893 - val_loss: 0.0355 - val_acc: 0.9895\n",
      "Epoch 193/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0394 - acc: 0.9884 - val_loss: 0.0367 - val_acc: 0.9901\n",
      "Epoch 194/200\n",
      "4656/4656 [==============================] - 0s 53us/step - loss: 0.0379 - acc: 0.9897 - val_loss: 0.0412 - val_acc: 0.9888\n",
      "Epoch 195/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.0381 - acc: 0.9897 - val_loss: 0.0351 - val_acc: 0.9897\n",
      "Epoch 196/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0384 - acc: 0.9886 - val_loss: 0.0400 - val_acc: 0.9890\n",
      "Epoch 197/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0398 - acc: 0.9884 - val_loss: 0.0363 - val_acc: 0.9903\n",
      "Epoch 198/200\n",
      "4656/4656 [==============================] - 0s 48us/step - loss: 0.0392 - acc: 0.9897 - val_loss: 0.0346 - val_acc: 0.9901\n",
      "Epoch 199/200\n",
      "4656/4656 [==============================] - 0s 50us/step - loss: 0.0367 - acc: 0.9886 - val_loss: 0.0373 - val_acc: 0.9890\n",
      "Epoch 200/200\n",
      "4656/4656 [==============================] - 0s 51us/step - loss: 0.0374 - acc: 0.9890 - val_loss: 0.0337 - val_acc: 0.9899\n",
      "1164/1164 [==============================] - 0s 66us/step\n",
      "4656/4656 [==============================] - 0s 62us/step\n",
      "Train on 2910 samples, validate on 2910 samples\n",
      "Epoch 1/200\n",
      "2910/2910 [==============================] - 3s 998us/step - loss: 0.9455 - acc: 0.6031 - val_loss: 0.9077 - val_acc: 0.6196\n",
      "Epoch 2/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.8974 - acc: 0.6196 - val_loss: 0.8820 - val_acc: 0.6203\n",
      "Epoch 3/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.8801 - acc: 0.6203 - val_loss: 0.8708 - val_acc: 0.6199\n",
      "Epoch 4/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.8691 - acc: 0.6199 - val_loss: 0.8577 - val_acc: 0.6213\n",
      "Epoch 5/200\n",
      "2910/2910 [==============================] - 0s 53us/step - loss: 0.8562 - acc: 0.6210 - val_loss: 0.8486 - val_acc: 0.6220\n",
      "Epoch 6/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.8484 - acc: 0.6223 - val_loss: 0.8452 - val_acc: 0.6261\n",
      "Epoch 7/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.8460 - acc: 0.6227 - val_loss: 0.8355 - val_acc: 0.6282\n",
      "Epoch 8/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.8378 - acc: 0.6251 - val_loss: 0.8304 - val_acc: 0.6299\n",
      "Epoch 9/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.8317 - acc: 0.6285 - val_loss: 0.8235 - val_acc: 0.6320\n",
      "Epoch 10/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.8260 - acc: 0.6351 - val_loss: 0.8181 - val_acc: 0.6333\n",
      "Epoch 11/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.8190 - acc: 0.6337 - val_loss: 0.8150 - val_acc: 0.6320\n",
      "Epoch 12/200\n",
      "2910/2910 [==============================] - 0s 53us/step - loss: 0.8162 - acc: 0.6371 - val_loss: 0.8138 - val_acc: 0.6351\n",
      "Epoch 13/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.8125 - acc: 0.6333 - val_loss: 0.8022 - val_acc: 0.6364\n",
      "Epoch 14/200\n",
      "2910/2910 [==============================] - 0s 53us/step - loss: 0.8081 - acc: 0.6344 - val_loss: 0.8004 - val_acc: 0.6416\n",
      "Epoch 15/200\n",
      "2910/2910 [==============================] - 0s 59us/step - loss: 0.8008 - acc: 0.6402 - val_loss: 0.7934 - val_acc: 0.6388\n",
      "Epoch 16/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.7966 - acc: 0.6416 - val_loss: 0.7881 - val_acc: 0.6433\n",
      "Epoch 17/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.7957 - acc: 0.6457 - val_loss: 0.7858 - val_acc: 0.6447\n",
      "Epoch 18/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.7900 - acc: 0.6440 - val_loss: 0.7814 - val_acc: 0.6488\n",
      "Epoch 19/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.7863 - acc: 0.6481 - val_loss: 0.7763 - val_acc: 0.6485\n",
      "Epoch 20/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.7781 - acc: 0.6491 - val_loss: 0.7712 - val_acc: 0.6440\n",
      "Epoch 21/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.7771 - acc: 0.6457 - val_loss: 0.7668 - val_acc: 0.6491\n",
      "Epoch 22/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.7709 - acc: 0.6467 - val_loss: 0.7630 - val_acc: 0.6550\n",
      "Epoch 23/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.7676 - acc: 0.6515 - val_loss: 0.7599 - val_acc: 0.6570\n",
      "Epoch 24/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.7648 - acc: 0.6564 - val_loss: 0.7574 - val_acc: 0.6577\n",
      "Epoch 25/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.7606 - acc: 0.6529 - val_loss: 0.7528 - val_acc: 0.6625\n",
      "Epoch 26/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.7563 - acc: 0.6522 - val_loss: 0.7521 - val_acc: 0.6615\n",
      "Epoch 27/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.7535 - acc: 0.6591 - val_loss: 0.7446 - val_acc: 0.6612\n",
      "Epoch 28/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.7496 - acc: 0.6619 - val_loss: 0.7443 - val_acc: 0.6629\n",
      "Epoch 29/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.7471 - acc: 0.6591 - val_loss: 0.7396 - val_acc: 0.6663\n",
      "Epoch 30/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.7428 - acc: 0.6639 - val_loss: 0.7334 - val_acc: 0.6656\n",
      "Epoch 31/200\n",
      "2910/2910 [==============================] - 0s 76us/step - loss: 0.7371 - acc: 0.6612 - val_loss: 0.7295 - val_acc: 0.6708\n",
      "Epoch 32/200\n",
      "2910/2910 [==============================] - 0s 88us/step - loss: 0.7361 - acc: 0.6619 - val_loss: 0.7268 - val_acc: 0.6660\n",
      "Epoch 33/200\n",
      "2910/2910 [==============================] - 0s 66us/step - loss: 0.7307 - acc: 0.6691 - val_loss: 0.7229 - val_acc: 0.6639\n",
      "Epoch 34/200\n",
      "2910/2910 [==============================] - 0s 92us/step - loss: 0.7262 - acc: 0.6704 - val_loss: 0.7193 - val_acc: 0.6684\n",
      "Epoch 35/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.7253 - acc: 0.6663 - val_loss: 0.7158 - val_acc: 0.6701\n",
      "Epoch 36/200\n",
      "2910/2910 [==============================] - 0s 62us/step - loss: 0.7185 - acc: 0.6694 - val_loss: 0.7106 - val_acc: 0.6766\n",
      "Epoch 37/200\n",
      "2910/2910 [==============================] - 0s 61us/step - loss: 0.7174 - acc: 0.6735 - val_loss: 0.7156 - val_acc: 0.6773\n",
      "Epoch 38/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.7147 - acc: 0.6725 - val_loss: 0.7060 - val_acc: 0.6818\n",
      "Epoch 39/200\n",
      "2910/2910 [==============================] - 0s 55us/step - loss: 0.7108 - acc: 0.6756 - val_loss: 0.7023 - val_acc: 0.6832\n",
      "Epoch 40/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.7073 - acc: 0.6790 - val_loss: 0.6966 - val_acc: 0.6852\n",
      "Epoch 41/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.7049 - acc: 0.6838 - val_loss: 0.6947 - val_acc: 0.6873\n",
      "Epoch 42/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.6979 - acc: 0.6924 - val_loss: 0.6919 - val_acc: 0.6900\n",
      "Epoch 43/200\n",
      "2910/2910 [==============================] - 0s 54us/step - loss: 0.6972 - acc: 0.6859 - val_loss: 0.6890 - val_acc: 0.6962\n",
      "Epoch 44/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6906 - acc: 0.6938 - val_loss: 0.6835 - val_acc: 0.6890\n",
      "Epoch 45/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.6852 - acc: 0.6918 - val_loss: 0.6821 - val_acc: 0.6948\n",
      "Epoch 46/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6887 - acc: 0.6955 - val_loss: 0.6797 - val_acc: 0.7027\n",
      "Epoch 47/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6844 - acc: 0.7007 - val_loss: 0.6726 - val_acc: 0.6997\n",
      "Epoch 48/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6763 - acc: 0.6990 - val_loss: 0.6699 - val_acc: 0.7014\n",
      "Epoch 49/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.6747 - acc: 0.6986 - val_loss: 0.6637 - val_acc: 0.7065\n",
      "Epoch 50/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.6679 - acc: 0.7007 - val_loss: 0.6633 - val_acc: 0.7127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200\n",
      "2910/2910 [==============================] - 0s 69us/step - loss: 0.6666 - acc: 0.7096 - val_loss: 0.6632 - val_acc: 0.7131\n",
      "Epoch 52/200\n",
      "2910/2910 [==============================] - 0s 66us/step - loss: 0.6668 - acc: 0.7120 - val_loss: 0.6532 - val_acc: 0.7131\n",
      "Epoch 53/200\n",
      "2910/2910 [==============================] - 0s 54us/step - loss: 0.6587 - acc: 0.7058 - val_loss: 0.6505 - val_acc: 0.7120\n",
      "Epoch 54/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.6586 - acc: 0.7120 - val_loss: 0.6490 - val_acc: 0.7216\n",
      "Epoch 55/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.6558 - acc: 0.7148 - val_loss: 0.6485 - val_acc: 0.7148\n",
      "Epoch 56/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.6526 - acc: 0.7117 - val_loss: 0.6527 - val_acc: 0.7210\n",
      "Epoch 57/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.6496 - acc: 0.7144 - val_loss: 0.6374 - val_acc: 0.7213\n",
      "Epoch 58/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.6426 - acc: 0.7265 - val_loss: 0.6377 - val_acc: 0.7223\n",
      "Epoch 59/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6425 - acc: 0.7186 - val_loss: 0.6322 - val_acc: 0.7306\n",
      "Epoch 60/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.6371 - acc: 0.7271 - val_loss: 0.6272 - val_acc: 0.7241\n",
      "Epoch 61/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.6340 - acc: 0.7271 - val_loss: 0.6243 - val_acc: 0.7364\n",
      "Epoch 62/200\n",
      "2910/2910 [==============================] - 0s 55us/step - loss: 0.6296 - acc: 0.7368 - val_loss: 0.6241 - val_acc: 0.7361\n",
      "Epoch 63/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.6311 - acc: 0.7316 - val_loss: 0.6182 - val_acc: 0.7419\n",
      "Epoch 64/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.6232 - acc: 0.7299 - val_loss: 0.6164 - val_acc: 0.7464\n",
      "Epoch 65/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.6219 - acc: 0.7419 - val_loss: 0.6131 - val_acc: 0.7457\n",
      "Epoch 66/200\n",
      "2910/2910 [==============================] - 0s 53us/step - loss: 0.6186 - acc: 0.7375 - val_loss: 0.6104 - val_acc: 0.7454\n",
      "Epoch 67/200\n",
      "2910/2910 [==============================] - 0s 56us/step - loss: 0.6118 - acc: 0.7502 - val_loss: 0.6082 - val_acc: 0.7443\n",
      "Epoch 68/200\n",
      "2910/2910 [==============================] - 0s 55us/step - loss: 0.6144 - acc: 0.7361 - val_loss: 0.6084 - val_acc: 0.7564\n",
      "Epoch 69/200\n",
      "2910/2910 [==============================] - 0s 60us/step - loss: 0.6120 - acc: 0.7553 - val_loss: 0.5986 - val_acc: 0.7639\n",
      "Epoch 70/200\n",
      "2910/2910 [==============================] - 0s 86us/step - loss: 0.6056 - acc: 0.7436 - val_loss: 0.5964 - val_acc: 0.7680\n",
      "Epoch 71/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.6069 - acc: 0.7533 - val_loss: 0.5928 - val_acc: 0.7564\n",
      "Epoch 72/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.5988 - acc: 0.7595 - val_loss: 0.5914 - val_acc: 0.7564\n",
      "Epoch 73/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.5953 - acc: 0.7567 - val_loss: 0.5884 - val_acc: 0.7612\n",
      "Epoch 74/200\n",
      "2910/2910 [==============================] - 0s 56us/step - loss: 0.5968 - acc: 0.7557 - val_loss: 0.5819 - val_acc: 0.7622\n",
      "Epoch 75/200\n",
      "2910/2910 [==============================] - 0s 53us/step - loss: 0.5890 - acc: 0.7622 - val_loss: 0.5833 - val_acc: 0.7505\n",
      "Epoch 76/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.5855 - acc: 0.7608 - val_loss: 0.5751 - val_acc: 0.7687\n",
      "Epoch 77/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.5848 - acc: 0.7653 - val_loss: 0.5714 - val_acc: 0.7739\n",
      "Epoch 78/200\n",
      "2910/2910 [==============================] - 0s 53us/step - loss: 0.5781 - acc: 0.7670 - val_loss: 0.5684 - val_acc: 0.7698\n",
      "Epoch 79/200\n",
      "2910/2910 [==============================] - 0s 55us/step - loss: 0.5794 - acc: 0.7670 - val_loss: 0.5693 - val_acc: 0.7828\n",
      "Epoch 80/200\n",
      "2910/2910 [==============================] - 0s 56us/step - loss: 0.5778 - acc: 0.7680 - val_loss: 0.5688 - val_acc: 0.7832\n",
      "Epoch 81/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.5745 - acc: 0.7674 - val_loss: 0.5599 - val_acc: 0.7849\n",
      "Epoch 82/200\n",
      "2910/2910 [==============================] - 0s 56us/step - loss: 0.5670 - acc: 0.7811 - val_loss: 0.5531 - val_acc: 0.7849\n",
      "Epoch 83/200\n",
      "2910/2910 [==============================] - 0s 54us/step - loss: 0.5620 - acc: 0.7808 - val_loss: 0.5570 - val_acc: 0.7766\n",
      "Epoch 84/200\n",
      "2910/2910 [==============================] - 0s 60us/step - loss: 0.5684 - acc: 0.7742 - val_loss: 0.5515 - val_acc: 0.7753\n",
      "Epoch 85/200\n",
      "2910/2910 [==============================] - 0s 62us/step - loss: 0.5560 - acc: 0.7797 - val_loss: 0.5449 - val_acc: 0.7952\n",
      "Epoch 86/200\n",
      "2910/2910 [==============================] - 0s 63us/step - loss: 0.5526 - acc: 0.7818 - val_loss: 0.5495 - val_acc: 0.7876\n",
      "Epoch 87/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.5557 - acc: 0.7811 - val_loss: 0.5481 - val_acc: 0.7893\n",
      "Epoch 88/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5487 - acc: 0.7808 - val_loss: 0.5485 - val_acc: 0.7777\n",
      "Epoch 89/200\n",
      "2910/2910 [==============================] - 0s 53us/step - loss: 0.5479 - acc: 0.7814 - val_loss: 0.5425 - val_acc: 0.7869\n",
      "Epoch 90/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5419 - acc: 0.7928 - val_loss: 0.5346 - val_acc: 0.7924\n",
      "Epoch 91/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5375 - acc: 0.7880 - val_loss: 0.5275 - val_acc: 0.8024\n",
      "Epoch 92/200\n",
      "2910/2910 [==============================] - 0s 54us/step - loss: 0.5318 - acc: 0.7921 - val_loss: 0.5240 - val_acc: 0.7952\n",
      "Epoch 93/200\n",
      "2910/2910 [==============================] - 0s 60us/step - loss: 0.5356 - acc: 0.7948 - val_loss: 0.5246 - val_acc: 0.7928\n",
      "Epoch 94/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.5304 - acc: 0.7959 - val_loss: 0.5165 - val_acc: 0.8003\n",
      "Epoch 95/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.5231 - acc: 0.7938 - val_loss: 0.5106 - val_acc: 0.8089\n",
      "Epoch 96/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.5170 - acc: 0.8024 - val_loss: 0.5135 - val_acc: 0.7955\n",
      "Epoch 97/200\n",
      "2910/2910 [==============================] - 0s 53us/step - loss: 0.5138 - acc: 0.8007 - val_loss: 0.5211 - val_acc: 0.8007\n",
      "Epoch 98/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.5242 - acc: 0.7924 - val_loss: 0.5219 - val_acc: 0.7900\n",
      "Epoch 99/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.5131 - acc: 0.8048 - val_loss: 0.4970 - val_acc: 0.8103\n",
      "Epoch 100/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.5086 - acc: 0.8021 - val_loss: 0.4977 - val_acc: 0.8065\n",
      "Epoch 101/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5034 - acc: 0.8052 - val_loss: 0.4925 - val_acc: 0.8144\n",
      "Epoch 102/200\n",
      "2910/2910 [==============================] - 0s 55us/step - loss: 0.4977 - acc: 0.8107 - val_loss: 0.4893 - val_acc: 0.8120\n",
      "Epoch 103/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.5010 - acc: 0.8045 - val_loss: 0.4892 - val_acc: 0.8179\n",
      "Epoch 104/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4924 - acc: 0.8089 - val_loss: 0.4800 - val_acc: 0.8258\n",
      "Epoch 105/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4932 - acc: 0.8096 - val_loss: 0.4894 - val_acc: 0.8165\n",
      "Epoch 106/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4855 - acc: 0.8089 - val_loss: 0.4767 - val_acc: 0.8168\n",
      "Epoch 107/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.4800 - acc: 0.8158 - val_loss: 0.4733 - val_acc: 0.8223\n",
      "Epoch 108/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.4815 - acc: 0.8137 - val_loss: 0.4695 - val_acc: 0.8210\n",
      "Epoch 109/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4770 - acc: 0.8162 - val_loss: 0.4630 - val_acc: 0.8265\n",
      "Epoch 110/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.4693 - acc: 0.8230 - val_loss: 0.4613 - val_acc: 0.8292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.4724 - acc: 0.8203 - val_loss: 0.4591 - val_acc: 0.8278\n",
      "Epoch 112/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4635 - acc: 0.8237 - val_loss: 0.4564 - val_acc: 0.8275\n",
      "Epoch 113/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.4628 - acc: 0.8206 - val_loss: 0.4529 - val_acc: 0.8282\n",
      "Epoch 114/200\n",
      "2910/2910 [==============================] - 0s 83us/step - loss: 0.4596 - acc: 0.8247 - val_loss: 0.4517 - val_acc: 0.8385\n",
      "Epoch 115/200\n",
      "2910/2910 [==============================] - 0s 74us/step - loss: 0.4575 - acc: 0.8278 - val_loss: 0.4453 - val_acc: 0.8351\n",
      "Epoch 116/200\n",
      "2910/2910 [==============================] - 0s 58us/step - loss: 0.4522 - acc: 0.8292 - val_loss: 0.4395 - val_acc: 0.8361\n",
      "Epoch 117/200\n",
      "2910/2910 [==============================] - 0s 53us/step - loss: 0.4447 - acc: 0.8313 - val_loss: 0.4485 - val_acc: 0.8309\n",
      "Epoch 118/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.4515 - acc: 0.8292 - val_loss: 0.4378 - val_acc: 0.8351\n",
      "Epoch 119/200\n",
      "2910/2910 [==============================] - 0s 54us/step - loss: 0.4466 - acc: 0.8254 - val_loss: 0.4346 - val_acc: 0.8371\n",
      "Epoch 120/200\n",
      "2910/2910 [==============================] - 0s 54us/step - loss: 0.4444 - acc: 0.8302 - val_loss: 0.4314 - val_acc: 0.8471\n",
      "Epoch 121/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.4389 - acc: 0.8371 - val_loss: 0.4326 - val_acc: 0.8423\n",
      "Epoch 122/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.4368 - acc: 0.8375 - val_loss: 0.4277 - val_acc: 0.8436\n",
      "Epoch 123/200\n",
      "2910/2910 [==============================] - 0s 53us/step - loss: 0.4409 - acc: 0.8354 - val_loss: 0.4269 - val_acc: 0.8423\n",
      "Epoch 124/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.4346 - acc: 0.8371 - val_loss: 0.4194 - val_acc: 0.8447\n",
      "Epoch 125/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.4225 - acc: 0.8454 - val_loss: 0.4177 - val_acc: 0.8443\n",
      "Epoch 126/200\n",
      "2910/2910 [==============================] - 0s 53us/step - loss: 0.4208 - acc: 0.8419 - val_loss: 0.4149 - val_acc: 0.8460\n",
      "Epoch 127/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.4166 - acc: 0.8474 - val_loss: 0.4080 - val_acc: 0.8491\n",
      "Epoch 128/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.4147 - acc: 0.8433 - val_loss: 0.4043 - val_acc: 0.8526\n",
      "Epoch 129/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.4104 - acc: 0.8485 - val_loss: 0.4068 - val_acc: 0.8509\n",
      "Epoch 130/200\n",
      "2910/2910 [==============================] - 0s 54us/step - loss: 0.4085 - acc: 0.8498 - val_loss: 0.3985 - val_acc: 0.8540\n",
      "Epoch 131/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.4082 - acc: 0.8464 - val_loss: 0.3961 - val_acc: 0.8495\n",
      "Epoch 132/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.4046 - acc: 0.8471 - val_loss: 0.3990 - val_acc: 0.8491\n",
      "Epoch 133/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.4007 - acc: 0.8436 - val_loss: 0.3849 - val_acc: 0.8553\n",
      "Epoch 134/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.4049 - acc: 0.8467 - val_loss: 0.3882 - val_acc: 0.8588\n",
      "Epoch 135/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.3930 - acc: 0.8564 - val_loss: 0.3837 - val_acc: 0.8591\n",
      "Epoch 136/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.3844 - acc: 0.8588 - val_loss: 0.3786 - val_acc: 0.8608\n",
      "Epoch 137/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.3821 - acc: 0.8574 - val_loss: 0.3762 - val_acc: 0.8550\n",
      "Epoch 138/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.3872 - acc: 0.8567 - val_loss: 0.3766 - val_acc: 0.8632\n",
      "Epoch 139/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.3792 - acc: 0.8584 - val_loss: 0.3638 - val_acc: 0.8660\n",
      "Epoch 140/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3770 - acc: 0.8608 - val_loss: 0.3912 - val_acc: 0.8505\n",
      "Epoch 141/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.3798 - acc: 0.8608 - val_loss: 0.3644 - val_acc: 0.8684\n",
      "Epoch 142/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.3720 - acc: 0.8660 - val_loss: 0.3567 - val_acc: 0.8701\n",
      "Epoch 143/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.3680 - acc: 0.8660 - val_loss: 0.3583 - val_acc: 0.8612\n",
      "Epoch 144/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3621 - acc: 0.8701 - val_loss: 0.3574 - val_acc: 0.8811\n",
      "Epoch 145/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.3602 - acc: 0.8691 - val_loss: 0.3534 - val_acc: 0.8770\n",
      "Epoch 146/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.3571 - acc: 0.8742 - val_loss: 0.3444 - val_acc: 0.8797\n",
      "Epoch 147/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.3520 - acc: 0.8756 - val_loss: 0.3440 - val_acc: 0.8735\n",
      "Epoch 148/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3423 - acc: 0.8842 - val_loss: 0.3378 - val_acc: 0.8825\n",
      "Epoch 149/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3410 - acc: 0.8790 - val_loss: 0.3358 - val_acc: 0.8811\n",
      "Epoch 150/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3427 - acc: 0.8749 - val_loss: 0.3332 - val_acc: 0.8914\n",
      "Epoch 151/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3380 - acc: 0.8828 - val_loss: 0.3319 - val_acc: 0.8814\n",
      "Epoch 152/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.3393 - acc: 0.8790 - val_loss: 0.3252 - val_acc: 0.8876\n",
      "Epoch 153/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.3347 - acc: 0.8818 - val_loss: 0.3336 - val_acc: 0.8904\n",
      "Epoch 154/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.3315 - acc: 0.8883 - val_loss: 0.3268 - val_acc: 0.8887\n",
      "Epoch 155/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3307 - acc: 0.8869 - val_loss: 0.3175 - val_acc: 0.8907\n",
      "Epoch 156/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.3187 - acc: 0.8918 - val_loss: 0.3118 - val_acc: 0.8942\n",
      "Epoch 157/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3206 - acc: 0.8935 - val_loss: 0.3118 - val_acc: 0.9038\n",
      "Epoch 158/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3171 - acc: 0.8948 - val_loss: 0.3051 - val_acc: 0.8962\n",
      "Epoch 159/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.3126 - acc: 0.8931 - val_loss: 0.3095 - val_acc: 0.8962\n",
      "Epoch 160/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3091 - acc: 0.8966 - val_loss: 0.3043 - val_acc: 0.9021\n",
      "Epoch 161/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.3072 - acc: 0.8942 - val_loss: 0.2960 - val_acc: 0.9089\n",
      "Epoch 162/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.3050 - acc: 0.9031 - val_loss: 0.2912 - val_acc: 0.9100\n",
      "Epoch 163/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.2988 - acc: 0.9041 - val_loss: 0.2910 - val_acc: 0.9096\n",
      "Epoch 164/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.2966 - acc: 0.9069 - val_loss: 0.2897 - val_acc: 0.9100\n",
      "Epoch 165/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.2906 - acc: 0.9100 - val_loss: 0.2842 - val_acc: 0.9103\n",
      "Epoch 166/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.2936 - acc: 0.9045 - val_loss: 0.2842 - val_acc: 0.9124\n",
      "Epoch 167/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.2943 - acc: 0.9041 - val_loss: 0.2801 - val_acc: 0.9093\n",
      "Epoch 168/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.2883 - acc: 0.9069 - val_loss: 0.2763 - val_acc: 0.9124\n",
      "Epoch 169/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.2784 - acc: 0.9096 - val_loss: 0.2707 - val_acc: 0.9155\n",
      "Epoch 170/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.2765 - acc: 0.9175 - val_loss: 0.2691 - val_acc: 0.9165\n",
      "Epoch 171/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.2745 - acc: 0.9158 - val_loss: 0.2688 - val_acc: 0.9127\n",
      "Epoch 172/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.2778 - acc: 0.9155 - val_loss: 0.2683 - val_acc: 0.9189\n",
      "Epoch 173/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.2777 - acc: 0.9120 - val_loss: 0.2625 - val_acc: 0.9220\n",
      "Epoch 174/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.2669 - acc: 0.9203 - val_loss: 0.2628 - val_acc: 0.9244\n",
      "Epoch 175/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.2664 - acc: 0.9189 - val_loss: 0.2576 - val_acc: 0.9199\n",
      "Epoch 176/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.2615 - acc: 0.9158 - val_loss: 0.2597 - val_acc: 0.9192\n",
      "Epoch 177/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.2588 - acc: 0.9206 - val_loss: 0.2544 - val_acc: 0.9186\n",
      "Epoch 178/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.2541 - acc: 0.9210 - val_loss: 0.2429 - val_acc: 0.9268\n",
      "Epoch 179/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.2554 - acc: 0.9216 - val_loss: 0.2448 - val_acc: 0.9275\n",
      "Epoch 180/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.2499 - acc: 0.9237 - val_loss: 0.2486 - val_acc: 0.9175\n",
      "Epoch 181/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.2498 - acc: 0.9237 - val_loss: 0.2374 - val_acc: 0.9320\n",
      "Epoch 182/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.2416 - acc: 0.9251 - val_loss: 0.2320 - val_acc: 0.9268\n",
      "Epoch 183/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.2374 - acc: 0.9258 - val_loss: 0.2292 - val_acc: 0.9364\n",
      "Epoch 184/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.2386 - acc: 0.9271 - val_loss: 0.2310 - val_acc: 0.9289\n",
      "Epoch 185/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.2361 - acc: 0.9251 - val_loss: 0.2354 - val_acc: 0.9306\n",
      "Epoch 186/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.2304 - acc: 0.9323 - val_loss: 0.2312 - val_acc: 0.9364\n",
      "Epoch 187/200\n",
      "2910/2910 [==============================] - 0s 53us/step - loss: 0.2335 - acc: 0.9289 - val_loss: 0.2217 - val_acc: 0.9254\n",
      "Epoch 188/200\n",
      "2910/2910 [==============================] - 0s 64us/step - loss: 0.2429 - acc: 0.9213 - val_loss: 0.2159 - val_acc: 0.9347\n",
      "Epoch 189/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.2223 - acc: 0.9381 - val_loss: 0.2142 - val_acc: 0.9399\n",
      "Epoch 190/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.2171 - acc: 0.9361 - val_loss: 0.2070 - val_acc: 0.9351\n",
      "Epoch 191/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.2127 - acc: 0.9351 - val_loss: 0.2069 - val_acc: 0.9385\n",
      "Epoch 192/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.2127 - acc: 0.9326 - val_loss: 0.2018 - val_acc: 0.9430\n",
      "Epoch 193/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.2143 - acc: 0.9368 - val_loss: 0.1989 - val_acc: 0.9443\n",
      "Epoch 194/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.2048 - acc: 0.9395 - val_loss: 0.2004 - val_acc: 0.9368\n",
      "Epoch 195/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.2080 - acc: 0.9378 - val_loss: 0.1954 - val_acc: 0.9416\n",
      "Epoch 196/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.1988 - acc: 0.9412 - val_loss: 0.1954 - val_acc: 0.9474\n",
      "Epoch 197/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.1994 - acc: 0.9395 - val_loss: 0.2036 - val_acc: 0.9426\n",
      "Epoch 198/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.1990 - acc: 0.9405 - val_loss: 0.1869 - val_acc: 0.9512\n",
      "Epoch 199/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.1892 - acc: 0.9440 - val_loss: 0.1834 - val_acc: 0.9502\n",
      "Epoch 200/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.1896 - acc: 0.9450 - val_loss: 0.1823 - val_acc: 0.9488\n",
      "2910/2910 [==============================] - 0s 47us/step\n",
      "2910/2910 [==============================] - 0s 49us/step\n",
      "Train on 2910 samples, validate on 2910 samples\n",
      "Epoch 1/200\n",
      "2910/2910 [==============================] - 3s 889us/step - loss: 0.9768 - acc: 0.5540 - val_loss: 0.9312 - val_acc: 0.6110\n",
      "Epoch 2/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.9158 - acc: 0.6131 - val_loss: 0.8988 - val_acc: 0.6155\n",
      "Epoch 3/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.8917 - acc: 0.6151 - val_loss: 0.8827 - val_acc: 0.6162\n",
      "Epoch 4/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.8817 - acc: 0.6155 - val_loss: 0.8721 - val_acc: 0.6155\n",
      "Epoch 5/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.8712 - acc: 0.6168 - val_loss: 0.8624 - val_acc: 0.6175\n",
      "Epoch 6/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.8641 - acc: 0.6206 - val_loss: 0.8561 - val_acc: 0.6179\n",
      "Epoch 7/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.8552 - acc: 0.6213 - val_loss: 0.8512 - val_acc: 0.6192\n",
      "Epoch 8/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.8525 - acc: 0.6234 - val_loss: 0.8452 - val_acc: 0.6261\n",
      "Epoch 9/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.8464 - acc: 0.6210 - val_loss: 0.8435 - val_acc: 0.6275\n",
      "Epoch 10/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.8448 - acc: 0.6234 - val_loss: 0.8408 - val_acc: 0.6275\n",
      "Epoch 11/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.8390 - acc: 0.6271 - val_loss: 0.8327 - val_acc: 0.6275\n",
      "Epoch 12/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.8324 - acc: 0.6265 - val_loss: 0.8350 - val_acc: 0.6289\n",
      "Epoch 13/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.8343 - acc: 0.6244 - val_loss: 0.8288 - val_acc: 0.6330\n",
      "Epoch 14/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.8286 - acc: 0.6296 - val_loss: 0.8202 - val_acc: 0.6347\n",
      "Epoch 15/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.8233 - acc: 0.6326 - val_loss: 0.8167 - val_acc: 0.6289\n",
      "Epoch 16/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.8191 - acc: 0.6354 - val_loss: 0.8158 - val_acc: 0.6405\n",
      "Epoch 17/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.8174 - acc: 0.6347 - val_loss: 0.8092 - val_acc: 0.6409\n",
      "Epoch 18/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.8112 - acc: 0.6385 - val_loss: 0.8059 - val_acc: 0.6412\n",
      "Epoch 19/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.8090 - acc: 0.6419 - val_loss: 0.8015 - val_acc: 0.6412\n",
      "Epoch 20/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.8049 - acc: 0.6392 - val_loss: 0.7990 - val_acc: 0.6460\n",
      "Epoch 21/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.8012 - acc: 0.6440 - val_loss: 0.7934 - val_acc: 0.6450\n",
      "Epoch 22/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.7948 - acc: 0.6426 - val_loss: 0.7897 - val_acc: 0.6433\n",
      "Epoch 23/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.7915 - acc: 0.6478 - val_loss: 0.7858 - val_acc: 0.6488\n",
      "Epoch 24/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.7870 - acc: 0.6447 - val_loss: 0.7836 - val_acc: 0.6478\n",
      "Epoch 25/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.7856 - acc: 0.6471 - val_loss: 0.7770 - val_acc: 0.6505\n",
      "Epoch 26/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.7811 - acc: 0.6509 - val_loss: 0.7793 - val_acc: 0.6515\n",
      "Epoch 27/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.7750 - acc: 0.6581 - val_loss: 0.7710 - val_acc: 0.6553\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.7728 - acc: 0.6543 - val_loss: 0.7625 - val_acc: 0.6615\n",
      "Epoch 29/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.7677 - acc: 0.6601 - val_loss: 0.7591 - val_acc: 0.6660\n",
      "Epoch 30/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.7642 - acc: 0.6643 - val_loss: 0.7560 - val_acc: 0.6674\n",
      "Epoch 31/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.7605 - acc: 0.6663 - val_loss: 0.7591 - val_acc: 0.6729\n",
      "Epoch 32/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.7545 - acc: 0.6677 - val_loss: 0.7456 - val_acc: 0.6701\n",
      "Epoch 33/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.7487 - acc: 0.6742 - val_loss: 0.7444 - val_acc: 0.6715\n",
      "Epoch 34/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.7497 - acc: 0.6708 - val_loss: 0.7439 - val_acc: 0.6845\n",
      "Epoch 35/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.7412 - acc: 0.6777 - val_loss: 0.7381 - val_acc: 0.6794\n",
      "Epoch 36/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.7412 - acc: 0.6784 - val_loss: 0.7364 - val_acc: 0.6838\n",
      "Epoch 37/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.7386 - acc: 0.6804 - val_loss: 0.7266 - val_acc: 0.6890\n",
      "Epoch 38/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.7336 - acc: 0.6797 - val_loss: 0.7280 - val_acc: 0.6842\n",
      "Epoch 39/200\n",
      "2910/2910 [==============================] - 0s 64us/step - loss: 0.7330 - acc: 0.6801 - val_loss: 0.7206 - val_acc: 0.6993\n",
      "Epoch 40/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.7227 - acc: 0.6808 - val_loss: 0.7139 - val_acc: 0.6869\n",
      "Epoch 41/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.7220 - acc: 0.6876 - val_loss: 0.7150 - val_acc: 0.6938\n",
      "Epoch 42/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.7185 - acc: 0.6928 - val_loss: 0.7097 - val_acc: 0.6897\n",
      "Epoch 43/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.7096 - acc: 0.6880 - val_loss: 0.7035 - val_acc: 0.7003\n",
      "Epoch 44/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.7083 - acc: 0.6942 - val_loss: 0.7028 - val_acc: 0.6979\n",
      "Epoch 45/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.7068 - acc: 0.6900 - val_loss: 0.6964 - val_acc: 0.6990\n",
      "Epoch 46/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.7005 - acc: 0.6924 - val_loss: 0.6960 - val_acc: 0.6955\n",
      "Epoch 47/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.7019 - acc: 0.6942 - val_loss: 0.6873 - val_acc: 0.6986\n",
      "Epoch 48/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.6941 - acc: 0.6986 - val_loss: 0.6877 - val_acc: 0.7069\n",
      "Epoch 49/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.6884 - acc: 0.7014 - val_loss: 0.6812 - val_acc: 0.7034\n",
      "Epoch 50/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6859 - acc: 0.7065 - val_loss: 0.6809 - val_acc: 0.7062\n",
      "Epoch 51/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.6832 - acc: 0.7031 - val_loss: 0.6761 - val_acc: 0.7045\n",
      "Epoch 52/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.6799 - acc: 0.7062 - val_loss: 0.6722 - val_acc: 0.7127\n",
      "Epoch 53/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6747 - acc: 0.7127 - val_loss: 0.6735 - val_acc: 0.7117\n",
      "Epoch 54/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.6774 - acc: 0.7107 - val_loss: 0.6619 - val_acc: 0.7165\n",
      "Epoch 55/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.6665 - acc: 0.7186 - val_loss: 0.6633 - val_acc: 0.7302\n",
      "Epoch 56/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.6678 - acc: 0.7210 - val_loss: 0.6568 - val_acc: 0.7165\n",
      "Epoch 57/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6591 - acc: 0.7223 - val_loss: 0.6528 - val_acc: 0.7254\n",
      "Epoch 58/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.6562 - acc: 0.7247 - val_loss: 0.6494 - val_acc: 0.7326\n",
      "Epoch 59/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6531 - acc: 0.7244 - val_loss: 0.6499 - val_acc: 0.7258\n",
      "Epoch 60/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.6515 - acc: 0.7223 - val_loss: 0.6415 - val_acc: 0.7392\n",
      "Epoch 61/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.6477 - acc: 0.7326 - val_loss: 0.6447 - val_acc: 0.7395\n",
      "Epoch 62/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.6414 - acc: 0.7330 - val_loss: 0.6339 - val_acc: 0.7381\n",
      "Epoch 63/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.6371 - acc: 0.7361 - val_loss: 0.6282 - val_acc: 0.7460\n",
      "Epoch 64/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.6358 - acc: 0.7320 - val_loss: 0.6282 - val_acc: 0.7436\n",
      "Epoch 65/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.6298 - acc: 0.7395 - val_loss: 0.6208 - val_acc: 0.7488\n",
      "Epoch 66/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.6284 - acc: 0.7423 - val_loss: 0.6169 - val_acc: 0.7440\n",
      "Epoch 67/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.6214 - acc: 0.7381 - val_loss: 0.6150 - val_acc: 0.7533\n",
      "Epoch 68/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6184 - acc: 0.7402 - val_loss: 0.6161 - val_acc: 0.7330\n",
      "Epoch 69/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.6235 - acc: 0.7395 - val_loss: 0.6114 - val_acc: 0.7505\n",
      "Epoch 70/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.6239 - acc: 0.7402 - val_loss: 0.6089 - val_acc: 0.7378\n",
      "Epoch 71/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.6097 - acc: 0.7357 - val_loss: 0.6022 - val_acc: 0.7440\n",
      "Epoch 72/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.6034 - acc: 0.7447 - val_loss: 0.5962 - val_acc: 0.7522\n",
      "Epoch 73/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.6002 - acc: 0.7474 - val_loss: 0.5922 - val_acc: 0.7488\n",
      "Epoch 74/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5989 - acc: 0.7515 - val_loss: 0.5883 - val_acc: 0.7491\n",
      "Epoch 75/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.5945 - acc: 0.7485 - val_loss: 0.5827 - val_acc: 0.7588\n",
      "Epoch 76/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5916 - acc: 0.7543 - val_loss: 0.5804 - val_acc: 0.7636\n",
      "Epoch 77/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5838 - acc: 0.7612 - val_loss: 0.5787 - val_acc: 0.7615\n",
      "Epoch 78/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5853 - acc: 0.7584 - val_loss: 0.5777 - val_acc: 0.7533\n",
      "Epoch 79/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5802 - acc: 0.7632 - val_loss: 0.5765 - val_acc: 0.7656\n",
      "Epoch 80/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5787 - acc: 0.7694 - val_loss: 0.5701 - val_acc: 0.7615\n",
      "Epoch 81/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5769 - acc: 0.7625 - val_loss: 0.5645 - val_acc: 0.7749\n",
      "Epoch 82/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5710 - acc: 0.7622 - val_loss: 0.5611 - val_acc: 0.7784\n",
      "Epoch 83/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.5698 - acc: 0.7646 - val_loss: 0.5568 - val_acc: 0.7735\n",
      "Epoch 84/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.5651 - acc: 0.7636 - val_loss: 0.5515 - val_acc: 0.7797\n",
      "Epoch 85/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.5589 - acc: 0.7670 - val_loss: 0.5514 - val_acc: 0.7766\n",
      "Epoch 86/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.5548 - acc: 0.7722 - val_loss: 0.5484 - val_acc: 0.7725\n",
      "Epoch 87/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.5527 - acc: 0.7677 - val_loss: 0.5420 - val_acc: 0.7749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.5507 - acc: 0.7698 - val_loss: 0.5407 - val_acc: 0.7784\n",
      "Epoch 89/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5445 - acc: 0.7773 - val_loss: 0.5401 - val_acc: 0.7715\n",
      "Epoch 90/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5465 - acc: 0.7732 - val_loss: 0.5338 - val_acc: 0.7852\n",
      "Epoch 91/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.5389 - acc: 0.7804 - val_loss: 0.5301 - val_acc: 0.7804\n",
      "Epoch 92/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.5376 - acc: 0.7773 - val_loss: 0.5331 - val_acc: 0.7794\n",
      "Epoch 93/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5425 - acc: 0.7773 - val_loss: 0.5293 - val_acc: 0.7838\n",
      "Epoch 94/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.5305 - acc: 0.7801 - val_loss: 0.5200 - val_acc: 0.7918\n",
      "Epoch 95/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5291 - acc: 0.7835 - val_loss: 0.5185 - val_acc: 0.7732\n",
      "Epoch 96/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5362 - acc: 0.7742 - val_loss: 0.5231 - val_acc: 0.7897\n",
      "Epoch 97/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5214 - acc: 0.7849 - val_loss: 0.5128 - val_acc: 0.7928\n",
      "Epoch 98/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.5198 - acc: 0.7887 - val_loss: 0.5124 - val_acc: 0.7918\n",
      "Epoch 99/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5117 - acc: 0.7863 - val_loss: 0.5123 - val_acc: 0.8024\n",
      "Epoch 100/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.5157 - acc: 0.7890 - val_loss: 0.5101 - val_acc: 0.7866\n",
      "Epoch 101/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5137 - acc: 0.7814 - val_loss: 0.5038 - val_acc: 0.7948\n",
      "Epoch 102/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5083 - acc: 0.7863 - val_loss: 0.5105 - val_acc: 0.8024\n",
      "Epoch 103/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5158 - acc: 0.7931 - val_loss: 0.5000 - val_acc: 0.8000\n",
      "Epoch 104/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5037 - acc: 0.7945 - val_loss: 0.4996 - val_acc: 0.7948\n",
      "Epoch 105/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5005 - acc: 0.7900 - val_loss: 0.4897 - val_acc: 0.7986\n",
      "Epoch 106/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.4978 - acc: 0.7966 - val_loss: 0.4838 - val_acc: 0.7979\n",
      "Epoch 107/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.4882 - acc: 0.7907 - val_loss: 0.4802 - val_acc: 0.8069\n",
      "Epoch 108/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.4900 - acc: 0.7966 - val_loss: 0.4821 - val_acc: 0.8021\n",
      "Epoch 109/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4855 - acc: 0.7955 - val_loss: 0.4796 - val_acc: 0.7973\n",
      "Epoch 110/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4891 - acc: 0.7924 - val_loss: 0.4762 - val_acc: 0.8034\n",
      "Epoch 111/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4851 - acc: 0.7969 - val_loss: 0.4756 - val_acc: 0.8072\n",
      "Epoch 112/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4786 - acc: 0.8031 - val_loss: 0.4729 - val_acc: 0.8107\n",
      "Epoch 113/200\n",
      "2910/2910 [==============================] - 0s 54us/step - loss: 0.4733 - acc: 0.8062 - val_loss: 0.4685 - val_acc: 0.8065\n",
      "Epoch 114/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4728 - acc: 0.8041 - val_loss: 0.4655 - val_acc: 0.8031\n",
      "Epoch 115/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4717 - acc: 0.8017 - val_loss: 0.4600 - val_acc: 0.8096\n",
      "Epoch 116/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.4696 - acc: 0.8041 - val_loss: 0.4679 - val_acc: 0.8038\n",
      "Epoch 117/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.4910 - acc: 0.7966 - val_loss: 0.4574 - val_acc: 0.8134\n",
      "Epoch 118/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.4640 - acc: 0.8038 - val_loss: 0.4531 - val_acc: 0.8103\n",
      "Epoch 119/200\n",
      "2910/2910 [==============================] - 0s 54us/step - loss: 0.4579 - acc: 0.8069 - val_loss: 0.4463 - val_acc: 0.8189\n",
      "Epoch 120/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.4570 - acc: 0.8093 - val_loss: 0.4507 - val_acc: 0.8285\n",
      "Epoch 121/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4633 - acc: 0.8086 - val_loss: 0.4477 - val_acc: 0.8220\n",
      "Epoch 122/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.4531 - acc: 0.8144 - val_loss: 0.4383 - val_acc: 0.8117\n",
      "Epoch 123/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.4435 - acc: 0.8131 - val_loss: 0.4356 - val_acc: 0.8213\n",
      "Epoch 124/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4428 - acc: 0.8151 - val_loss: 0.4425 - val_acc: 0.8162\n",
      "Epoch 125/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4418 - acc: 0.8213 - val_loss: 0.4309 - val_acc: 0.8162\n",
      "Epoch 126/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4377 - acc: 0.8175 - val_loss: 0.4266 - val_acc: 0.8285\n",
      "Epoch 127/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.4350 - acc: 0.8175 - val_loss: 0.4272 - val_acc: 0.8368\n",
      "Epoch 128/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4301 - acc: 0.8196 - val_loss: 0.4211 - val_acc: 0.8292\n",
      "Epoch 129/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4301 - acc: 0.8234 - val_loss: 0.4278 - val_acc: 0.8206\n",
      "Epoch 130/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.4283 - acc: 0.8289 - val_loss: 0.4210 - val_acc: 0.8278\n",
      "Epoch 131/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4260 - acc: 0.8275 - val_loss: 0.4148 - val_acc: 0.8423\n",
      "Epoch 132/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4238 - acc: 0.8316 - val_loss: 0.4087 - val_acc: 0.8326\n",
      "Epoch 133/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4151 - acc: 0.8268 - val_loss: 0.4082 - val_acc: 0.8405\n",
      "Epoch 134/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.4203 - acc: 0.8309 - val_loss: 0.4090 - val_acc: 0.8457\n",
      "Epoch 135/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.4146 - acc: 0.8323 - val_loss: 0.4152 - val_acc: 0.8368\n",
      "Epoch 136/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4093 - acc: 0.8330 - val_loss: 0.3990 - val_acc: 0.8385\n",
      "Epoch 137/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4073 - acc: 0.8347 - val_loss: 0.3930 - val_acc: 0.8436\n",
      "Epoch 138/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4056 - acc: 0.8392 - val_loss: 0.3885 - val_acc: 0.8433\n",
      "Epoch 139/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4020 - acc: 0.8433 - val_loss: 0.3942 - val_acc: 0.8351\n",
      "Epoch 140/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.4022 - acc: 0.8371 - val_loss: 0.3883 - val_acc: 0.8405\n",
      "Epoch 141/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3907 - acc: 0.8412 - val_loss: 0.3834 - val_acc: 0.8478\n",
      "Epoch 142/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.3844 - acc: 0.8515 - val_loss: 0.3812 - val_acc: 0.8588\n",
      "Epoch 143/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.3840 - acc: 0.8478 - val_loss: 0.3767 - val_acc: 0.8550\n",
      "Epoch 144/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3803 - acc: 0.8526 - val_loss: 0.3776 - val_acc: 0.8436\n",
      "Epoch 145/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3862 - acc: 0.8457 - val_loss: 0.3755 - val_acc: 0.8564\n",
      "Epoch 146/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.3791 - acc: 0.8460 - val_loss: 0.3694 - val_acc: 0.8570\n",
      "Epoch 147/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.3732 - acc: 0.8529 - val_loss: 0.3672 - val_acc: 0.8646\n",
      "Epoch 148/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3706 - acc: 0.8577 - val_loss: 0.3606 - val_acc: 0.8584\n",
      "Epoch 149/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.3671 - acc: 0.8622 - val_loss: 0.3634 - val_acc: 0.8632\n",
      "Epoch 150/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3655 - acc: 0.8622 - val_loss: 0.3532 - val_acc: 0.8725\n",
      "Epoch 151/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3629 - acc: 0.8581 - val_loss: 0.3496 - val_acc: 0.8698\n",
      "Epoch 152/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3615 - acc: 0.8643 - val_loss: 0.3605 - val_acc: 0.8711\n",
      "Epoch 153/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3538 - acc: 0.8608 - val_loss: 0.3493 - val_acc: 0.8608\n",
      "Epoch 154/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3510 - acc: 0.8636 - val_loss: 0.3409 - val_acc: 0.8729\n",
      "Epoch 155/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3539 - acc: 0.8598 - val_loss: 0.3385 - val_acc: 0.8722\n",
      "Epoch 156/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3506 - acc: 0.8691 - val_loss: 0.3403 - val_acc: 0.8763\n",
      "Epoch 157/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3503 - acc: 0.8698 - val_loss: 0.3431 - val_acc: 0.8742\n",
      "Epoch 158/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3409 - acc: 0.8694 - val_loss: 0.3309 - val_acc: 0.8753\n",
      "Epoch 159/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3360 - acc: 0.8746 - val_loss: 0.3334 - val_acc: 0.8732\n",
      "Epoch 160/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3407 - acc: 0.8663 - val_loss: 0.3296 - val_acc: 0.8859\n",
      "Epoch 161/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3311 - acc: 0.8801 - val_loss: 0.3269 - val_acc: 0.8876\n",
      "Epoch 162/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3328 - acc: 0.8821 - val_loss: 0.3279 - val_acc: 0.8708\n",
      "Epoch 163/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3292 - acc: 0.8749 - val_loss: 0.3286 - val_acc: 0.8883\n",
      "Epoch 164/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3302 - acc: 0.8773 - val_loss: 0.3186 - val_acc: 0.8938\n",
      "Epoch 165/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.3279 - acc: 0.8797 - val_loss: 0.3205 - val_acc: 0.8818\n",
      "Epoch 166/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3205 - acc: 0.8808 - val_loss: 0.3113 - val_acc: 0.8814\n",
      "Epoch 167/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3177 - acc: 0.8804 - val_loss: 0.3086 - val_acc: 0.8911\n",
      "Epoch 168/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3132 - acc: 0.8849 - val_loss: 0.3054 - val_acc: 0.8931\n",
      "Epoch 169/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3127 - acc: 0.8876 - val_loss: 0.3101 - val_acc: 0.8832\n",
      "Epoch 170/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3254 - acc: 0.8770 - val_loss: 0.3051 - val_acc: 0.8890\n",
      "Epoch 171/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3077 - acc: 0.8849 - val_loss: 0.3003 - val_acc: 0.8859\n",
      "Epoch 172/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3070 - acc: 0.8907 - val_loss: 0.3013 - val_acc: 0.8931\n",
      "Epoch 173/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3016 - acc: 0.8900 - val_loss: 0.3020 - val_acc: 0.8869\n",
      "Epoch 174/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3132 - acc: 0.8849 - val_loss: 0.2949 - val_acc: 0.8918\n",
      "Epoch 175/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3040 - acc: 0.8900 - val_loss: 0.3056 - val_acc: 0.8890\n",
      "Epoch 176/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.2980 - acc: 0.8863 - val_loss: 0.3026 - val_acc: 0.8797\n",
      "Epoch 177/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.2943 - acc: 0.8924 - val_loss: 0.2816 - val_acc: 0.9034\n",
      "Epoch 178/200\n",
      "2910/2910 [==============================] - 0s 59us/step - loss: 0.2930 - acc: 0.8935 - val_loss: 0.2839 - val_acc: 0.8993\n",
      "Epoch 179/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.2853 - acc: 0.9010 - val_loss: 0.2813 - val_acc: 0.9031\n",
      "Epoch 180/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.2898 - acc: 0.8993 - val_loss: 0.2767 - val_acc: 0.9093\n",
      "Epoch 181/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.2830 - acc: 0.9007 - val_loss: 0.2778 - val_acc: 0.9055\n",
      "Epoch 182/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.2833 - acc: 0.9038 - val_loss: 0.2786 - val_acc: 0.8935\n",
      "Epoch 183/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.2805 - acc: 0.8997 - val_loss: 0.2709 - val_acc: 0.9048\n",
      "Epoch 184/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.2749 - acc: 0.9034 - val_loss: 0.2735 - val_acc: 0.9065\n",
      "Epoch 185/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.2784 - acc: 0.8979 - val_loss: 0.2687 - val_acc: 0.9082\n",
      "Epoch 186/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.2752 - acc: 0.9038 - val_loss: 0.2777 - val_acc: 0.8979\n",
      "Epoch 187/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.2755 - acc: 0.9021 - val_loss: 0.2610 - val_acc: 0.9137\n",
      "Epoch 188/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.2710 - acc: 0.9021 - val_loss: 0.2649 - val_acc: 0.9072\n",
      "Epoch 189/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.2650 - acc: 0.9076 - val_loss: 0.2602 - val_acc: 0.9058\n",
      "Epoch 190/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.2617 - acc: 0.9107 - val_loss: 0.2580 - val_acc: 0.9168\n",
      "Epoch 191/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.2609 - acc: 0.9100 - val_loss: 0.2578 - val_acc: 0.9165\n",
      "Epoch 192/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.2578 - acc: 0.9134 - val_loss: 0.2519 - val_acc: 0.9134\n",
      "Epoch 193/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.2574 - acc: 0.9134 - val_loss: 0.2481 - val_acc: 0.9175\n",
      "Epoch 194/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.2541 - acc: 0.9172 - val_loss: 0.2460 - val_acc: 0.9210\n",
      "Epoch 195/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.2548 - acc: 0.9141 - val_loss: 0.2482 - val_acc: 0.9175\n",
      "Epoch 196/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.2574 - acc: 0.9096 - val_loss: 0.2463 - val_acc: 0.9137\n",
      "Epoch 197/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.2579 - acc: 0.9045 - val_loss: 0.2425 - val_acc: 0.9220\n",
      "Epoch 198/200\n",
      "2910/2910 [==============================] - 0s 43us/step - loss: 0.2473 - acc: 0.9127 - val_loss: 0.2430 - val_acc: 0.9203\n",
      "Epoch 199/200\n",
      "2910/2910 [==============================] - 0s 43us/step - loss: 0.2489 - acc: 0.9162 - val_loss: 0.2403 - val_acc: 0.9186\n",
      "Epoch 200/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.2451 - acc: 0.9175 - val_loss: 0.2405 - val_acc: 0.9124\n",
      "2910/2910 [==============================] - 0s 49us/step\n",
      "2910/2910 [==============================] - 0s 48us/step\n",
      "Train on 2910 samples, validate on 2910 samples\n",
      "Epoch 1/200\n",
      "2910/2910 [==============================] - 3s 907us/step - loss: 1.0571 - acc: 0.4715 - val_loss: 0.9700 - val_acc: 0.6172\n",
      "Epoch 2/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.9432 - acc: 0.6182 - val_loss: 0.9182 - val_acc: 0.6210\n",
      "Epoch 3/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.9070 - acc: 0.6213 - val_loss: 0.8909 - val_acc: 0.6216\n",
      "Epoch 4/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.8860 - acc: 0.6216 - val_loss: 0.8749 - val_acc: 0.6216\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.8712 - acc: 0.6210 - val_loss: 0.8635 - val_acc: 0.6223\n",
      "Epoch 6/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.8624 - acc: 0.6230 - val_loss: 0.8558 - val_acc: 0.6230\n",
      "Epoch 7/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.8548 - acc: 0.6247 - val_loss: 0.8485 - val_acc: 0.6254\n",
      "Epoch 8/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.8497 - acc: 0.6265 - val_loss: 0.8424 - val_acc: 0.6296\n",
      "Epoch 9/200\n",
      "2910/2910 [==============================] - 0s 43us/step - loss: 0.8434 - acc: 0.6289 - val_loss: 0.8383 - val_acc: 0.6289\n",
      "Epoch 10/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.8380 - acc: 0.6309 - val_loss: 0.8301 - val_acc: 0.6309\n",
      "Epoch 11/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.8334 - acc: 0.6313 - val_loss: 0.8246 - val_acc: 0.6302\n",
      "Epoch 12/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.8320 - acc: 0.6254 - val_loss: 0.8202 - val_acc: 0.6326\n",
      "Epoch 13/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.8236 - acc: 0.6371 - val_loss: 0.8161 - val_acc: 0.6323\n",
      "Epoch 14/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.8163 - acc: 0.6340 - val_loss: 0.8086 - val_acc: 0.6340\n",
      "Epoch 15/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.8138 - acc: 0.6364 - val_loss: 0.8025 - val_acc: 0.6388\n",
      "Epoch 16/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.8046 - acc: 0.6364 - val_loss: 0.7971 - val_acc: 0.6385\n",
      "Epoch 17/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.8008 - acc: 0.6361 - val_loss: 0.7925 - val_acc: 0.6471\n",
      "Epoch 18/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.7925 - acc: 0.6454 - val_loss: 0.7845 - val_acc: 0.6481\n",
      "Epoch 19/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.7865 - acc: 0.6471 - val_loss: 0.7795 - val_acc: 0.6588\n",
      "Epoch 20/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.7806 - acc: 0.6509 - val_loss: 0.7735 - val_acc: 0.6550\n",
      "Epoch 21/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.7747 - acc: 0.6529 - val_loss: 0.7661 - val_acc: 0.6529\n",
      "Epoch 22/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.7713 - acc: 0.6574 - val_loss: 0.7631 - val_acc: 0.6574\n",
      "Epoch 23/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.7656 - acc: 0.6567 - val_loss: 0.7564 - val_acc: 0.6629\n",
      "Epoch 24/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.7586 - acc: 0.6605 - val_loss: 0.7537 - val_acc: 0.6667\n",
      "Epoch 25/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.7570 - acc: 0.6577 - val_loss: 0.7443 - val_acc: 0.6749\n",
      "Epoch 26/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.7480 - acc: 0.6656 - val_loss: 0.7407 - val_acc: 0.6773\n",
      "Epoch 27/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.7543 - acc: 0.6622 - val_loss: 0.7393 - val_acc: 0.6591\n",
      "Epoch 28/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.7394 - acc: 0.6701 - val_loss: 0.7319 - val_acc: 0.6708\n",
      "Epoch 29/200\n",
      "2910/2910 [==============================] - 0s 63us/step - loss: 0.7332 - acc: 0.6746 - val_loss: 0.7227 - val_acc: 0.6797\n",
      "Epoch 30/200\n",
      "2910/2910 [==============================] - 0s 53us/step - loss: 0.7274 - acc: 0.6739 - val_loss: 0.7214 - val_acc: 0.6701\n",
      "Epoch 31/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.7200 - acc: 0.6753 - val_loss: 0.7148 - val_acc: 0.6904\n",
      "Epoch 32/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.7183 - acc: 0.6821 - val_loss: 0.7128 - val_acc: 0.6722\n",
      "Epoch 33/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.7119 - acc: 0.6880 - val_loss: 0.7085 - val_acc: 0.6990\n",
      "Epoch 34/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.7128 - acc: 0.6787 - val_loss: 0.7010 - val_acc: 0.6890\n",
      "Epoch 35/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.7022 - acc: 0.6845 - val_loss: 0.6919 - val_acc: 0.6849\n",
      "Epoch 36/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.6994 - acc: 0.6931 - val_loss: 0.6862 - val_acc: 0.6962\n",
      "Epoch 37/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6911 - acc: 0.6914 - val_loss: 0.6835 - val_acc: 0.6938\n",
      "Epoch 38/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6847 - acc: 0.6942 - val_loss: 0.6808 - val_acc: 0.7062\n",
      "Epoch 39/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6852 - acc: 0.6997 - val_loss: 0.6767 - val_acc: 0.7069\n",
      "Epoch 40/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.6781 - acc: 0.7017 - val_loss: 0.6679 - val_acc: 0.7076\n",
      "Epoch 41/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6742 - acc: 0.7052 - val_loss: 0.6619 - val_acc: 0.7196\n",
      "Epoch 42/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6683 - acc: 0.7158 - val_loss: 0.6591 - val_acc: 0.7220\n",
      "Epoch 43/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.6634 - acc: 0.7206 - val_loss: 0.6529 - val_acc: 0.7234\n",
      "Epoch 44/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6581 - acc: 0.7234 - val_loss: 0.6522 - val_acc: 0.7162\n",
      "Epoch 45/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.6603 - acc: 0.7107 - val_loss: 0.6483 - val_acc: 0.7247\n",
      "Epoch 46/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.6488 - acc: 0.7313 - val_loss: 0.6410 - val_acc: 0.7320\n",
      "Epoch 47/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.6440 - acc: 0.7347 - val_loss: 0.6351 - val_acc: 0.7354\n",
      "Epoch 48/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6394 - acc: 0.7326 - val_loss: 0.6364 - val_acc: 0.7388\n",
      "Epoch 49/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6388 - acc: 0.7361 - val_loss: 0.6286 - val_acc: 0.7433\n",
      "Epoch 50/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6309 - acc: 0.7426 - val_loss: 0.6313 - val_acc: 0.7306\n",
      "Epoch 51/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.6314 - acc: 0.7351 - val_loss: 0.6179 - val_acc: 0.7515\n",
      "Epoch 52/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.6253 - acc: 0.7436 - val_loss: 0.6136 - val_acc: 0.7519\n",
      "Epoch 53/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.6190 - acc: 0.7464 - val_loss: 0.6142 - val_acc: 0.7505\n",
      "Epoch 54/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.6157 - acc: 0.7471 - val_loss: 0.6063 - val_acc: 0.7515\n",
      "Epoch 55/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6105 - acc: 0.7533 - val_loss: 0.6014 - val_acc: 0.7502\n",
      "Epoch 56/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.6060 - acc: 0.7498 - val_loss: 0.5966 - val_acc: 0.7608\n",
      "Epoch 57/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.6041 - acc: 0.7467 - val_loss: 0.5934 - val_acc: 0.7560\n",
      "Epoch 58/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5970 - acc: 0.7581 - val_loss: 0.5909 - val_acc: 0.7529\n",
      "Epoch 59/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.5945 - acc: 0.7588 - val_loss: 0.5871 - val_acc: 0.7588\n",
      "Epoch 60/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5907 - acc: 0.7598 - val_loss: 0.5815 - val_acc: 0.7649\n",
      "Epoch 61/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.5889 - acc: 0.7557 - val_loss: 0.5791 - val_acc: 0.7612\n",
      "Epoch 62/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5832 - acc: 0.7629 - val_loss: 0.5745 - val_acc: 0.7698\n",
      "Epoch 63/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.5796 - acc: 0.7646 - val_loss: 0.5699 - val_acc: 0.7787\n",
      "Epoch 64/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.5759 - acc: 0.7667 - val_loss: 0.5682 - val_acc: 0.7759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.5752 - acc: 0.7622 - val_loss: 0.5696 - val_acc: 0.7725\n",
      "Epoch 66/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.5712 - acc: 0.7698 - val_loss: 0.5621 - val_acc: 0.7701\n",
      "Epoch 67/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5681 - acc: 0.7639 - val_loss: 0.5660 - val_acc: 0.7656\n",
      "Epoch 68/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5703 - acc: 0.7701 - val_loss: 0.5563 - val_acc: 0.7773\n",
      "Epoch 69/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5661 - acc: 0.7680 - val_loss: 0.5538 - val_acc: 0.7759\n",
      "Epoch 70/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.5593 - acc: 0.7746 - val_loss: 0.5484 - val_acc: 0.7784\n",
      "Epoch 71/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.5596 - acc: 0.7777 - val_loss: 0.5489 - val_acc: 0.7818\n",
      "Epoch 72/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5530 - acc: 0.7766 - val_loss: 0.5451 - val_acc: 0.7729\n",
      "Epoch 73/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.5527 - acc: 0.7759 - val_loss: 0.5475 - val_acc: 0.7756\n",
      "Epoch 74/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.5469 - acc: 0.7773 - val_loss: 0.5413 - val_acc: 0.7852\n",
      "Epoch 75/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5457 - acc: 0.7794 - val_loss: 0.5330 - val_acc: 0.7938\n",
      "Epoch 76/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5425 - acc: 0.7804 - val_loss: 0.5324 - val_acc: 0.7890\n",
      "Epoch 77/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5387 - acc: 0.7825 - val_loss: 0.5280 - val_acc: 0.7859\n",
      "Epoch 78/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5363 - acc: 0.7821 - val_loss: 0.5251 - val_acc: 0.7825\n",
      "Epoch 79/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.5310 - acc: 0.7852 - val_loss: 0.5225 - val_acc: 0.7928\n",
      "Epoch 80/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.5391 - acc: 0.7766 - val_loss: 0.5232 - val_acc: 0.8048\n",
      "Epoch 81/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.5272 - acc: 0.7904 - val_loss: 0.5169 - val_acc: 0.7990\n",
      "Epoch 82/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5231 - acc: 0.7887 - val_loss: 0.5133 - val_acc: 0.8041\n",
      "Epoch 83/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.5223 - acc: 0.7976 - val_loss: 0.5102 - val_acc: 0.7997\n",
      "Epoch 84/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5179 - acc: 0.7921 - val_loss: 0.5104 - val_acc: 0.7962\n",
      "Epoch 85/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5150 - acc: 0.7990 - val_loss: 0.5063 - val_acc: 0.8031\n",
      "Epoch 86/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5139 - acc: 0.7990 - val_loss: 0.5007 - val_acc: 0.8017\n",
      "Epoch 87/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5081 - acc: 0.8014 - val_loss: 0.5020 - val_acc: 0.8058\n",
      "Epoch 88/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.5088 - acc: 0.8003 - val_loss: 0.4987 - val_acc: 0.8065\n",
      "Epoch 89/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5056 - acc: 0.8010 - val_loss: 0.4949 - val_acc: 0.8141\n",
      "Epoch 90/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.5063 - acc: 0.8003 - val_loss: 0.4973 - val_acc: 0.8103\n",
      "Epoch 91/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.5024 - acc: 0.8072 - val_loss: 0.4918 - val_acc: 0.8069\n",
      "Epoch 92/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.5016 - acc: 0.7893 - val_loss: 0.4910 - val_acc: 0.8093\n",
      "Epoch 93/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.4937 - acc: 0.8096 - val_loss: 0.4851 - val_acc: 0.8134\n",
      "Epoch 94/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4927 - acc: 0.8089 - val_loss: 0.4820 - val_acc: 0.8141\n",
      "Epoch 95/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4907 - acc: 0.8072 - val_loss: 0.4796 - val_acc: 0.8158\n",
      "Epoch 96/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.4908 - acc: 0.8100 - val_loss: 0.4792 - val_acc: 0.8127\n",
      "Epoch 97/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4934 - acc: 0.8000 - val_loss: 0.4794 - val_acc: 0.8103\n",
      "Epoch 98/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4846 - acc: 0.8113 - val_loss: 0.4799 - val_acc: 0.8131\n",
      "Epoch 99/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4832 - acc: 0.8127 - val_loss: 0.4709 - val_acc: 0.8192\n",
      "Epoch 100/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4778 - acc: 0.8134 - val_loss: 0.4663 - val_acc: 0.8199\n",
      "Epoch 101/200\n",
      "2910/2910 [==============================] - 0s 60us/step - loss: 0.4756 - acc: 0.8134 - val_loss: 0.4652 - val_acc: 0.8227\n",
      "Epoch 102/200\n",
      "2910/2910 [==============================] - 0s 63us/step - loss: 0.4768 - acc: 0.8168 - val_loss: 0.4675 - val_acc: 0.8210\n",
      "Epoch 103/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.4746 - acc: 0.8107 - val_loss: 0.4678 - val_acc: 0.8247\n",
      "Epoch 104/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.4695 - acc: 0.8165 - val_loss: 0.4588 - val_acc: 0.8220\n",
      "Epoch 105/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.4686 - acc: 0.8172 - val_loss: 0.4594 - val_acc: 0.8271\n",
      "Epoch 106/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4658 - acc: 0.8189 - val_loss: 0.4551 - val_acc: 0.8271\n",
      "Epoch 107/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.4609 - acc: 0.8247 - val_loss: 0.4545 - val_acc: 0.8237\n",
      "Epoch 108/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4656 - acc: 0.8199 - val_loss: 0.4492 - val_acc: 0.8320\n",
      "Epoch 109/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4590 - acc: 0.8241 - val_loss: 0.4561 - val_acc: 0.8199\n",
      "Epoch 110/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4645 - acc: 0.8216 - val_loss: 0.4482 - val_acc: 0.8416\n",
      "Epoch 111/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4568 - acc: 0.8313 - val_loss: 0.4476 - val_acc: 0.8333\n",
      "Epoch 112/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4566 - acc: 0.8254 - val_loss: 0.4428 - val_acc: 0.8443\n",
      "Epoch 113/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4484 - acc: 0.8313 - val_loss: 0.4407 - val_acc: 0.8378\n",
      "Epoch 114/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.4470 - acc: 0.8282 - val_loss: 0.4441 - val_acc: 0.8378\n",
      "Epoch 115/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4519 - acc: 0.8302 - val_loss: 0.4375 - val_acc: 0.8371\n",
      "Epoch 116/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.4456 - acc: 0.8351 - val_loss: 0.4400 - val_acc: 0.8344\n",
      "Epoch 117/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.4459 - acc: 0.8302 - val_loss: 0.4328 - val_acc: 0.8474\n",
      "Epoch 118/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4455 - acc: 0.8337 - val_loss: 0.4382 - val_acc: 0.8313\n",
      "Epoch 119/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4408 - acc: 0.8313 - val_loss: 0.4347 - val_acc: 0.8436\n",
      "Epoch 120/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4396 - acc: 0.8378 - val_loss: 0.4264 - val_acc: 0.8378\n",
      "Epoch 121/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4346 - acc: 0.8375 - val_loss: 0.4249 - val_acc: 0.8478\n",
      "Epoch 122/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.4395 - acc: 0.8357 - val_loss: 0.4254 - val_acc: 0.8515\n",
      "Epoch 123/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4368 - acc: 0.8323 - val_loss: 0.4289 - val_acc: 0.8526\n",
      "Epoch 124/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.4297 - acc: 0.8423 - val_loss: 0.4216 - val_acc: 0.8399\n",
      "Epoch 125/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4320 - acc: 0.8333 - val_loss: 0.4192 - val_acc: 0.8450\n",
      "Epoch 126/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4241 - acc: 0.8450 - val_loss: 0.4163 - val_acc: 0.8443\n",
      "Epoch 127/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4261 - acc: 0.8361 - val_loss: 0.4142 - val_acc: 0.8519\n",
      "Epoch 128/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4202 - acc: 0.8491 - val_loss: 0.4148 - val_acc: 0.8574\n",
      "Epoch 129/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4179 - acc: 0.8481 - val_loss: 0.4117 - val_acc: 0.8526\n",
      "Epoch 130/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.4199 - acc: 0.8454 - val_loss: 0.4194 - val_acc: 0.8368\n",
      "Epoch 131/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4192 - acc: 0.8378 - val_loss: 0.4032 - val_acc: 0.8584\n",
      "Epoch 132/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.4129 - acc: 0.8495 - val_loss: 0.4018 - val_acc: 0.8605\n",
      "Epoch 133/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4156 - acc: 0.8447 - val_loss: 0.4056 - val_acc: 0.8502\n",
      "Epoch 134/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4156 - acc: 0.8464 - val_loss: 0.3997 - val_acc: 0.8546\n",
      "Epoch 135/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.4112 - acc: 0.8519 - val_loss: 0.3969 - val_acc: 0.8540\n",
      "Epoch 136/200\n",
      "2910/2910 [==============================] - 0s 44us/step - loss: 0.4042 - acc: 0.8488 - val_loss: 0.3951 - val_acc: 0.8557\n",
      "Epoch 137/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.4183 - acc: 0.8454 - val_loss: 0.3925 - val_acc: 0.8567\n",
      "Epoch 138/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.4093 - acc: 0.8522 - val_loss: 0.3932 - val_acc: 0.8663\n",
      "Epoch 139/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.3963 - acc: 0.8553 - val_loss: 0.3907 - val_acc: 0.8619\n",
      "Epoch 140/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3980 - acc: 0.8584 - val_loss: 0.3906 - val_acc: 0.8667\n",
      "Epoch 141/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.3973 - acc: 0.8550 - val_loss: 0.3860 - val_acc: 0.8625\n",
      "Epoch 142/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.3918 - acc: 0.8608 - val_loss: 0.3861 - val_acc: 0.8543\n",
      "Epoch 143/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.4003 - acc: 0.8522 - val_loss: 0.3843 - val_acc: 0.8564\n",
      "Epoch 144/200\n",
      "2910/2910 [==============================] - 0s 56us/step - loss: 0.3925 - acc: 0.8591 - val_loss: 0.3801 - val_acc: 0.8619\n",
      "Epoch 145/200\n",
      "2910/2910 [==============================] - 0s 58us/step - loss: 0.3862 - acc: 0.8653 - val_loss: 0.3773 - val_acc: 0.8704\n",
      "Epoch 146/200\n",
      "2910/2910 [==============================] - 0s 54us/step - loss: 0.3840 - acc: 0.8629 - val_loss: 0.3736 - val_acc: 0.8718\n",
      "Epoch 147/200\n",
      "2910/2910 [==============================] - 0s 53us/step - loss: 0.3819 - acc: 0.8619 - val_loss: 0.3756 - val_acc: 0.8684\n",
      "Epoch 148/200\n",
      "2910/2910 [==============================] - 0s 57us/step - loss: 0.3772 - acc: 0.8694 - val_loss: 0.3767 - val_acc: 0.8615\n",
      "Epoch 149/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.3767 - acc: 0.8615 - val_loss: 0.3744 - val_acc: 0.8698\n",
      "Epoch 150/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.3744 - acc: 0.8653 - val_loss: 0.3636 - val_acc: 0.8770\n",
      "Epoch 151/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.3726 - acc: 0.8660 - val_loss: 0.3671 - val_acc: 0.8588\n",
      "Epoch 152/200\n",
      "2910/2910 [==============================] - 0s 54us/step - loss: 0.3764 - acc: 0.8625 - val_loss: 0.3633 - val_acc: 0.8701\n",
      "Epoch 153/200\n",
      "2910/2910 [==============================] - 0s 64us/step - loss: 0.3679 - acc: 0.8742 - val_loss: 0.3586 - val_acc: 0.8756\n",
      "Epoch 154/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.3678 - acc: 0.8694 - val_loss: 0.3587 - val_acc: 0.8735\n",
      "Epoch 155/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.3656 - acc: 0.8674 - val_loss: 0.3553 - val_acc: 0.8718\n",
      "Epoch 156/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.3616 - acc: 0.8708 - val_loss: 0.3517 - val_acc: 0.8790\n",
      "Epoch 157/200\n",
      "2910/2910 [==============================] - 0s 62us/step - loss: 0.3589 - acc: 0.8735 - val_loss: 0.3522 - val_acc: 0.8797\n",
      "Epoch 158/200\n",
      "2910/2910 [==============================] - 0s 56us/step - loss: 0.3603 - acc: 0.8718 - val_loss: 0.3495 - val_acc: 0.8790\n",
      "Epoch 159/200\n",
      "2910/2910 [==============================] - 0s 69us/step - loss: 0.3579 - acc: 0.8739 - val_loss: 0.3472 - val_acc: 0.8859\n",
      "Epoch 160/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.3566 - acc: 0.8780 - val_loss: 0.3424 - val_acc: 0.8828\n",
      "Epoch 161/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.3544 - acc: 0.8790 - val_loss: 0.3471 - val_acc: 0.8794\n",
      "Epoch 162/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.3507 - acc: 0.8711 - val_loss: 0.3407 - val_acc: 0.8852\n",
      "Epoch 163/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3474 - acc: 0.8780 - val_loss: 0.3415 - val_acc: 0.8849\n",
      "Epoch 164/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.3563 - acc: 0.8715 - val_loss: 0.3425 - val_acc: 0.8845\n",
      "Epoch 165/200\n",
      "2910/2910 [==============================] - 0s 52us/step - loss: 0.3433 - acc: 0.8801 - val_loss: 0.3351 - val_acc: 0.8811\n",
      "Epoch 166/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.3492 - acc: 0.8790 - val_loss: 0.3451 - val_acc: 0.8729\n",
      "Epoch 167/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.3450 - acc: 0.8790 - val_loss: 0.3315 - val_acc: 0.8784\n",
      "Epoch 168/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.3374 - acc: 0.8794 - val_loss: 0.3306 - val_acc: 0.8893\n",
      "Epoch 169/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.3351 - acc: 0.8856 - val_loss: 0.3298 - val_acc: 0.8856\n",
      "Epoch 170/200\n",
      "2910/2910 [==============================] - 0s 56us/step - loss: 0.3341 - acc: 0.8801 - val_loss: 0.3275 - val_acc: 0.8821\n",
      "Epoch 171/200\n",
      "2910/2910 [==============================] - 0s 66us/step - loss: 0.3316 - acc: 0.8852 - val_loss: 0.3228 - val_acc: 0.8893\n",
      "Epoch 172/200\n",
      "2910/2910 [==============================] - 0s 55us/step - loss: 0.3298 - acc: 0.8821 - val_loss: 0.3181 - val_acc: 0.8904\n",
      "Epoch 173/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.3277 - acc: 0.8856 - val_loss: 0.3164 - val_acc: 0.8897\n",
      "Epoch 174/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.3273 - acc: 0.8893 - val_loss: 0.3180 - val_acc: 0.8911\n",
      "Epoch 175/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.3231 - acc: 0.8866 - val_loss: 0.3162 - val_acc: 0.8924\n",
      "Epoch 176/200\n",
      "2910/2910 [==============================] - 0s 50us/step - loss: 0.3200 - acc: 0.8893 - val_loss: 0.3131 - val_acc: 0.8966\n",
      "Epoch 177/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.3220 - acc: 0.8835 - val_loss: 0.3194 - val_acc: 0.8938\n",
      "Epoch 178/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.3204 - acc: 0.8869 - val_loss: 0.3070 - val_acc: 0.8942\n",
      "Epoch 179/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3141 - acc: 0.8911 - val_loss: 0.3044 - val_acc: 0.8948\n",
      "Epoch 180/200\n",
      "2910/2910 [==============================] - 0s 53us/step - loss: 0.3144 - acc: 0.8887 - val_loss: 0.3079 - val_acc: 0.8938\n",
      "Epoch 181/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.3107 - acc: 0.8890 - val_loss: 0.3003 - val_acc: 0.8973\n",
      "Epoch 182/200\n",
      "2910/2910 [==============================] - 0s 51us/step - loss: 0.3093 - acc: 0.8904 - val_loss: 0.3015 - val_acc: 0.8983\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.3108 - acc: 0.8907 - val_loss: 0.3023 - val_acc: 0.9014\n",
      "Epoch 184/200\n",
      "2910/2910 [==============================] - 0s 45us/step - loss: 0.3030 - acc: 0.8945 - val_loss: 0.2981 - val_acc: 0.8976\n",
      "Epoch 185/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.3116 - acc: 0.8900 - val_loss: 0.3000 - val_acc: 0.8928\n",
      "Epoch 186/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.3087 - acc: 0.8945 - val_loss: 0.3008 - val_acc: 0.8959\n",
      "Epoch 187/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.3023 - acc: 0.8969 - val_loss: 0.2962 - val_acc: 0.8966\n",
      "Epoch 188/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.2967 - acc: 0.8959 - val_loss: 0.2906 - val_acc: 0.9007\n",
      "Epoch 189/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.2939 - acc: 0.8969 - val_loss: 0.2870 - val_acc: 0.9000\n",
      "Epoch 190/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.2912 - acc: 0.8962 - val_loss: 0.2855 - val_acc: 0.9000\n",
      "Epoch 191/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.2995 - acc: 0.8959 - val_loss: 0.2815 - val_acc: 0.9062\n",
      "Epoch 192/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.2884 - acc: 0.8986 - val_loss: 0.2785 - val_acc: 0.9058\n",
      "Epoch 193/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.2861 - acc: 0.9062 - val_loss: 0.2774 - val_acc: 0.9024\n",
      "Epoch 194/200\n",
      "2910/2910 [==============================] - 0s 49us/step - loss: 0.2847 - acc: 0.9017 - val_loss: 0.2761 - val_acc: 0.9117\n",
      "Epoch 195/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.2795 - acc: 0.8997 - val_loss: 0.2701 - val_acc: 0.9089\n",
      "Epoch 196/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.2823 - acc: 0.9045 - val_loss: 0.2744 - val_acc: 0.9086\n",
      "Epoch 197/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.2783 - acc: 0.9021 - val_loss: 0.2703 - val_acc: 0.9117\n",
      "Epoch 198/200\n",
      "2910/2910 [==============================] - 0s 47us/step - loss: 0.2711 - acc: 0.9069 - val_loss: 0.2640 - val_acc: 0.9062\n",
      "Epoch 199/200\n",
      "2910/2910 [==============================] - 0s 48us/step - loss: 0.2737 - acc: 0.9082 - val_loss: 0.2614 - val_acc: 0.9144\n",
      "Epoch 200/200\n",
      "2910/2910 [==============================] - 0s 46us/step - loss: 0.2720 - acc: 0.9065 - val_loss: 0.2657 - val_acc: 0.9144\n",
      "2910/2910 [==============================] - 0s 49us/step\n",
      "2910/2910 [==============================] - 0s 50us/step\n",
      "Train on 1164 samples, validate on 1164 samples\n",
      "Epoch 1/200\n",
      "1164/1164 [==============================] - 3s 2ms/step - loss: 1.0058 - acc: 0.5636 - val_loss: 0.9535 - val_acc: 0.5902\n",
      "Epoch 2/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.9376 - acc: 0.5893 - val_loss: 0.9192 - val_acc: 0.5962\n",
      "Epoch 3/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.9113 - acc: 0.5988 - val_loss: 0.8992 - val_acc: 0.6100\n",
      "Epoch 4/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.8946 - acc: 0.6048 - val_loss: 0.8856 - val_acc: 0.6091\n",
      "Epoch 5/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.8822 - acc: 0.6091 - val_loss: 0.8747 - val_acc: 0.6151\n",
      "Epoch 6/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.8734 - acc: 0.6160 - val_loss: 0.8658 - val_acc: 0.6143\n",
      "Epoch 7/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.8643 - acc: 0.6151 - val_loss: 0.8585 - val_acc: 0.6220\n",
      "Epoch 8/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.8577 - acc: 0.6220 - val_loss: 0.8516 - val_acc: 0.6246\n",
      "Epoch 9/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.8503 - acc: 0.6220 - val_loss: 0.8452 - val_acc: 0.6194\n",
      "Epoch 10/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.8449 - acc: 0.6237 - val_loss: 0.8391 - val_acc: 0.6229\n",
      "Epoch 11/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.8419 - acc: 0.6143 - val_loss: 0.8342 - val_acc: 0.6237\n",
      "Epoch 12/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.8345 - acc: 0.6271 - val_loss: 0.8296 - val_acc: 0.6229\n",
      "Epoch 13/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.8279 - acc: 0.6177 - val_loss: 0.8233 - val_acc: 0.6186\n",
      "Epoch 14/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.8236 - acc: 0.6220 - val_loss: 0.8179 - val_acc: 0.6297\n",
      "Epoch 15/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.8180 - acc: 0.6263 - val_loss: 0.8126 - val_acc: 0.6246\n",
      "Epoch 16/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.8159 - acc: 0.6229 - val_loss: 0.8085 - val_acc: 0.6211\n",
      "Epoch 17/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.8122 - acc: 0.6289 - val_loss: 0.8045 - val_acc: 0.6297\n",
      "Epoch 18/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.8036 - acc: 0.6263 - val_loss: 0.7997 - val_acc: 0.6229\n",
      "Epoch 19/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.8008 - acc: 0.6332 - val_loss: 0.7937 - val_acc: 0.6460\n",
      "Epoch 20/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.7951 - acc: 0.6332 - val_loss: 0.7886 - val_acc: 0.6314\n",
      "Epoch 21/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.7894 - acc: 0.6383 - val_loss: 0.7838 - val_acc: 0.6418\n",
      "Epoch 22/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.7847 - acc: 0.6426 - val_loss: 0.7790 - val_acc: 0.6314\n",
      "Epoch 23/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.7791 - acc: 0.6289 - val_loss: 0.7739 - val_acc: 0.6383\n",
      "Epoch 24/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.7759 - acc: 0.6340 - val_loss: 0.7686 - val_acc: 0.6452\n",
      "Epoch 25/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.7739 - acc: 0.6512 - val_loss: 0.7637 - val_acc: 0.6529\n",
      "Epoch 26/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.7669 - acc: 0.6495 - val_loss: 0.7592 - val_acc: 0.6581\n",
      "Epoch 27/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.7623 - acc: 0.6486 - val_loss: 0.7548 - val_acc: 0.6503\n",
      "Epoch 28/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.7566 - acc: 0.6555 - val_loss: 0.7495 - val_acc: 0.6555\n",
      "Epoch 29/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.7521 - acc: 0.6555 - val_loss: 0.7454 - val_acc: 0.6701\n",
      "Epoch 30/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.7478 - acc: 0.6658 - val_loss: 0.7426 - val_acc: 0.6632\n",
      "Epoch 31/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.7423 - acc: 0.6598 - val_loss: 0.7382 - val_acc: 0.6770\n",
      "Epoch 32/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.7413 - acc: 0.6744 - val_loss: 0.7323 - val_acc: 0.6744\n",
      "Epoch 33/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.7357 - acc: 0.6727 - val_loss: 0.7269 - val_acc: 0.6813\n",
      "Epoch 34/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.7306 - acc: 0.6753 - val_loss: 0.7227 - val_acc: 0.6813\n",
      "Epoch 35/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.7255 - acc: 0.6821 - val_loss: 0.7187 - val_acc: 0.6813\n",
      "Epoch 36/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.7212 - acc: 0.6804 - val_loss: 0.7147 - val_acc: 0.6727\n",
      "Epoch 37/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.7198 - acc: 0.6744 - val_loss: 0.7097 - val_acc: 0.6907\n",
      "Epoch 38/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.7112 - acc: 0.6830 - val_loss: 0.7060 - val_acc: 0.6864\n",
      "Epoch 39/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.7081 - acc: 0.6864 - val_loss: 0.7018 - val_acc: 0.6976\n",
      "Epoch 40/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.7047 - acc: 0.6933 - val_loss: 0.6986 - val_acc: 0.6950\n",
      "Epoch 41/200\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 0.6995 - acc: 0.6950 - val_loss: 0.6944 - val_acc: 0.6873\n",
      "Epoch 42/200\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 0.6983 - acc: 0.6864 - val_loss: 0.6905 - val_acc: 0.7062\n",
      "Epoch 43/200\n",
      "1164/1164 [==============================] - 0s 78us/step - loss: 0.6927 - acc: 0.6985 - val_loss: 0.6871 - val_acc: 0.6873\n",
      "Epoch 44/200\n",
      "1164/1164 [==============================] - 0s 62us/step - loss: 0.6900 - acc: 0.6899 - val_loss: 0.6814 - val_acc: 0.7027\n",
      "Epoch 45/200\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 0.6869 - acc: 0.6924 - val_loss: 0.6785 - val_acc: 0.7036\n",
      "Epoch 46/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.6804 - acc: 0.7036 - val_loss: 0.6740 - val_acc: 0.7027\n",
      "Epoch 47/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.6791 - acc: 0.7053 - val_loss: 0.6698 - val_acc: 0.7122\n",
      "Epoch 48/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.6785 - acc: 0.7010 - val_loss: 0.6688 - val_acc: 0.7131\n",
      "Epoch 49/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.6710 - acc: 0.7045 - val_loss: 0.6639 - val_acc: 0.7199\n",
      "Epoch 50/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.6683 - acc: 0.7010 - val_loss: 0.6594 - val_acc: 0.7105\n",
      "Epoch 51/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.6647 - acc: 0.7062 - val_loss: 0.6559 - val_acc: 0.7148\n",
      "Epoch 52/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.6592 - acc: 0.7096 - val_loss: 0.6515 - val_acc: 0.7199\n",
      "Epoch 53/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.6541 - acc: 0.7148 - val_loss: 0.6485 - val_acc: 0.7208\n",
      "Epoch 54/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.6548 - acc: 0.7199 - val_loss: 0.6458 - val_acc: 0.7199\n",
      "Epoch 55/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.6509 - acc: 0.7216 - val_loss: 0.6420 - val_acc: 0.7268\n",
      "Epoch 56/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.6470 - acc: 0.7208 - val_loss: 0.6393 - val_acc: 0.7242\n",
      "Epoch 57/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.6451 - acc: 0.7148 - val_loss: 0.6371 - val_acc: 0.7225\n",
      "Epoch 58/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.6471 - acc: 0.7148 - val_loss: 0.6384 - val_acc: 0.7113\n",
      "Epoch 59/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.6389 - acc: 0.7096 - val_loss: 0.6343 - val_acc: 0.7165\n",
      "Epoch 60/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.6356 - acc: 0.7199 - val_loss: 0.6278 - val_acc: 0.7259\n",
      "Epoch 61/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.6317 - acc: 0.7251 - val_loss: 0.6235 - val_acc: 0.7268\n",
      "Epoch 62/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.6325 - acc: 0.7191 - val_loss: 0.6210 - val_acc: 0.7294\n",
      "Epoch 63/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.6260 - acc: 0.7311 - val_loss: 0.6183 - val_acc: 0.7285\n",
      "Epoch 64/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.6222 - acc: 0.7285 - val_loss: 0.6158 - val_acc: 0.7311\n",
      "Epoch 65/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.6196 - acc: 0.7337 - val_loss: 0.6126 - val_acc: 0.7345\n",
      "Epoch 66/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.6151 - acc: 0.7285 - val_loss: 0.6106 - val_acc: 0.7294\n",
      "Epoch 67/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.6144 - acc: 0.7294 - val_loss: 0.6064 - val_acc: 0.7371\n",
      "Epoch 68/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.6128 - acc: 0.7345 - val_loss: 0.6044 - val_acc: 0.7363\n",
      "Epoch 69/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.6097 - acc: 0.7277 - val_loss: 0.6023 - val_acc: 0.7440\n",
      "Epoch 70/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.6051 - acc: 0.7345 - val_loss: 0.5988 - val_acc: 0.7354\n",
      "Epoch 71/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.6044 - acc: 0.7345 - val_loss: 0.5961 - val_acc: 0.7388\n",
      "Epoch 72/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.6013 - acc: 0.7320 - val_loss: 0.5991 - val_acc: 0.7363\n",
      "Epoch 73/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.6068 - acc: 0.7414 - val_loss: 0.5979 - val_acc: 0.7405\n",
      "Epoch 74/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.6012 - acc: 0.7380 - val_loss: 0.5918 - val_acc: 0.7354\n",
      "Epoch 75/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.5952 - acc: 0.7414 - val_loss: 0.5881 - val_acc: 0.7440\n",
      "Epoch 76/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.5937 - acc: 0.7457 - val_loss: 0.5850 - val_acc: 0.7509\n",
      "Epoch 77/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5900 - acc: 0.7474 - val_loss: 0.5811 - val_acc: 0.7517\n",
      "Epoch 78/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5860 - acc: 0.7423 - val_loss: 0.5790 - val_acc: 0.7491\n",
      "Epoch 79/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.5842 - acc: 0.7500 - val_loss: 0.5791 - val_acc: 0.7509\n",
      "Epoch 80/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5800 - acc: 0.7448 - val_loss: 0.5769 - val_acc: 0.7534\n",
      "Epoch 81/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.5797 - acc: 0.7448 - val_loss: 0.5738 - val_acc: 0.7483\n",
      "Epoch 82/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.5760 - acc: 0.7457 - val_loss: 0.5706 - val_acc: 0.7552\n",
      "Epoch 83/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.5737 - acc: 0.7500 - val_loss: 0.5669 - val_acc: 0.7586\n",
      "Epoch 84/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.5709 - acc: 0.7552 - val_loss: 0.5661 - val_acc: 0.7552\n",
      "Epoch 85/200\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 0.5689 - acc: 0.7569 - val_loss: 0.5637 - val_acc: 0.7577\n",
      "Epoch 86/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.5677 - acc: 0.7543 - val_loss: 0.5619 - val_acc: 0.7569\n",
      "Epoch 87/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.5683 - acc: 0.7491 - val_loss: 0.5590 - val_acc: 0.7586\n",
      "Epoch 88/200\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 0.5611 - acc: 0.7603 - val_loss: 0.5556 - val_acc: 0.7629\n",
      "Epoch 89/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.5608 - acc: 0.7603 - val_loss: 0.5547 - val_acc: 0.7595\n",
      "Epoch 90/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5610 - acc: 0.7526 - val_loss: 0.5543 - val_acc: 0.7577\n",
      "Epoch 91/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5581 - acc: 0.7646 - val_loss: 0.5506 - val_acc: 0.7637\n",
      "Epoch 92/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.5540 - acc: 0.7629 - val_loss: 0.5530 - val_acc: 0.7612\n",
      "Epoch 93/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5574 - acc: 0.7560 - val_loss: 0.5464 - val_acc: 0.7680\n",
      "Epoch 94/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5514 - acc: 0.7637 - val_loss: 0.5435 - val_acc: 0.7655\n",
      "Epoch 95/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5474 - acc: 0.7663 - val_loss: 0.5411 - val_acc: 0.7715\n",
      "Epoch 96/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.5498 - acc: 0.7689 - val_loss: 0.5399 - val_acc: 0.7689\n",
      "Epoch 97/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5457 - acc: 0.7689 - val_loss: 0.5393 - val_acc: 0.7672\n",
      "Epoch 98/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.5446 - acc: 0.7620 - val_loss: 0.5335 - val_acc: 0.7758\n",
      "Epoch 99/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.5480 - acc: 0.7663 - val_loss: 0.5368 - val_acc: 0.7758\n",
      "Epoch 100/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.5393 - acc: 0.7698 - val_loss: 0.5313 - val_acc: 0.7766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.5369 - acc: 0.7749 - val_loss: 0.5287 - val_acc: 0.7758\n",
      "Epoch 102/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.5346 - acc: 0.7680 - val_loss: 0.5268 - val_acc: 0.7809\n",
      "Epoch 103/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5322 - acc: 0.7698 - val_loss: 0.5258 - val_acc: 0.7792\n",
      "Epoch 104/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5351 - acc: 0.7706 - val_loss: 0.5231 - val_acc: 0.7809\n",
      "Epoch 105/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.5276 - acc: 0.7826 - val_loss: 0.5191 - val_acc: 0.7826\n",
      "Epoch 106/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.5238 - acc: 0.7809 - val_loss: 0.5174 - val_acc: 0.7826\n",
      "Epoch 107/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.5197 - acc: 0.7801 - val_loss: 0.5150 - val_acc: 0.7844\n",
      "Epoch 108/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5187 - acc: 0.7775 - val_loss: 0.5171 - val_acc: 0.7792\n",
      "Epoch 109/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5202 - acc: 0.7775 - val_loss: 0.5157 - val_acc: 0.7775\n",
      "Epoch 110/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.5223 - acc: 0.7741 - val_loss: 0.5154 - val_acc: 0.7844\n",
      "Epoch 111/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.5166 - acc: 0.7818 - val_loss: 0.5074 - val_acc: 0.7878\n",
      "Epoch 112/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.5161 - acc: 0.7749 - val_loss: 0.5053 - val_acc: 0.7887\n",
      "Epoch 113/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.5122 - acc: 0.7844 - val_loss: 0.5055 - val_acc: 0.7861\n",
      "Epoch 114/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.5098 - acc: 0.7741 - val_loss: 0.5008 - val_acc: 0.7852\n",
      "Epoch 115/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.5073 - acc: 0.7818 - val_loss: 0.4992 - val_acc: 0.7861\n",
      "Epoch 116/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5037 - acc: 0.7844 - val_loss: 0.4964 - val_acc: 0.7861\n",
      "Epoch 117/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4987 - acc: 0.7869 - val_loss: 0.4934 - val_acc: 0.7921\n",
      "Epoch 118/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4978 - acc: 0.7921 - val_loss: 0.4924 - val_acc: 0.7930\n",
      "Epoch 119/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4966 - acc: 0.7861 - val_loss: 0.4908 - val_acc: 0.7887\n",
      "Epoch 120/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4988 - acc: 0.7861 - val_loss: 0.4931 - val_acc: 0.7990\n",
      "Epoch 121/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4946 - acc: 0.7955 - val_loss: 0.4858 - val_acc: 0.7964\n",
      "Epoch 122/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4891 - acc: 0.7938 - val_loss: 0.4846 - val_acc: 0.8007\n",
      "Epoch 123/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.4900 - acc: 0.7887 - val_loss: 0.4812 - val_acc: 0.7973\n",
      "Epoch 124/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4840 - acc: 0.7973 - val_loss: 0.4793 - val_acc: 0.8024\n",
      "Epoch 125/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4846 - acc: 0.7964 - val_loss: 0.4812 - val_acc: 0.8007\n",
      "Epoch 126/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4894 - acc: 0.7938 - val_loss: 0.4782 - val_acc: 0.7947\n",
      "Epoch 127/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4832 - acc: 0.7921 - val_loss: 0.4804 - val_acc: 0.8033\n",
      "Epoch 128/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4810 - acc: 0.7973 - val_loss: 0.4802 - val_acc: 0.7904\n",
      "Epoch 129/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4808 - acc: 0.7904 - val_loss: 0.4701 - val_acc: 0.8024\n",
      "Epoch 130/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.4742 - acc: 0.7998 - val_loss: 0.4694 - val_acc: 0.8076\n",
      "Epoch 131/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4786 - acc: 0.7947 - val_loss: 0.4718 - val_acc: 0.8050\n",
      "Epoch 132/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4826 - acc: 0.8007 - val_loss: 0.4703 - val_acc: 0.7998\n",
      "Epoch 133/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.4824 - acc: 0.7904 - val_loss: 0.4805 - val_acc: 0.7921\n",
      "Epoch 134/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4755 - acc: 0.8033 - val_loss: 0.4684 - val_acc: 0.7921\n",
      "Epoch 135/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4691 - acc: 0.7964 - val_loss: 0.4637 - val_acc: 0.8076\n",
      "Epoch 136/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4687 - acc: 0.7973 - val_loss: 0.4624 - val_acc: 0.8119\n",
      "Epoch 137/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4652 - acc: 0.8153 - val_loss: 0.4583 - val_acc: 0.8050\n",
      "Epoch 138/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4619 - acc: 0.8067 - val_loss: 0.4545 - val_acc: 0.8127\n",
      "Epoch 139/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4579 - acc: 0.8136 - val_loss: 0.4550 - val_acc: 0.8033\n",
      "Epoch 140/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4624 - acc: 0.8084 - val_loss: 0.4521 - val_acc: 0.8084\n",
      "Epoch 141/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4590 - acc: 0.8050 - val_loss: 0.4592 - val_acc: 0.8144\n",
      "Epoch 142/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4614 - acc: 0.8153 - val_loss: 0.4511 - val_acc: 0.8058\n",
      "Epoch 143/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4524 - acc: 0.8093 - val_loss: 0.4480 - val_acc: 0.8222\n",
      "Epoch 144/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4500 - acc: 0.8162 - val_loss: 0.4427 - val_acc: 0.8213\n",
      "Epoch 145/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.4446 - acc: 0.8170 - val_loss: 0.4401 - val_acc: 0.8222\n",
      "Epoch 146/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.4459 - acc: 0.8162 - val_loss: 0.4393 - val_acc: 0.8136\n",
      "Epoch 147/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4476 - acc: 0.8084 - val_loss: 0.4381 - val_acc: 0.8273\n",
      "Epoch 148/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4463 - acc: 0.8162 - val_loss: 0.4400 - val_acc: 0.8170\n",
      "Epoch 149/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4444 - acc: 0.8127 - val_loss: 0.4387 - val_acc: 0.8144\n",
      "Epoch 150/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4435 - acc: 0.8101 - val_loss: 0.4332 - val_acc: 0.8247\n",
      "Epoch 151/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4462 - acc: 0.8093 - val_loss: 0.4472 - val_acc: 0.8084\n",
      "Epoch 152/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4423 - acc: 0.8187 - val_loss: 0.4309 - val_acc: 0.8230\n",
      "Epoch 153/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4409 - acc: 0.8076 - val_loss: 0.4386 - val_acc: 0.8222\n",
      "Epoch 154/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4436 - acc: 0.8153 - val_loss: 0.4351 - val_acc: 0.8136\n",
      "Epoch 155/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4384 - acc: 0.8119 - val_loss: 0.4289 - val_acc: 0.8239\n",
      "Epoch 156/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.4334 - acc: 0.8162 - val_loss: 0.4244 - val_acc: 0.8170\n",
      "Epoch 157/200\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 0.4315 - acc: 0.8110 - val_loss: 0.4258 - val_acc: 0.8273\n",
      "Epoch 158/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.4336 - acc: 0.8222 - val_loss: 0.4251 - val_acc: 0.8290\n",
      "Epoch 159/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4280 - acc: 0.8213 - val_loss: 0.4200 - val_acc: 0.8230\n",
      "Epoch 160/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4250 - acc: 0.8230 - val_loss: 0.4237 - val_acc: 0.8325\n",
      "Epoch 161/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.4271 - acc: 0.8308 - val_loss: 0.4243 - val_acc: 0.8127\n",
      "Epoch 162/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4256 - acc: 0.8222 - val_loss: 0.4190 - val_acc: 0.8308\n",
      "Epoch 163/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.4238 - acc: 0.8247 - val_loss: 0.4164 - val_acc: 0.8290\n",
      "Epoch 164/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4205 - acc: 0.8290 - val_loss: 0.4189 - val_acc: 0.8282\n",
      "Epoch 165/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4206 - acc: 0.8290 - val_loss: 0.4094 - val_acc: 0.8351\n",
      "Epoch 166/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4155 - acc: 0.8299 - val_loss: 0.4110 - val_acc: 0.8393\n",
      "Epoch 167/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4176 - acc: 0.8333 - val_loss: 0.4081 - val_acc: 0.8316\n",
      "Epoch 168/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4100 - acc: 0.8308 - val_loss: 0.4068 - val_acc: 0.8411\n",
      "Epoch 169/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4132 - acc: 0.8282 - val_loss: 0.4042 - val_acc: 0.8462\n",
      "Epoch 170/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4107 - acc: 0.8351 - val_loss: 0.4032 - val_acc: 0.8376\n",
      "Epoch 171/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4101 - acc: 0.8368 - val_loss: 0.4053 - val_acc: 0.8385\n",
      "Epoch 172/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4081 - acc: 0.8333 - val_loss: 0.3999 - val_acc: 0.8419\n",
      "Epoch 173/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4033 - acc: 0.8402 - val_loss: 0.3986 - val_acc: 0.8445\n",
      "Epoch 174/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.4034 - acc: 0.8359 - val_loss: 0.3967 - val_acc: 0.8419\n",
      "Epoch 175/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.4052 - acc: 0.8351 - val_loss: 0.4044 - val_acc: 0.8333\n",
      "Epoch 176/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4033 - acc: 0.8308 - val_loss: 0.3964 - val_acc: 0.8402\n",
      "Epoch 177/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4017 - acc: 0.8393 - val_loss: 0.3945 - val_acc: 0.8411\n",
      "Epoch 178/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3987 - acc: 0.8411 - val_loss: 0.3957 - val_acc: 0.8393\n",
      "Epoch 179/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.3972 - acc: 0.8411 - val_loss: 0.4054 - val_acc: 0.8342\n",
      "Epoch 180/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4079 - acc: 0.8333 - val_loss: 0.3906 - val_acc: 0.8488\n",
      "Epoch 181/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3929 - acc: 0.8471 - val_loss: 0.3912 - val_acc: 0.8471\n",
      "Epoch 182/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3964 - acc: 0.8419 - val_loss: 0.4005 - val_acc: 0.8385\n",
      "Epoch 183/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.3964 - acc: 0.8402 - val_loss: 0.3854 - val_acc: 0.8462\n",
      "Epoch 184/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.3910 - acc: 0.8428 - val_loss: 0.3855 - val_acc: 0.8419\n",
      "Epoch 185/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3914 - acc: 0.8402 - val_loss: 0.3847 - val_acc: 0.8531\n",
      "Epoch 186/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.3921 - acc: 0.8471 - val_loss: 0.3839 - val_acc: 0.8514\n",
      "Epoch 187/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.3909 - acc: 0.8531 - val_loss: 0.3813 - val_acc: 0.8565\n",
      "Epoch 188/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3857 - acc: 0.8531 - val_loss: 0.3812 - val_acc: 0.8574\n",
      "Epoch 189/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3861 - acc: 0.8479 - val_loss: 0.3812 - val_acc: 0.8479\n",
      "Epoch 190/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.3848 - acc: 0.8514 - val_loss: 0.3822 - val_acc: 0.8479\n",
      "Epoch 191/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.3899 - acc: 0.8419 - val_loss: 0.3798 - val_acc: 0.8479\n",
      "Epoch 192/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.3825 - acc: 0.8471 - val_loss: 0.3760 - val_acc: 0.8565\n",
      "Epoch 193/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.3809 - acc: 0.8471 - val_loss: 0.3771 - val_acc: 0.8582\n",
      "Epoch 194/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3805 - acc: 0.8540 - val_loss: 0.3748 - val_acc: 0.8600\n",
      "Epoch 195/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.3788 - acc: 0.8531 - val_loss: 0.3717 - val_acc: 0.8591\n",
      "Epoch 196/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3820 - acc: 0.8488 - val_loss: 0.3722 - val_acc: 0.8591\n",
      "Epoch 197/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.3755 - acc: 0.8600 - val_loss: 0.3738 - val_acc: 0.8548\n",
      "Epoch 198/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3756 - acc: 0.8522 - val_loss: 0.3754 - val_acc: 0.8703\n",
      "Epoch 199/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3748 - acc: 0.8625 - val_loss: 0.3666 - val_acc: 0.8651\n",
      "Epoch 200/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.3717 - acc: 0.8574 - val_loss: 0.3665 - val_acc: 0.8591\n",
      "4656/4656 [==============================] - 0s 50us/step\n",
      "1164/1164 [==============================] - 0s 53us/step\n",
      "Train on 1164 samples, validate on 1164 samples\n",
      "Epoch 1/200\n",
      "1164/1164 [==============================] - 3s 2ms/step - loss: 1.3408 - acc: 0.1933 - val_loss: 1.1356 - val_acc: 0.3084\n",
      "Epoch 2/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 1.0507 - acc: 0.4622 - val_loss: 0.9834 - val_acc: 0.5808\n",
      "Epoch 3/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.9677 - acc: 0.6125 - val_loss: 0.9480 - val_acc: 0.6194\n",
      "Epoch 4/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.9391 - acc: 0.6229 - val_loss: 0.9262 - val_acc: 0.6246\n",
      "Epoch 5/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.9208 - acc: 0.6254 - val_loss: 0.9122 - val_acc: 0.6246\n",
      "Epoch 6/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.9077 - acc: 0.6254 - val_loss: 0.8997 - val_acc: 0.6263\n",
      "Epoch 7/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.8962 - acc: 0.6263 - val_loss: 0.8898 - val_acc: 0.6263\n",
      "Epoch 8/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.8878 - acc: 0.6254 - val_loss: 0.8810 - val_acc: 0.6254\n",
      "Epoch 9/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.8791 - acc: 0.6271 - val_loss: 0.8735 - val_acc: 0.6280\n",
      "Epoch 10/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.8720 - acc: 0.6263 - val_loss: 0.8669 - val_acc: 0.6271\n",
      "Epoch 11/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.8654 - acc: 0.6271 - val_loss: 0.8606 - val_acc: 0.6280\n",
      "Epoch 12/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.8596 - acc: 0.6271 - val_loss: 0.8548 - val_acc: 0.6271\n",
      "Epoch 13/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.8544 - acc: 0.6271 - val_loss: 0.8493 - val_acc: 0.6297\n",
      "Epoch 14/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.8490 - acc: 0.6289 - val_loss: 0.8442 - val_acc: 0.6289\n",
      "Epoch 15/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.8437 - acc: 0.6297 - val_loss: 0.8396 - val_acc: 0.6297\n",
      "Epoch 16/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.8401 - acc: 0.6314 - val_loss: 0.8343 - val_acc: 0.6349\n",
      "Epoch 17/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.8337 - acc: 0.6357 - val_loss: 0.8294 - val_acc: 0.6357\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.8296 - acc: 0.6357 - val_loss: 0.8249 - val_acc: 0.6383\n",
      "Epoch 19/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.8252 - acc: 0.6383 - val_loss: 0.8205 - val_acc: 0.6409\n",
      "Epoch 20/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.8210 - acc: 0.6452 - val_loss: 0.8163 - val_acc: 0.6435\n",
      "Epoch 21/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.8161 - acc: 0.6426 - val_loss: 0.8122 - val_acc: 0.6443\n",
      "Epoch 22/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.8119 - acc: 0.6443 - val_loss: 0.8073 - val_acc: 0.6469\n",
      "Epoch 23/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.8096 - acc: 0.6460 - val_loss: 0.8034 - val_acc: 0.6443\n",
      "Epoch 24/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.8033 - acc: 0.6503 - val_loss: 0.7995 - val_acc: 0.6503\n",
      "Epoch 25/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.7998 - acc: 0.6512 - val_loss: 0.7949 - val_acc: 0.6512\n",
      "Epoch 26/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.7958 - acc: 0.6521 - val_loss: 0.7920 - val_acc: 0.6538\n",
      "Epoch 27/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.7932 - acc: 0.6521 - val_loss: 0.7877 - val_acc: 0.6555\n",
      "Epoch 28/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.7871 - acc: 0.6555 - val_loss: 0.7832 - val_acc: 0.6555\n",
      "Epoch 29/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.7836 - acc: 0.6546 - val_loss: 0.7795 - val_acc: 0.6555\n",
      "Epoch 30/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.7814 - acc: 0.6589 - val_loss: 0.7760 - val_acc: 0.6615\n",
      "Epoch 31/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.7787 - acc: 0.6581 - val_loss: 0.7728 - val_acc: 0.6564\n",
      "Epoch 32/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.7767 - acc: 0.6589 - val_loss: 0.7689 - val_acc: 0.6632\n",
      "Epoch 33/200\n",
      "1164/1164 [==============================] - ETA: 0s - loss: 0.8753 - acc: 0.580 - 0s 59us/step - loss: 0.7684 - acc: 0.6589 - val_loss: 0.7650 - val_acc: 0.6589\n",
      "Epoch 34/200\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 0.7707 - acc: 0.6649 - val_loss: 0.7613 - val_acc: 0.6615\n",
      "Epoch 35/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.7638 - acc: 0.6607 - val_loss: 0.7583 - val_acc: 0.6632\n",
      "Epoch 36/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.7610 - acc: 0.6641 - val_loss: 0.7548 - val_acc: 0.6624\n",
      "Epoch 37/200\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 0.7555 - acc: 0.6667 - val_loss: 0.7509 - val_acc: 0.6649\n",
      "Epoch 38/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.7519 - acc: 0.6624 - val_loss: 0.7473 - val_acc: 0.6667\n",
      "Epoch 39/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.7479 - acc: 0.6649 - val_loss: 0.7438 - val_acc: 0.6701\n",
      "Epoch 40/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.7445 - acc: 0.6692 - val_loss: 0.7398 - val_acc: 0.6710\n",
      "Epoch 41/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.7423 - acc: 0.6710 - val_loss: 0.7356 - val_acc: 0.6735\n",
      "Epoch 42/200\n",
      "1164/1164 [==============================] - 0s 58us/step - loss: 0.7379 - acc: 0.6753 - val_loss: 0.7327 - val_acc: 0.6753\n",
      "Epoch 43/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.7349 - acc: 0.6761 - val_loss: 0.7288 - val_acc: 0.6753\n",
      "Epoch 44/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.7327 - acc: 0.6778 - val_loss: 0.7253 - val_acc: 0.6813\n",
      "Epoch 45/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.7277 - acc: 0.6778 - val_loss: 0.7216 - val_acc: 0.6838\n",
      "Epoch 46/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.7242 - acc: 0.6804 - val_loss: 0.7184 - val_acc: 0.6813\n",
      "Epoch 47/200\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 0.7234 - acc: 0.6830 - val_loss: 0.7150 - val_acc: 0.6821\n",
      "Epoch 48/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.7166 - acc: 0.6821 - val_loss: 0.7110 - val_acc: 0.6838\n",
      "Epoch 49/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.7170 - acc: 0.6873 - val_loss: 0.7083 - val_acc: 0.6899\n",
      "Epoch 50/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.7157 - acc: 0.6881 - val_loss: 0.7046 - val_acc: 0.6924\n",
      "Epoch 51/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.7057 - acc: 0.6967 - val_loss: 0.7003 - val_acc: 0.6993\n",
      "Epoch 52/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.7034 - acc: 0.7010 - val_loss: 0.6971 - val_acc: 0.7019\n",
      "Epoch 53/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.6969 - acc: 0.7010 - val_loss: 0.6928 - val_acc: 0.6985\n",
      "Epoch 54/200\n",
      "1164/1164 [==============================] - 0s 65us/step - loss: 0.6953 - acc: 0.6959 - val_loss: 0.6888 - val_acc: 0.7019\n",
      "Epoch 55/200\n",
      "1164/1164 [==============================] - 0s 61us/step - loss: 0.6936 - acc: 0.7010 - val_loss: 0.6858 - val_acc: 0.7002\n",
      "Epoch 56/200\n",
      "1164/1164 [==============================] - 0s 63us/step - loss: 0.6917 - acc: 0.6985 - val_loss: 0.6831 - val_acc: 0.7045\n",
      "Epoch 57/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.6849 - acc: 0.7053 - val_loss: 0.6800 - val_acc: 0.7122\n",
      "Epoch 58/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.6838 - acc: 0.7088 - val_loss: 0.6750 - val_acc: 0.7105\n",
      "Epoch 59/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.6799 - acc: 0.7088 - val_loss: 0.6729 - val_acc: 0.7156\n",
      "Epoch 60/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.6768 - acc: 0.7156 - val_loss: 0.6688 - val_acc: 0.7139\n",
      "Epoch 61/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.6710 - acc: 0.7079 - val_loss: 0.6647 - val_acc: 0.7165\n",
      "Epoch 62/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.6672 - acc: 0.7122 - val_loss: 0.6609 - val_acc: 0.7131\n",
      "Epoch 63/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.6672 - acc: 0.7105 - val_loss: 0.6584 - val_acc: 0.7174\n",
      "Epoch 64/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.6621 - acc: 0.7139 - val_loss: 0.6535 - val_acc: 0.7208\n",
      "Epoch 65/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.6565 - acc: 0.7165 - val_loss: 0.6509 - val_acc: 0.7182\n",
      "Epoch 66/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.6542 - acc: 0.7156 - val_loss: 0.6483 - val_acc: 0.7259\n",
      "Epoch 67/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.6520 - acc: 0.7191 - val_loss: 0.6437 - val_acc: 0.7234\n",
      "Epoch 68/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.6472 - acc: 0.7268 - val_loss: 0.6401 - val_acc: 0.7259\n",
      "Epoch 69/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.6422 - acc: 0.7285 - val_loss: 0.6375 - val_acc: 0.7251\n",
      "Epoch 70/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.6402 - acc: 0.7337 - val_loss: 0.6344 - val_acc: 0.7294\n",
      "Epoch 71/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.6366 - acc: 0.7302 - val_loss: 0.6303 - val_acc: 0.7388\n",
      "Epoch 72/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.6347 - acc: 0.7345 - val_loss: 0.6261 - val_acc: 0.7414\n",
      "Epoch 73/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.6286 - acc: 0.7414 - val_loss: 0.6226 - val_acc: 0.7440\n",
      "Epoch 74/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.6281 - acc: 0.7397 - val_loss: 0.6195 - val_acc: 0.7431\n",
      "Epoch 75/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.6223 - acc: 0.7448 - val_loss: 0.6165 - val_acc: 0.7448\n",
      "Epoch 76/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.6224 - acc: 0.7448 - val_loss: 0.6173 - val_acc: 0.7423\n",
      "Epoch 77/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.6226 - acc: 0.7457 - val_loss: 0.6102 - val_acc: 0.7517\n",
      "Epoch 78/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.6120 - acc: 0.7474 - val_loss: 0.6067 - val_acc: 0.7483\n",
      "Epoch 79/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.6108 - acc: 0.7457 - val_loss: 0.6029 - val_acc: 0.7543\n",
      "Epoch 80/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.6052 - acc: 0.7500 - val_loss: 0.5998 - val_acc: 0.7500\n",
      "Epoch 81/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.6028 - acc: 0.7466 - val_loss: 0.5966 - val_acc: 0.7534\n",
      "Epoch 82/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.6037 - acc: 0.7534 - val_loss: 0.5962 - val_acc: 0.7509\n",
      "Epoch 83/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.6004 - acc: 0.7526 - val_loss: 0.5929 - val_acc: 0.7620\n",
      "Epoch 84/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5951 - acc: 0.7637 - val_loss: 0.5863 - val_acc: 0.7595\n",
      "Epoch 85/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5908 - acc: 0.7517 - val_loss: 0.5837 - val_acc: 0.7663\n",
      "Epoch 86/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5876 - acc: 0.7612 - val_loss: 0.5803 - val_acc: 0.7646\n",
      "Epoch 87/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.5900 - acc: 0.7534 - val_loss: 0.5798 - val_acc: 0.7706\n",
      "Epoch 88/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.5867 - acc: 0.7715 - val_loss: 0.5781 - val_acc: 0.7620\n",
      "Epoch 89/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.5836 - acc: 0.7629 - val_loss: 0.5736 - val_acc: 0.7723\n",
      "Epoch 90/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.5751 - acc: 0.7706 - val_loss: 0.5756 - val_acc: 0.7741\n",
      "Epoch 91/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.5753 - acc: 0.7586 - val_loss: 0.5703 - val_acc: 0.7775\n",
      "Epoch 92/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.5704 - acc: 0.7732 - val_loss: 0.5621 - val_acc: 0.7758\n",
      "Epoch 93/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.5648 - acc: 0.7698 - val_loss: 0.5581 - val_acc: 0.7861\n",
      "Epoch 94/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.5612 - acc: 0.7844 - val_loss: 0.5544 - val_acc: 0.7878\n",
      "Epoch 95/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5598 - acc: 0.7801 - val_loss: 0.5502 - val_acc: 0.7852\n",
      "Epoch 96/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.5594 - acc: 0.7835 - val_loss: 0.5516 - val_acc: 0.7766\n",
      "Epoch 97/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.5540 - acc: 0.7792 - val_loss: 0.5496 - val_acc: 0.7904\n",
      "Epoch 98/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.5522 - acc: 0.7912 - val_loss: 0.5455 - val_acc: 0.7775\n",
      "Epoch 99/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.5509 - acc: 0.7809 - val_loss: 0.5395 - val_acc: 0.7887\n",
      "Epoch 100/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.5431 - acc: 0.7869 - val_loss: 0.5385 - val_acc: 0.7792\n",
      "Epoch 101/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.5453 - acc: 0.7852 - val_loss: 0.5356 - val_acc: 0.7878\n",
      "Epoch 102/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.5393 - acc: 0.7912 - val_loss: 0.5303 - val_acc: 0.8015\n",
      "Epoch 103/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.5322 - acc: 0.7895 - val_loss: 0.5260 - val_acc: 0.7947\n",
      "Epoch 104/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.5297 - acc: 0.7981 - val_loss: 0.5223 - val_acc: 0.8015\n",
      "Epoch 105/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.5279 - acc: 0.7947 - val_loss: 0.5219 - val_acc: 0.8015\n",
      "Epoch 106/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.5228 - acc: 0.7938 - val_loss: 0.5197 - val_acc: 0.7921\n",
      "Epoch 107/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5204 - acc: 0.8041 - val_loss: 0.5143 - val_acc: 0.8093\n",
      "Epoch 108/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.5169 - acc: 0.7990 - val_loss: 0.5115 - val_acc: 0.7955\n",
      "Epoch 109/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.5164 - acc: 0.7938 - val_loss: 0.5103 - val_acc: 0.8101\n",
      "Epoch 110/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5105 - acc: 0.7973 - val_loss: 0.5073 - val_acc: 0.8067\n",
      "Epoch 111/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5112 - acc: 0.8024 - val_loss: 0.5004 - val_acc: 0.8170\n",
      "Epoch 112/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5069 - acc: 0.8015 - val_loss: 0.4979 - val_acc: 0.8076\n",
      "Epoch 113/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.5056 - acc: 0.8007 - val_loss: 0.5058 - val_acc: 0.8033\n",
      "Epoch 114/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.5136 - acc: 0.7973 - val_loss: 0.4943 - val_acc: 0.8119\n",
      "Epoch 115/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.5035 - acc: 0.8101 - val_loss: 0.4945 - val_acc: 0.8153\n",
      "Epoch 116/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4965 - acc: 0.8136 - val_loss: 0.4974 - val_acc: 0.8101\n",
      "Epoch 117/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4973 - acc: 0.8101 - val_loss: 0.4830 - val_acc: 0.8170\n",
      "Epoch 118/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4907 - acc: 0.8127 - val_loss: 0.4790 - val_acc: 0.8222\n",
      "Epoch 119/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4879 - acc: 0.8093 - val_loss: 0.4788 - val_acc: 0.8222\n",
      "Epoch 120/200\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 0.4813 - acc: 0.8282 - val_loss: 0.4791 - val_acc: 0.8247\n",
      "Epoch 121/200\n",
      "1164/1164 [==============================] - 0s 64us/step - loss: 0.4857 - acc: 0.8196 - val_loss: 0.4711 - val_acc: 0.8196\n",
      "Epoch 122/200\n",
      "1164/1164 [==============================] - 0s 62us/step - loss: 0.4746 - acc: 0.8239 - val_loss: 0.4664 - val_acc: 0.8239\n",
      "Epoch 123/200\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 0.4716 - acc: 0.8213 - val_loss: 0.4631 - val_acc: 0.8333\n",
      "Epoch 124/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.4714 - acc: 0.8325 - val_loss: 0.4623 - val_acc: 0.8265\n",
      "Epoch 125/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4667 - acc: 0.8290 - val_loss: 0.4579 - val_acc: 0.8316\n",
      "Epoch 126/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4650 - acc: 0.8187 - val_loss: 0.4552 - val_acc: 0.8368\n",
      "Epoch 127/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.4625 - acc: 0.8256 - val_loss: 0.4568 - val_acc: 0.8273\n",
      "Epoch 128/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4615 - acc: 0.8239 - val_loss: 0.4529 - val_acc: 0.8376\n",
      "Epoch 129/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.4562 - acc: 0.8290 - val_loss: 0.4470 - val_acc: 0.8402\n",
      "Epoch 130/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.4499 - acc: 0.8368 - val_loss: 0.4430 - val_acc: 0.8385\n",
      "Epoch 131/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4510 - acc: 0.8419 - val_loss: 0.4431 - val_acc: 0.8342\n",
      "Epoch 132/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.4469 - acc: 0.8359 - val_loss: 0.4405 - val_acc: 0.8505\n",
      "Epoch 133/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.4466 - acc: 0.8419 - val_loss: 0.4448 - val_acc: 0.8222\n",
      "Epoch 134/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.4498 - acc: 0.8273 - val_loss: 0.4374 - val_acc: 0.8462\n",
      "Epoch 135/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4402 - acc: 0.8454 - val_loss: 0.4328 - val_acc: 0.8428\n",
      "Epoch 136/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.4363 - acc: 0.8402 - val_loss: 0.4326 - val_acc: 0.8471\n",
      "Epoch 137/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4364 - acc: 0.8402 - val_loss: 0.4371 - val_acc: 0.8428\n",
      "Epoch 138/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.4381 - acc: 0.8419 - val_loss: 0.4251 - val_acc: 0.8488\n",
      "Epoch 139/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.4338 - acc: 0.8445 - val_loss: 0.4215 - val_acc: 0.8462\n",
      "Epoch 140/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.4254 - acc: 0.8454 - val_loss: 0.4177 - val_acc: 0.8557\n",
      "Epoch 141/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.4246 - acc: 0.8514 - val_loss: 0.4150 - val_acc: 0.8668\n",
      "Epoch 142/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.4242 - acc: 0.8479 - val_loss: 0.4164 - val_acc: 0.8462\n",
      "Epoch 143/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.4213 - acc: 0.8488 - val_loss: 0.4147 - val_acc: 0.8582\n",
      "Epoch 144/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4200 - acc: 0.8548 - val_loss: 0.4097 - val_acc: 0.8522\n",
      "Epoch 145/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4145 - acc: 0.8591 - val_loss: 0.4052 - val_acc: 0.8660\n",
      "Epoch 146/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4174 - acc: 0.8454 - val_loss: 0.4048 - val_acc: 0.8625\n",
      "Epoch 147/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.4145 - acc: 0.8531 - val_loss: 0.4060 - val_acc: 0.8625\n",
      "Epoch 148/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.4148 - acc: 0.8497 - val_loss: 0.4096 - val_acc: 0.8582\n",
      "Epoch 149/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4037 - acc: 0.8668 - val_loss: 0.3963 - val_acc: 0.8668\n",
      "Epoch 150/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.4010 - acc: 0.8591 - val_loss: 0.4020 - val_acc: 0.8600\n",
      "Epoch 151/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.4078 - acc: 0.8600 - val_loss: 0.3974 - val_acc: 0.8582\n",
      "Epoch 152/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.3998 - acc: 0.8608 - val_loss: 0.3905 - val_acc: 0.8720\n",
      "Epoch 153/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.4012 - acc: 0.8608 - val_loss: 0.3940 - val_acc: 0.8694\n",
      "Epoch 154/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.3925 - acc: 0.8677 - val_loss: 0.3859 - val_acc: 0.8617\n",
      "Epoch 155/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.3887 - acc: 0.8711 - val_loss: 0.3835 - val_acc: 0.8711\n",
      "Epoch 156/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.3868 - acc: 0.8694 - val_loss: 0.3818 - val_acc: 0.8711\n",
      "Epoch 157/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.3900 - acc: 0.8686 - val_loss: 0.3806 - val_acc: 0.8729\n",
      "Epoch 158/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.3906 - acc: 0.8634 - val_loss: 0.3895 - val_acc: 0.8522\n",
      "Epoch 159/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3885 - acc: 0.8600 - val_loss: 0.3743 - val_acc: 0.8746\n",
      "Epoch 160/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.3800 - acc: 0.8703 - val_loss: 0.3714 - val_acc: 0.8737\n",
      "Epoch 161/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.3804 - acc: 0.8668 - val_loss: 0.3716 - val_acc: 0.8763\n",
      "Epoch 162/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.3858 - acc: 0.8668 - val_loss: 0.3721 - val_acc: 0.8686\n",
      "Epoch 163/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.3838 - acc: 0.8720 - val_loss: 0.3687 - val_acc: 0.8763\n",
      "Epoch 164/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.3737 - acc: 0.8737 - val_loss: 0.3648 - val_acc: 0.8746\n",
      "Epoch 165/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.3711 - acc: 0.8720 - val_loss: 0.3640 - val_acc: 0.8814\n",
      "Epoch 166/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.3685 - acc: 0.8754 - val_loss: 0.3600 - val_acc: 0.8746\n",
      "Epoch 167/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.3658 - acc: 0.8763 - val_loss: 0.3565 - val_acc: 0.8806\n",
      "Epoch 168/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.3609 - acc: 0.8771 - val_loss: 0.3562 - val_acc: 0.8797\n",
      "Epoch 169/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.3632 - acc: 0.8814 - val_loss: 0.3622 - val_acc: 0.8703\n",
      "Epoch 170/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3699 - acc: 0.8686 - val_loss: 0.3566 - val_acc: 0.8823\n",
      "Epoch 171/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.3645 - acc: 0.8711 - val_loss: 0.3531 - val_acc: 0.8814\n",
      "Epoch 172/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3577 - acc: 0.8771 - val_loss: 0.3480 - val_acc: 0.8849\n",
      "Epoch 173/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3535 - acc: 0.8771 - val_loss: 0.3510 - val_acc: 0.8840\n",
      "Epoch 174/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.3615 - acc: 0.8763 - val_loss: 0.3482 - val_acc: 0.8814\n",
      "Epoch 175/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.3586 - acc: 0.8780 - val_loss: 0.3479 - val_acc: 0.8729\n",
      "Epoch 176/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.3575 - acc: 0.8729 - val_loss: 0.3516 - val_acc: 0.8840\n",
      "Epoch 177/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3506 - acc: 0.8797 - val_loss: 0.3422 - val_acc: 0.8789\n",
      "Epoch 178/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.3475 - acc: 0.8797 - val_loss: 0.3369 - val_acc: 0.8849\n",
      "Epoch 179/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3428 - acc: 0.8832 - val_loss: 0.3354 - val_acc: 0.8857\n",
      "Epoch 180/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3413 - acc: 0.8832 - val_loss: 0.3360 - val_acc: 0.8866\n",
      "Epoch 181/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.3411 - acc: 0.8840 - val_loss: 0.3414 - val_acc: 0.8952\n",
      "Epoch 182/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.3405 - acc: 0.8832 - val_loss: 0.3406 - val_acc: 0.8832\n",
      "Epoch 183/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.3381 - acc: 0.8806 - val_loss: 0.3445 - val_acc: 0.8814\n",
      "Epoch 184/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.3431 - acc: 0.8814 - val_loss: 0.3277 - val_acc: 0.8875\n",
      "Epoch 185/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.3354 - acc: 0.8797 - val_loss: 0.3267 - val_acc: 0.8883\n",
      "Epoch 186/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.3318 - acc: 0.8832 - val_loss: 0.3251 - val_acc: 0.8849\n",
      "Epoch 187/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3285 - acc: 0.8814 - val_loss: 0.3221 - val_acc: 0.8909\n",
      "Epoch 188/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.3320 - acc: 0.8814 - val_loss: 0.3257 - val_acc: 0.8866\n",
      "Epoch 189/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.3344 - acc: 0.8857 - val_loss: 0.3197 - val_acc: 0.8909\n",
      "Epoch 190/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.3256 - acc: 0.8875 - val_loss: 0.3211 - val_acc: 0.8926\n",
      "Epoch 191/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.3276 - acc: 0.8832 - val_loss: 0.3164 - val_acc: 0.8892\n",
      "Epoch 192/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.3249 - acc: 0.8857 - val_loss: 0.3171 - val_acc: 0.8909\n",
      "Epoch 193/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.3224 - acc: 0.8883 - val_loss: 0.3206 - val_acc: 0.8900\n",
      "Epoch 194/200\n",
      "1164/1164 [==============================] - 0s 46us/step - loss: 0.3240 - acc: 0.8849 - val_loss: 0.3142 - val_acc: 0.8875\n",
      "Epoch 195/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.3230 - acc: 0.8892 - val_loss: 0.3149 - val_acc: 0.8909\n",
      "Epoch 196/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.3253 - acc: 0.8875 - val_loss: 0.3259 - val_acc: 0.8866\n",
      "Epoch 197/200\n",
      "1164/1164 [==============================] - 0s 45us/step - loss: 0.3290 - acc: 0.8832 - val_loss: 0.3102 - val_acc: 0.8952\n",
      "Epoch 198/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.3242 - acc: 0.8849 - val_loss: 0.3168 - val_acc: 0.8892\n",
      "Epoch 199/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.3163 - acc: 0.8918 - val_loss: 0.3093 - val_acc: 0.8935\n",
      "Epoch 200/200\n",
      "1164/1164 [==============================] - 0s 47us/step - loss: 0.3134 - acc: 0.8900 - val_loss: 0.3164 - val_acc: 0.9038\n",
      "4656/4656 [==============================] - 0s 50us/step\n",
      "1164/1164 [==============================] - 0s 53us/step\n",
      "Train on 1164 samples, validate on 1164 samples\n",
      "Epoch 1/200\n",
      "1164/1164 [==============================] - 3s 2ms/step - loss: 1.0001 - acc: 0.5550 - val_loss: 0.9598 - val_acc: 0.5799\n",
      "Epoch 2/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.9507 - acc: 0.5928 - val_loss: 0.9349 - val_acc: 0.5928\n",
      "Epoch 3/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.9268 - acc: 0.5988 - val_loss: 0.9156 - val_acc: 0.5971\n",
      "Epoch 4/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.9103 - acc: 0.5997 - val_loss: 0.9022 - val_acc: 0.6040\n",
      "Epoch 5/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.8994 - acc: 0.6031 - val_loss: 0.8904 - val_acc: 0.6040\n",
      "Epoch 6/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.8899 - acc: 0.6057 - val_loss: 0.8811 - val_acc: 0.6048\n",
      "Epoch 7/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.8791 - acc: 0.6040 - val_loss: 0.8731 - val_acc: 0.6082\n",
      "Epoch 8/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.8722 - acc: 0.6134 - val_loss: 0.8659 - val_acc: 0.6125\n",
      "Epoch 9/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.8666 - acc: 0.6057 - val_loss: 0.8588 - val_acc: 0.6117\n",
      "Epoch 10/200\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 0.8581 - acc: 0.6091 - val_loss: 0.8523 - val_acc: 0.6168\n",
      "Epoch 11/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.8525 - acc: 0.6074 - val_loss: 0.8462 - val_acc: 0.6091\n",
      "Epoch 12/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.8462 - acc: 0.6100 - val_loss: 0.8405 - val_acc: 0.6143\n",
      "Epoch 13/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.8403 - acc: 0.6160 - val_loss: 0.8346 - val_acc: 0.6134\n",
      "Epoch 14/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.8339 - acc: 0.6117 - val_loss: 0.8290 - val_acc: 0.6168\n",
      "Epoch 15/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.8299 - acc: 0.6177 - val_loss: 0.8238 - val_acc: 0.6168\n",
      "Epoch 16/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.8234 - acc: 0.6194 - val_loss: 0.8182 - val_acc: 0.6254\n",
      "Epoch 17/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.8179 - acc: 0.6229 - val_loss: 0.8119 - val_acc: 0.6271\n",
      "Epoch 18/200\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 0.8124 - acc: 0.6280 - val_loss: 0.8069 - val_acc: 0.6280\n",
      "Epoch 19/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.8076 - acc: 0.6297 - val_loss: 0.8022 - val_acc: 0.6332\n",
      "Epoch 20/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.8031 - acc: 0.6314 - val_loss: 0.7974 - val_acc: 0.6332\n",
      "Epoch 21/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.7988 - acc: 0.6314 - val_loss: 0.7925 - val_acc: 0.6314\n",
      "Epoch 22/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.7946 - acc: 0.6332 - val_loss: 0.7883 - val_acc: 0.6340\n",
      "Epoch 23/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.7898 - acc: 0.6349 - val_loss: 0.7839 - val_acc: 0.6366\n",
      "Epoch 24/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.7844 - acc: 0.6375 - val_loss: 0.7792 - val_acc: 0.6357\n",
      "Epoch 25/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.7826 - acc: 0.6306 - val_loss: 0.7751 - val_acc: 0.6443\n",
      "Epoch 26/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.7766 - acc: 0.6400 - val_loss: 0.7706 - val_acc: 0.6435\n",
      "Epoch 27/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.7730 - acc: 0.6349 - val_loss: 0.7668 - val_acc: 0.6452\n",
      "Epoch 28/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.7686 - acc: 0.6460 - val_loss: 0.7630 - val_acc: 0.6452\n",
      "Epoch 29/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.7657 - acc: 0.6375 - val_loss: 0.7586 - val_acc: 0.6460\n",
      "Epoch 30/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.7610 - acc: 0.6495 - val_loss: 0.7548 - val_acc: 0.6495\n",
      "Epoch 31/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.7556 - acc: 0.6512 - val_loss: 0.7503 - val_acc: 0.6503\n",
      "Epoch 32/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.7515 - acc: 0.6529 - val_loss: 0.7466 - val_acc: 0.6581\n",
      "Epoch 33/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.7505 - acc: 0.6607 - val_loss: 0.7425 - val_acc: 0.6546\n",
      "Epoch 34/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.7443 - acc: 0.6546 - val_loss: 0.7383 - val_acc: 0.6675\n",
      "Epoch 35/200\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 0.7406 - acc: 0.6624 - val_loss: 0.7354 - val_acc: 0.6692\n",
      "Epoch 36/200\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 0.7380 - acc: 0.6641 - val_loss: 0.7308 - val_acc: 0.6727\n",
      "Epoch 37/200\n",
      "1164/1164 [==============================] - 0s 75us/step - loss: 0.7354 - acc: 0.6641 - val_loss: 0.7286 - val_acc: 0.6710\n",
      "Epoch 38/200\n",
      "1164/1164 [==============================] - 0s 71us/step - loss: 0.7296 - acc: 0.6735 - val_loss: 0.7238 - val_acc: 0.6787\n",
      "Epoch 39/200\n",
      "1164/1164 [==============================] - 0s 61us/step - loss: 0.7268 - acc: 0.6813 - val_loss: 0.7201 - val_acc: 0.6753\n",
      "Epoch 40/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.7249 - acc: 0.6692 - val_loss: 0.7182 - val_acc: 0.6813\n",
      "Epoch 41/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.7213 - acc: 0.6847 - val_loss: 0.7150 - val_acc: 0.6856\n",
      "Epoch 42/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.7204 - acc: 0.6744 - val_loss: 0.7122 - val_acc: 0.6838\n",
      "Epoch 43/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.7128 - acc: 0.6847 - val_loss: 0.7060 - val_acc: 0.6856\n",
      "Epoch 44/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.7099 - acc: 0.6830 - val_loss: 0.7020 - val_acc: 0.6873\n",
      "Epoch 45/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.7055 - acc: 0.6873 - val_loss: 0.6988 - val_acc: 0.6933\n",
      "Epoch 46/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.7029 - acc: 0.6907 - val_loss: 0.6972 - val_acc: 0.6942\n",
      "Epoch 47/200\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 0.6990 - acc: 0.6942 - val_loss: 0.6929 - val_acc: 0.6959\n",
      "Epoch 48/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.6966 - acc: 0.6959 - val_loss: 0.6892 - val_acc: 0.7096\n",
      "Epoch 49/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.6955 - acc: 0.6864 - val_loss: 0.6862 - val_acc: 0.6993\n",
      "Epoch 50/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.6904 - acc: 0.7036 - val_loss: 0.6823 - val_acc: 0.7027\n",
      "Epoch 51/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.6859 - acc: 0.6942 - val_loss: 0.6785 - val_acc: 0.7070\n",
      "Epoch 52/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.6826 - acc: 0.7088 - val_loss: 0.6754 - val_acc: 0.7088\n",
      "Epoch 53/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.6786 - acc: 0.7096 - val_loss: 0.6724 - val_acc: 0.7122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.6773 - acc: 0.7070 - val_loss: 0.6688 - val_acc: 0.7036\n",
      "Epoch 55/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.6738 - acc: 0.7096 - val_loss: 0.6649 - val_acc: 0.7148\n",
      "Epoch 56/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.6692 - acc: 0.7105 - val_loss: 0.6622 - val_acc: 0.7139\n",
      "Epoch 57/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.6658 - acc: 0.7131 - val_loss: 0.6600 - val_acc: 0.7105\n",
      "Epoch 58/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.6643 - acc: 0.7122 - val_loss: 0.6569 - val_acc: 0.7216\n",
      "Epoch 59/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.6607 - acc: 0.7139 - val_loss: 0.6529 - val_acc: 0.7182\n",
      "Epoch 60/200\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 0.6609 - acc: 0.7088 - val_loss: 0.6556 - val_acc: 0.7036\n",
      "Epoch 61/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.6589 - acc: 0.7053 - val_loss: 0.6487 - val_acc: 0.7251\n",
      "Epoch 62/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.6547 - acc: 0.7139 - val_loss: 0.6464 - val_acc: 0.7242\n",
      "Epoch 63/200\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 0.6484 - acc: 0.7199 - val_loss: 0.6410 - val_acc: 0.7174\n",
      "Epoch 64/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.6452 - acc: 0.7216 - val_loss: 0.6393 - val_acc: 0.7225\n",
      "Epoch 65/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.6436 - acc: 0.7174 - val_loss: 0.6357 - val_acc: 0.7268\n",
      "Epoch 66/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.6403 - acc: 0.7216 - val_loss: 0.6338 - val_acc: 0.7285\n",
      "Epoch 67/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.6379 - acc: 0.7268 - val_loss: 0.6298 - val_acc: 0.7345\n",
      "Epoch 68/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.6370 - acc: 0.7242 - val_loss: 0.6286 - val_acc: 0.7414\n",
      "Epoch 69/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.6312 - acc: 0.7405 - val_loss: 0.6257 - val_acc: 0.7457\n",
      "Epoch 70/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.6305 - acc: 0.7405 - val_loss: 0.6227 - val_acc: 0.7268\n",
      "Epoch 71/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.6264 - acc: 0.7251 - val_loss: 0.6194 - val_acc: 0.7466\n",
      "Epoch 72/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.6230 - acc: 0.7474 - val_loss: 0.6169 - val_acc: 0.7345\n",
      "Epoch 73/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.6214 - acc: 0.7345 - val_loss: 0.6133 - val_acc: 0.7448\n",
      "Epoch 74/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.6210 - acc: 0.7388 - val_loss: 0.6126 - val_acc: 0.7448\n",
      "Epoch 75/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.6184 - acc: 0.7302 - val_loss: 0.6109 - val_acc: 0.7354\n",
      "Epoch 76/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.6175 - acc: 0.7397 - val_loss: 0.6058 - val_acc: 0.7491\n",
      "Epoch 77/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.6110 - acc: 0.7423 - val_loss: 0.6044 - val_acc: 0.7526\n",
      "Epoch 78/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.6080 - acc: 0.7526 - val_loss: 0.6030 - val_acc: 0.7517\n",
      "Epoch 79/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.6056 - acc: 0.7466 - val_loss: 0.5982 - val_acc: 0.7534\n",
      "Epoch 80/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.6058 - acc: 0.7457 - val_loss: 0.5969 - val_acc: 0.7448\n",
      "Epoch 81/200\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 0.6015 - acc: 0.7414 - val_loss: 0.5923 - val_acc: 0.7560\n",
      "Epoch 82/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.5986 - acc: 0.7543 - val_loss: 0.5915 - val_acc: 0.7466\n",
      "Epoch 83/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.5960 - acc: 0.7509 - val_loss: 0.5905 - val_acc: 0.7534\n",
      "Epoch 84/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.5945 - acc: 0.7534 - val_loss: 0.5855 - val_acc: 0.7620\n",
      "Epoch 85/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.5915 - acc: 0.7629 - val_loss: 0.5845 - val_acc: 0.7629\n",
      "Epoch 86/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.5875 - acc: 0.7534 - val_loss: 0.5829 - val_acc: 0.7526\n",
      "Epoch 87/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.5884 - acc: 0.7526 - val_loss: 0.5775 - val_acc: 0.7586\n",
      "Epoch 88/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.5842 - acc: 0.7491 - val_loss: 0.5759 - val_acc: 0.7629\n",
      "Epoch 89/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.5858 - acc: 0.7706 - val_loss: 0.5730 - val_acc: 0.7612\n",
      "Epoch 90/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.5834 - acc: 0.7620 - val_loss: 0.5713 - val_acc: 0.7689\n",
      "Epoch 91/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.5764 - acc: 0.7620 - val_loss: 0.5703 - val_acc: 0.7741\n",
      "Epoch 92/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.5742 - acc: 0.7612 - val_loss: 0.5663 - val_acc: 0.7680\n",
      "Epoch 93/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.5710 - acc: 0.7569 - val_loss: 0.5639 - val_acc: 0.7766\n",
      "Epoch 94/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.5707 - acc: 0.7775 - val_loss: 0.5617 - val_acc: 0.7741\n",
      "Epoch 95/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.5674 - acc: 0.7680 - val_loss: 0.5581 - val_acc: 0.7758\n",
      "Epoch 96/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.5660 - acc: 0.7732 - val_loss: 0.5549 - val_acc: 0.7835\n",
      "Epoch 97/200\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 0.5636 - acc: 0.7706 - val_loss: 0.5619 - val_acc: 0.7706\n",
      "Epoch 98/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.5610 - acc: 0.7689 - val_loss: 0.5529 - val_acc: 0.7758\n",
      "Epoch 99/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.5552 - acc: 0.7766 - val_loss: 0.5472 - val_acc: 0.7835\n",
      "Epoch 100/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.5561 - acc: 0.7792 - val_loss: 0.5459 - val_acc: 0.7835\n",
      "Epoch 101/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.5530 - acc: 0.7741 - val_loss: 0.5445 - val_acc: 0.7861\n",
      "Epoch 102/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.5513 - acc: 0.7741 - val_loss: 0.5395 - val_acc: 0.7878\n",
      "Epoch 103/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.5474 - acc: 0.7758 - val_loss: 0.5374 - val_acc: 0.7861\n",
      "Epoch 104/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.5452 - acc: 0.7826 - val_loss: 0.5384 - val_acc: 0.7912\n",
      "Epoch 105/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.5434 - acc: 0.7775 - val_loss: 0.5357 - val_acc: 0.7818\n",
      "Epoch 106/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.5405 - acc: 0.7869 - val_loss: 0.5298 - val_acc: 0.7852\n",
      "Epoch 107/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.5364 - acc: 0.7775 - val_loss: 0.5272 - val_acc: 0.7878\n",
      "Epoch 108/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.5321 - acc: 0.7861 - val_loss: 0.5257 - val_acc: 0.7964\n",
      "Epoch 109/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.5318 - acc: 0.7809 - val_loss: 0.5211 - val_acc: 0.7938\n",
      "Epoch 110/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.5337 - acc: 0.7792 - val_loss: 0.5278 - val_acc: 0.7826\n",
      "Epoch 111/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.5249 - acc: 0.7869 - val_loss: 0.5307 - val_acc: 0.7887\n",
      "Epoch 112/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.5313 - acc: 0.7809 - val_loss: 0.5146 - val_acc: 0.7981\n",
      "Epoch 113/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.5246 - acc: 0.7869 - val_loss: 0.5170 - val_acc: 0.7904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.5226 - acc: 0.7973 - val_loss: 0.5136 - val_acc: 0.7921\n",
      "Epoch 115/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.5236 - acc: 0.7887 - val_loss: 0.5103 - val_acc: 0.7964\n",
      "Epoch 116/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.5188 - acc: 0.7878 - val_loss: 0.5054 - val_acc: 0.7955\n",
      "Epoch 117/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.5105 - acc: 0.8033 - val_loss: 0.5026 - val_acc: 0.8058\n",
      "Epoch 118/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.5088 - acc: 0.7973 - val_loss: 0.5073 - val_acc: 0.7964\n",
      "Epoch 119/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.5122 - acc: 0.7955 - val_loss: 0.4984 - val_acc: 0.8136\n",
      "Epoch 120/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.5058 - acc: 0.8101 - val_loss: 0.5025 - val_acc: 0.7981\n",
      "Epoch 121/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.5055 - acc: 0.7990 - val_loss: 0.4951 - val_acc: 0.8084\n",
      "Epoch 122/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.5043 - acc: 0.8058 - val_loss: 0.4936 - val_acc: 0.8084\n",
      "Epoch 123/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.4990 - acc: 0.8127 - val_loss: 0.4894 - val_acc: 0.8136\n",
      "Epoch 124/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.4981 - acc: 0.8093 - val_loss: 0.4935 - val_acc: 0.8015\n",
      "Epoch 125/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.5006 - acc: 0.8015 - val_loss: 0.4903 - val_acc: 0.8110\n",
      "Epoch 126/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.4943 - acc: 0.8024 - val_loss: 0.4832 - val_acc: 0.8213\n",
      "Epoch 127/200\n",
      "1164/1164 [==============================] - 0s 62us/step - loss: 0.4928 - acc: 0.8007 - val_loss: 0.4842 - val_acc: 0.8076\n",
      "Epoch 128/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.4930 - acc: 0.8093 - val_loss: 0.4819 - val_acc: 0.8187\n",
      "Epoch 129/200\n",
      "1164/1164 [==============================] - 0s 59us/step - loss: 0.4856 - acc: 0.8204 - val_loss: 0.4811 - val_acc: 0.8162\n",
      "Epoch 130/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.4827 - acc: 0.8110 - val_loss: 0.4800 - val_acc: 0.8213\n",
      "Epoch 131/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.4857 - acc: 0.8076 - val_loss: 0.4756 - val_acc: 0.8162\n",
      "Epoch 132/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.4816 - acc: 0.8213 - val_loss: 0.4766 - val_acc: 0.8196\n",
      "Epoch 133/200\n",
      "1164/1164 [==============================] - 0s 60us/step - loss: 0.4871 - acc: 0.8058 - val_loss: 0.4738 - val_acc: 0.8213\n",
      "Epoch 134/200\n",
      "1164/1164 [==============================] - 0s 62us/step - loss: 0.4797 - acc: 0.8127 - val_loss: 0.4698 - val_acc: 0.8239\n",
      "Epoch 135/200\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 0.4725 - acc: 0.8187 - val_loss: 0.4680 - val_acc: 0.8290\n",
      "Epoch 136/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.4731 - acc: 0.8196 - val_loss: 0.4637 - val_acc: 0.8282\n",
      "Epoch 137/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.4722 - acc: 0.8170 - val_loss: 0.4666 - val_acc: 0.8239\n",
      "Epoch 138/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.4727 - acc: 0.8136 - val_loss: 0.4623 - val_acc: 0.8222\n",
      "Epoch 139/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4659 - acc: 0.8265 - val_loss: 0.4578 - val_acc: 0.8342\n",
      "Epoch 140/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4674 - acc: 0.8213 - val_loss: 0.4555 - val_acc: 0.8333\n",
      "Epoch 141/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.4667 - acc: 0.8273 - val_loss: 0.4571 - val_acc: 0.8230\n",
      "Epoch 142/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.4601 - acc: 0.8282 - val_loss: 0.4533 - val_acc: 0.8342\n",
      "Epoch 143/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4624 - acc: 0.8316 - val_loss: 0.4546 - val_acc: 0.8385\n",
      "Epoch 144/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.4587 - acc: 0.8351 - val_loss: 0.4478 - val_acc: 0.8428\n",
      "Epoch 145/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.4532 - acc: 0.8325 - val_loss: 0.4454 - val_acc: 0.8411\n",
      "Epoch 146/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4506 - acc: 0.8368 - val_loss: 0.4446 - val_acc: 0.8359\n",
      "Epoch 147/200\n",
      "1164/1164 [==============================] - 0s 48us/step - loss: 0.4539 - acc: 0.8376 - val_loss: 0.4424 - val_acc: 0.8376\n",
      "Epoch 148/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.4489 - acc: 0.8359 - val_loss: 0.4455 - val_acc: 0.8376\n",
      "Epoch 149/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.4487 - acc: 0.8351 - val_loss: 0.4403 - val_acc: 0.8497\n",
      "Epoch 150/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.4450 - acc: 0.8479 - val_loss: 0.4386 - val_acc: 0.8385\n",
      "Epoch 151/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.4483 - acc: 0.8299 - val_loss: 0.4372 - val_acc: 0.8488\n",
      "Epoch 152/200\n",
      "1164/1164 [==============================] - 0s 57us/step - loss: 0.4449 - acc: 0.8411 - val_loss: 0.4399 - val_acc: 0.8333\n",
      "Epoch 153/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.4471 - acc: 0.8256 - val_loss: 0.4453 - val_acc: 0.8462\n",
      "Epoch 154/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4470 - acc: 0.8445 - val_loss: 0.4433 - val_acc: 0.8393\n",
      "Epoch 155/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4512 - acc: 0.8385 - val_loss: 0.4316 - val_acc: 0.8488\n",
      "Epoch 156/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4407 - acc: 0.8385 - val_loss: 0.4354 - val_acc: 0.8462\n",
      "Epoch 157/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.4342 - acc: 0.8436 - val_loss: 0.4392 - val_acc: 0.8419\n",
      "Epoch 158/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.4390 - acc: 0.8351 - val_loss: 0.4367 - val_acc: 0.8419\n",
      "Epoch 159/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4337 - acc: 0.8505 - val_loss: 0.4228 - val_acc: 0.8505\n",
      "Epoch 160/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.4273 - acc: 0.8548 - val_loss: 0.4218 - val_acc: 0.8514\n",
      "Epoch 161/200\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 0.4244 - acc: 0.8531 - val_loss: 0.4179 - val_acc: 0.8582\n",
      "Epoch 162/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.4251 - acc: 0.8557 - val_loss: 0.4205 - val_acc: 0.8514\n",
      "Epoch 163/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4268 - acc: 0.8505 - val_loss: 0.4207 - val_acc: 0.8540\n",
      "Epoch 164/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.4281 - acc: 0.8548 - val_loss: 0.4181 - val_acc: 0.8531\n",
      "Epoch 165/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4282 - acc: 0.8548 - val_loss: 0.4140 - val_acc: 0.8608\n",
      "Epoch 166/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.4222 - acc: 0.8514 - val_loss: 0.4182 - val_acc: 0.8531\n",
      "Epoch 167/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.4179 - acc: 0.8608 - val_loss: 0.4123 - val_acc: 0.8540\n",
      "Epoch 168/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.4150 - acc: 0.8522 - val_loss: 0.4124 - val_acc: 0.8634\n",
      "Epoch 169/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4150 - acc: 0.8591 - val_loss: 0.4093 - val_acc: 0.8591\n",
      "Epoch 170/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.4171 - acc: 0.8557 - val_loss: 0.4097 - val_acc: 0.8591\n",
      "Epoch 171/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4114 - acc: 0.8522 - val_loss: 0.4049 - val_acc: 0.8617\n",
      "Epoch 172/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4105 - acc: 0.8591 - val_loss: 0.4020 - val_acc: 0.8711\n",
      "Epoch 173/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4118 - acc: 0.8634 - val_loss: 0.4082 - val_acc: 0.8557\n",
      "Epoch 174/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.4061 - acc: 0.8582 - val_loss: 0.4020 - val_acc: 0.8582\n",
      "Epoch 175/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.4085 - acc: 0.8660 - val_loss: 0.4035 - val_acc: 0.8643\n",
      "Epoch 176/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.4094 - acc: 0.8608 - val_loss: 0.4002 - val_acc: 0.8643\n",
      "Epoch 177/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.4090 - acc: 0.8548 - val_loss: 0.4033 - val_acc: 0.8574\n",
      "Epoch 178/200\n",
      "1164/1164 [==============================] - 0s 55us/step - loss: 0.4058 - acc: 0.8625 - val_loss: 0.3957 - val_acc: 0.8643\n",
      "Epoch 179/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.4037 - acc: 0.8617 - val_loss: 0.4013 - val_acc: 0.8591\n",
      "Epoch 180/200\n",
      "1164/1164 [==============================] - 0s 52us/step - loss: 0.4029 - acc: 0.8557 - val_loss: 0.3929 - val_acc: 0.8651\n",
      "Epoch 181/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.3977 - acc: 0.8617 - val_loss: 0.3929 - val_acc: 0.8686\n",
      "Epoch 182/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.3975 - acc: 0.8617 - val_loss: 0.3904 - val_acc: 0.8737\n",
      "Epoch 183/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.3967 - acc: 0.8677 - val_loss: 0.3871 - val_acc: 0.8711\n",
      "Epoch 184/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.3959 - acc: 0.8668 - val_loss: 0.4041 - val_acc: 0.8540\n",
      "Epoch 185/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.4060 - acc: 0.8574 - val_loss: 0.3928 - val_acc: 0.8600\n",
      "Epoch 186/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.3991 - acc: 0.8608 - val_loss: 0.3840 - val_acc: 0.8694\n",
      "Epoch 187/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.3878 - acc: 0.8746 - val_loss: 0.3825 - val_acc: 0.8746\n",
      "Epoch 188/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.3890 - acc: 0.8703 - val_loss: 0.3801 - val_acc: 0.8746\n",
      "Epoch 189/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.3891 - acc: 0.8677 - val_loss: 0.3865 - val_acc: 0.8634\n",
      "Epoch 190/200\n",
      "1164/1164 [==============================] - 0s 51us/step - loss: 0.3882 - acc: 0.8668 - val_loss: 0.3808 - val_acc: 0.8763\n",
      "Epoch 191/200\n",
      "1164/1164 [==============================] - 0s 53us/step - loss: 0.3832 - acc: 0.8754 - val_loss: 0.3807 - val_acc: 0.8694\n",
      "Epoch 192/200\n",
      "1164/1164 [==============================] - 0s 50us/step - loss: 0.3841 - acc: 0.8677 - val_loss: 0.3794 - val_acc: 0.8720\n",
      "Epoch 193/200\n",
      "1164/1164 [==============================] - 0s 54us/step - loss: 0.3847 - acc: 0.8686 - val_loss: 0.3770 - val_acc: 0.8703\n",
      "Epoch 194/200\n",
      "1164/1164 [==============================] - 0s 49us/step - loss: 0.3867 - acc: 0.8565 - val_loss: 0.3825 - val_acc: 0.8677\n",
      "Epoch 195/200\n",
      "1164/1164 [==============================] - 0s 65us/step - loss: 0.3846 - acc: 0.8720 - val_loss: 0.3787 - val_acc: 0.8694\n",
      "Epoch 196/200\n",
      "1164/1164 [==============================] - 0s 56us/step - loss: 0.3849 - acc: 0.8651 - val_loss: 0.3737 - val_acc: 0.8729\n",
      "Epoch 197/200\n",
      "1164/1164 [==============================] - 0s 65us/step - loss: 0.3806 - acc: 0.8677 - val_loss: 0.3718 - val_acc: 0.8703\n",
      "Epoch 198/200\n",
      "1164/1164 [==============================] - 0s 61us/step - loss: 0.3927 - acc: 0.8608 - val_loss: 0.3729 - val_acc: 0.8703\n",
      "Epoch 199/200\n",
      "1164/1164 [==============================] - 0s 68us/step - loss: 0.3812 - acc: 0.8634 - val_loss: 0.3709 - val_acc: 0.8720\n",
      "Epoch 200/200\n",
      "1164/1164 [==============================] - 0s 64us/step - loss: 0.3761 - acc: 0.8720 - val_loss: 0.3664 - val_acc: 0.8771\n",
      "4656/4656 [==============================] - 0s 53us/step\n",
      "1164/1164 [==============================] - 0s 61us/step\n",
      "[0.9590492555092837, 0.7973654066847224, 0.6476947308132875]\n",
      "[0.9893327605956473, 0.9252004580262874, 0.8800114547537228]\n"
     ]
    }
   ],
   "source": [
    "ave_acc_eva_ann=[]\n",
    "ave_acc_eva_ann_train=[]\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(eva_x, eva_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        model = create_model(X_train1.shape[1],y_train1.shape[1])\n",
    "        history = model.fit(X_train1, y_train1,validation_data=(X_train1,y_train1),batch_size=100,epochs=200)\n",
    "        score2 += model.evaluate(X_test1,y_test1,verbose=1)[1]\n",
    "        score1 += model.evaluate(X_train1,y_train1,verbose=1)[1]\n",
    "    ave_acc_eva_ann.append(score2/3.0)\n",
    "    ave_acc_eva_ann_train.append(score1/3.0)\n",
    "    \n",
    "print ave_acc_eva_ann  \n",
    "print ave_acc_eva_ann_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28573 samples, validate on 28573 samples\n",
      "Epoch 1/300\n",
      "28573/28573 [==============================] - 3s 107us/step - loss: 3.2099 - acc: 0.0705 - val_loss: 3.0065 - val_acc: 0.1103\n",
      "Epoch 2/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 2.8391 - acc: 0.1292 - val_loss: 2.6821 - val_acc: 0.1723\n",
      "Epoch 3/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 2.5533 - acc: 0.1759 - val_loss: 2.4206 - val_acc: 0.2084\n",
      "Epoch 4/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 2.2949 - acc: 0.2774 - val_loss: 2.1650 - val_acc: 0.3180\n",
      "Epoch 5/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 2.0531 - acc: 0.3613 - val_loss: 1.9417 - val_acc: 0.3826\n",
      "Epoch 6/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.8531 - acc: 0.4185 - val_loss: 1.7650 - val_acc: 0.4295\n",
      "Epoch 7/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.6939 - acc: 0.4778 - val_loss: 1.6242 - val_acc: 0.5041\n",
      "Epoch 8/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.5654 - acc: 0.5451 - val_loss: 1.5048 - val_acc: 0.5556\n",
      "Epoch 9/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.4553 - acc: 0.5607 - val_loss: 1.4043 - val_acc: 0.6007\n",
      "Epoch 10/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.3621 - acc: 0.5947 - val_loss: 1.3169 - val_acc: 0.5898\n",
      "Epoch 11/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.2805 - acc: 0.6199 - val_loss: 1.2404 - val_acc: 0.6368\n",
      "Epoch 12/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.2088 - acc: 0.6434 - val_loss: 1.1760 - val_acc: 0.6872\n",
      "Epoch 13/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.1460 - acc: 0.6736 - val_loss: 1.1172 - val_acc: 0.6554\n",
      "Epoch 14/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.0888 - acc: 0.6922 - val_loss: 1.0610 - val_acc: 0.7111\n",
      "Epoch 15/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.0386 - acc: 0.7089 - val_loss: 1.0137 - val_acc: 0.7033\n",
      "Epoch 16/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.9929 - acc: 0.7178 - val_loss: 0.9690 - val_acc: 0.7447\n",
      "Epoch 17/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.9517 - acc: 0.7342 - val_loss: 0.9290 - val_acc: 0.7617\n",
      "Epoch 18/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.9136 - acc: 0.7484 - val_loss: 0.8962 - val_acc: 0.7578\n",
      "Epoch 19/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.8770 - acc: 0.7612 - val_loss: 0.8587 - val_acc: 0.7622\n",
      "Epoch 20/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.8443 - acc: 0.7690 - val_loss: 0.8316 - val_acc: 0.7461\n",
      "Epoch 21/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.8148 - acc: 0.7736 - val_loss: 0.7994 - val_acc: 0.7785\n",
      "Epoch 22/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.7873 - acc: 0.7773 - val_loss: 0.7722 - val_acc: 0.7876\n",
      "Epoch 23/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.7599 - acc: 0.7888 - val_loss: 0.7483 - val_acc: 0.7921\n",
      "Epoch 24/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.7351 - acc: 0.8012 - val_loss: 0.7201 - val_acc: 0.8032\n",
      "Epoch 25/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.7122 - acc: 0.8026 - val_loss: 0.6998 - val_acc: 0.8079\n",
      "Epoch 26/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.6897 - acc: 0.8109 - val_loss: 0.6803 - val_acc: 0.8034\n",
      "Epoch 27/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.6692 - acc: 0.8115 - val_loss: 0.6575 - val_acc: 0.8166\n",
      "Epoch 28/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.6487 - acc: 0.8205 - val_loss: 0.6410 - val_acc: 0.8209\n",
      "Epoch 29/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.6298 - acc: 0.8263 - val_loss: 0.6196 - val_acc: 0.8278\n",
      "Epoch 30/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.6149 - acc: 0.8239 - val_loss: 0.6033 - val_acc: 0.8202\n",
      "Epoch 31/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.5959 - acc: 0.8303 - val_loss: 0.5869 - val_acc: 0.8346\n",
      "Epoch 32/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.5796 - acc: 0.8321 - val_loss: 0.5755 - val_acc: 0.8279\n",
      "Epoch 33/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.5652 - acc: 0.8388 - val_loss: 0.5569 - val_acc: 0.8426\n",
      "Epoch 34/300\n",
      "28573/28573 [==============================] - 0s 17us/step - loss: 0.5496 - acc: 0.8411 - val_loss: 0.5415 - val_acc: 0.8455\n",
      "Epoch 35/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.5361 - acc: 0.8416 - val_loss: 0.5287 - val_acc: 0.8532\n",
      "Epoch 36/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.5241 - acc: 0.8450 - val_loss: 0.5171 - val_acc: 0.8539\n",
      "Epoch 37/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.5117 - acc: 0.8481 - val_loss: 0.5058 - val_acc: 0.8526\n",
      "Epoch 38/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4996 - acc: 0.8489 - val_loss: 0.4917 - val_acc: 0.8485\n",
      "Epoch 39/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4888 - acc: 0.8531 - val_loss: 0.4822 - val_acc: 0.8572\n",
      "Epoch 40/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4780 - acc: 0.8558 - val_loss: 0.4721 - val_acc: 0.8593\n",
      "Epoch 41/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.4688 - acc: 0.8591 - val_loss: 0.4640 - val_acc: 0.8579\n",
      "Epoch 42/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4631 - acc: 0.8572 - val_loss: 0.4579 - val_acc: 0.8562\n",
      "Epoch 43/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4519 - acc: 0.8602 - val_loss: 0.4454 - val_acc: 0.8656\n",
      "Epoch 44/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4425 - acc: 0.8617 - val_loss: 0.4362 - val_acc: 0.8660\n",
      "Epoch 45/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4338 - acc: 0.8642 - val_loss: 0.4296 - val_acc: 0.8655\n",
      "Epoch 46/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4251 - acc: 0.8671 - val_loss: 0.4212 - val_acc: 0.8655\n",
      "Epoch 47/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4182 - acc: 0.8669 - val_loss: 0.4131 - val_acc: 0.8682\n",
      "Epoch 48/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4126 - acc: 0.8664 - val_loss: 0.4077 - val_acc: 0.8708\n",
      "Epoch 49/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4064 - acc: 0.8681 - val_loss: 0.4000 - val_acc: 0.8688\n",
      "Epoch 50/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3989 - acc: 0.8683 - val_loss: 0.3961 - val_acc: 0.8722\n",
      "Epoch 51/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3917 - acc: 0.8711 - val_loss: 0.3881 - val_acc: 0.8659\n",
      "Epoch 52/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3870 - acc: 0.8701 - val_loss: 0.3823 - val_acc: 0.8732\n",
      "Epoch 53/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3804 - acc: 0.8712 - val_loss: 0.3770 - val_acc: 0.8728\n",
      "Epoch 54/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3765 - acc: 0.8726 - val_loss: 0.3734 - val_acc: 0.8717\n",
      "Epoch 55/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3723 - acc: 0.8732 - val_loss: 0.3702 - val_acc: 0.8717\n",
      "Epoch 56/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3644 - acc: 0.8764 - val_loss: 0.3580 - val_acc: 0.8759\n",
      "Epoch 57/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.3579 - acc: 0.8773 - val_loss: 0.3566 - val_acc: 0.8765\n",
      "Epoch 58/300\n",
      "28573/28573 [==============================] - 0s 17us/step - loss: 0.3538 - acc: 0.8769 - val_loss: 0.3512 - val_acc: 0.8804\n",
      "Epoch 59/300\n",
      "28573/28573 [==============================] - 1s 18us/step - loss: 0.3490 - acc: 0.8793 - val_loss: 0.3467 - val_acc: 0.8748\n",
      "Epoch 60/300\n",
      "28573/28573 [==============================] - 1s 18us/step - loss: 0.3447 - acc: 0.8828 - val_loss: 0.3412 - val_acc: 0.8780\n",
      "Epoch 61/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.3398 - acc: 0.8823 - val_loss: 0.3358 - val_acc: 0.8818\n",
      "Epoch 62/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.3359 - acc: 0.8817 - val_loss: 0.3291 - val_acc: 0.8816\n",
      "Epoch 63/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.3311 - acc: 0.8839 - val_loss: 0.3272 - val_acc: 0.8834\n",
      "Epoch 64/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.3267 - acc: 0.8847 - val_loss: 0.3230 - val_acc: 0.8841\n",
      "Epoch 65/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.3234 - acc: 0.8856 - val_loss: 0.3204 - val_acc: 0.8815\n",
      "Epoch 66/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3192 - acc: 0.8870 - val_loss: 0.3163 - val_acc: 0.8823\n",
      "Epoch 67/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3153 - acc: 0.8877 - val_loss: 0.3171 - val_acc: 0.8870\n",
      "Epoch 68/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3111 - acc: 0.8890 - val_loss: 0.3082 - val_acc: 0.8910\n",
      "Epoch 69/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3085 - acc: 0.8914 - val_loss: 0.3056 - val_acc: 0.8967\n",
      "Epoch 70/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3059 - acc: 0.8923 - val_loss: 0.3020 - val_acc: 0.8926\n",
      "Epoch 71/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3031 - acc: 0.8911 - val_loss: 0.3020 - val_acc: 0.8984\n",
      "Epoch 72/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2988 - acc: 0.8928 - val_loss: 0.2997 - val_acc: 0.8947\n",
      "Epoch 73/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2966 - acc: 0.8950 - val_loss: 0.2967 - val_acc: 0.8959\n",
      "Epoch 74/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.2936 - acc: 0.8956 - val_loss: 0.2956 - val_acc: 0.8915\n",
      "Epoch 75/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2900 - acc: 0.8957 - val_loss: 0.2862 - val_acc: 0.8919\n",
      "Epoch 76/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2857 - acc: 0.8953 - val_loss: 0.2828 - val_acc: 0.8935\n",
      "Epoch 77/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2830 - acc: 0.8969 - val_loss: 0.2790 - val_acc: 0.9048\n",
      "Epoch 78/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2795 - acc: 0.8985 - val_loss: 0.2777 - val_acc: 0.8953\n",
      "Epoch 79/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2782 - acc: 0.8984 - val_loss: 0.2761 - val_acc: 0.8982\n",
      "Epoch 80/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2740 - acc: 0.8988 - val_loss: 0.2733 - val_acc: 0.8960\n",
      "Epoch 81/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2727 - acc: 0.9016 - val_loss: 0.2696 - val_acc: 0.9032\n",
      "Epoch 82/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2717 - acc: 0.9005 - val_loss: 0.2700 - val_acc: 0.8970\n",
      "Epoch 83/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2692 - acc: 0.8979 - val_loss: 0.2636 - val_acc: 0.9090\n",
      "Epoch 84/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2639 - acc: 0.9043 - val_loss: 0.2637 - val_acc: 0.8969\n",
      "Epoch 85/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2616 - acc: 0.9033 - val_loss: 0.2604 - val_acc: 0.8989\n",
      "Epoch 86/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2595 - acc: 0.9048 - val_loss: 0.2574 - val_acc: 0.9076\n",
      "Epoch 87/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.2570 - acc: 0.9056 - val_loss: 0.2546 - val_acc: 0.9012\n",
      "Epoch 88/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2551 - acc: 0.9055 - val_loss: 0.2503 - val_acc: 0.9072\n",
      "Epoch 89/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2524 - acc: 0.9046 - val_loss: 0.2491 - val_acc: 0.9050\n",
      "Epoch 90/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2499 - acc: 0.9045 - val_loss: 0.2479 - val_acc: 0.9065\n",
      "Epoch 91/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2478 - acc: 0.9079 - val_loss: 0.2470 - val_acc: 0.9074\n",
      "Epoch 92/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2451 - acc: 0.9086 - val_loss: 0.2430 - val_acc: 0.9097\n",
      "Epoch 93/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2429 - acc: 0.9085 - val_loss: 0.2441 - val_acc: 0.9074\n",
      "Epoch 94/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2409 - acc: 0.9092 - val_loss: 0.2427 - val_acc: 0.9082\n",
      "Epoch 95/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2413 - acc: 0.9100 - val_loss: 0.2394 - val_acc: 0.9128\n",
      "Epoch 96/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2369 - acc: 0.9113 - val_loss: 0.2354 - val_acc: 0.9148\n",
      "Epoch 97/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2353 - acc: 0.9129 - val_loss: 0.2341 - val_acc: 0.9173\n",
      "Epoch 98/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2355 - acc: 0.9123 - val_loss: 0.2329 - val_acc: 0.9125\n",
      "Epoch 99/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2326 - acc: 0.9124 - val_loss: 0.2318 - val_acc: 0.9159\n",
      "Epoch 100/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2303 - acc: 0.9149 - val_loss: 0.2286 - val_acc: 0.9110\n",
      "Epoch 101/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2274 - acc: 0.9150 - val_loss: 0.2261 - val_acc: 0.9248\n",
      "Epoch 102/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2257 - acc: 0.9181 - val_loss: 0.2274 - val_acc: 0.9090\n",
      "Epoch 103/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2237 - acc: 0.9144 - val_loss: 0.2247 - val_acc: 0.9087\n",
      "Epoch 104/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.2232 - acc: 0.9165 - val_loss: 0.2272 - val_acc: 0.9102\n",
      "Epoch 105/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.2226 - acc: 0.9173 - val_loss: 0.2197 - val_acc: 0.9144\n",
      "Epoch 106/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.2198 - acc: 0.9182 - val_loss: 0.2178 - val_acc: 0.9121\n",
      "Epoch 107/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.2173 - acc: 0.9211 - val_loss: 0.2156 - val_acc: 0.9315\n",
      "Epoch 108/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2159 - acc: 0.9221 - val_loss: 0.2141 - val_acc: 0.9279\n",
      "Epoch 109/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2152 - acc: 0.9198 - val_loss: 0.2178 - val_acc: 0.9178\n",
      "Epoch 110/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.2122 - acc: 0.9221 - val_loss: 0.2096 - val_acc: 0.9213\n",
      "Epoch 111/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.2109 - acc: 0.9241 - val_loss: 0.2073 - val_acc: 0.9240\n",
      "Epoch 112/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2076 - acc: 0.9262 - val_loss: 0.2065 - val_acc: 0.9171\n",
      "Epoch 113/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2095 - acc: 0.9231 - val_loss: 0.2123 - val_acc: 0.9253\n",
      "Epoch 114/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.2077 - acc: 0.9229 - val_loss: 0.2104 - val_acc: 0.9302\n",
      "Epoch 115/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2041 - acc: 0.9263 - val_loss: 0.2040 - val_acc: 0.9178\n",
      "Epoch 116/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2032 - acc: 0.9271 - val_loss: 0.2028 - val_acc: 0.9217\n",
      "Epoch 117/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.2024 - acc: 0.9275 - val_loss: 0.2013 - val_acc: 0.9176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2005 - acc: 0.9259 - val_loss: 0.1991 - val_acc: 0.9291\n",
      "Epoch 119/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1976 - acc: 0.9302 - val_loss: 0.1960 - val_acc: 0.9429\n",
      "Epoch 120/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1972 - acc: 0.9303 - val_loss: 0.1996 - val_acc: 0.9214\n",
      "Epoch 121/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1956 - acc: 0.9316 - val_loss: 0.1940 - val_acc: 0.9329\n",
      "Epoch 122/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1941 - acc: 0.9325 - val_loss: 0.1919 - val_acc: 0.9403\n",
      "Epoch 123/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1929 - acc: 0.9328 - val_loss: 0.1944 - val_acc: 0.9281\n",
      "Epoch 124/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1917 - acc: 0.9320 - val_loss: 0.1901 - val_acc: 0.9280\n",
      "Epoch 125/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1898 - acc: 0.9322 - val_loss: 0.1909 - val_acc: 0.9471\n",
      "Epoch 126/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1899 - acc: 0.9360 - val_loss: 0.1862 - val_acc: 0.9425\n",
      "Epoch 127/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1876 - acc: 0.9357 - val_loss: 0.1925 - val_acc: 0.9358\n",
      "Epoch 128/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1871 - acc: 0.9368 - val_loss: 0.1853 - val_acc: 0.9238\n",
      "Epoch 129/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1847 - acc: 0.9386 - val_loss: 0.1824 - val_acc: 0.9302\n",
      "Epoch 130/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1835 - acc: 0.9353 - val_loss: 0.1809 - val_acc: 0.9370\n",
      "Epoch 131/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1825 - acc: 0.9375 - val_loss: 0.1838 - val_acc: 0.9411\n",
      "Epoch 132/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1815 - acc: 0.9394 - val_loss: 0.1810 - val_acc: 0.9396\n",
      "Epoch 133/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1811 - acc: 0.9396 - val_loss: 0.1801 - val_acc: 0.9333\n",
      "Epoch 134/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.1794 - acc: 0.9398 - val_loss: 0.1764 - val_acc: 0.9377\n",
      "Epoch 135/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1779 - acc: 0.9387 - val_loss: 0.1777 - val_acc: 0.9341\n",
      "Epoch 136/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1768 - acc: 0.9402 - val_loss: 0.1759 - val_acc: 0.9512\n",
      "Epoch 137/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1755 - acc: 0.9405 - val_loss: 0.1742 - val_acc: 0.9521\n",
      "Epoch 138/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1735 - acc: 0.9445 - val_loss: 0.1709 - val_acc: 0.9434\n",
      "Epoch 139/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.1732 - acc: 0.9428 - val_loss: 0.1706 - val_acc: 0.9446\n",
      "Epoch 140/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1723 - acc: 0.9430 - val_loss: 0.1764 - val_acc: 0.9580\n",
      "Epoch 141/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1720 - acc: 0.9456 - val_loss: 0.1701 - val_acc: 0.9374\n",
      "Epoch 142/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1698 - acc: 0.9445 - val_loss: 0.1721 - val_acc: 0.9409\n",
      "Epoch 143/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1688 - acc: 0.9459 - val_loss: 0.1654 - val_acc: 0.9485\n",
      "Epoch 144/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1681 - acc: 0.9457 - val_loss: 0.1671 - val_acc: 0.9440\n",
      "Epoch 145/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1653 - acc: 0.9481 - val_loss: 0.1661 - val_acc: 0.9437\n",
      "Epoch 146/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1657 - acc: 0.9468 - val_loss: 0.1644 - val_acc: 0.9567\n",
      "Epoch 147/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1633 - acc: 0.9484 - val_loss: 0.1631 - val_acc: 0.9495\n",
      "Epoch 148/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1638 - acc: 0.9480 - val_loss: 0.1629 - val_acc: 0.9489\n",
      "Epoch 149/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1616 - acc: 0.9496 - val_loss: 0.1658 - val_acc: 0.9596\n",
      "Epoch 150/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1622 - acc: 0.9501 - val_loss: 0.1596 - val_acc: 0.9490\n",
      "Epoch 151/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1593 - acc: 0.9503 - val_loss: 0.1579 - val_acc: 0.9426\n",
      "Epoch 152/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1586 - acc: 0.9488 - val_loss: 0.1580 - val_acc: 0.9590\n",
      "Epoch 153/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1576 - acc: 0.9535 - val_loss: 0.1585 - val_acc: 0.9468\n",
      "Epoch 154/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1569 - acc: 0.9512 - val_loss: 0.1583 - val_acc: 0.9500\n",
      "Epoch 155/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1565 - acc: 0.9519 - val_loss: 0.1538 - val_acc: 0.9596\n",
      "Epoch 156/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1541 - acc: 0.9543 - val_loss: 0.1533 - val_acc: 0.9512\n",
      "Epoch 157/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1529 - acc: 0.9516 - val_loss: 0.1508 - val_acc: 0.9607\n",
      "Epoch 158/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1521 - acc: 0.9553 - val_loss: 0.1504 - val_acc: 0.9582\n",
      "Epoch 159/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1533 - acc: 0.9531 - val_loss: 0.1504 - val_acc: 0.9609\n",
      "Epoch 160/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1513 - acc: 0.9539 - val_loss: 0.1482 - val_acc: 0.9549\n",
      "Epoch 161/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1533 - acc: 0.9512 - val_loss: 0.1488 - val_acc: 0.9581\n",
      "Epoch 162/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1480 - acc: 0.9556 - val_loss: 0.1480 - val_acc: 0.9623\n",
      "Epoch 163/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1471 - acc: 0.9566 - val_loss: 0.1467 - val_acc: 0.9601\n",
      "Epoch 164/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1478 - acc: 0.9530 - val_loss: 0.1470 - val_acc: 0.9614\n",
      "Epoch 165/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1458 - acc: 0.9579 - val_loss: 0.1425 - val_acc: 0.9620\n",
      "Epoch 166/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1450 - acc: 0.9572 - val_loss: 0.1426 - val_acc: 0.9616\n",
      "Epoch 167/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1432 - acc: 0.9587 - val_loss: 0.1412 - val_acc: 0.9598\n",
      "Epoch 168/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1435 - acc: 0.9560 - val_loss: 0.1416 - val_acc: 0.9646\n",
      "Epoch 169/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1421 - acc: 0.9578 - val_loss: 0.1407 - val_acc: 0.9549\n",
      "Epoch 170/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1408 - acc: 0.9588 - val_loss: 0.1415 - val_acc: 0.9610\n",
      "Epoch 171/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1406 - acc: 0.9578 - val_loss: 0.1379 - val_acc: 0.9574\n",
      "Epoch 172/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1388 - acc: 0.9607 - val_loss: 0.1361 - val_acc: 0.9661\n",
      "Epoch 173/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1379 - acc: 0.9599 - val_loss: 0.1356 - val_acc: 0.9641\n",
      "Epoch 174/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1361 - acc: 0.9628 - val_loss: 0.1359 - val_acc: 0.9604\n",
      "Epoch 175/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1363 - acc: 0.9616 - val_loss: 0.1339 - val_acc: 0.9676\n",
      "Epoch 176/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1365 - acc: 0.9593 - val_loss: 0.1360 - val_acc: 0.9654\n",
      "Epoch 177/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1345 - acc: 0.9612 - val_loss: 0.1328 - val_acc: 0.9652\n",
      "Epoch 178/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1336 - acc: 0.9630 - val_loss: 0.1330 - val_acc: 0.9608\n",
      "Epoch 179/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1335 - acc: 0.9603 - val_loss: 0.1350 - val_acc: 0.9602\n",
      "Epoch 180/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1319 - acc: 0.9630 - val_loss: 0.1325 - val_acc: 0.9571\n",
      "Epoch 181/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1317 - acc: 0.9636 - val_loss: 0.1306 - val_acc: 0.9617\n",
      "Epoch 182/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1310 - acc: 0.9629 - val_loss: 0.1307 - val_acc: 0.9554\n",
      "Epoch 183/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1292 - acc: 0.9645 - val_loss: 0.1294 - val_acc: 0.9610\n",
      "Epoch 184/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.1278 - acc: 0.9649 - val_loss: 0.1276 - val_acc: 0.9672\n",
      "Epoch 185/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1279 - acc: 0.9637 - val_loss: 0.1287 - val_acc: 0.9665\n",
      "Epoch 186/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1270 - acc: 0.9641 - val_loss: 0.1267 - val_acc: 0.9617\n",
      "Epoch 187/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1263 - acc: 0.9645 - val_loss: 0.1257 - val_acc: 0.9670\n",
      "Epoch 188/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1255 - acc: 0.9656 - val_loss: 0.1235 - val_acc: 0.9686\n",
      "Epoch 189/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1239 - acc: 0.9663 - val_loss: 0.1238 - val_acc: 0.9689\n",
      "Epoch 190/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1237 - acc: 0.9661 - val_loss: 0.1270 - val_acc: 0.9623\n",
      "Epoch 191/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1228 - acc: 0.9670 - val_loss: 0.1207 - val_acc: 0.9653\n",
      "Epoch 192/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1216 - acc: 0.9673 - val_loss: 0.1194 - val_acc: 0.9696\n",
      "Epoch 193/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1206 - acc: 0.9673 - val_loss: 0.1182 - val_acc: 0.9689\n",
      "Epoch 194/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1194 - acc: 0.9677 - val_loss: 0.1237 - val_acc: 0.9633\n",
      "Epoch 195/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1197 - acc: 0.9676 - val_loss: 0.1183 - val_acc: 0.9711\n",
      "Epoch 196/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1189 - acc: 0.9675 - val_loss: 0.1195 - val_acc: 0.9600\n",
      "Epoch 197/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1181 - acc: 0.9686 - val_loss: 0.1167 - val_acc: 0.9718\n",
      "Epoch 198/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1169 - acc: 0.9680 - val_loss: 0.1143 - val_acc: 0.9726\n",
      "Epoch 199/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1158 - acc: 0.9690 - val_loss: 0.1150 - val_acc: 0.9719\n",
      "Epoch 200/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1157 - acc: 0.9697 - val_loss: 0.1132 - val_acc: 0.9716\n",
      "Epoch 201/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1142 - acc: 0.9697 - val_loss: 0.1137 - val_acc: 0.9716\n",
      "Epoch 202/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1145 - acc: 0.9697 - val_loss: 0.1154 - val_acc: 0.9632\n",
      "Epoch 203/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1151 - acc: 0.9673 - val_loss: 0.1131 - val_acc: 0.9691\n",
      "Epoch 204/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1130 - acc: 0.9700 - val_loss: 0.1145 - val_acc: 0.9702\n",
      "Epoch 205/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1116 - acc: 0.9712 - val_loss: 0.1101 - val_acc: 0.9715\n",
      "Epoch 206/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1109 - acc: 0.9701 - val_loss: 0.1092 - val_acc: 0.9724\n",
      "Epoch 207/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1097 - acc: 0.9708 - val_loss: 0.1084 - val_acc: 0.9708\n",
      "Epoch 208/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1100 - acc: 0.9715 - val_loss: 0.1102 - val_acc: 0.9721\n",
      "Epoch 209/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1093 - acc: 0.9707 - val_loss: 0.1101 - val_acc: 0.9683\n",
      "Epoch 210/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1086 - acc: 0.9717 - val_loss: 0.1092 - val_acc: 0.9676\n",
      "Epoch 211/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1075 - acc: 0.9725 - val_loss: 0.1061 - val_acc: 0.9754\n",
      "Epoch 212/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1077 - acc: 0.9719 - val_loss: 0.1060 - val_acc: 0.9727\n",
      "Epoch 213/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1064 - acc: 0.9715 - val_loss: 0.1056 - val_acc: 0.9732\n",
      "Epoch 214/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1062 - acc: 0.9723 - val_loss: 0.1057 - val_acc: 0.9737\n",
      "Epoch 215/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1064 - acc: 0.9724 - val_loss: 0.1045 - val_acc: 0.9733\n",
      "Epoch 216/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1034 - acc: 0.9735 - val_loss: 0.1025 - val_acc: 0.9756\n",
      "Epoch 217/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1046 - acc: 0.9731 - val_loss: 0.1097 - val_acc: 0.9629\n",
      "Epoch 218/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1046 - acc: 0.9722 - val_loss: 0.1029 - val_acc: 0.9746\n",
      "Epoch 219/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1022 - acc: 0.9736 - val_loss: 0.1031 - val_acc: 0.9740\n",
      "Epoch 220/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1013 - acc: 0.9750 - val_loss: 0.0998 - val_acc: 0.9741\n",
      "Epoch 221/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1011 - acc: 0.9731 - val_loss: 0.1000 - val_acc: 0.9766\n",
      "Epoch 222/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1009 - acc: 0.9748 - val_loss: 0.0997 - val_acc: 0.9759\n",
      "Epoch 223/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0990 - acc: 0.9750 - val_loss: 0.0979 - val_acc: 0.9760\n",
      "Epoch 224/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0984 - acc: 0.9754 - val_loss: 0.0981 - val_acc: 0.9748\n",
      "Epoch 225/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0980 - acc: 0.9759 - val_loss: 0.0982 - val_acc: 0.9763\n",
      "Epoch 226/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0981 - acc: 0.9757 - val_loss: 0.0989 - val_acc: 0.9746\n",
      "Epoch 227/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0972 - acc: 0.9756 - val_loss: 0.0966 - val_acc: 0.9767\n",
      "Epoch 228/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0980 - acc: 0.9748 - val_loss: 0.0967 - val_acc: 0.9759\n",
      "Epoch 229/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0969 - acc: 0.9744 - val_loss: 0.0957 - val_acc: 0.9764\n",
      "Epoch 230/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0961 - acc: 0.9753 - val_loss: 0.0952 - val_acc: 0.9761\n",
      "Epoch 231/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0943 - acc: 0.9763 - val_loss: 0.0984 - val_acc: 0.9731\n",
      "Epoch 232/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0951 - acc: 0.9761 - val_loss: 0.0928 - val_acc: 0.9770\n",
      "Epoch 233/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0930 - acc: 0.9777 - val_loss: 0.0916 - val_acc: 0.9784\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0924 - acc: 0.9776 - val_loss: 0.0922 - val_acc: 0.9777\n",
      "Epoch 235/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0924 - acc: 0.9768 - val_loss: 0.0933 - val_acc: 0.9742\n",
      "Epoch 236/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0923 - acc: 0.9777 - val_loss: 0.0937 - val_acc: 0.9749\n",
      "Epoch 237/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0922 - acc: 0.9768 - val_loss: 0.0894 - val_acc: 0.9783\n",
      "Epoch 238/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0915 - acc: 0.9760 - val_loss: 0.0916 - val_acc: 0.9750\n",
      "Epoch 239/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0902 - acc: 0.9772 - val_loss: 0.0920 - val_acc: 0.9760\n",
      "Epoch 240/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0890 - acc: 0.9787 - val_loss: 0.0878 - val_acc: 0.9801\n",
      "Epoch 241/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0884 - acc: 0.9783 - val_loss: 0.0895 - val_acc: 0.9756\n",
      "Epoch 242/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0891 - acc: 0.9766 - val_loss: 0.0873 - val_acc: 0.9788\n",
      "Epoch 243/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0886 - acc: 0.9776 - val_loss: 0.0894 - val_acc: 0.9796\n",
      "Epoch 244/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0879 - acc: 0.9777 - val_loss: 0.0858 - val_acc: 0.9811\n",
      "Epoch 245/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0872 - acc: 0.9783 - val_loss: 0.0862 - val_acc: 0.9775\n",
      "Epoch 246/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0856 - acc: 0.9795 - val_loss: 0.0882 - val_acc: 0.9747\n",
      "Epoch 247/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0866 - acc: 0.9781 - val_loss: 0.0863 - val_acc: 0.9799\n",
      "Epoch 248/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0863 - acc: 0.9782 - val_loss: 0.0864 - val_acc: 0.9805\n",
      "Epoch 249/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0854 - acc: 0.9785 - val_loss: 0.0842 - val_acc: 0.9773\n",
      "Epoch 250/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0852 - acc: 0.9786 - val_loss: 0.0845 - val_acc: 0.9801\n",
      "Epoch 251/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0840 - acc: 0.9793 - val_loss: 0.0823 - val_acc: 0.9802\n",
      "Epoch 252/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0838 - acc: 0.9789 - val_loss: 0.0825 - val_acc: 0.9815\n",
      "Epoch 253/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0834 - acc: 0.9786 - val_loss: 0.0824 - val_acc: 0.9813\n",
      "Epoch 254/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0822 - acc: 0.9795 - val_loss: 0.0828 - val_acc: 0.9776\n",
      "Epoch 255/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0821 - acc: 0.9797 - val_loss: 0.0803 - val_acc: 0.9816\n",
      "Epoch 256/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0813 - acc: 0.9803 - val_loss: 0.0799 - val_acc: 0.9810\n",
      "Epoch 257/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0810 - acc: 0.9802 - val_loss: 0.0788 - val_acc: 0.9817\n",
      "Epoch 258/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0799 - acc: 0.9805 - val_loss: 0.0800 - val_acc: 0.9810\n",
      "Epoch 259/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0799 - acc: 0.9797 - val_loss: 0.0797 - val_acc: 0.9793\n",
      "Epoch 260/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.0791 - acc: 0.9809 - val_loss: 0.0790 - val_acc: 0.9806\n",
      "Epoch 261/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0792 - acc: 0.9802 - val_loss: 0.0794 - val_acc: 0.9800\n",
      "Epoch 262/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0793 - acc: 0.9800 - val_loss: 0.0777 - val_acc: 0.9822\n",
      "Epoch 263/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0791 - acc: 0.9807 - val_loss: 0.0769 - val_acc: 0.9821\n",
      "Epoch 264/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0774 - acc: 0.9810 - val_loss: 0.0789 - val_acc: 0.9775\n",
      "Epoch 265/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0773 - acc: 0.9802 - val_loss: 0.0774 - val_acc: 0.9808\n",
      "Epoch 266/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0764 - acc: 0.9811 - val_loss: 0.0758 - val_acc: 0.9809\n",
      "Epoch 267/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0765 - acc: 0.9808 - val_loss: 0.0777 - val_acc: 0.9779\n",
      "Epoch 268/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0768 - acc: 0.9795 - val_loss: 0.0742 - val_acc: 0.9822\n",
      "Epoch 269/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0750 - acc: 0.9819 - val_loss: 0.0767 - val_acc: 0.9784\n",
      "Epoch 270/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0751 - acc: 0.9816 - val_loss: 0.0756 - val_acc: 0.9802\n",
      "Epoch 271/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0747 - acc: 0.9816 - val_loss: 0.0743 - val_acc: 0.9825\n",
      "Epoch 272/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0752 - acc: 0.9808 - val_loss: 0.0744 - val_acc: 0.9829\n",
      "Epoch 273/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0740 - acc: 0.9821 - val_loss: 0.0733 - val_acc: 0.9819\n",
      "Epoch 274/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0741 - acc: 0.9811 - val_loss: 0.0739 - val_acc: 0.9797\n",
      "Epoch 275/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0736 - acc: 0.9819 - val_loss: 0.0716 - val_acc: 0.9832\n",
      "Epoch 276/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0724 - acc: 0.9821 - val_loss: 0.0717 - val_acc: 0.9838\n",
      "Epoch 277/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0721 - acc: 0.9823 - val_loss: 0.0713 - val_acc: 0.9835\n",
      "Epoch 278/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0715 - acc: 0.9827 - val_loss: 0.0726 - val_acc: 0.9826\n",
      "Epoch 279/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0711 - acc: 0.9824 - val_loss: 0.0719 - val_acc: 0.9822\n",
      "Epoch 280/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0725 - acc: 0.9817 - val_loss: 0.0704 - val_acc: 0.9828\n",
      "Epoch 281/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0712 - acc: 0.9814 - val_loss: 0.0702 - val_acc: 0.9826\n",
      "Epoch 282/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0707 - acc: 0.9805 - val_loss: 0.0681 - val_acc: 0.9840\n",
      "Epoch 283/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0699 - acc: 0.9824 - val_loss: 0.0738 - val_acc: 0.9754\n",
      "Epoch 284/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0696 - acc: 0.9821 - val_loss: 0.0703 - val_acc: 0.9824\n",
      "Epoch 285/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.0686 - acc: 0.9827 - val_loss: 0.0680 - val_acc: 0.9823\n",
      "Epoch 286/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0684 - acc: 0.9824 - val_loss: 0.0670 - val_acc: 0.9838\n",
      "Epoch 287/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0680 - acc: 0.9826 - val_loss: 0.0680 - val_acc: 0.9803\n",
      "Epoch 288/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0679 - acc: 0.9834 - val_loss: 0.0692 - val_acc: 0.9812\n",
      "Epoch 289/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0689 - acc: 0.9818 - val_loss: 0.0661 - val_acc: 0.9848\n",
      "Epoch 290/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0671 - acc: 0.9835 - val_loss: 0.0658 - val_acc: 0.9843\n",
      "Epoch 291/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0677 - acc: 0.9816 - val_loss: 0.0664 - val_acc: 0.9836\n",
      "Epoch 292/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0665 - acc: 0.9827 - val_loss: 0.0666 - val_acc: 0.9845\n",
      "Epoch 293/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0652 - acc: 0.9846 - val_loss: 0.0644 - val_acc: 0.9845\n",
      "Epoch 294/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0652 - acc: 0.9825 - val_loss: 0.0641 - val_acc: 0.9847\n",
      "Epoch 295/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0649 - acc: 0.9843 - val_loss: 0.0656 - val_acc: 0.9844\n",
      "Epoch 296/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0647 - acc: 0.9840 - val_loss: 0.0639 - val_acc: 0.9843\n",
      "Epoch 297/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0640 - acc: 0.9841 - val_loss: 0.0630 - val_acc: 0.9846\n",
      "Epoch 298/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0634 - acc: 0.9847 - val_loss: 0.0626 - val_acc: 0.9849\n",
      "Epoch 299/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0636 - acc: 0.9841 - val_loss: 0.0622 - val_acc: 0.9848\n",
      "Epoch 300/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0633 - acc: 0.9839 - val_loss: 0.0634 - val_acc: 0.9843\n",
      "7144/7144 [==============================] - 0s 55us/step\n",
      "28573/28573 [==============================] - 2s 54us/step\n",
      "Train on 28573 samples, validate on 28573 samples\n",
      "Epoch 1/300\n",
      "28573/28573 [==============================] - 3s 114us/step - loss: 3.2625 - acc: 0.0809 - val_loss: 3.0967 - val_acc: 0.0874\n",
      "Epoch 2/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 2.8954 - acc: 0.1180 - val_loss: 2.6918 - val_acc: 0.1766\n",
      "Epoch 3/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 2.5278 - acc: 0.2275 - val_loss: 2.3623 - val_acc: 0.2840\n",
      "Epoch 4/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 2.2253 - acc: 0.3009 - val_loss: 2.0914 - val_acc: 0.3469\n",
      "Epoch 5/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.9897 - acc: 0.3736 - val_loss: 1.8909 - val_acc: 0.4138\n",
      "Epoch 6/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.8140 - acc: 0.4253 - val_loss: 1.7385 - val_acc: 0.4227\n",
      "Epoch 7/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.6762 - acc: 0.4774 - val_loss: 1.6134 - val_acc: 0.5081\n",
      "Epoch 8/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.5603 - acc: 0.5468 - val_loss: 1.5045 - val_acc: 0.5920\n",
      "Epoch 9/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.4588 - acc: 0.5777 - val_loss: 1.4107 - val_acc: 0.6291\n",
      "Epoch 10/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 1.3700 - acc: 0.6035 - val_loss: 1.3277 - val_acc: 0.6330\n",
      "Epoch 11/300\n",
      "28573/28573 [==============================] - 0s 17us/step - loss: 1.2919 - acc: 0.6271 - val_loss: 1.2531 - val_acc: 0.6489\n",
      "Epoch 12/300\n",
      "28573/28573 [==============================] - 0s 17us/step - loss: 1.2204 - acc: 0.6580 - val_loss: 1.1869 - val_acc: 0.6638\n",
      "Epoch 13/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 1.1582 - acc: 0.6806 - val_loss: 1.1277 - val_acc: 0.7117\n",
      "Epoch 14/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.1005 - acc: 0.6966 - val_loss: 1.0682 - val_acc: 0.7314\n",
      "Epoch 15/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.0460 - acc: 0.7303 - val_loss: 1.0193 - val_acc: 0.7086\n",
      "Epoch 16/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.9971 - acc: 0.7368 - val_loss: 0.9721 - val_acc: 0.7491\n",
      "Epoch 17/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.9521 - acc: 0.7560 - val_loss: 0.9370 - val_acc: 0.7527\n",
      "Epoch 18/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.9138 - acc: 0.7540 - val_loss: 0.8909 - val_acc: 0.7371\n",
      "Epoch 19/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.8745 - acc: 0.7603 - val_loss: 0.8571 - val_acc: 0.7690\n",
      "Epoch 20/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.8392 - acc: 0.7750 - val_loss: 0.8224 - val_acc: 0.7814\n",
      "Epoch 21/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.8075 - acc: 0.7714 - val_loss: 0.7921 - val_acc: 0.7706\n",
      "Epoch 22/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.7786 - acc: 0.7816 - val_loss: 0.7638 - val_acc: 0.7861\n",
      "Epoch 23/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.7515 - acc: 0.7906 - val_loss: 0.7364 - val_acc: 0.7969\n",
      "Epoch 24/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.7267 - acc: 0.7911 - val_loss: 0.7157 - val_acc: 0.7794\n",
      "Epoch 25/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.7043 - acc: 0.7947 - val_loss: 0.6972 - val_acc: 0.7905\n",
      "Epoch 26/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.6828 - acc: 0.7977 - val_loss: 0.6715 - val_acc: 0.8072\n",
      "Epoch 27/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.6624 - acc: 0.8003 - val_loss: 0.6586 - val_acc: 0.8007\n",
      "Epoch 28/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.6467 - acc: 0.8010 - val_loss: 0.6355 - val_acc: 0.8132\n",
      "Epoch 29/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.6279 - acc: 0.8073 - val_loss: 0.6193 - val_acc: 0.8240\n",
      "Epoch 30/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.6139 - acc: 0.8121 - val_loss: 0.6055 - val_acc: 0.8127\n",
      "Epoch 31/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.5983 - acc: 0.8135 - val_loss: 0.5908 - val_acc: 0.8244\n",
      "Epoch 32/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.5847 - acc: 0.8212 - val_loss: 0.5764 - val_acc: 0.8055\n",
      "Epoch 33/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.5712 - acc: 0.8250 - val_loss: 0.5628 - val_acc: 0.8409\n",
      "Epoch 34/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.5591 - acc: 0.8242 - val_loss: 0.5546 - val_acc: 0.8187\n",
      "Epoch 35/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.5472 - acc: 0.8268 - val_loss: 0.5429 - val_acc: 0.8370\n",
      "Epoch 36/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.5362 - acc: 0.8310 - val_loss: 0.5322 - val_acc: 0.8035\n",
      "Epoch 37/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.5252 - acc: 0.8340 - val_loss: 0.5245 - val_acc: 0.8429\n",
      "Epoch 38/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.5161 - acc: 0.8428 - val_loss: 0.5153 - val_acc: 0.8437\n",
      "Epoch 39/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.5070 - acc: 0.8401 - val_loss: 0.5039 - val_acc: 0.8420\n",
      "Epoch 40/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4984 - acc: 0.8412 - val_loss: 0.4917 - val_acc: 0.8443\n",
      "Epoch 41/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4890 - acc: 0.8457 - val_loss: 0.4830 - val_acc: 0.8429\n",
      "Epoch 42/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4803 - acc: 0.8438 - val_loss: 0.4760 - val_acc: 0.8419\n",
      "Epoch 43/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4724 - acc: 0.8469 - val_loss: 0.4687 - val_acc: 0.8399\n",
      "Epoch 44/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4654 - acc: 0.8509 - val_loss: 0.4600 - val_acc: 0.8615\n",
      "Epoch 45/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.4580 - acc: 0.8522 - val_loss: 0.4499 - val_acc: 0.8659\n",
      "Epoch 46/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4500 - acc: 0.8566 - val_loss: 0.4441 - val_acc: 0.8677\n",
      "Epoch 47/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.4416 - acc: 0.8636 - val_loss: 0.4410 - val_acc: 0.8618\n",
      "Epoch 48/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4359 - acc: 0.8632 - val_loss: 0.4304 - val_acc: 0.8717\n",
      "Epoch 49/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.4278 - acc: 0.8648 - val_loss: 0.4225 - val_acc: 0.8753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4233 - acc: 0.8654 - val_loss: 0.4182 - val_acc: 0.8701\n",
      "Epoch 51/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4160 - acc: 0.8683 - val_loss: 0.4131 - val_acc: 0.8726\n",
      "Epoch 52/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4092 - acc: 0.8701 - val_loss: 0.4046 - val_acc: 0.8787\n",
      "Epoch 53/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4029 - acc: 0.8755 - val_loss: 0.4028 - val_acc: 0.8785\n",
      "Epoch 54/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3971 - acc: 0.8778 - val_loss: 0.3950 - val_acc: 0.8884\n",
      "Epoch 55/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3908 - acc: 0.8804 - val_loss: 0.3880 - val_acc: 0.8737\n",
      "Epoch 56/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3869 - acc: 0.8746 - val_loss: 0.3834 - val_acc: 0.8791\n",
      "Epoch 57/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3827 - acc: 0.8799 - val_loss: 0.3772 - val_acc: 0.8800\n",
      "Epoch 58/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3767 - acc: 0.8814 - val_loss: 0.3731 - val_acc: 0.8832\n",
      "Epoch 59/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3722 - acc: 0.8833 - val_loss: 0.3718 - val_acc: 0.8799\n",
      "Epoch 60/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3678 - acc: 0.8845 - val_loss: 0.3654 - val_acc: 0.8880\n",
      "Epoch 61/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3612 - acc: 0.8855 - val_loss: 0.3599 - val_acc: 0.8770\n",
      "Epoch 62/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3578 - acc: 0.8876 - val_loss: 0.3533 - val_acc: 0.8905\n",
      "Epoch 63/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3531 - acc: 0.8903 - val_loss: 0.3501 - val_acc: 0.8940\n",
      "Epoch 64/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3485 - acc: 0.8909 - val_loss: 0.3442 - val_acc: 0.8954\n",
      "Epoch 65/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3430 - acc: 0.8935 - val_loss: 0.3385 - val_acc: 0.9006\n",
      "Epoch 66/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3398 - acc: 0.8937 - val_loss: 0.3361 - val_acc: 0.9030\n",
      "Epoch 67/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3341 - acc: 0.8989 - val_loss: 0.3308 - val_acc: 0.9027\n",
      "Epoch 68/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3301 - acc: 0.8972 - val_loss: 0.3273 - val_acc: 0.8908\n",
      "Epoch 69/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.3261 - acc: 0.8984 - val_loss: 0.3240 - val_acc: 0.9084\n",
      "Epoch 70/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3246 - acc: 0.8973 - val_loss: 0.3204 - val_acc: 0.9064\n",
      "Epoch 71/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3184 - acc: 0.9034 - val_loss: 0.3156 - val_acc: 0.9055\n",
      "Epoch 72/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.3149 - acc: 0.9005 - val_loss: 0.3149 - val_acc: 0.8925\n",
      "Epoch 73/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.3117 - acc: 0.9041 - val_loss: 0.3099 - val_acc: 0.9074\n",
      "Epoch 74/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.3066 - acc: 0.9053 - val_loss: 0.3044 - val_acc: 0.9117\n",
      "Epoch 75/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.3037 - acc: 0.9066 - val_loss: 0.3009 - val_acc: 0.9045\n",
      "Epoch 76/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3019 - acc: 0.9044 - val_loss: 0.2965 - val_acc: 0.9070\n",
      "Epoch 77/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2967 - acc: 0.9082 - val_loss: 0.2943 - val_acc: 0.9081\n",
      "Epoch 78/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2939 - acc: 0.9074 - val_loss: 0.2896 - val_acc: 0.9182\n",
      "Epoch 79/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2902 - acc: 0.9117 - val_loss: 0.2870 - val_acc: 0.9173\n",
      "Epoch 80/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.2871 - acc: 0.9110 - val_loss: 0.2855 - val_acc: 0.9067\n",
      "Epoch 81/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2830 - acc: 0.9131 - val_loss: 0.2804 - val_acc: 0.9119\n",
      "Epoch 82/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.2802 - acc: 0.9140 - val_loss: 0.2786 - val_acc: 0.9139\n",
      "Epoch 83/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2764 - acc: 0.9166 - val_loss: 0.2742 - val_acc: 0.9234\n",
      "Epoch 84/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2754 - acc: 0.9143 - val_loss: 0.2716 - val_acc: 0.9136\n",
      "Epoch 85/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2720 - acc: 0.9153 - val_loss: 0.2735 - val_acc: 0.9224\n",
      "Epoch 86/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2689 - acc: 0.9160 - val_loss: 0.2672 - val_acc: 0.9147\n",
      "Epoch 87/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.2651 - acc: 0.9196 - val_loss: 0.2644 - val_acc: 0.9262\n",
      "Epoch 88/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2621 - acc: 0.9217 - val_loss: 0.2603 - val_acc: 0.9160\n",
      "Epoch 89/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.2589 - acc: 0.9222 - val_loss: 0.2594 - val_acc: 0.9168\n",
      "Epoch 90/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2566 - acc: 0.9198 - val_loss: 0.2600 - val_acc: 0.9028\n",
      "Epoch 91/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2527 - acc: 0.9244 - val_loss: 0.2504 - val_acc: 0.9202\n",
      "Epoch 92/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2507 - acc: 0.9251 - val_loss: 0.2487 - val_acc: 0.9321\n",
      "Epoch 93/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2481 - acc: 0.9262 - val_loss: 0.2453 - val_acc: 0.9325\n",
      "Epoch 94/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2460 - acc: 0.9242 - val_loss: 0.2447 - val_acc: 0.9192\n",
      "Epoch 95/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.2432 - acc: 0.9290 - val_loss: 0.2418 - val_acc: 0.9236\n",
      "Epoch 96/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2412 - acc: 0.9259 - val_loss: 0.2384 - val_acc: 0.9259\n",
      "Epoch 97/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2384 - acc: 0.9289 - val_loss: 0.2354 - val_acc: 0.9333\n",
      "Epoch 98/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2348 - acc: 0.9319 - val_loss: 0.2346 - val_acc: 0.9289\n",
      "Epoch 99/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2340 - acc: 0.9297 - val_loss: 0.2300 - val_acc: 0.9258\n",
      "Epoch 100/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2300 - acc: 0.9315 - val_loss: 0.2269 - val_acc: 0.9364\n",
      "Epoch 101/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2268 - acc: 0.9345 - val_loss: 0.2251 - val_acc: 0.9343\n",
      "Epoch 102/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2254 - acc: 0.9355 - val_loss: 0.2227 - val_acc: 0.9375\n",
      "Epoch 103/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2246 - acc: 0.9315 - val_loss: 0.2197 - val_acc: 0.9413\n",
      "Epoch 104/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2204 - acc: 0.9365 - val_loss: 0.2178 - val_acc: 0.9335\n",
      "Epoch 105/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2183 - acc: 0.9358 - val_loss: 0.2167 - val_acc: 0.9420\n",
      "Epoch 106/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2171 - acc: 0.9375 - val_loss: 0.2132 - val_acc: 0.9454\n",
      "Epoch 107/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2135 - acc: 0.9410 - val_loss: 0.2137 - val_acc: 0.9428\n",
      "Epoch 108/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2118 - acc: 0.9388 - val_loss: 0.2096 - val_acc: 0.9429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2100 - acc: 0.9378 - val_loss: 0.2103 - val_acc: 0.9416\n",
      "Epoch 110/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2073 - acc: 0.9414 - val_loss: 0.2055 - val_acc: 0.9417\n",
      "Epoch 111/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2061 - acc: 0.9405 - val_loss: 0.2022 - val_acc: 0.9404\n",
      "Epoch 112/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2020 - acc: 0.9443 - val_loss: 0.1990 - val_acc: 0.9469\n",
      "Epoch 113/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1998 - acc: 0.9459 - val_loss: 0.1998 - val_acc: 0.9444\n",
      "Epoch 114/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1988 - acc: 0.9458 - val_loss: 0.1977 - val_acc: 0.9451\n",
      "Epoch 115/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1963 - acc: 0.9475 - val_loss: 0.1972 - val_acc: 0.9518\n",
      "Epoch 116/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1948 - acc: 0.9473 - val_loss: 0.1933 - val_acc: 0.9559\n",
      "Epoch 117/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1928 - acc: 0.9480 - val_loss: 0.1930 - val_acc: 0.9424\n",
      "Epoch 118/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1901 - acc: 0.9494 - val_loss: 0.1881 - val_acc: 0.9463\n",
      "Epoch 119/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1897 - acc: 0.9474 - val_loss: 0.1864 - val_acc: 0.9551\n",
      "Epoch 120/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1868 - acc: 0.9493 - val_loss: 0.1861 - val_acc: 0.9387\n",
      "Epoch 121/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1832 - acc: 0.9522 - val_loss: 0.1857 - val_acc: 0.9469\n",
      "Epoch 122/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1831 - acc: 0.9516 - val_loss: 0.1820 - val_acc: 0.9546\n",
      "Epoch 123/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1807 - acc: 0.9535 - val_loss: 0.1841 - val_acc: 0.9431\n",
      "Epoch 124/300\n",
      "28573/28573 [==============================] - 0s 17us/step - loss: 0.1782 - acc: 0.9546 - val_loss: 0.1763 - val_acc: 0.9554\n",
      "Epoch 125/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1768 - acc: 0.9571 - val_loss: 0.1752 - val_acc: 0.9535\n",
      "Epoch 126/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1737 - acc: 0.9580 - val_loss: 0.1766 - val_acc: 0.9566\n",
      "Epoch 127/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1722 - acc: 0.9580 - val_loss: 0.1739 - val_acc: 0.9536\n",
      "Epoch 128/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1727 - acc: 0.9566 - val_loss: 0.1689 - val_acc: 0.9584\n",
      "Epoch 129/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1695 - acc: 0.9597 - val_loss: 0.1669 - val_acc: 0.9563\n",
      "Epoch 130/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1677 - acc: 0.9590 - val_loss: 0.1656 - val_acc: 0.9602\n",
      "Epoch 131/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1667 - acc: 0.9597 - val_loss: 0.1639 - val_acc: 0.9557\n",
      "Epoch 132/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1636 - acc: 0.9612 - val_loss: 0.1651 - val_acc: 0.9591\n",
      "Epoch 133/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1625 - acc: 0.9621 - val_loss: 0.1610 - val_acc: 0.9588\n",
      "Epoch 134/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1611 - acc: 0.9623 - val_loss: 0.1617 - val_acc: 0.9599\n",
      "Epoch 135/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1595 - acc: 0.9616 - val_loss: 0.1568 - val_acc: 0.9651\n",
      "Epoch 136/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1577 - acc: 0.9629 - val_loss: 0.1555 - val_acc: 0.9605\n",
      "Epoch 137/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1553 - acc: 0.9641 - val_loss: 0.1553 - val_acc: 0.9567\n",
      "Epoch 138/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1534 - acc: 0.9641 - val_loss: 0.1535 - val_acc: 0.9614\n",
      "Epoch 139/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1527 - acc: 0.9646 - val_loss: 0.1507 - val_acc: 0.9626\n",
      "Epoch 140/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1509 - acc: 0.9641 - val_loss: 0.1504 - val_acc: 0.9643\n",
      "Epoch 141/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1494 - acc: 0.9659 - val_loss: 0.1481 - val_acc: 0.9673\n",
      "Epoch 142/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1490 - acc: 0.9636 - val_loss: 0.1491 - val_acc: 0.9575\n",
      "Epoch 143/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1476 - acc: 0.9649 - val_loss: 0.1461 - val_acc: 0.9651\n",
      "Epoch 144/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1450 - acc: 0.9670 - val_loss: 0.1474 - val_acc: 0.9578\n",
      "Epoch 145/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1449 - acc: 0.9648 - val_loss: 0.1413 - val_acc: 0.9703\n",
      "Epoch 146/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1421 - acc: 0.9661 - val_loss: 0.1421 - val_acc: 0.9698\n",
      "Epoch 147/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1403 - acc: 0.9679 - val_loss: 0.1385 - val_acc: 0.9684\n",
      "Epoch 148/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1387 - acc: 0.9674 - val_loss: 0.1392 - val_acc: 0.9692\n",
      "Epoch 149/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1375 - acc: 0.9682 - val_loss: 0.1380 - val_acc: 0.9700\n",
      "Epoch 150/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1368 - acc: 0.9672 - val_loss: 0.1379 - val_acc: 0.9632\n",
      "Epoch 151/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1362 - acc: 0.9670 - val_loss: 0.1325 - val_acc: 0.9708\n",
      "Epoch 152/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.1329 - acc: 0.9696 - val_loss: 0.1314 - val_acc: 0.9696\n",
      "Epoch 153/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.1318 - acc: 0.9690 - val_loss: 0.1322 - val_acc: 0.9695\n",
      "Epoch 154/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1312 - acc: 0.9689 - val_loss: 0.1300 - val_acc: 0.9709\n",
      "Epoch 155/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1298 - acc: 0.9699 - val_loss: 0.1275 - val_acc: 0.9703\n",
      "Epoch 156/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1284 - acc: 0.9693 - val_loss: 0.1283 - val_acc: 0.9664\n",
      "Epoch 157/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1272 - acc: 0.9700 - val_loss: 0.1278 - val_acc: 0.9665\n",
      "Epoch 158/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1267 - acc: 0.9697 - val_loss: 0.1258 - val_acc: 0.9716\n",
      "Epoch 159/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1263 - acc: 0.9692 - val_loss: 0.1266 - val_acc: 0.9675\n",
      "Epoch 160/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.1239 - acc: 0.9696 - val_loss: 0.1221 - val_acc: 0.9710\n",
      "Epoch 161/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1244 - acc: 0.9674 - val_loss: 0.1260 - val_acc: 0.9707\n",
      "Epoch 162/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1227 - acc: 0.9691 - val_loss: 0.1210 - val_acc: 0.9726\n",
      "Epoch 163/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1206 - acc: 0.9712 - val_loss: 0.1197 - val_acc: 0.9699\n",
      "Epoch 164/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1198 - acc: 0.9707 - val_loss: 0.1180 - val_acc: 0.9687\n",
      "Epoch 165/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1175 - acc: 0.9719 - val_loss: 0.1174 - val_acc: 0.9727\n",
      "Epoch 166/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1166 - acc: 0.9709 - val_loss: 0.1157 - val_acc: 0.9706\n",
      "Epoch 167/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1165 - acc: 0.9705 - val_loss: 0.1160 - val_acc: 0.9698\n",
      "Epoch 168/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1152 - acc: 0.9704 - val_loss: 0.1154 - val_acc: 0.9692\n",
      "Epoch 169/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.1146 - acc: 0.9706 - val_loss: 0.1127 - val_acc: 0.9721\n",
      "Epoch 170/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1143 - acc: 0.9704 - val_loss: 0.1110 - val_acc: 0.9728\n",
      "Epoch 171/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1127 - acc: 0.9706 - val_loss: 0.1120 - val_acc: 0.9715\n",
      "Epoch 172/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.1110 - acc: 0.9720 - val_loss: 0.1113 - val_acc: 0.9733\n",
      "Epoch 173/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1103 - acc: 0.9722 - val_loss: 0.1095 - val_acc: 0.9724\n",
      "Epoch 174/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1095 - acc: 0.9718 - val_loss: 0.1077 - val_acc: 0.9727\n",
      "Epoch 175/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1078 - acc: 0.9728 - val_loss: 0.1066 - val_acc: 0.9725\n",
      "Epoch 176/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1078 - acc: 0.9718 - val_loss: 0.1084 - val_acc: 0.9701\n",
      "Epoch 177/300\n",
      "28573/28573 [==============================] - 8s 289us/step - loss: 0.1059 - acc: 0.9720 - val_loss: 0.1044 - val_acc: 0.9727\n",
      "Epoch 178/300\n",
      "28573/28573 [==============================] - 0s 17us/step - loss: 0.1055 - acc: 0.9722 - val_loss: 0.1054 - val_acc: 0.9746\n",
      "Epoch 179/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.1050 - acc: 0.9722 - val_loss: 0.1043 - val_acc: 0.9742\n",
      "Epoch 180/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.1036 - acc: 0.9719 - val_loss: 0.1068 - val_acc: 0.9730\n",
      "Epoch 181/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.1029 - acc: 0.9724 - val_loss: 0.1038 - val_acc: 0.9742\n",
      "Epoch 182/300\n",
      "28573/28573 [==============================] - 1s 44us/step - loss: 0.1027 - acc: 0.9716 - val_loss: 0.1015 - val_acc: 0.9751\n",
      "Epoch 183/300\n",
      "28573/28573 [==============================] - 1s 41us/step - loss: 0.1015 - acc: 0.9731 - val_loss: 0.1016 - val_acc: 0.9738\n",
      "Epoch 184/300\n",
      "28573/28573 [==============================] - 1s 37us/step - loss: 0.1002 - acc: 0.9732 - val_loss: 0.0995 - val_acc: 0.9728\n",
      "Epoch 185/300\n",
      "28573/28573 [==============================] - 1s 31us/step - loss: 0.1000 - acc: 0.9725 - val_loss: 0.0984 - val_acc: 0.9724\n",
      "Epoch 186/300\n",
      "28573/28573 [==============================] - 1s 28us/step - loss: 0.0994 - acc: 0.9731 - val_loss: 0.1009 - val_acc: 0.9754\n",
      "Epoch 187/300\n",
      "28573/28573 [==============================] - 1s 25us/step - loss: 0.0983 - acc: 0.9726 - val_loss: 0.0974 - val_acc: 0.9757\n",
      "Epoch 188/300\n",
      "28573/28573 [==============================] - 1s 24us/step - loss: 0.0976 - acc: 0.9734 - val_loss: 0.0958 - val_acc: 0.9755\n",
      "Epoch 189/300\n",
      "28573/28573 [==============================] - 1s 23us/step - loss: 0.0958 - acc: 0.9733 - val_loss: 0.0954 - val_acc: 0.9726\n",
      "Epoch 190/300\n",
      "28573/28573 [==============================] - 1s 21us/step - loss: 0.0956 - acc: 0.9734 - val_loss: 0.0940 - val_acc: 0.9744\n",
      "Epoch 191/300\n",
      "28573/28573 [==============================] - 1s 29us/step - loss: 0.0959 - acc: 0.9733 - val_loss: 0.0940 - val_acc: 0.9742\n",
      "Epoch 192/300\n",
      "28573/28573 [==============================] - 1s 21us/step - loss: 0.0938 - acc: 0.9736 - val_loss: 0.0939 - val_acc: 0.9730\n",
      "Epoch 193/300\n",
      "28573/28573 [==============================] - 1s 18us/step - loss: 0.0940 - acc: 0.9740 - val_loss: 0.0916 - val_acc: 0.9744\n",
      "Epoch 194/300\n",
      "28573/28573 [==============================] - 1s 19us/step - loss: 0.0925 - acc: 0.9745 - val_loss: 0.0920 - val_acc: 0.9745\n",
      "Epoch 195/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.0921 - acc: 0.9733 - val_loss: 0.0924 - val_acc: 0.9740\n",
      "Epoch 196/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.0910 - acc: 0.9748 - val_loss: 0.0902 - val_acc: 0.9743\n",
      "Epoch 197/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0906 - acc: 0.9742 - val_loss: 0.0897 - val_acc: 0.9739\n",
      "Epoch 198/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0893 - acc: 0.9746 - val_loss: 0.0902 - val_acc: 0.9768\n",
      "Epoch 199/300\n",
      "28573/28573 [==============================] - 0s 17us/step - loss: 0.0892 - acc: 0.9740 - val_loss: 0.0913 - val_acc: 0.9713\n",
      "Epoch 200/300\n",
      "28573/28573 [==============================] - 1s 19us/step - loss: 0.0891 - acc: 0.9745 - val_loss: 0.0865 - val_acc: 0.9766\n",
      "Epoch 201/300\n",
      "28573/28573 [==============================] - 0s 17us/step - loss: 0.0878 - acc: 0.9746 - val_loss: 0.0872 - val_acc: 0.9765\n",
      "Epoch 202/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0882 - acc: 0.9734 - val_loss: 0.0864 - val_acc: 0.9737\n",
      "Epoch 203/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0860 - acc: 0.9752 - val_loss: 0.0859 - val_acc: 0.9770\n",
      "Epoch 204/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0855 - acc: 0.9757 - val_loss: 0.0851 - val_acc: 0.9760\n",
      "Epoch 205/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0851 - acc: 0.9754 - val_loss: 0.0843 - val_acc: 0.9764\n",
      "Epoch 206/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0852 - acc: 0.9747 - val_loss: 0.0859 - val_acc: 0.9737\n",
      "Epoch 207/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0838 - acc: 0.9755 - val_loss: 0.0837 - val_acc: 0.9731\n",
      "Epoch 208/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0830 - acc: 0.9761 - val_loss: 0.0815 - val_acc: 0.9769\n",
      "Epoch 209/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0822 - acc: 0.9754 - val_loss: 0.0809 - val_acc: 0.9763\n",
      "Epoch 210/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0815 - acc: 0.9760 - val_loss: 0.0817 - val_acc: 0.9764\n",
      "Epoch 211/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0815 - acc: 0.9754 - val_loss: 0.0809 - val_acc: 0.9766\n",
      "Epoch 212/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0807 - acc: 0.9758 - val_loss: 0.0801 - val_acc: 0.9766\n",
      "Epoch 213/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0797 - acc: 0.9763 - val_loss: 0.0788 - val_acc: 0.9759\n",
      "Epoch 214/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0797 - acc: 0.9761 - val_loss: 0.0781 - val_acc: 0.9770\n",
      "Epoch 215/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0794 - acc: 0.9760 - val_loss: 0.0785 - val_acc: 0.9768\n",
      "Epoch 216/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0784 - acc: 0.9770 - val_loss: 0.0771 - val_acc: 0.9774\n",
      "Epoch 217/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0781 - acc: 0.9768 - val_loss: 0.0784 - val_acc: 0.9768\n",
      "Epoch 218/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0767 - acc: 0.9764 - val_loss: 0.0789 - val_acc: 0.9724\n",
      "Epoch 219/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0769 - acc: 0.9766 - val_loss: 0.0758 - val_acc: 0.9780\n",
      "Epoch 220/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0759 - acc: 0.9774 - val_loss: 0.0753 - val_acc: 0.9774\n",
      "Epoch 221/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0758 - acc: 0.9769 - val_loss: 0.0753 - val_acc: 0.9752\n",
      "Epoch 222/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0757 - acc: 0.9764 - val_loss: 0.0755 - val_acc: 0.9766\n",
      "Epoch 223/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0744 - acc: 0.9791 - val_loss: 0.0747 - val_acc: 0.9768\n",
      "Epoch 224/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0749 - acc: 0.9770 - val_loss: 0.0733 - val_acc: 0.9776\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0732 - acc: 0.9774 - val_loss: 0.0739 - val_acc: 0.9767\n",
      "Epoch 226/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0732 - acc: 0.9778 - val_loss: 0.0726 - val_acc: 0.9767\n",
      "Epoch 227/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0725 - acc: 0.9784 - val_loss: 0.0743 - val_acc: 0.9749\n",
      "Epoch 228/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0720 - acc: 0.9779 - val_loss: 0.0708 - val_acc: 0.9789\n",
      "Epoch 229/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0712 - acc: 0.9786 - val_loss: 0.0706 - val_acc: 0.9789\n",
      "Epoch 230/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0717 - acc: 0.9773 - val_loss: 0.0706 - val_acc: 0.9782\n",
      "Epoch 231/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0712 - acc: 0.9777 - val_loss: 0.0691 - val_acc: 0.9790\n",
      "Epoch 232/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0698 - acc: 0.9786 - val_loss: 0.0739 - val_acc: 0.9724\n",
      "Epoch 233/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0699 - acc: 0.9786 - val_loss: 0.0715 - val_acc: 0.9753\n",
      "Epoch 234/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0704 - acc: 0.9782 - val_loss: 0.0689 - val_acc: 0.9789\n",
      "Epoch 235/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0687 - acc: 0.9781 - val_loss: 0.0675 - val_acc: 0.9791\n",
      "Epoch 236/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0688 - acc: 0.9783 - val_loss: 0.0684 - val_acc: 0.9796\n",
      "Epoch 237/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0688 - acc: 0.9781 - val_loss: 0.0674 - val_acc: 0.9799\n",
      "Epoch 238/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0681 - acc: 0.9790 - val_loss: 0.0679 - val_acc: 0.9769\n",
      "Epoch 239/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0683 - acc: 0.9778 - val_loss: 0.0661 - val_acc: 0.9801\n",
      "Epoch 240/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0674 - acc: 0.9785 - val_loss: 0.0677 - val_acc: 0.9799\n",
      "Epoch 241/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0662 - acc: 0.9790 - val_loss: 0.0673 - val_acc: 0.9801\n",
      "Epoch 242/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0658 - acc: 0.9790 - val_loss: 0.0686 - val_acc: 0.9745\n",
      "Epoch 243/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0653 - acc: 0.9793 - val_loss: 0.0649 - val_acc: 0.9802\n",
      "Epoch 244/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0648 - acc: 0.9797 - val_loss: 0.0655 - val_acc: 0.9774\n",
      "Epoch 245/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0646 - acc: 0.9786 - val_loss: 0.0643 - val_acc: 0.9806\n",
      "Epoch 246/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0639 - acc: 0.9804 - val_loss: 0.0628 - val_acc: 0.9808\n",
      "Epoch 247/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0637 - acc: 0.9799 - val_loss: 0.0629 - val_acc: 0.9804\n",
      "Epoch 248/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0631 - acc: 0.9801 - val_loss: 0.0622 - val_acc: 0.9808\n",
      "Epoch 249/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0628 - acc: 0.9804 - val_loss: 0.0632 - val_acc: 0.9799\n",
      "Epoch 250/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0628 - acc: 0.9798 - val_loss: 0.0625 - val_acc: 0.9808\n",
      "Epoch 251/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0626 - acc: 0.9798 - val_loss: 0.0617 - val_acc: 0.9803\n",
      "Epoch 252/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0627 - acc: 0.9792 - val_loss: 0.0624 - val_acc: 0.9792\n",
      "Epoch 253/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0616 - acc: 0.9804 - val_loss: 0.0618 - val_acc: 0.9785\n",
      "Epoch 254/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0620 - acc: 0.9791 - val_loss: 0.0611 - val_acc: 0.9815\n",
      "Epoch 255/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0609 - acc: 0.9808 - val_loss: 0.0605 - val_acc: 0.9808\n",
      "Epoch 256/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0609 - acc: 0.9803 - val_loss: 0.0615 - val_acc: 0.9799\n",
      "Epoch 257/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0606 - acc: 0.9802 - val_loss: 0.0626 - val_acc: 0.9810\n",
      "Epoch 258/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0602 - acc: 0.9804 - val_loss: 0.0618 - val_acc: 0.9785\n",
      "Epoch 259/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0592 - acc: 0.9809 - val_loss: 0.0582 - val_acc: 0.9820\n",
      "Epoch 260/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0602 - acc: 0.9814 - val_loss: 0.0584 - val_acc: 0.9801\n",
      "Epoch 261/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0591 - acc: 0.9806 - val_loss: 0.0587 - val_acc: 0.9814\n",
      "Epoch 262/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0592 - acc: 0.9810 - val_loss: 0.0577 - val_acc: 0.9824\n",
      "Epoch 263/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0588 - acc: 0.9809 - val_loss: 0.0571 - val_acc: 0.9823\n",
      "Epoch 264/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0575 - acc: 0.9812 - val_loss: 0.0572 - val_acc: 0.9815\n",
      "Epoch 265/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0578 - acc: 0.9816 - val_loss: 0.0563 - val_acc: 0.9825\n",
      "Epoch 266/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0569 - acc: 0.9816 - val_loss: 0.0558 - val_acc: 0.9824\n",
      "Epoch 267/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0575 - acc: 0.9812 - val_loss: 0.0562 - val_acc: 0.9806\n",
      "Epoch 268/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0565 - acc: 0.9814 - val_loss: 0.0553 - val_acc: 0.9829\n",
      "Epoch 269/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0561 - acc: 0.9816 - val_loss: 0.0549 - val_acc: 0.9828\n",
      "Epoch 270/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0555 - acc: 0.9823 - val_loss: 0.0570 - val_acc: 0.9818\n",
      "Epoch 271/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0553 - acc: 0.9822 - val_loss: 0.0546 - val_acc: 0.9833\n",
      "Epoch 272/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0558 - acc: 0.9825 - val_loss: 0.0555 - val_acc: 0.9830\n",
      "Epoch 273/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0553 - acc: 0.9826 - val_loss: 0.0558 - val_acc: 0.9809\n",
      "Epoch 274/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0553 - acc: 0.9821 - val_loss: 0.0541 - val_acc: 0.9823\n",
      "Epoch 275/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0545 - acc: 0.9822 - val_loss: 0.0529 - val_acc: 0.9835\n",
      "Epoch 276/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0537 - acc: 0.9825 - val_loss: 0.0538 - val_acc: 0.9827\n",
      "Epoch 277/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0537 - acc: 0.9830 - val_loss: 0.0534 - val_acc: 0.9836\n",
      "Epoch 278/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0538 - acc: 0.9824 - val_loss: 0.0520 - val_acc: 0.9838\n",
      "Epoch 279/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0530 - acc: 0.9827 - val_loss: 0.0524 - val_acc: 0.9840\n",
      "Epoch 280/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0528 - acc: 0.9832 - val_loss: 0.0530 - val_acc: 0.9843\n",
      "Epoch 281/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0526 - acc: 0.9829 - val_loss: 0.0531 - val_acc: 0.9817\n",
      "Epoch 282/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0525 - acc: 0.9829 - val_loss: 0.0519 - val_acc: 0.9827\n",
      "Epoch 283/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0522 - acc: 0.9831 - val_loss: 0.0520 - val_acc: 0.9830\n",
      "Epoch 284/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0513 - acc: 0.9839 - val_loss: 0.0517 - val_acc: 0.9836\n",
      "Epoch 285/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0512 - acc: 0.9839 - val_loss: 0.0514 - val_acc: 0.9833\n",
      "Epoch 286/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0521 - acc: 0.9832 - val_loss: 0.0506 - val_acc: 0.9841\n",
      "Epoch 287/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0512 - acc: 0.9832 - val_loss: 0.0528 - val_acc: 0.9830\n",
      "Epoch 288/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0517 - acc: 0.9826 - val_loss: 0.0512 - val_acc: 0.9839\n",
      "Epoch 289/300\n",
      "28573/28573 [==============================] - 341s 12ms/step - loss: 0.0514 - acc: 0.9836 - val_loss: 0.0495 - val_acc: 0.9845\n",
      "Epoch 290/300\n",
      "28573/28573 [==============================] - 1s 45us/step - loss: 0.0502 - acc: 0.9842 - val_loss: 0.0493 - val_acc: 0.9851\n",
      "Epoch 291/300\n",
      "28573/28573 [==============================] - 1s 24us/step - loss: 0.0504 - acc: 0.9849 - val_loss: 0.0494 - val_acc: 0.9840\n",
      "Epoch 292/300\n",
      "28573/28573 [==============================] - 1s 20us/step - loss: 0.0498 - acc: 0.9836 - val_loss: 0.0502 - val_acc: 0.9848\n",
      "Epoch 293/300\n",
      "28573/28573 [==============================] - 1s 25us/step - loss: 0.0501 - acc: 0.9836 - val_loss: 0.0506 - val_acc: 0.9848\n",
      "Epoch 294/300\n",
      "28573/28573 [==============================] - 1s 25us/step - loss: 0.0491 - acc: 0.9844 - val_loss: 0.0488 - val_acc: 0.9846\n",
      "Epoch 295/300\n",
      "28573/28573 [==============================] - 1s 18us/step - loss: 0.0492 - acc: 0.9841 - val_loss: 0.0484 - val_acc: 0.9850\n",
      "Epoch 296/300\n",
      "28573/28573 [==============================] - 1s 21us/step - loss: 0.0488 - acc: 0.9844 - val_loss: 0.0482 - val_acc: 0.9841\n",
      "Epoch 297/300\n",
      "28573/28573 [==============================] - 1s 20us/step - loss: 0.0488 - acc: 0.9845 - val_loss: 0.0480 - val_acc: 0.9857\n",
      "Epoch 298/300\n",
      "28573/28573 [==============================] - 1s 20us/step - loss: 0.0481 - acc: 0.9849 - val_loss: 0.0483 - val_acc: 0.9829\n",
      "Epoch 299/300\n",
      "28573/28573 [==============================] - 1s 20us/step - loss: 0.0482 - acc: 0.9844 - val_loss: 0.0485 - val_acc: 0.9857\n",
      "Epoch 300/300\n",
      "28573/28573 [==============================] - 1s 19us/step - loss: 0.0478 - acc: 0.9846 - val_loss: 0.0491 - val_acc: 0.9827\n",
      "7144/7144 [==============================] - 1s 93us/step\n",
      "28573/28573 [==============================] - 3s 99us/step\n",
      "Train on 28573 samples, validate on 28573 samples\n",
      "Epoch 1/300\n",
      "28573/28573 [==============================] - 5s 160us/step - loss: 3.2091 - acc: 0.0789 - val_loss: 3.0251 - val_acc: 0.1027\n",
      "Epoch 2/300\n",
      "28573/28573 [==============================] - 0s 17us/step - loss: 2.8837 - acc: 0.1041 - val_loss: 2.7429 - val_acc: 0.0945\n",
      "Epoch 3/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 2.6114 - acc: 0.1674 - val_loss: 2.4674 - val_acc: 0.2432\n",
      "Epoch 4/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 2.3286 - acc: 0.2982 - val_loss: 2.1875 - val_acc: 0.3644\n",
      "Epoch 5/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 2.0724 - acc: 0.3985 - val_loss: 1.9626 - val_acc: 0.4183\n",
      "Epoch 6/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 1.8742 - acc: 0.4373 - val_loss: 1.7866 - val_acc: 0.4353\n",
      "Epoch 7/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.7164 - acc: 0.4640 - val_loss: 1.6454 - val_acc: 0.4680\n",
      "Epoch 8/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 1.5872 - acc: 0.5046 - val_loss: 1.5263 - val_acc: 0.5189\n",
      "Epoch 9/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 1.4755 - acc: 0.5450 - val_loss: 1.4239 - val_acc: 0.5562\n",
      "Epoch 10/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.3814 - acc: 0.5738 - val_loss: 1.3367 - val_acc: 0.6102\n",
      "Epoch 11/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.2980 - acc: 0.6220 - val_loss: 1.2576 - val_acc: 0.6120\n",
      "Epoch 12/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 1.2231 - acc: 0.6473 - val_loss: 1.1856 - val_acc: 0.6593\n",
      "Epoch 13/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 1.1545 - acc: 0.6747 - val_loss: 1.1194 - val_acc: 0.6901\n",
      "Epoch 14/300\n",
      "28573/28573 [==============================] - 1s 18us/step - loss: 1.0923 - acc: 0.6957 - val_loss: 1.0593 - val_acc: 0.7108\n",
      "Epoch 15/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 1.0348 - acc: 0.7232 - val_loss: 1.0057 - val_acc: 0.7360\n",
      "Epoch 16/300\n",
      "28573/28573 [==============================] - 0s 17us/step - loss: 0.9821 - acc: 0.7361 - val_loss: 0.9590 - val_acc: 0.7199\n",
      "Epoch 17/300\n",
      "28573/28573 [==============================] - 0s 17us/step - loss: 0.9350 - acc: 0.7449 - val_loss: 0.9113 - val_acc: 0.7461\n",
      "Epoch 18/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.8907 - acc: 0.7673 - val_loss: 0.8663 - val_acc: 0.7837\n",
      "Epoch 19/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.8497 - acc: 0.7662 - val_loss: 0.8284 - val_acc: 0.7991\n",
      "Epoch 20/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.8110 - acc: 0.7891 - val_loss: 0.7905 - val_acc: 0.7928\n",
      "Epoch 21/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.7758 - acc: 0.8004 - val_loss: 0.7560 - val_acc: 0.8125\n",
      "Epoch 22/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.7426 - acc: 0.8068 - val_loss: 0.7276 - val_acc: 0.8063\n",
      "Epoch 23/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.7135 - acc: 0.8142 - val_loss: 0.6987 - val_acc: 0.8095\n",
      "Epoch 24/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.6840 - acc: 0.8141 - val_loss: 0.6692 - val_acc: 0.8169\n",
      "Epoch 25/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.6580 - acc: 0.8230 - val_loss: 0.6439 - val_acc: 0.8256\n",
      "Epoch 26/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.6344 - acc: 0.8286 - val_loss: 0.6207 - val_acc: 0.8286\n",
      "Epoch 27/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.6133 - acc: 0.8323 - val_loss: 0.6013 - val_acc: 0.8404\n",
      "Epoch 28/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.5921 - acc: 0.8345 - val_loss: 0.5809 - val_acc: 0.8383\n",
      "Epoch 29/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.5725 - acc: 0.8384 - val_loss: 0.5642 - val_acc: 0.8344\n",
      "Epoch 30/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.5555 - acc: 0.8427 - val_loss: 0.5441 - val_acc: 0.8471\n",
      "Epoch 31/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.5385 - acc: 0.8449 - val_loss: 0.5361 - val_acc: 0.8447\n",
      "Epoch 32/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.5229 - acc: 0.8458 - val_loss: 0.5136 - val_acc: 0.8506\n",
      "Epoch 33/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.5079 - acc: 0.8467 - val_loss: 0.5001 - val_acc: 0.8517\n",
      "Epoch 34/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4929 - acc: 0.8502 - val_loss: 0.4852 - val_acc: 0.8492\n",
      "Epoch 35/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.4807 - acc: 0.8486 - val_loss: 0.4745 - val_acc: 0.8550\n",
      "Epoch 36/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.4693 - acc: 0.8519 - val_loss: 0.4619 - val_acc: 0.8540\n",
      "Epoch 37/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.4583 - acc: 0.8516 - val_loss: 0.4485 - val_acc: 0.8556\n",
      "Epoch 38/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.4459 - acc: 0.8539 - val_loss: 0.4375 - val_acc: 0.8569\n",
      "Epoch 39/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.4343 - acc: 0.8553 - val_loss: 0.4284 - val_acc: 0.8562\n",
      "Epoch 40/300\n",
      "28573/28573 [==============================] - ETA: 0s - loss: 0.4252 - acc: 0.857 - 0s 15us/step - loss: 0.4254 - acc: 0.8579 - val_loss: 0.4195 - val_acc: 0.8580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/300\n",
      "28573/28573 [==============================] - 0s 17us/step - loss: 0.4177 - acc: 0.8585 - val_loss: 0.4100 - val_acc: 0.8608\n",
      "Epoch 42/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4090 - acc: 0.8618 - val_loss: 0.4039 - val_acc: 0.8628\n",
      "Epoch 43/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.4015 - acc: 0.8638 - val_loss: 0.3942 - val_acc: 0.8656\n",
      "Epoch 44/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3911 - acc: 0.8657 - val_loss: 0.3858 - val_acc: 0.8702\n",
      "Epoch 45/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3845 - acc: 0.8674 - val_loss: 0.3781 - val_acc: 0.8667\n",
      "Epoch 46/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3763 - acc: 0.8699 - val_loss: 0.3727 - val_acc: 0.8696\n",
      "Epoch 47/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3713 - acc: 0.8723 - val_loss: 0.3669 - val_acc: 0.8668\n",
      "Epoch 48/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3631 - acc: 0.8732 - val_loss: 0.3600 - val_acc: 0.8697\n",
      "Epoch 49/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.3571 - acc: 0.8767 - val_loss: 0.3534 - val_acc: 0.8739\n",
      "Epoch 50/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3512 - acc: 0.8766 - val_loss: 0.3472 - val_acc: 0.8821\n",
      "Epoch 51/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3447 - acc: 0.8786 - val_loss: 0.3406 - val_acc: 0.8807\n",
      "Epoch 52/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3400 - acc: 0.8788 - val_loss: 0.3381 - val_acc: 0.8774\n",
      "Epoch 53/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3345 - acc: 0.8806 - val_loss: 0.3304 - val_acc: 0.8818\n",
      "Epoch 54/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3297 - acc: 0.8826 - val_loss: 0.3282 - val_acc: 0.8876\n",
      "Epoch 55/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3246 - acc: 0.8835 - val_loss: 0.3199 - val_acc: 0.8829\n",
      "Epoch 56/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3198 - acc: 0.8849 - val_loss: 0.3199 - val_acc: 0.8838\n",
      "Epoch 57/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3154 - acc: 0.8858 - val_loss: 0.3131 - val_acc: 0.8902\n",
      "Epoch 58/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.3106 - acc: 0.8858 - val_loss: 0.3080 - val_acc: 0.8809\n",
      "Epoch 59/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.3067 - acc: 0.8881 - val_loss: 0.3040 - val_acc: 0.8932\n",
      "Epoch 60/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.3017 - acc: 0.8912 - val_loss: 0.2998 - val_acc: 0.8870\n",
      "Epoch 61/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2981 - acc: 0.8907 - val_loss: 0.2970 - val_acc: 0.8928\n",
      "Epoch 62/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2955 - acc: 0.8907 - val_loss: 0.2922 - val_acc: 0.8902\n",
      "Epoch 63/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.2912 - acc: 0.8918 - val_loss: 0.2892 - val_acc: 0.8889\n",
      "Epoch 64/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.2870 - acc: 0.8926 - val_loss: 0.2902 - val_acc: 0.8903\n",
      "Epoch 65/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2847 - acc: 0.8932 - val_loss: 0.2820 - val_acc: 0.8937\n",
      "Epoch 66/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2800 - acc: 0.8944 - val_loss: 0.2771 - val_acc: 0.8985\n",
      "Epoch 67/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2776 - acc: 0.8951 - val_loss: 0.2745 - val_acc: 0.8918\n",
      "Epoch 68/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.2734 - acc: 0.8963 - val_loss: 0.2726 - val_acc: 0.8941\n",
      "Epoch 69/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2708 - acc: 0.8965 - val_loss: 0.2692 - val_acc: 0.8906\n",
      "Epoch 70/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2675 - acc: 0.8981 - val_loss: 0.2663 - val_acc: 0.8977\n",
      "Epoch 71/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2649 - acc: 0.8974 - val_loss: 0.2623 - val_acc: 0.8987\n",
      "Epoch 72/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2616 - acc: 0.8990 - val_loss: 0.2599 - val_acc: 0.8966\n",
      "Epoch 73/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2596 - acc: 0.8995 - val_loss: 0.2578 - val_acc: 0.9021\n",
      "Epoch 74/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2556 - acc: 0.8996 - val_loss: 0.2529 - val_acc: 0.9046\n",
      "Epoch 75/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2534 - acc: 0.9022 - val_loss: 0.2520 - val_acc: 0.9095\n",
      "Epoch 76/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.2514 - acc: 0.9030 - val_loss: 0.2477 - val_acc: 0.8997\n",
      "Epoch 77/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2482 - acc: 0.9048 - val_loss: 0.2467 - val_acc: 0.9006\n",
      "Epoch 78/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2448 - acc: 0.9058 - val_loss: 0.2418 - val_acc: 0.9062\n",
      "Epoch 79/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2432 - acc: 0.9062 - val_loss: 0.2419 - val_acc: 0.9072\n",
      "Epoch 80/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2421 - acc: 0.9060 - val_loss: 0.2413 - val_acc: 0.9034\n",
      "Epoch 81/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2380 - acc: 0.9075 - val_loss: 0.2370 - val_acc: 0.9058\n",
      "Epoch 82/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2365 - acc: 0.9077 - val_loss: 0.2342 - val_acc: 0.9071\n",
      "Epoch 83/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.2328 - acc: 0.9096 - val_loss: 0.2342 - val_acc: 0.9154\n",
      "Epoch 84/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.2311 - acc: 0.9116 - val_loss: 0.2299 - val_acc: 0.9043\n",
      "Epoch 85/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2297 - acc: 0.9129 - val_loss: 0.2267 - val_acc: 0.9151\n",
      "Epoch 86/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.2264 - acc: 0.9155 - val_loss: 0.2254 - val_acc: 0.9075\n",
      "Epoch 87/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.2247 - acc: 0.9160 - val_loss: 0.2211 - val_acc: 0.9217\n",
      "Epoch 88/300\n",
      "28573/28573 [==============================] - 1s 18us/step - loss: 0.2223 - acc: 0.9167 - val_loss: 0.2191 - val_acc: 0.9171\n",
      "Epoch 89/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.2203 - acc: 0.9176 - val_loss: 0.2169 - val_acc: 0.9198\n",
      "Epoch 90/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.2174 - acc: 0.9178 - val_loss: 0.2195 - val_acc: 0.9253\n",
      "Epoch 91/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.2156 - acc: 0.9202 - val_loss: 0.2135 - val_acc: 0.9079\n",
      "Epoch 92/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.2130 - acc: 0.9208 - val_loss: 0.2112 - val_acc: 0.9270\n",
      "Epoch 93/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.2111 - acc: 0.9221 - val_loss: 0.2110 - val_acc: 0.9252\n",
      "Epoch 94/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2099 - acc: 0.9235 - val_loss: 0.2083 - val_acc: 0.9259\n",
      "Epoch 95/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2079 - acc: 0.9238 - val_loss: 0.2081 - val_acc: 0.9342\n",
      "Epoch 96/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.2075 - acc: 0.9259 - val_loss: 0.2065 - val_acc: 0.9129\n",
      "Epoch 97/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.2041 - acc: 0.9259 - val_loss: 0.2013 - val_acc: 0.9147\n",
      "Epoch 98/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.2016 - acc: 0.9281 - val_loss: 0.1990 - val_acc: 0.9300\n",
      "Epoch 99/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1993 - acc: 0.9292 - val_loss: 0.1969 - val_acc: 0.9280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.1985 - acc: 0.9310 - val_loss: 0.1951 - val_acc: 0.9392\n",
      "Epoch 101/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1973 - acc: 0.9334 - val_loss: 0.2001 - val_acc: 0.9293\n",
      "Epoch 102/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1949 - acc: 0.9304 - val_loss: 0.1927 - val_acc: 0.9340\n",
      "Epoch 103/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1922 - acc: 0.9335 - val_loss: 0.1934 - val_acc: 0.9277\n",
      "Epoch 104/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1913 - acc: 0.9343 - val_loss: 0.1901 - val_acc: 0.9271\n",
      "Epoch 105/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1900 - acc: 0.9348 - val_loss: 0.1867 - val_acc: 0.9372\n",
      "Epoch 106/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1880 - acc: 0.9347 - val_loss: 0.1856 - val_acc: 0.9464\n",
      "Epoch 107/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1860 - acc: 0.9383 - val_loss: 0.1861 - val_acc: 0.9462\n",
      "Epoch 108/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1854 - acc: 0.9370 - val_loss: 0.1860 - val_acc: 0.9336\n",
      "Epoch 109/300\n",
      "28573/28573 [==============================] - 0s 17us/step - loss: 0.1826 - acc: 0.9394 - val_loss: 0.1794 - val_acc: 0.9381\n",
      "Epoch 110/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1810 - acc: 0.9403 - val_loss: 0.1806 - val_acc: 0.9447\n",
      "Epoch 111/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1790 - acc: 0.9425 - val_loss: 0.1774 - val_acc: 0.9480\n",
      "Epoch 112/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1767 - acc: 0.9414 - val_loss: 0.1765 - val_acc: 0.9491\n",
      "Epoch 113/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1761 - acc: 0.9425 - val_loss: 0.1754 - val_acc: 0.9542\n",
      "Epoch 114/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1752 - acc: 0.9425 - val_loss: 0.1735 - val_acc: 0.9453\n",
      "Epoch 115/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1725 - acc: 0.9449 - val_loss: 0.1725 - val_acc: 0.9362\n",
      "Epoch 116/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.1718 - acc: 0.9438 - val_loss: 0.1686 - val_acc: 0.9406\n",
      "Epoch 117/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1707 - acc: 0.9456 - val_loss: 0.1692 - val_acc: 0.9419\n",
      "Epoch 118/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1684 - acc: 0.9472 - val_loss: 0.1656 - val_acc: 0.9512\n",
      "Epoch 119/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1664 - acc: 0.9490 - val_loss: 0.1651 - val_acc: 0.9384\n",
      "Epoch 120/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1665 - acc: 0.9468 - val_loss: 0.1665 - val_acc: 0.9513\n",
      "Epoch 121/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1639 - acc: 0.9501 - val_loss: 0.1621 - val_acc: 0.9541\n",
      "Epoch 122/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1620 - acc: 0.9510 - val_loss: 0.1624 - val_acc: 0.9565\n",
      "Epoch 123/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1620 - acc: 0.9491 - val_loss: 0.1609 - val_acc: 0.9454\n",
      "Epoch 124/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1595 - acc: 0.9518 - val_loss: 0.1575 - val_acc: 0.9502\n",
      "Epoch 125/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1583 - acc: 0.9532 - val_loss: 0.1554 - val_acc: 0.9535\n",
      "Epoch 126/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1570 - acc: 0.9549 - val_loss: 0.1544 - val_acc: 0.9554\n",
      "Epoch 127/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1554 - acc: 0.9541 - val_loss: 0.1559 - val_acc: 0.9454\n",
      "Epoch 128/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1535 - acc: 0.9557 - val_loss: 0.1507 - val_acc: 0.9586\n",
      "Epoch 129/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1527 - acc: 0.9553 - val_loss: 0.1546 - val_acc: 0.9554\n",
      "Epoch 130/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1505 - acc: 0.9573 - val_loss: 0.1502 - val_acc: 0.9565\n",
      "Epoch 131/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1489 - acc: 0.9589 - val_loss: 0.1474 - val_acc: 0.9585\n",
      "Epoch 132/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1486 - acc: 0.9588 - val_loss: 0.1471 - val_acc: 0.9581\n",
      "Epoch 133/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1464 - acc: 0.9595 - val_loss: 0.1454 - val_acc: 0.9594\n",
      "Epoch 134/300\n",
      "28573/28573 [==============================] - 0s 17us/step - loss: 0.1454 - acc: 0.9593 - val_loss: 0.1469 - val_acc: 0.9621\n",
      "Epoch 135/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1443 - acc: 0.9604 - val_loss: 0.1433 - val_acc: 0.9537\n",
      "Epoch 136/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1427 - acc: 0.9617 - val_loss: 0.1432 - val_acc: 0.9607\n",
      "Epoch 137/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1423 - acc: 0.9620 - val_loss: 0.1407 - val_acc: 0.9645\n",
      "Epoch 138/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1422 - acc: 0.9613 - val_loss: 0.1377 - val_acc: 0.9690\n",
      "Epoch 139/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1388 - acc: 0.9634 - val_loss: 0.1382 - val_acc: 0.9558\n",
      "Epoch 140/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1382 - acc: 0.9621 - val_loss: 0.1438 - val_acc: 0.9571\n",
      "Epoch 141/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1380 - acc: 0.9623 - val_loss: 0.1374 - val_acc: 0.9521\n",
      "Epoch 142/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1355 - acc: 0.9660 - val_loss: 0.1372 - val_acc: 0.9643\n",
      "Epoch 143/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1356 - acc: 0.9645 - val_loss: 0.1370 - val_acc: 0.9629\n",
      "Epoch 144/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1342 - acc: 0.9650 - val_loss: 0.1375 - val_acc: 0.9690\n",
      "Epoch 145/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1336 - acc: 0.9664 - val_loss: 0.1297 - val_acc: 0.9649\n",
      "Epoch 146/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1312 - acc: 0.9675 - val_loss: 0.1299 - val_acc: 0.9689\n",
      "Epoch 147/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1299 - acc: 0.9676 - val_loss: 0.1362 - val_acc: 0.9573\n",
      "Epoch 148/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1293 - acc: 0.9679 - val_loss: 0.1275 - val_acc: 0.9644\n",
      "Epoch 149/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1276 - acc: 0.9692 - val_loss: 0.1256 - val_acc: 0.9743\n",
      "Epoch 150/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1270 - acc: 0.9701 - val_loss: 0.1248 - val_acc: 0.9715\n",
      "Epoch 151/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1261 - acc: 0.9694 - val_loss: 0.1230 - val_acc: 0.9771\n",
      "Epoch 152/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1243 - acc: 0.9721 - val_loss: 0.1256 - val_acc: 0.9642\n",
      "Epoch 153/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1235 - acc: 0.9716 - val_loss: 0.1210 - val_acc: 0.9728\n",
      "Epoch 154/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1223 - acc: 0.9724 - val_loss: 0.1208 - val_acc: 0.9729\n",
      "Epoch 155/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1212 - acc: 0.9735 - val_loss: 0.1198 - val_acc: 0.9719\n",
      "Epoch 156/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1212 - acc: 0.9720 - val_loss: 0.1207 - val_acc: 0.9757\n",
      "Epoch 157/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1189 - acc: 0.9742 - val_loss: 0.1173 - val_acc: 0.9789\n",
      "Epoch 158/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1189 - acc: 0.9731 - val_loss: 0.1184 - val_acc: 0.9734\n",
      "Epoch 159/300\n",
      "28573/28573 [==============================] - 1s 18us/step - loss: 0.1176 - acc: 0.9740 - val_loss: 0.1177 - val_acc: 0.9783\n",
      "Epoch 160/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1155 - acc: 0.9763 - val_loss: 0.1167 - val_acc: 0.9713\n",
      "Epoch 161/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1143 - acc: 0.9775 - val_loss: 0.1129 - val_acc: 0.9806\n",
      "Epoch 162/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1128 - acc: 0.9781 - val_loss: 0.1129 - val_acc: 0.9812\n",
      "Epoch 163/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1150 - acc: 0.9738 - val_loss: 0.1115 - val_acc: 0.9762\n",
      "Epoch 164/300\n",
      "28573/28573 [==============================] - ETA: 0s - loss: 0.1127 - acc: 0.977 - 0s 14us/step - loss: 0.1125 - acc: 0.9776 - val_loss: 0.1109 - val_acc: 0.9791\n",
      "Epoch 165/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1117 - acc: 0.9775 - val_loss: 0.1147 - val_acc: 0.9711\n",
      "Epoch 166/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1117 - acc: 0.9760 - val_loss: 0.1082 - val_acc: 0.9752\n",
      "Epoch 167/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1094 - acc: 0.9787 - val_loss: 0.1083 - val_acc: 0.9823\n",
      "Epoch 168/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1096 - acc: 0.9775 - val_loss: 0.1061 - val_acc: 0.9794\n",
      "Epoch 169/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1067 - acc: 0.9820 - val_loss: 0.1077 - val_acc: 0.9795\n",
      "Epoch 170/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1066 - acc: 0.9787 - val_loss: 0.1065 - val_acc: 0.9749\n",
      "Epoch 171/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1051 - acc: 0.9811 - val_loss: 0.1051 - val_acc: 0.9763\n",
      "Epoch 172/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1049 - acc: 0.9794 - val_loss: 0.1051 - val_acc: 0.9833\n",
      "Epoch 173/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.1040 - acc: 0.9822 - val_loss: 0.1047 - val_acc: 0.9868\n",
      "Epoch 174/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1019 - acc: 0.9832 - val_loss: 0.1022 - val_acc: 0.9819\n",
      "Epoch 175/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1015 - acc: 0.9843 - val_loss: 0.1026 - val_acc: 0.9763\n",
      "Epoch 176/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1017 - acc: 0.9815 - val_loss: 0.0994 - val_acc: 0.9792\n",
      "Epoch 177/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.1000 - acc: 0.9835 - val_loss: 0.0985 - val_acc: 0.9880\n",
      "Epoch 178/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0987 - acc: 0.9836 - val_loss: 0.0986 - val_acc: 0.9847\n",
      "Epoch 179/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0983 - acc: 0.9839 - val_loss: 0.0978 - val_acc: 0.9773\n",
      "Epoch 180/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0970 - acc: 0.9838 - val_loss: 0.0966 - val_acc: 0.9836\n",
      "Epoch 181/300\n",
      "28573/28573 [==============================] - 1s 18us/step - loss: 0.0967 - acc: 0.9847 - val_loss: 0.0973 - val_acc: 0.9876\n",
      "Epoch 182/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0962 - acc: 0.9839 - val_loss: 0.0951 - val_acc: 0.9848\n",
      "Epoch 183/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.0957 - acc: 0.9839 - val_loss: 0.0971 - val_acc: 0.9777\n",
      "Epoch 184/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0951 - acc: 0.9832 - val_loss: 0.0930 - val_acc: 0.9851\n",
      "Epoch 185/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0940 - acc: 0.9853 - val_loss: 0.0934 - val_acc: 0.9870\n",
      "Epoch 186/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0926 - acc: 0.9851 - val_loss: 0.0922 - val_acc: 0.9876\n",
      "Epoch 187/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0925 - acc: 0.9849 - val_loss: 0.0909 - val_acc: 0.9860\n",
      "Epoch 188/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0904 - acc: 0.9876 - val_loss: 0.0893 - val_acc: 0.9882\n",
      "Epoch 189/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0908 - acc: 0.9861 - val_loss: 0.0882 - val_acc: 0.9869\n",
      "Epoch 190/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0893 - acc: 0.9873 - val_loss: 0.0870 - val_acc: 0.9882\n",
      "Epoch 191/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0886 - acc: 0.9880 - val_loss: 0.0919 - val_acc: 0.9820\n",
      "Epoch 192/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0888 - acc: 0.9858 - val_loss: 0.0877 - val_acc: 0.9833\n",
      "Epoch 193/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0874 - acc: 0.9878 - val_loss: 0.0850 - val_acc: 0.9917\n",
      "Epoch 194/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0871 - acc: 0.9870 - val_loss: 0.0860 - val_acc: 0.9854\n",
      "Epoch 195/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0865 - acc: 0.9880 - val_loss: 0.0874 - val_acc: 0.9840\n",
      "Epoch 196/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0845 - acc: 0.9884 - val_loss: 0.0828 - val_acc: 0.9914\n",
      "Epoch 197/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0837 - acc: 0.9901 - val_loss: 0.0853 - val_acc: 0.9839\n",
      "Epoch 198/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0836 - acc: 0.9890 - val_loss: 0.0823 - val_acc: 0.9898\n",
      "Epoch 199/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0844 - acc: 0.9865 - val_loss: 0.0812 - val_acc: 0.9920\n",
      "Epoch 200/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0817 - acc: 0.9901 - val_loss: 0.0808 - val_acc: 0.9895\n",
      "Epoch 201/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0813 - acc: 0.9894 - val_loss: 0.0809 - val_acc: 0.9896\n",
      "Epoch 202/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0798 - acc: 0.9916 - val_loss: 0.0826 - val_acc: 0.9913\n",
      "Epoch 203/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0809 - acc: 0.9896 - val_loss: 0.0799 - val_acc: 0.9937\n",
      "Epoch 204/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0789 - acc: 0.9917 - val_loss: 0.0774 - val_acc: 0.9903\n",
      "Epoch 205/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0775 - acc: 0.9924 - val_loss: 0.0802 - val_acc: 0.9874\n",
      "Epoch 206/300\n",
      "28573/28573 [==============================] - 1s 20us/step - loss: 0.0768 - acc: 0.9927 - val_loss: 0.0764 - val_acc: 0.9937\n",
      "Epoch 207/300\n",
      "28573/28573 [==============================] - 0s 17us/step - loss: 0.0771 - acc: 0.9916 - val_loss: 0.0774 - val_acc: 0.9918\n",
      "Epoch 208/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.0763 - acc: 0.9917 - val_loss: 0.0746 - val_acc: 0.9946\n",
      "Epoch 209/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0749 - acc: 0.9930 - val_loss: 0.0747 - val_acc: 0.9918\n",
      "Epoch 210/300\n",
      "28573/28573 [==============================] - 0s 17us/step - loss: 0.0743 - acc: 0.9933 - val_loss: 0.0747 - val_acc: 0.9902\n",
      "Epoch 211/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0739 - acc: 0.9929 - val_loss: 0.0749 - val_acc: 0.9944\n",
      "Epoch 212/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0736 - acc: 0.9932 - val_loss: 0.0709 - val_acc: 0.9938\n",
      "Epoch 213/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0730 - acc: 0.9925 - val_loss: 0.0723 - val_acc: 0.9902\n",
      "Epoch 214/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0720 - acc: 0.9933 - val_loss: 0.0736 - val_acc: 0.9934\n",
      "Epoch 215/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0707 - acc: 0.9940 - val_loss: 0.0714 - val_acc: 0.9945\n",
      "Epoch 216/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0702 - acc: 0.9938 - val_loss: 0.0685 - val_acc: 0.9958\n",
      "Epoch 217/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0692 - acc: 0.9945 - val_loss: 0.0690 - val_acc: 0.9948\n",
      "Epoch 218/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0683 - acc: 0.9944 - val_loss: 0.0669 - val_acc: 0.9951\n",
      "Epoch 219/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0680 - acc: 0.9947 - val_loss: 0.0673 - val_acc: 0.9944\n",
      "Epoch 220/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0687 - acc: 0.9930 - val_loss: 0.0679 - val_acc: 0.9951\n",
      "Epoch 221/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0683 - acc: 0.9942 - val_loss: 0.0674 - val_acc: 0.9954\n",
      "Epoch 222/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0665 - acc: 0.9943 - val_loss: 0.0664 - val_acc: 0.9922\n",
      "Epoch 223/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0661 - acc: 0.9944 - val_loss: 0.0665 - val_acc: 0.9945\n",
      "Epoch 224/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0651 - acc: 0.9948 - val_loss: 0.0654 - val_acc: 0.9931\n",
      "Epoch 225/300\n",
      "28573/28573 [==============================] - 0s 13us/step - loss: 0.0647 - acc: 0.9946 - val_loss: 0.0650 - val_acc: 0.9962\n",
      "Epoch 226/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0635 - acc: 0.9949 - val_loss: 0.0634 - val_acc: 0.9962\n",
      "Epoch 227/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0632 - acc: 0.9949 - val_loss: 0.0621 - val_acc: 0.9962\n",
      "Epoch 228/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0628 - acc: 0.9951 - val_loss: 0.0644 - val_acc: 0.9956\n",
      "Epoch 229/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0625 - acc: 0.9950 - val_loss: 0.0611 - val_acc: 0.9957\n",
      "Epoch 230/300\n",
      "28573/28573 [==============================] - 0s 17us/step - loss: 0.0614 - acc: 0.9954 - val_loss: 0.0609 - val_acc: 0.9960\n",
      "Epoch 231/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0612 - acc: 0.9952 - val_loss: 0.0608 - val_acc: 0.9940\n",
      "Epoch 232/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.0614 - acc: 0.9948 - val_loss: 0.0630 - val_acc: 0.9918\n",
      "Epoch 233/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.0610 - acc: 0.9949 - val_loss: 0.0611 - val_acc: 0.9949\n",
      "Epoch 234/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0592 - acc: 0.9954 - val_loss: 0.0603 - val_acc: 0.9960\n",
      "Epoch 235/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0593 - acc: 0.9954 - val_loss: 0.0587 - val_acc: 0.9955\n",
      "Epoch 236/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0582 - acc: 0.9956 - val_loss: 0.0602 - val_acc: 0.9936\n",
      "Epoch 237/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0583 - acc: 0.9953 - val_loss: 0.0570 - val_acc: 0.9959\n",
      "Epoch 238/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0574 - acc: 0.9958 - val_loss: 0.0555 - val_acc: 0.9964\n",
      "Epoch 239/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0561 - acc: 0.9955 - val_loss: 0.0565 - val_acc: 0.9949\n",
      "Epoch 240/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0559 - acc: 0.9960 - val_loss: 0.0574 - val_acc: 0.9947\n",
      "Epoch 241/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0554 - acc: 0.9960 - val_loss: 0.0565 - val_acc: 0.9960\n",
      "Epoch 242/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0554 - acc: 0.9963 - val_loss: 0.0542 - val_acc: 0.9964\n",
      "Epoch 243/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0555 - acc: 0.9957 - val_loss: 0.0540 - val_acc: 0.9965\n",
      "Epoch 244/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0552 - acc: 0.9951 - val_loss: 0.0600 - val_acc: 0.9901\n",
      "Epoch 245/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0545 - acc: 0.9947 - val_loss: 0.0549 - val_acc: 0.9961\n",
      "Epoch 246/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0526 - acc: 0.9963 - val_loss: 0.0517 - val_acc: 0.9966\n",
      "Epoch 247/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0519 - acc: 0.9964 - val_loss: 0.0512 - val_acc: 0.9963\n",
      "Epoch 248/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0527 - acc: 0.9956 - val_loss: 0.0629 - val_acc: 0.9845\n",
      "Epoch 249/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0524 - acc: 0.9952 - val_loss: 0.0510 - val_acc: 0.9963\n",
      "Epoch 250/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0507 - acc: 0.9965 - val_loss: 0.0510 - val_acc: 0.9963\n",
      "Epoch 251/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0498 - acc: 0.9964 - val_loss: 0.0488 - val_acc: 0.9966\n",
      "Epoch 252/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0498 - acc: 0.9962 - val_loss: 0.0487 - val_acc: 0.9966\n",
      "Epoch 253/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0496 - acc: 0.9962 - val_loss: 0.0509 - val_acc: 0.9948\n",
      "Epoch 254/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0488 - acc: 0.9965 - val_loss: 0.0480 - val_acc: 0.9968\n",
      "Epoch 255/300\n",
      "28573/28573 [==============================] - 1s 18us/step - loss: 0.0484 - acc: 0.9965 - val_loss: 0.0476 - val_acc: 0.9966\n",
      "Epoch 256/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0479 - acc: 0.9962 - val_loss: 0.0490 - val_acc: 0.9956\n",
      "Epoch 257/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0473 - acc: 0.9967 - val_loss: 0.0464 - val_acc: 0.9966\n",
      "Epoch 258/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0472 - acc: 0.9963 - val_loss: 0.0458 - val_acc: 0.9970\n",
      "Epoch 259/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0463 - acc: 0.9968 - val_loss: 0.0452 - val_acc: 0.9967\n",
      "Epoch 260/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0466 - acc: 0.9962 - val_loss: 0.0468 - val_acc: 0.9967\n",
      "Epoch 261/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0468 - acc: 0.9961 - val_loss: 0.0463 - val_acc: 0.9955\n",
      "Epoch 262/300\n",
      "28573/28573 [==============================] - ETA: 0s - loss: 0.0457 - acc: 0.996 - 0s 15us/step - loss: 0.0459 - acc: 0.9963 - val_loss: 0.0439 - val_acc: 0.9967\n",
      "Epoch 263/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0446 - acc: 0.9966 - val_loss: 0.0434 - val_acc: 0.9966\n",
      "Epoch 264/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0440 - acc: 0.9966 - val_loss: 0.0469 - val_acc: 0.9938\n",
      "Epoch 265/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0438 - acc: 0.9965 - val_loss: 0.0432 - val_acc: 0.9967\n",
      "Epoch 266/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0439 - acc: 0.9965 - val_loss: 0.0429 - val_acc: 0.9966\n",
      "Epoch 267/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0433 - acc: 0.9964 - val_loss: 0.0424 - val_acc: 0.9963\n",
      "Epoch 268/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0427 - acc: 0.9968 - val_loss: 0.0427 - val_acc: 0.9967\n",
      "Epoch 269/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0421 - acc: 0.9967 - val_loss: 0.0454 - val_acc: 0.9972\n",
      "Epoch 270/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0423 - acc: 0.9966 - val_loss: 0.0405 - val_acc: 0.9967\n",
      "Epoch 271/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0416 - acc: 0.9967 - val_loss: 0.0407 - val_acc: 0.9968\n",
      "Epoch 272/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0410 - acc: 0.9967 - val_loss: 0.0449 - val_acc: 0.9937\n",
      "Epoch 273/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0414 - acc: 0.9962 - val_loss: 0.0405 - val_acc: 0.9967\n",
      "Epoch 274/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0401 - acc: 0.9968 - val_loss: 0.0406 - val_acc: 0.9972\n",
      "Epoch 275/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0400 - acc: 0.9966 - val_loss: 0.0399 - val_acc: 0.9972\n",
      "Epoch 276/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0399 - acc: 0.9962 - val_loss: 0.0387 - val_acc: 0.9968\n",
      "Epoch 277/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0386 - acc: 0.9969 - val_loss: 0.0376 - val_acc: 0.9967\n",
      "Epoch 278/300\n",
      "28573/28573 [==============================] - 0s 16us/step - loss: 0.0390 - acc: 0.9968 - val_loss: 0.0401 - val_acc: 0.9967\n",
      "Epoch 279/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0381 - acc: 0.9969 - val_loss: 0.0372 - val_acc: 0.9968\n",
      "Epoch 280/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0376 - acc: 0.9969 - val_loss: 0.0379 - val_acc: 0.9980\n",
      "Epoch 281/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0378 - acc: 0.9967 - val_loss: 0.0367 - val_acc: 0.9969\n",
      "Epoch 282/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0371 - acc: 0.9966 - val_loss: 0.0366 - val_acc: 0.9970\n",
      "Epoch 283/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0374 - acc: 0.9970 - val_loss: 0.0366 - val_acc: 0.9967\n",
      "Epoch 284/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0365 - acc: 0.9972 - val_loss: 0.0375 - val_acc: 0.9975\n",
      "Epoch 285/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0364 - acc: 0.9969 - val_loss: 0.0358 - val_acc: 0.9968\n",
      "Epoch 286/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0355 - acc: 0.9970 - val_loss: 0.0376 - val_acc: 0.9960\n",
      "Epoch 287/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0358 - acc: 0.9968 - val_loss: 0.0348 - val_acc: 0.9970\n",
      "Epoch 288/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0354 - acc: 0.9971 - val_loss: 0.0355 - val_acc: 0.9971\n",
      "Epoch 289/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0348 - acc: 0.9969 - val_loss: 0.0352 - val_acc: 0.9967\n",
      "Epoch 290/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0342 - acc: 0.9970 - val_loss: 0.0353 - val_acc: 0.9971\n",
      "Epoch 291/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0339 - acc: 0.9969 - val_loss: 0.0329 - val_acc: 0.9971\n",
      "Epoch 292/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0341 - acc: 0.9970 - val_loss: 0.0330 - val_acc: 0.9970\n",
      "Epoch 293/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0337 - acc: 0.9969 - val_loss: 0.0330 - val_acc: 0.9969\n",
      "Epoch 294/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0330 - acc: 0.9970 - val_loss: 0.0319 - val_acc: 0.9970\n",
      "Epoch 295/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0329 - acc: 0.9972 - val_loss: 0.0355 - val_acc: 0.9957\n",
      "Epoch 296/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0329 - acc: 0.9967 - val_loss: 0.0314 - val_acc: 0.9969\n",
      "Epoch 297/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0323 - acc: 0.9972 - val_loss: 0.0329 - val_acc: 0.9967\n",
      "Epoch 298/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0317 - acc: 0.9972 - val_loss: 0.0334 - val_acc: 0.9967\n",
      "Epoch 299/300\n",
      "28573/28573 [==============================] - 0s 15us/step - loss: 0.0318 - acc: 0.9969 - val_loss: 0.0313 - val_acc: 0.9969\n",
      "Epoch 300/300\n",
      "28573/28573 [==============================] - 0s 14us/step - loss: 0.0318 - acc: 0.9969 - val_loss: 0.0305 - val_acc: 0.9970\n",
      "7144/7144 [==============================] - 1s 83us/step\n",
      "28573/28573 [==============================] - 2s 68us/step\n",
      "Train on 17858 samples, validate on 17858 samples\n",
      "Epoch 1/300\n",
      "17858/17858 [==============================] - 3s 169us/step - loss: 3.3215 - acc: 0.0613 - val_loss: 3.2377 - val_acc: 0.1077\n",
      "Epoch 2/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 3.1289 - acc: 0.1205 - val_loss: 2.9939 - val_acc: 0.1221\n",
      "Epoch 3/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 2.8652 - acc: 0.1235 - val_loss: 2.7367 - val_acc: 0.1049\n",
      "Epoch 4/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 2.6386 - acc: 0.1490 - val_loss: 2.5389 - val_acc: 0.1876\n",
      "Epoch 5/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 2.4539 - acc: 0.2072 - val_loss: 2.3633 - val_acc: 0.2576\n",
      "Epoch 6/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 2.2870 - acc: 0.2882 - val_loss: 2.2055 - val_acc: 0.3040\n",
      "Epoch 7/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 2.1370 - acc: 0.3104 - val_loss: 2.0629 - val_acc: 0.3283\n",
      "Epoch 8/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 2.0031 - acc: 0.3579 - val_loss: 1.9394 - val_acc: 0.3783\n",
      "Epoch 9/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.8876 - acc: 0.4042 - val_loss: 1.8330 - val_acc: 0.4229\n",
      "Epoch 10/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.7887 - acc: 0.4479 - val_loss: 1.7403 - val_acc: 0.4485\n",
      "Epoch 11/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.7009 - acc: 0.4865 - val_loss: 1.6571 - val_acc: 0.5355\n",
      "Epoch 12/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.6235 - acc: 0.5128 - val_loss: 1.5862 - val_acc: 0.5018\n",
      "Epoch 13/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 1.5518 - acc: 0.5362 - val_loss: 1.5161 - val_acc: 0.5609\n",
      "Epoch 14/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 1.4855 - acc: 0.5723 - val_loss: 1.4522 - val_acc: 0.5885\n",
      "Epoch 15/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.4216 - acc: 0.5840 - val_loss: 1.3890 - val_acc: 0.6024\n",
      "Epoch 16/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 1.3621 - acc: 0.6166 - val_loss: 1.3317 - val_acc: 0.6061\n",
      "Epoch 17/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 1.3076 - acc: 0.6486 - val_loss: 1.2810 - val_acc: 0.6714\n",
      "Epoch 18/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.2595 - acc: 0.6527 - val_loss: 1.2335 - val_acc: 0.6666\n",
      "Epoch 19/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 1.2123 - acc: 0.6698 - val_loss: 1.1860 - val_acc: 0.6490\n",
      "Epoch 20/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 1.1668 - acc: 0.6934 - val_loss: 1.1438 - val_acc: 0.6597\n",
      "Epoch 21/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.1278 - acc: 0.6958 - val_loss: 1.1049 - val_acc: 0.7350\n",
      "Epoch 22/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 1.0874 - acc: 0.7154 - val_loss: 1.0701 - val_acc: 0.6866\n",
      "Epoch 23/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.0539 - acc: 0.7200 - val_loss: 1.0348 - val_acc: 0.7117\n",
      "Epoch 24/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.0198 - acc: 0.7414 - val_loss: 1.0016 - val_acc: 0.7643\n",
      "Epoch 25/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.9877 - acc: 0.7414 - val_loss: 0.9713 - val_acc: 0.7368\n",
      "Epoch 26/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.9568 - acc: 0.7451 - val_loss: 0.9431 - val_acc: 0.7538\n",
      "Epoch 27/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.9309 - acc: 0.7481 - val_loss: 0.9133 - val_acc: 0.7646\n",
      "Epoch 28/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.9008 - acc: 0.7730 - val_loss: 0.8871 - val_acc: 0.7769\n",
      "Epoch 29/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.8766 - acc: 0.7650 - val_loss: 0.8663 - val_acc: 0.7510\n",
      "Epoch 30/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.8534 - acc: 0.7715 - val_loss: 0.8388 - val_acc: 0.7854\n",
      "Epoch 31/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.8293 - acc: 0.7848 - val_loss: 0.8182 - val_acc: 0.7743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.8079 - acc: 0.7842 - val_loss: 0.7961 - val_acc: 0.7887\n",
      "Epoch 33/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.7872 - acc: 0.7961 - val_loss: 0.7732 - val_acc: 0.8013\n",
      "Epoch 34/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.7673 - acc: 0.7996 - val_loss: 0.7550 - val_acc: 0.8178\n",
      "Epoch 35/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.7480 - acc: 0.8108 - val_loss: 0.7381 - val_acc: 0.8080\n",
      "Epoch 36/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.7307 - acc: 0.8022 - val_loss: 0.7194 - val_acc: 0.8113\n",
      "Epoch 37/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.7137 - acc: 0.8037 - val_loss: 0.7068 - val_acc: 0.8059\n",
      "Epoch 38/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.6989 - acc: 0.8042 - val_loss: 0.6878 - val_acc: 0.8050\n",
      "Epoch 39/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.6836 - acc: 0.8080 - val_loss: 0.6758 - val_acc: 0.8167\n",
      "Epoch 40/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.6687 - acc: 0.8124 - val_loss: 0.6591 - val_acc: 0.8093\n",
      "Epoch 41/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.6543 - acc: 0.8141 - val_loss: 0.6481 - val_acc: 0.8137\n",
      "Epoch 42/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.6429 - acc: 0.8083 - val_loss: 0.6343 - val_acc: 0.8216\n",
      "Epoch 43/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.6309 - acc: 0.8170 - val_loss: 0.6211 - val_acc: 0.8181\n",
      "Epoch 44/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.6185 - acc: 0.8175 - val_loss: 0.6126 - val_acc: 0.8111\n",
      "Epoch 45/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.6063 - acc: 0.8186 - val_loss: 0.6016 - val_acc: 0.8082\n",
      "Epoch 46/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.5955 - acc: 0.8241 - val_loss: 0.5885 - val_acc: 0.8309\n",
      "Epoch 47/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5845 - acc: 0.8220 - val_loss: 0.5800 - val_acc: 0.8325\n",
      "Epoch 48/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5746 - acc: 0.8290 - val_loss: 0.5692 - val_acc: 0.8266\n",
      "Epoch 49/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.5662 - acc: 0.8311 - val_loss: 0.5607 - val_acc: 0.8278\n",
      "Epoch 50/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5576 - acc: 0.8314 - val_loss: 0.5538 - val_acc: 0.8238\n",
      "Epoch 51/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5487 - acc: 0.8298 - val_loss: 0.5466 - val_acc: 0.8158\n",
      "Epoch 52/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5409 - acc: 0.8307 - val_loss: 0.5364 - val_acc: 0.8274\n",
      "Epoch 53/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5323 - acc: 0.8348 - val_loss: 0.5294 - val_acc: 0.8387\n",
      "Epoch 54/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5244 - acc: 0.8378 - val_loss: 0.5230 - val_acc: 0.8362\n",
      "Epoch 55/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5167 - acc: 0.8426 - val_loss: 0.5119 - val_acc: 0.8490\n",
      "Epoch 56/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5092 - acc: 0.8399 - val_loss: 0.5077 - val_acc: 0.8452\n",
      "Epoch 57/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.5039 - acc: 0.8404 - val_loss: 0.4974 - val_acc: 0.8345\n",
      "Epoch 58/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.4956 - acc: 0.8441 - val_loss: 0.4889 - val_acc: 0.8479\n",
      "Epoch 59/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.4901 - acc: 0.8428 - val_loss: 0.4842 - val_acc: 0.8543\n",
      "Epoch 60/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4821 - acc: 0.8476 - val_loss: 0.4778 - val_acc: 0.8490\n",
      "Epoch 61/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4768 - acc: 0.8467 - val_loss: 0.4725 - val_acc: 0.8367\n",
      "Epoch 62/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4733 - acc: 0.8456 - val_loss: 0.4696 - val_acc: 0.8482\n",
      "Epoch 63/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.4645 - acc: 0.8497 - val_loss: 0.4608 - val_acc: 0.8614\n",
      "Epoch 64/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4587 - acc: 0.8535 - val_loss: 0.4550 - val_acc: 0.8583\n",
      "Epoch 65/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.4527 - acc: 0.8523 - val_loss: 0.4488 - val_acc: 0.8569\n",
      "Epoch 66/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4467 - acc: 0.8541 - val_loss: 0.4467 - val_acc: 0.8585\n",
      "Epoch 67/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4433 - acc: 0.8557 - val_loss: 0.4413 - val_acc: 0.8536\n",
      "Epoch 68/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.4374 - acc: 0.8554 - val_loss: 0.4317 - val_acc: 0.8589\n",
      "Epoch 69/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.4318 - acc: 0.8582 - val_loss: 0.4303 - val_acc: 0.8618\n",
      "Epoch 70/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.4279 - acc: 0.8550 - val_loss: 0.4239 - val_acc: 0.8573\n",
      "Epoch 71/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.4222 - acc: 0.8575 - val_loss: 0.4202 - val_acc: 0.8561\n",
      "Epoch 72/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.4182 - acc: 0.8605 - val_loss: 0.4158 - val_acc: 0.8653\n",
      "Epoch 73/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.4131 - acc: 0.8626 - val_loss: 0.4106 - val_acc: 0.8543\n",
      "Epoch 74/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.4084 - acc: 0.8629 - val_loss: 0.4082 - val_acc: 0.8592\n",
      "Epoch 75/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.4059 - acc: 0.8602 - val_loss: 0.4026 - val_acc: 0.8606\n",
      "Epoch 76/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.3988 - acc: 0.8648 - val_loss: 0.3967 - val_acc: 0.8695\n",
      "Epoch 77/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.3973 - acc: 0.8629 - val_loss: 0.3930 - val_acc: 0.8676\n",
      "Epoch 78/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.3932 - acc: 0.8644 - val_loss: 0.3902 - val_acc: 0.8696\n",
      "Epoch 79/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.3888 - acc: 0.8683 - val_loss: 0.3871 - val_acc: 0.8750\n",
      "Epoch 80/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.3836 - acc: 0.8680 - val_loss: 0.3802 - val_acc: 0.8692\n",
      "Epoch 81/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3818 - acc: 0.8677 - val_loss: 0.3772 - val_acc: 0.8748\n",
      "Epoch 82/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.3763 - acc: 0.8704 - val_loss: 0.3731 - val_acc: 0.8729\n",
      "Epoch 83/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3721 - acc: 0.8732 - val_loss: 0.3684 - val_acc: 0.8826\n",
      "Epoch 84/300\n",
      "17858/17858 [==============================] - ETA: 0s - loss: 0.3685 - acc: 0.872 - 0s 17us/step - loss: 0.3686 - acc: 0.8731 - val_loss: 0.3648 - val_acc: 0.8667\n",
      "Epoch 85/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.3646 - acc: 0.8704 - val_loss: 0.3607 - val_acc: 0.8696\n",
      "Epoch 86/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.3615 - acc: 0.8770 - val_loss: 0.3611 - val_acc: 0.8773\n",
      "Epoch 87/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.3592 - acc: 0.8777 - val_loss: 0.3567 - val_acc: 0.8850\n",
      "Epoch 88/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.3554 - acc: 0.8752 - val_loss: 0.3525 - val_acc: 0.8760\n",
      "Epoch 89/300\n",
      "17858/17858 [==============================] - 0s 23us/step - loss: 0.3537 - acc: 0.8803 - val_loss: 0.3496 - val_acc: 0.8889\n",
      "Epoch 90/300\n",
      "17858/17858 [==============================] - 0s 22us/step - loss: 0.3474 - acc: 0.8807 - val_loss: 0.3479 - val_acc: 0.8769\n",
      "Epoch 91/300\n",
      "17858/17858 [==============================] - 0s 22us/step - loss: 0.3456 - acc: 0.8805 - val_loss: 0.3439 - val_acc: 0.8839\n",
      "Epoch 92/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.3428 - acc: 0.8807 - val_loss: 0.3412 - val_acc: 0.8853\n",
      "Epoch 93/300\n",
      "17858/17858 [==============================] - 1s 29us/step - loss: 0.3397 - acc: 0.8837 - val_loss: 0.3372 - val_acc: 0.8902\n",
      "Epoch 94/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.3367 - acc: 0.8812 - val_loss: 0.3366 - val_acc: 0.8808\n",
      "Epoch 95/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.3360 - acc: 0.8801 - val_loss: 0.3339 - val_acc: 0.8911\n",
      "Epoch 96/300\n",
      "17858/17858 [==============================] - 1s 30us/step - loss: 0.3311 - acc: 0.8871 - val_loss: 0.3283 - val_acc: 0.8878\n",
      "Epoch 97/300\n",
      "17858/17858 [==============================] - 0s 27us/step - loss: 0.3270 - acc: 0.8873 - val_loss: 0.3244 - val_acc: 0.8841\n",
      "Epoch 98/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.3238 - acc: 0.8890 - val_loss: 0.3218 - val_acc: 0.8836\n",
      "Epoch 99/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3212 - acc: 0.8881 - val_loss: 0.3206 - val_acc: 0.9012\n",
      "Epoch 100/300\n",
      "17858/17858 [==============================] - 1s 33us/step - loss: 0.3190 - acc: 0.8887 - val_loss: 0.3166 - val_acc: 0.8873\n",
      "Epoch 101/300\n",
      "17858/17858 [==============================] - 0s 26us/step - loss: 0.3158 - acc: 0.8913 - val_loss: 0.3142 - val_acc: 0.8820\n",
      "Epoch 102/300\n",
      "17858/17858 [==============================] - 1s 31us/step - loss: 0.3137 - acc: 0.8885 - val_loss: 0.3119 - val_acc: 0.8938\n",
      "Epoch 103/300\n",
      "17858/17858 [==============================] - 1s 39us/step - loss: 0.3128 - acc: 0.8907 - val_loss: 0.3091 - val_acc: 0.8999\n",
      "Epoch 104/300\n",
      "17858/17858 [==============================] - 0s 23us/step - loss: 0.3080 - acc: 0.8944 - val_loss: 0.3043 - val_acc: 0.8992\n",
      "Epoch 105/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.3049 - acc: 0.8918 - val_loss: 0.3058 - val_acc: 0.8898\n",
      "Epoch 106/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.3028 - acc: 0.8932 - val_loss: 0.3009 - val_acc: 0.8949\n",
      "Epoch 107/300\n",
      "17858/17858 [==============================] - 1s 31us/step - loss: 0.3002 - acc: 0.8916 - val_loss: 0.2982 - val_acc: 0.8949\n",
      "Epoch 108/300\n",
      "17858/17858 [==============================] - 1s 42us/step - loss: 0.2963 - acc: 0.8953 - val_loss: 0.2954 - val_acc: 0.8950\n",
      "Epoch 109/300\n",
      "17858/17858 [==============================] - 1s 33us/step - loss: 0.2960 - acc: 0.8972 - val_loss: 0.2969 - val_acc: 0.8928\n",
      "Epoch 110/300\n",
      "17858/17858 [==============================] - 0s 24us/step - loss: 0.2940 - acc: 0.8969 - val_loss: 0.2926 - val_acc: 0.8992\n",
      "Epoch 111/300\n",
      "17858/17858 [==============================] - 0s 24us/step - loss: 0.2904 - acc: 0.8944 - val_loss: 0.2877 - val_acc: 0.8902\n",
      "Epoch 112/300\n",
      "17858/17858 [==============================] - 0s 22us/step - loss: 0.2899 - acc: 0.8967 - val_loss: 0.2913 - val_acc: 0.8902\n",
      "Epoch 113/300\n",
      "17858/17858 [==============================] - 0s 21us/step - loss: 0.2862 - acc: 0.8967 - val_loss: 0.2881 - val_acc: 0.9040\n",
      "Epoch 114/300\n",
      "17858/17858 [==============================] - 0s 22us/step - loss: 0.2841 - acc: 0.9014 - val_loss: 0.2825 - val_acc: 0.8946\n",
      "Epoch 115/300\n",
      "17858/17858 [==============================] - 1s 31us/step - loss: 0.2804 - acc: 0.9032 - val_loss: 0.2802 - val_acc: 0.8985\n",
      "Epoch 116/300\n",
      "17858/17858 [==============================] - 1s 36us/step - loss: 0.2792 - acc: 0.9025 - val_loss: 0.2780 - val_acc: 0.9186\n",
      "Epoch 117/300\n",
      "17858/17858 [==============================] - 1s 35us/step - loss: 0.2769 - acc: 0.9009 - val_loss: 0.2776 - val_acc: 0.8953\n",
      "Epoch 118/300\n",
      "17858/17858 [==============================] - 0s 22us/step - loss: 0.2757 - acc: 0.9061 - val_loss: 0.2764 - val_acc: 0.8970\n",
      "Epoch 119/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.2762 - acc: 0.9036 - val_loss: 0.2727 - val_acc: 0.9011\n",
      "Epoch 120/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.2710 - acc: 0.9052 - val_loss: 0.2712 - val_acc: 0.9072\n",
      "Epoch 121/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.2682 - acc: 0.9091 - val_loss: 0.2672 - val_acc: 0.9167\n",
      "Epoch 122/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2678 - acc: 0.9036 - val_loss: 0.2693 - val_acc: 0.8998\n",
      "Epoch 123/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2642 - acc: 0.9051 - val_loss: 0.2633 - val_acc: 0.9075\n",
      "Epoch 124/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.2620 - acc: 0.9079 - val_loss: 0.2647 - val_acc: 0.9053\n",
      "Epoch 125/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.2612 - acc: 0.9064 - val_loss: 0.2577 - val_acc: 0.8972\n",
      "Epoch 126/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2578 - acc: 0.9107 - val_loss: 0.2589 - val_acc: 0.9042\n",
      "Epoch 127/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.2562 - acc: 0.9088 - val_loss: 0.2524 - val_acc: 0.9175\n",
      "Epoch 128/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.2545 - acc: 0.9130 - val_loss: 0.2519 - val_acc: 0.9251\n",
      "Epoch 129/300\n",
      "17858/17858 [==============================] - 0s 24us/step - loss: 0.2510 - acc: 0.9157 - val_loss: 0.2521 - val_acc: 0.9186\n",
      "Epoch 130/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.2524 - acc: 0.9106 - val_loss: 0.2468 - val_acc: 0.9075\n",
      "Epoch 131/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.2497 - acc: 0.9081 - val_loss: 0.2460 - val_acc: 0.9275\n",
      "Epoch 132/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.2472 - acc: 0.9175 - val_loss: 0.2445 - val_acc: 0.9107\n",
      "Epoch 133/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.2451 - acc: 0.9149 - val_loss: 0.2429 - val_acc: 0.9220\n",
      "Epoch 134/300\n",
      "17858/17858 [==============================] - 0s 21us/step - loss: 0.2423 - acc: 0.9226 - val_loss: 0.2409 - val_acc: 0.9097\n",
      "Epoch 135/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.2410 - acc: 0.9166 - val_loss: 0.2388 - val_acc: 0.9093\n",
      "Epoch 136/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.2389 - acc: 0.9215 - val_loss: 0.2407 - val_acc: 0.9110\n",
      "Epoch 137/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.2386 - acc: 0.9159 - val_loss: 0.2348 - val_acc: 0.9139\n",
      "Epoch 138/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.2356 - acc: 0.9210 - val_loss: 0.2343 - val_acc: 0.9246\n",
      "Epoch 139/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2352 - acc: 0.9210 - val_loss: 0.2354 - val_acc: 0.8963\n",
      "Epoch 140/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.2322 - acc: 0.9212 - val_loss: 0.2306 - val_acc: 0.9277\n",
      "Epoch 141/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.2307 - acc: 0.9237 - val_loss: 0.2304 - val_acc: 0.9265\n",
      "Epoch 142/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.2293 - acc: 0.9248 - val_loss: 0.2306 - val_acc: 0.9161\n",
      "Epoch 143/300\n",
      "17858/17858 [==============================] - 0s 21us/step - loss: 0.2273 - acc: 0.9254 - val_loss: 0.2252 - val_acc: 0.9261\n",
      "Epoch 144/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.2265 - acc: 0.9232 - val_loss: 0.2276 - val_acc: 0.9105\n",
      "Epoch 145/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.2247 - acc: 0.9271 - val_loss: 0.2230 - val_acc: 0.9292\n",
      "Epoch 146/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.2234 - acc: 0.9287 - val_loss: 0.2220 - val_acc: 0.9425\n",
      "Epoch 147/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2205 - acc: 0.9285 - val_loss: 0.2197 - val_acc: 0.9340\n",
      "Epoch 148/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2196 - acc: 0.9329 - val_loss: 0.2196 - val_acc: 0.9465\n",
      "Epoch 149/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.2186 - acc: 0.9307 - val_loss: 0.2164 - val_acc: 0.9369\n",
      "Epoch 150/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2178 - acc: 0.9298 - val_loss: 0.2184 - val_acc: 0.9143\n",
      "Epoch 151/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2163 - acc: 0.9300 - val_loss: 0.2150 - val_acc: 0.9426\n",
      "Epoch 152/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.2135 - acc: 0.9363 - val_loss: 0.2144 - val_acc: 0.9235\n",
      "Epoch 153/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.2144 - acc: 0.9316 - val_loss: 0.2156 - val_acc: 0.9339\n",
      "Epoch 154/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.2115 - acc: 0.9321 - val_loss: 0.2085 - val_acc: 0.9469\n",
      "Epoch 155/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.2089 - acc: 0.9362 - val_loss: 0.2070 - val_acc: 0.9381\n",
      "Epoch 156/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.2074 - acc: 0.9397 - val_loss: 0.2060 - val_acc: 0.9411\n",
      "Epoch 157/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.2066 - acc: 0.9380 - val_loss: 0.2035 - val_acc: 0.9516\n",
      "Epoch 158/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.2045 - acc: 0.9422 - val_loss: 0.2023 - val_acc: 0.9292\n",
      "Epoch 159/300\n",
      "17858/17858 [==============================] - 0s 22us/step - loss: 0.2044 - acc: 0.9361 - val_loss: 0.2043 - val_acc: 0.9395\n",
      "Epoch 160/300\n",
      "17858/17858 [==============================] - 0s 21us/step - loss: 0.2034 - acc: 0.9379 - val_loss: 0.2027 - val_acc: 0.9349\n",
      "Epoch 161/300\n",
      "17858/17858 [==============================] - 0s 21us/step - loss: 0.2028 - acc: 0.9375 - val_loss: 0.2013 - val_acc: 0.9287\n",
      "Epoch 162/300\n",
      "17858/17858 [==============================] - 0s 22us/step - loss: 0.2004 - acc: 0.9397 - val_loss: 0.1994 - val_acc: 0.9347\n",
      "Epoch 163/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.1985 - acc: 0.9405 - val_loss: 0.1960 - val_acc: 0.9395\n",
      "Epoch 164/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.1976 - acc: 0.9405 - val_loss: 0.2003 - val_acc: 0.9510\n",
      "Epoch 165/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.1966 - acc: 0.9416 - val_loss: 0.1939 - val_acc: 0.9456\n",
      "Epoch 166/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.1955 - acc: 0.9390 - val_loss: 0.1924 - val_acc: 0.9497\n",
      "Epoch 167/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1920 - acc: 0.9480 - val_loss: 0.1939 - val_acc: 0.9387\n",
      "Epoch 168/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1930 - acc: 0.9418 - val_loss: 0.1913 - val_acc: 0.9404\n",
      "Epoch 169/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.1913 - acc: 0.9429 - val_loss: 0.1943 - val_acc: 0.9345\n",
      "Epoch 170/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1908 - acc: 0.9428 - val_loss: 0.1867 - val_acc: 0.9531\n",
      "Epoch 171/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1884 - acc: 0.9480 - val_loss: 0.1879 - val_acc: 0.9425\n",
      "Epoch 172/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1868 - acc: 0.9481 - val_loss: 0.1889 - val_acc: 0.9450\n",
      "Epoch 173/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1874 - acc: 0.9464 - val_loss: 0.1885 - val_acc: 0.9442\n",
      "Epoch 174/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1852 - acc: 0.9512 - val_loss: 0.1848 - val_acc: 0.9428\n",
      "Epoch 175/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.1834 - acc: 0.9502 - val_loss: 0.1819 - val_acc: 0.9589\n",
      "Epoch 176/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1821 - acc: 0.9519 - val_loss: 0.1803 - val_acc: 0.9524\n",
      "Epoch 177/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1807 - acc: 0.9514 - val_loss: 0.1809 - val_acc: 0.9472\n",
      "Epoch 178/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1805 - acc: 0.9496 - val_loss: 0.1779 - val_acc: 0.9528\n",
      "Epoch 179/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1780 - acc: 0.9523 - val_loss: 0.1762 - val_acc: 0.9579\n",
      "Epoch 180/300\n",
      "17858/17858 [==============================] - 0s 13us/step - loss: 0.1778 - acc: 0.9506 - val_loss: 0.1754 - val_acc: 0.9561\n",
      "Epoch 181/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1766 - acc: 0.9509 - val_loss: 0.1772 - val_acc: 0.9458\n",
      "Epoch 182/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1761 - acc: 0.9479 - val_loss: 0.1750 - val_acc: 0.9405\n",
      "Epoch 183/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1749 - acc: 0.9520 - val_loss: 0.1775 - val_acc: 0.9414\n",
      "Epoch 184/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1750 - acc: 0.9496 - val_loss: 0.1715 - val_acc: 0.9567\n",
      "Epoch 185/300\n",
      "17858/17858 [==============================] - 0s 13us/step - loss: 0.1724 - acc: 0.9534 - val_loss: 0.1695 - val_acc: 0.9523\n",
      "Epoch 186/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1701 - acc: 0.9551 - val_loss: 0.1702 - val_acc: 0.9555\n",
      "Epoch 187/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1700 - acc: 0.9539 - val_loss: 0.1674 - val_acc: 0.9534\n",
      "Epoch 188/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1689 - acc: 0.9546 - val_loss: 0.1675 - val_acc: 0.9548\n",
      "Epoch 189/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1674 - acc: 0.9525 - val_loss: 0.1656 - val_acc: 0.9519\n",
      "Epoch 190/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1660 - acc: 0.9540 - val_loss: 0.1659 - val_acc: 0.9518\n",
      "Epoch 191/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1651 - acc: 0.9532 - val_loss: 0.1647 - val_acc: 0.9522\n",
      "Epoch 192/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1650 - acc: 0.9531 - val_loss: 0.1621 - val_acc: 0.9570\n",
      "Epoch 193/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1625 - acc: 0.9572 - val_loss: 0.1624 - val_acc: 0.9562\n",
      "Epoch 194/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1625 - acc: 0.9564 - val_loss: 0.1606 - val_acc: 0.9540\n",
      "Epoch 195/300\n",
      "17858/17858 [==============================] - 0s 13us/step - loss: 0.1617 - acc: 0.9557 - val_loss: 0.1602 - val_acc: 0.9604\n",
      "Epoch 196/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1613 - acc: 0.9539 - val_loss: 0.1611 - val_acc: 0.9467\n",
      "Epoch 197/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1595 - acc: 0.9579 - val_loss: 0.1615 - val_acc: 0.9484\n",
      "Epoch 198/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1594 - acc: 0.9532 - val_loss: 0.1599 - val_acc: 0.9550\n",
      "Epoch 199/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1575 - acc: 0.9588 - val_loss: 0.1584 - val_acc: 0.9562\n",
      "Epoch 200/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1562 - acc: 0.9572 - val_loss: 0.1536 - val_acc: 0.9587\n",
      "Epoch 201/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1569 - acc: 0.9545 - val_loss: 0.1540 - val_acc: 0.9568\n",
      "Epoch 202/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1545 - acc: 0.9556 - val_loss: 0.1520 - val_acc: 0.9592\n",
      "Epoch 203/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1535 - acc: 0.9598 - val_loss: 0.1547 - val_acc: 0.9551\n",
      "Epoch 204/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1537 - acc: 0.9588 - val_loss: 0.1519 - val_acc: 0.9590\n",
      "Epoch 205/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.1521 - acc: 0.9596 - val_loss: 0.1523 - val_acc: 0.9552\n",
      "Epoch 206/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1516 - acc: 0.9563 - val_loss: 0.1499 - val_acc: 0.9583\n",
      "Epoch 207/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1504 - acc: 0.9592 - val_loss: 0.1496 - val_acc: 0.9610\n",
      "Epoch 208/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1504 - acc: 0.9594 - val_loss: 0.1497 - val_acc: 0.9582\n",
      "Epoch 209/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.1482 - acc: 0.9603 - val_loss: 0.1464 - val_acc: 0.9573\n",
      "Epoch 210/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.1485 - acc: 0.9586 - val_loss: 0.1466 - val_acc: 0.9559\n",
      "Epoch 211/300\n",
      "17858/17858 [==============================] - ETA: 0s - loss: 0.1490 - acc: 0.954 - 0s 14us/step - loss: 0.1476 - acc: 0.9576 - val_loss: 0.1439 - val_acc: 0.9617\n",
      "Epoch 212/300\n",
      "17858/17858 [==============================] - 0s 27us/step - loss: 0.1457 - acc: 0.9610 - val_loss: 0.1451 - val_acc: 0.9562\n",
      "Epoch 213/300\n",
      "17858/17858 [==============================] - 0s 21us/step - loss: 0.1463 - acc: 0.9569 - val_loss: 0.1486 - val_acc: 0.9540\n",
      "Epoch 214/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1457 - acc: 0.9578 - val_loss: 0.1417 - val_acc: 0.9643\n",
      "Epoch 215/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1440 - acc: 0.9576 - val_loss: 0.1440 - val_acc: 0.9548\n",
      "Epoch 216/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1432 - acc: 0.9606 - val_loss: 0.1413 - val_acc: 0.9582\n",
      "Epoch 217/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1413 - acc: 0.9629 - val_loss: 0.1390 - val_acc: 0.9673\n",
      "Epoch 218/300\n",
      "17858/17858 [==============================] - 0s 13us/step - loss: 0.1413 - acc: 0.9606 - val_loss: 0.1431 - val_acc: 0.9569\n",
      "Epoch 219/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1408 - acc: 0.9604 - val_loss: 0.1413 - val_acc: 0.9583\n",
      "Epoch 220/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1406 - acc: 0.9583 - val_loss: 0.1381 - val_acc: 0.9623\n",
      "Epoch 221/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1389 - acc: 0.9603 - val_loss: 0.1417 - val_acc: 0.9674\n",
      "Epoch 222/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.1382 - acc: 0.9616 - val_loss: 0.1362 - val_acc: 0.9657\n",
      "Epoch 223/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1377 - acc: 0.9627 - val_loss: 0.1353 - val_acc: 0.9643\n",
      "Epoch 224/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.1355 - acc: 0.9650 - val_loss: 0.1348 - val_acc: 0.9617\n",
      "Epoch 225/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1357 - acc: 0.9639 - val_loss: 0.1390 - val_acc: 0.9534\n",
      "Epoch 226/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1362 - acc: 0.9602 - val_loss: 0.1362 - val_acc: 0.9627\n",
      "Epoch 227/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1370 - acc: 0.9621 - val_loss: 0.1341 - val_acc: 0.9649\n",
      "Epoch 228/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.1332 - acc: 0.9643 - val_loss: 0.1314 - val_acc: 0.9670\n",
      "Epoch 229/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1329 - acc: 0.9626 - val_loss: 0.1353 - val_acc: 0.9550\n",
      "Epoch 230/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1324 - acc: 0.9606 - val_loss: 0.1321 - val_acc: 0.9627\n",
      "Epoch 231/300\n",
      "17858/17858 [==============================] - 0s 13us/step - loss: 0.1317 - acc: 0.9615 - val_loss: 0.1298 - val_acc: 0.9604\n",
      "Epoch 232/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1305 - acc: 0.9638 - val_loss: 0.1284 - val_acc: 0.9674\n",
      "Epoch 233/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1290 - acc: 0.9668 - val_loss: 0.1305 - val_acc: 0.9633\n",
      "Epoch 234/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.1282 - acc: 0.9646 - val_loss: 0.1304 - val_acc: 0.9580\n",
      "Epoch 235/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.1294 - acc: 0.9641 - val_loss: 0.1262 - val_acc: 0.9698\n",
      "Epoch 236/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.1279 - acc: 0.9659 - val_loss: 0.1261 - val_acc: 0.9658\n",
      "Epoch 237/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.1284 - acc: 0.9668 - val_loss: 0.1251 - val_acc: 0.9699\n",
      "Epoch 238/300\n",
      "17858/17858 [==============================] - 0s 25us/step - loss: 0.1256 - acc: 0.9681 - val_loss: 0.1241 - val_acc: 0.9713\n",
      "Epoch 239/300\n",
      "17858/17858 [==============================] - 1s 32us/step - loss: 0.1257 - acc: 0.9660 - val_loss: 0.1232 - val_acc: 0.9706\n",
      "Epoch 240/300\n",
      "17858/17858 [==============================] - 1s 29us/step - loss: 0.1241 - acc: 0.9677 - val_loss: 0.1259 - val_acc: 0.9616\n",
      "Epoch 241/300\n",
      "17858/17858 [==============================] - 0s 25us/step - loss: 0.1245 - acc: 0.9670 - val_loss: 0.1232 - val_acc: 0.9663\n",
      "Epoch 242/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1238 - acc: 0.9649 - val_loss: 0.1233 - val_acc: 0.9635\n",
      "Epoch 243/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1229 - acc: 0.9692 - val_loss: 0.1221 - val_acc: 0.9712\n",
      "Epoch 244/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.1231 - acc: 0.9649 - val_loss: 0.1243 - val_acc: 0.9668\n",
      "Epoch 245/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1231 - acc: 0.9654 - val_loss: 0.1198 - val_acc: 0.9705\n",
      "Epoch 246/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.1209 - acc: 0.9699 - val_loss: 0.1197 - val_acc: 0.9688\n",
      "Epoch 247/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1195 - acc: 0.9691 - val_loss: 0.1204 - val_acc: 0.9632\n",
      "Epoch 248/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1205 - acc: 0.9677 - val_loss: 0.1177 - val_acc: 0.9724\n",
      "Epoch 249/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.1190 - acc: 0.9683 - val_loss: 0.1176 - val_acc: 0.9727\n",
      "Epoch 250/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.1182 - acc: 0.9699 - val_loss: 0.1213 - val_acc: 0.9604\n",
      "Epoch 251/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.1188 - acc: 0.9684 - val_loss: 0.1172 - val_acc: 0.9673\n",
      "Epoch 252/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.1172 - acc: 0.9681 - val_loss: 0.1155 - val_acc: 0.9737\n",
      "Epoch 253/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1171 - acc: 0.9676 - val_loss: 0.1184 - val_acc: 0.9604\n",
      "Epoch 254/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1163 - acc: 0.9688 - val_loss: 0.1161 - val_acc: 0.9670\n",
      "Epoch 255/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1180 - acc: 0.9644 - val_loss: 0.1161 - val_acc: 0.9672\n",
      "Epoch 256/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1152 - acc: 0.9691 - val_loss: 0.1148 - val_acc: 0.9705\n",
      "Epoch 257/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1144 - acc: 0.9688 - val_loss: 0.1145 - val_acc: 0.9685\n",
      "Epoch 258/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1132 - acc: 0.9709 - val_loss: 0.1130 - val_acc: 0.9737\n",
      "Epoch 259/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1137 - acc: 0.9705 - val_loss: 0.1137 - val_acc: 0.9667\n",
      "Epoch 260/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1130 - acc: 0.9693 - val_loss: 0.1124 - val_acc: 0.9709\n",
      "Epoch 261/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1116 - acc: 0.9719 - val_loss: 0.1128 - val_acc: 0.9670\n",
      "Epoch 262/300\n",
      "17858/17858 [==============================] - 0s 21us/step - loss: 0.1115 - acc: 0.9709 - val_loss: 0.1107 - val_acc: 0.9696\n",
      "Epoch 263/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.1107 - acc: 0.9726 - val_loss: 0.1113 - val_acc: 0.9682\n",
      "Epoch 264/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.1101 - acc: 0.9708 - val_loss: 0.1082 - val_acc: 0.9756\n",
      "Epoch 265/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.1102 - acc: 0.9709 - val_loss: 0.1102 - val_acc: 0.9658\n",
      "Epoch 266/300\n",
      "17858/17858 [==============================] - 0s 23us/step - loss: 0.1104 - acc: 0.9721 - val_loss: 0.1090 - val_acc: 0.9718\n",
      "Epoch 267/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.1092 - acc: 0.9707 - val_loss: 0.1069 - val_acc: 0.9751\n",
      "Epoch 268/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1080 - acc: 0.9726 - val_loss: 0.1072 - val_acc: 0.9727\n",
      "Epoch 269/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.1081 - acc: 0.9711 - val_loss: 0.1063 - val_acc: 0.9768\n",
      "Epoch 270/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.1079 - acc: 0.9708 - val_loss: 0.1078 - val_acc: 0.9724\n",
      "Epoch 271/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1060 - acc: 0.9732 - val_loss: 0.1065 - val_acc: 0.9696\n",
      "Epoch 272/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1065 - acc: 0.9709 - val_loss: 0.1072 - val_acc: 0.9673\n",
      "Epoch 273/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1062 - acc: 0.9713 - val_loss: 0.1054 - val_acc: 0.9714\n",
      "Epoch 274/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1057 - acc: 0.9726 - val_loss: 0.1064 - val_acc: 0.9668\n",
      "Epoch 275/300\n",
      "17858/17858 [==============================] - 0s 22us/step - loss: 0.1060 - acc: 0.9694 - val_loss: 0.1042 - val_acc: 0.9772\n",
      "Epoch 276/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.1040 - acc: 0.9719 - val_loss: 0.1025 - val_acc: 0.9758\n",
      "Epoch 277/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1032 - acc: 0.9714 - val_loss: 0.1023 - val_acc: 0.9727\n",
      "Epoch 278/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.1025 - acc: 0.9751 - val_loss: 0.1015 - val_acc: 0.9776\n",
      "Epoch 279/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.1023 - acc: 0.9731 - val_loss: 0.1040 - val_acc: 0.9749\n",
      "Epoch 280/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.1024 - acc: 0.9727 - val_loss: 0.1010 - val_acc: 0.9768\n",
      "Epoch 281/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.1015 - acc: 0.9735 - val_loss: 0.1012 - val_acc: 0.9747\n",
      "Epoch 282/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1010 - acc: 0.9748 - val_loss: 0.1014 - val_acc: 0.9736\n",
      "Epoch 283/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1003 - acc: 0.9745 - val_loss: 0.0992 - val_acc: 0.9762\n",
      "Epoch 284/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1005 - acc: 0.9736 - val_loss: 0.0991 - val_acc: 0.9758\n",
      "Epoch 285/300\n",
      "17858/17858 [==============================] - 0s 21us/step - loss: 0.0994 - acc: 0.9748 - val_loss: 0.0982 - val_acc: 0.9778\n",
      "Epoch 286/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.0993 - acc: 0.9724 - val_loss: 0.0991 - val_acc: 0.9704\n",
      "Epoch 287/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.0999 - acc: 0.9742 - val_loss: 0.0988 - val_acc: 0.9756\n",
      "Epoch 288/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0986 - acc: 0.9762 - val_loss: 0.0978 - val_acc: 0.9722\n",
      "Epoch 289/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0995 - acc: 0.9692 - val_loss: 0.1034 - val_acc: 0.9599\n",
      "Epoch 290/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.1009 - acc: 0.9682 - val_loss: 0.0961 - val_acc: 0.9765\n",
      "Epoch 291/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.0969 - acc: 0.9745 - val_loss: 0.0965 - val_acc: 0.9730\n",
      "Epoch 292/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.0964 - acc: 0.9723 - val_loss: 0.0957 - val_acc: 0.9756\n",
      "Epoch 293/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.0961 - acc: 0.9757 - val_loss: 0.0954 - val_acc: 0.9769\n",
      "Epoch 294/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0957 - acc: 0.9765 - val_loss: 0.0942 - val_acc: 0.9747\n",
      "Epoch 295/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.0958 - acc: 0.9751 - val_loss: 0.0966 - val_acc: 0.9676\n",
      "Epoch 296/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0955 - acc: 0.9740 - val_loss: 0.0934 - val_acc: 0.9786\n",
      "Epoch 297/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0949 - acc: 0.9741 - val_loss: 0.0942 - val_acc: 0.9797\n",
      "Epoch 298/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0941 - acc: 0.9766 - val_loss: 0.0931 - val_acc: 0.9791\n",
      "Epoch 299/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0942 - acc: 0.9733 - val_loss: 0.0946 - val_acc: 0.9680\n",
      "Epoch 300/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.0933 - acc: 0.9759 - val_loss: 0.0934 - val_acc: 0.9762\n",
      "17859/17859 [==============================] - 1s 82us/step\n",
      "17858/17858 [==============================] - 2s 90us/step\n",
      "Train on 17858 samples, validate on 17858 samples\n",
      "Epoch 1/300\n",
      "17858/17858 [==============================] - 4s 227us/step - loss: 3.3640 - acc: 0.0483 - val_loss: 3.2724 - val_acc: 0.0645\n",
      "Epoch 2/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 3.1656 - acc: 0.0713 - val_loss: 3.0403 - val_acc: 0.0731\n",
      "Epoch 3/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 2.9181 - acc: 0.0778 - val_loss: 2.7914 - val_acc: 0.0838\n",
      "Epoch 4/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 2.6861 - acc: 0.1348 - val_loss: 2.5783 - val_acc: 0.2046\n",
      "Epoch 5/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 2.4875 - acc: 0.2408 - val_loss: 2.3929 - val_acc: 0.2556\n",
      "Epoch 6/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 2.3122 - acc: 0.2922 - val_loss: 2.2250 - val_acc: 0.3522\n",
      "Epoch 7/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 2.1515 - acc: 0.3531 - val_loss: 2.0737 - val_acc: 0.3919\n",
      "Epoch 8/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 2.0099 - acc: 0.3833 - val_loss: 1.9428 - val_acc: 0.4017\n",
      "Epoch 9/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 1.8884 - acc: 0.4476 - val_loss: 1.8295 - val_acc: 0.4481\n",
      "Epoch 10/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 1.7815 - acc: 0.4747 - val_loss: 1.7315 - val_acc: 0.4877\n",
      "Epoch 11/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.6889 - acc: 0.5042 - val_loss: 1.6411 - val_acc: 0.5453\n",
      "Epoch 12/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.6036 - acc: 0.5410 - val_loss: 1.5640 - val_acc: 0.5596\n",
      "Epoch 13/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.5306 - acc: 0.5613 - val_loss: 1.4925 - val_acc: 0.5723\n",
      "Epoch 14/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 1.4631 - acc: 0.5965 - val_loss: 1.4288 - val_acc: 0.5877\n",
      "Epoch 15/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 1.4024 - acc: 0.5982 - val_loss: 1.3713 - val_acc: 0.6152\n",
      "Epoch 16/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 1.3464 - acc: 0.6191 - val_loss: 1.3173 - val_acc: 0.6211\n",
      "Epoch 17/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.2952 - acc: 0.6243 - val_loss: 1.2691 - val_acc: 0.6691\n",
      "Epoch 18/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 1.2466 - acc: 0.6458 - val_loss: 1.2219 - val_acc: 0.6321\n",
      "Epoch 19/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 1.2024 - acc: 0.6537 - val_loss: 1.1791 - val_acc: 0.6900\n",
      "Epoch 20/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 1.1632 - acc: 0.6631 - val_loss: 1.1396 - val_acc: 0.6931\n",
      "Epoch 21/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.1245 - acc: 0.6830 - val_loss: 1.1038 - val_acc: 0.6781\n",
      "Epoch 22/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 1.0894 - acc: 0.6918 - val_loss: 1.0695 - val_acc: 0.7033\n",
      "Epoch 23/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.0544 - acc: 0.7028 - val_loss: 1.0356 - val_acc: 0.7253\n",
      "Epoch 24/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.0224 - acc: 0.7199 - val_loss: 1.0059 - val_acc: 0.7241\n",
      "Epoch 25/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.9935 - acc: 0.7276 - val_loss: 0.9749 - val_acc: 0.7299\n",
      "Epoch 26/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.9644 - acc: 0.7334 - val_loss: 0.9490 - val_acc: 0.7429\n",
      "Epoch 27/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.9372 - acc: 0.7443 - val_loss: 0.9234 - val_acc: 0.7481\n",
      "Epoch 28/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.9133 - acc: 0.7387 - val_loss: 0.8979 - val_acc: 0.7489\n",
      "Epoch 29/300\n",
      "17858/17858 [==============================] - 0s 21us/step - loss: 0.8874 - acc: 0.7567 - val_loss: 0.8752 - val_acc: 0.7548\n",
      "Epoch 30/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.8652 - acc: 0.7590 - val_loss: 0.8506 - val_acc: 0.7596\n",
      "Epoch 31/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.8414 - acc: 0.7758 - val_loss: 0.8313 - val_acc: 0.7763\n",
      "Epoch 32/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.8233 - acc: 0.7759 - val_loss: 0.8102 - val_acc: 0.7911\n",
      "Epoch 33/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.8027 - acc: 0.7804 - val_loss: 0.7922 - val_acc: 0.7853\n",
      "Epoch 34/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.7844 - acc: 0.7913 - val_loss: 0.7724 - val_acc: 0.8065\n",
      "Epoch 35/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.7658 - acc: 0.7955 - val_loss: 0.7555 - val_acc: 0.7914\n",
      "Epoch 36/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.7493 - acc: 0.7931 - val_loss: 0.7409 - val_acc: 0.7992\n",
      "Epoch 37/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.7332 - acc: 0.7964 - val_loss: 0.7248 - val_acc: 0.8052\n",
      "Epoch 38/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.7174 - acc: 0.8059 - val_loss: 0.7061 - val_acc: 0.8084\n",
      "Epoch 39/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.7029 - acc: 0.8052 - val_loss: 0.6940 - val_acc: 0.8216\n",
      "Epoch 40/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.6882 - acc: 0.8121 - val_loss: 0.6837 - val_acc: 0.7944\n",
      "Epoch 41/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.6763 - acc: 0.8116 - val_loss: 0.6670 - val_acc: 0.8273\n",
      "Epoch 42/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.6613 - acc: 0.8159 - val_loss: 0.6545 - val_acc: 0.8240\n",
      "Epoch 43/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.6503 - acc: 0.8233 - val_loss: 0.6446 - val_acc: 0.8071\n",
      "Epoch 44/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.6376 - acc: 0.8247 - val_loss: 0.6300 - val_acc: 0.8320\n",
      "Epoch 45/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.6261 - acc: 0.8265 - val_loss: 0.6209 - val_acc: 0.8238\n",
      "Epoch 46/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.6153 - acc: 0.8279 - val_loss: 0.6116 - val_acc: 0.8231\n",
      "Epoch 47/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.6056 - acc: 0.8302 - val_loss: 0.6004 - val_acc: 0.8156\n",
      "Epoch 48/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.5974 - acc: 0.8280 - val_loss: 0.5927 - val_acc: 0.8101\n",
      "Epoch 49/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5866 - acc: 0.8297 - val_loss: 0.5765 - val_acc: 0.8416\n",
      "Epoch 50/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5751 - acc: 0.8341 - val_loss: 0.5687 - val_acc: 0.8306\n",
      "Epoch 51/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.5669 - acc: 0.8368 - val_loss: 0.5604 - val_acc: 0.8326\n",
      "Epoch 52/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.5571 - acc: 0.8389 - val_loss: 0.5519 - val_acc: 0.8367\n",
      "Epoch 53/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5509 - acc: 0.8387 - val_loss: 0.5421 - val_acc: 0.8451\n",
      "Epoch 54/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5430 - acc: 0.8303 - val_loss: 0.5377 - val_acc: 0.8350\n",
      "Epoch 55/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5335 - acc: 0.8448 - val_loss: 0.5324 - val_acc: 0.8317\n",
      "Epoch 56/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5274 - acc: 0.8387 - val_loss: 0.5186 - val_acc: 0.8578\n",
      "Epoch 57/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5159 - acc: 0.8493 - val_loss: 0.5115 - val_acc: 0.8507\n",
      "Epoch 58/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.5091 - acc: 0.8474 - val_loss: 0.5069 - val_acc: 0.8501\n",
      "Epoch 59/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5034 - acc: 0.8506 - val_loss: 0.4995 - val_acc: 0.8519\n",
      "Epoch 60/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.4954 - acc: 0.8543 - val_loss: 0.4898 - val_acc: 0.8589\n",
      "Epoch 61/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.4894 - acc: 0.8536 - val_loss: 0.4849 - val_acc: 0.8505\n",
      "Epoch 62/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.4819 - acc: 0.8559 - val_loss: 0.4791 - val_acc: 0.8484\n",
      "Epoch 63/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4760 - acc: 0.8569 - val_loss: 0.4718 - val_acc: 0.8554\n",
      "Epoch 64/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.4710 - acc: 0.8565 - val_loss: 0.4691 - val_acc: 0.8703\n",
      "Epoch 65/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4655 - acc: 0.8587 - val_loss: 0.4604 - val_acc: 0.8556\n",
      "Epoch 66/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.4602 - acc: 0.8594 - val_loss: 0.4587 - val_acc: 0.8508\n",
      "Epoch 67/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4532 - acc: 0.8633 - val_loss: 0.4481 - val_acc: 0.8667\n",
      "Epoch 68/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.4476 - acc: 0.8626 - val_loss: 0.4488 - val_acc: 0.8657\n",
      "Epoch 69/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4449 - acc: 0.8622 - val_loss: 0.4405 - val_acc: 0.8652\n",
      "Epoch 70/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.4381 - acc: 0.8638 - val_loss: 0.4344 - val_acc: 0.8635\n",
      "Epoch 71/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4333 - acc: 0.8659 - val_loss: 0.4307 - val_acc: 0.8598\n",
      "Epoch 72/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.4287 - acc: 0.8661 - val_loss: 0.4251 - val_acc: 0.8722\n",
      "Epoch 73/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4229 - acc: 0.8685 - val_loss: 0.4246 - val_acc: 0.8680\n",
      "Epoch 74/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.4195 - acc: 0.8714 - val_loss: 0.4139 - val_acc: 0.8781\n",
      "Epoch 75/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4140 - acc: 0.8733 - val_loss: 0.4100 - val_acc: 0.8748\n",
      "Epoch 76/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.4107 - acc: 0.8749 - val_loss: 0.4069 - val_acc: 0.8739\n",
      "Epoch 77/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.4069 - acc: 0.8755 - val_loss: 0.4033 - val_acc: 0.8670\n",
      "Epoch 78/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.4024 - acc: 0.8738 - val_loss: 0.3982 - val_acc: 0.8792\n",
      "Epoch 79/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3975 - acc: 0.8794 - val_loss: 0.3946 - val_acc: 0.8784\n",
      "Epoch 80/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3954 - acc: 0.8767 - val_loss: 0.3924 - val_acc: 0.8759\n",
      "Epoch 81/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.3908 - acc: 0.8781 - val_loss: 0.3882 - val_acc: 0.8855\n",
      "Epoch 82/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3861 - acc: 0.8794 - val_loss: 0.3853 - val_acc: 0.8718\n",
      "Epoch 83/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3844 - acc: 0.8794 - val_loss: 0.3804 - val_acc: 0.8764\n",
      "Epoch 84/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.3775 - acc: 0.8820 - val_loss: 0.3752 - val_acc: 0.8832\n",
      "Epoch 85/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3753 - acc: 0.8839 - val_loss: 0.3694 - val_acc: 0.8846\n",
      "Epoch 86/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.3706 - acc: 0.8820 - val_loss: 0.3678 - val_acc: 0.8813\n",
      "Epoch 87/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.3668 - acc: 0.8846 - val_loss: 0.3652 - val_acc: 0.8823\n",
      "Epoch 88/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.3658 - acc: 0.8853 - val_loss: 0.3596 - val_acc: 0.8855\n",
      "Epoch 89/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3605 - acc: 0.8863 - val_loss: 0.3583 - val_acc: 0.8851\n",
      "Epoch 90/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3569 - acc: 0.8879 - val_loss: 0.3540 - val_acc: 0.8865\n",
      "Epoch 91/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.3536 - acc: 0.8877 - val_loss: 0.3536 - val_acc: 0.8925\n",
      "Epoch 92/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.3514 - acc: 0.8885 - val_loss: 0.3484 - val_acc: 0.8877\n",
      "Epoch 93/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3486 - acc: 0.8884 - val_loss: 0.3448 - val_acc: 0.8907\n",
      "Epoch 94/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.3448 - acc: 0.8906 - val_loss: 0.3428 - val_acc: 0.8905\n",
      "Epoch 95/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3432 - acc: 0.8931 - val_loss: 0.3416 - val_acc: 0.8948\n",
      "Epoch 96/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.3393 - acc: 0.8894 - val_loss: 0.3395 - val_acc: 0.8892\n",
      "Epoch 97/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3384 - acc: 0.8924 - val_loss: 0.3344 - val_acc: 0.8928\n",
      "Epoch 98/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3345 - acc: 0.8915 - val_loss: 0.3301 - val_acc: 0.8900\n",
      "Epoch 99/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3303 - acc: 0.8937 - val_loss: 0.3307 - val_acc: 0.8909\n",
      "Epoch 100/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3284 - acc: 0.8910 - val_loss: 0.3276 - val_acc: 0.8888\n",
      "Epoch 101/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3258 - acc: 0.8947 - val_loss: 0.3228 - val_acc: 0.8967\n",
      "Epoch 102/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3237 - acc: 0.8941 - val_loss: 0.3231 - val_acc: 0.8948\n",
      "Epoch 103/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3228 - acc: 0.8951 - val_loss: 0.3181 - val_acc: 0.9008\n",
      "Epoch 104/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3182 - acc: 0.8977 - val_loss: 0.3142 - val_acc: 0.8956\n",
      "Epoch 105/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3153 - acc: 0.8983 - val_loss: 0.3166 - val_acc: 0.8917\n",
      "Epoch 106/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3133 - acc: 0.8975 - val_loss: 0.3115 - val_acc: 0.8952\n",
      "Epoch 107/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3115 - acc: 0.8997 - val_loss: 0.3084 - val_acc: 0.8977\n",
      "Epoch 108/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3086 - acc: 0.8963 - val_loss: 0.3072 - val_acc: 0.9007\n",
      "Epoch 109/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3082 - acc: 0.9011 - val_loss: 0.3052 - val_acc: 0.8981\n",
      "Epoch 110/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3047 - acc: 0.8995 - val_loss: 0.3014 - val_acc: 0.9030\n",
      "Epoch 111/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.3010 - acc: 0.9026 - val_loss: 0.2995 - val_acc: 0.9109\n",
      "Epoch 112/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2988 - acc: 0.9014 - val_loss: 0.2970 - val_acc: 0.9058\n",
      "Epoch 113/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2967 - acc: 0.9018 - val_loss: 0.2958 - val_acc: 0.8980\n",
      "Epoch 114/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2957 - acc: 0.9045 - val_loss: 0.2920 - val_acc: 0.9116\n",
      "Epoch 115/300\n",
      "17858/17858 [==============================] - 0s 13us/step - loss: 0.2933 - acc: 0.9048 - val_loss: 0.2929 - val_acc: 0.9117\n",
      "Epoch 116/300\n",
      "17858/17858 [==============================] - 0s 13us/step - loss: 0.2896 - acc: 0.9064 - val_loss: 0.2879 - val_acc: 0.9054\n",
      "Epoch 117/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2893 - acc: 0.9056 - val_loss: 0.2881 - val_acc: 0.9176\n",
      "Epoch 118/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2869 - acc: 0.9074 - val_loss: 0.2874 - val_acc: 0.9060\n",
      "Epoch 119/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2844 - acc: 0.9089 - val_loss: 0.2816 - val_acc: 0.9023\n",
      "Epoch 120/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2833 - acc: 0.9056 - val_loss: 0.2801 - val_acc: 0.9176\n",
      "Epoch 121/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2813 - acc: 0.9073 - val_loss: 0.2832 - val_acc: 0.9216\n",
      "Epoch 122/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2804 - acc: 0.9089 - val_loss: 0.2800 - val_acc: 0.9188\n",
      "Epoch 123/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.2768 - acc: 0.9099 - val_loss: 0.2733 - val_acc: 0.9093\n",
      "Epoch 124/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2754 - acc: 0.9124 - val_loss: 0.2724 - val_acc: 0.9131\n",
      "Epoch 125/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2734 - acc: 0.9125 - val_loss: 0.2745 - val_acc: 0.9268\n",
      "Epoch 126/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2715 - acc: 0.9115 - val_loss: 0.2701 - val_acc: 0.9095\n",
      "Epoch 127/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2713 - acc: 0.9120 - val_loss: 0.2694 - val_acc: 0.9099\n",
      "Epoch 128/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2697 - acc: 0.9125 - val_loss: 0.2663 - val_acc: 0.9073\n",
      "Epoch 129/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2681 - acc: 0.9117 - val_loss: 0.2660 - val_acc: 0.9186\n",
      "Epoch 130/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2665 - acc: 0.9151 - val_loss: 0.2618 - val_acc: 0.9223\n",
      "Epoch 131/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2629 - acc: 0.9161 - val_loss: 0.2597 - val_acc: 0.9234\n",
      "Epoch 132/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2606 - acc: 0.9181 - val_loss: 0.2602 - val_acc: 0.9273\n",
      "Epoch 133/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2592 - acc: 0.9184 - val_loss: 0.2562 - val_acc: 0.9268\n",
      "Epoch 134/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2570 - acc: 0.9207 - val_loss: 0.2547 - val_acc: 0.9275\n",
      "Epoch 135/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2560 - acc: 0.9177 - val_loss: 0.2557 - val_acc: 0.9297\n",
      "Epoch 136/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2554 - acc: 0.9167 - val_loss: 0.2582 - val_acc: 0.9101\n",
      "Epoch 137/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2541 - acc: 0.9186 - val_loss: 0.2549 - val_acc: 0.9218\n",
      "Epoch 138/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2514 - acc: 0.9222 - val_loss: 0.2476 - val_acc: 0.9235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.2490 - acc: 0.9241 - val_loss: 0.2482 - val_acc: 0.9271\n",
      "Epoch 140/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2487 - acc: 0.9217 - val_loss: 0.2506 - val_acc: 0.9241\n",
      "Epoch 141/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2464 - acc: 0.9217 - val_loss: 0.2423 - val_acc: 0.9327\n",
      "Epoch 142/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2442 - acc: 0.9252 - val_loss: 0.2438 - val_acc: 0.9252\n",
      "Epoch 143/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2447 - acc: 0.9208 - val_loss: 0.2430 - val_acc: 0.9212\n",
      "Epoch 144/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2423 - acc: 0.9270 - val_loss: 0.2402 - val_acc: 0.9316\n",
      "Epoch 145/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2406 - acc: 0.9247 - val_loss: 0.2396 - val_acc: 0.9134\n",
      "Epoch 146/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2397 - acc: 0.9260 - val_loss: 0.2381 - val_acc: 0.9311\n",
      "Epoch 147/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2380 - acc: 0.9253 - val_loss: 0.2374 - val_acc: 0.9316\n",
      "Epoch 148/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2354 - acc: 0.9270 - val_loss: 0.2341 - val_acc: 0.9314\n",
      "Epoch 149/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2355 - acc: 0.9298 - val_loss: 0.2365 - val_acc: 0.9112\n",
      "Epoch 150/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2350 - acc: 0.9254 - val_loss: 0.2305 - val_acc: 0.9311\n",
      "Epoch 151/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2327 - acc: 0.9280 - val_loss: 0.2289 - val_acc: 0.9320\n",
      "Epoch 152/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2291 - acc: 0.9319 - val_loss: 0.2283 - val_acc: 0.9219\n",
      "Epoch 153/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2281 - acc: 0.9326 - val_loss: 0.2247 - val_acc: 0.9381\n",
      "Epoch 154/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2265 - acc: 0.9335 - val_loss: 0.2261 - val_acc: 0.9325\n",
      "Epoch 155/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2270 - acc: 0.9325 - val_loss: 0.2268 - val_acc: 0.9368\n",
      "Epoch 156/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2247 - acc: 0.9340 - val_loss: 0.2269 - val_acc: 0.9319\n",
      "Epoch 157/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2238 - acc: 0.9316 - val_loss: 0.2235 - val_acc: 0.9377\n",
      "Epoch 158/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2228 - acc: 0.9326 - val_loss: 0.2208 - val_acc: 0.9255\n",
      "Epoch 159/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2223 - acc: 0.9330 - val_loss: 0.2172 - val_acc: 0.9389\n",
      "Epoch 160/300\n",
      "17858/17858 [==============================] - ETA: 0s - loss: 0.2206 - acc: 0.932 - 0s 14us/step - loss: 0.2204 - acc: 0.9326 - val_loss: 0.2212 - val_acc: 0.9341\n",
      "Epoch 161/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2186 - acc: 0.9354 - val_loss: 0.2191 - val_acc: 0.9321\n",
      "Epoch 162/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2167 - acc: 0.9340 - val_loss: 0.2137 - val_acc: 0.9405\n",
      "Epoch 163/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.2157 - acc: 0.9361 - val_loss: 0.2200 - val_acc: 0.9330\n",
      "Epoch 164/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2160 - acc: 0.9368 - val_loss: 0.2145 - val_acc: 0.9411\n",
      "Epoch 165/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2139 - acc: 0.9367 - val_loss: 0.2171 - val_acc: 0.9319\n",
      "Epoch 166/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2132 - acc: 0.9343 - val_loss: 0.2092 - val_acc: 0.9400\n",
      "Epoch 167/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2100 - acc: 0.9384 - val_loss: 0.2079 - val_acc: 0.9433\n",
      "Epoch 168/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2098 - acc: 0.9405 - val_loss: 0.2090 - val_acc: 0.9448\n",
      "Epoch 169/300\n",
      "17858/17858 [==============================] - 0s 13us/step - loss: 0.2079 - acc: 0.9399 - val_loss: 0.2062 - val_acc: 0.9402\n",
      "Epoch 170/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2071 - acc: 0.9403 - val_loss: 0.2046 - val_acc: 0.9430\n",
      "Epoch 171/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2058 - acc: 0.9396 - val_loss: 0.2048 - val_acc: 0.9430\n",
      "Epoch 172/300\n",
      "17858/17858 [==============================] - 0s 13us/step - loss: 0.2049 - acc: 0.9413 - val_loss: 0.2038 - val_acc: 0.9422\n",
      "Epoch 173/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2055 - acc: 0.9418 - val_loss: 0.2044 - val_acc: 0.9405\n",
      "Epoch 174/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.2035 - acc: 0.9395 - val_loss: 0.2036 - val_acc: 0.9363\n",
      "Epoch 175/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2041 - acc: 0.9403 - val_loss: 0.2058 - val_acc: 0.9401\n",
      "Epoch 176/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2002 - acc: 0.9421 - val_loss: 0.1992 - val_acc: 0.9406\n",
      "Epoch 177/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1992 - acc: 0.9425 - val_loss: 0.2001 - val_acc: 0.9381\n",
      "Epoch 178/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1983 - acc: 0.9425 - val_loss: 0.1968 - val_acc: 0.9450\n",
      "Epoch 179/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1968 - acc: 0.9423 - val_loss: 0.1969 - val_acc: 0.9418\n",
      "Epoch 180/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1956 - acc: 0.9408 - val_loss: 0.1959 - val_acc: 0.9359\n",
      "Epoch 181/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1941 - acc: 0.9438 - val_loss: 0.1947 - val_acc: 0.9436\n",
      "Epoch 182/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1957 - acc: 0.9434 - val_loss: 0.1954 - val_acc: 0.9377\n",
      "Epoch 183/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1933 - acc: 0.9437 - val_loss: 0.1919 - val_acc: 0.9479\n",
      "Epoch 184/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1928 - acc: 0.9446 - val_loss: 0.1896 - val_acc: 0.9474\n",
      "Epoch 185/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1908 - acc: 0.9444 - val_loss: 0.1900 - val_acc: 0.9454\n",
      "Epoch 186/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1906 - acc: 0.9431 - val_loss: 0.1904 - val_acc: 0.9407\n",
      "Epoch 187/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1899 - acc: 0.9438 - val_loss: 0.1883 - val_acc: 0.9441\n",
      "Epoch 188/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1875 - acc: 0.9462 - val_loss: 0.1853 - val_acc: 0.9464\n",
      "Epoch 189/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1858 - acc: 0.9453 - val_loss: 0.1881 - val_acc: 0.9406\n",
      "Epoch 190/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1862 - acc: 0.9445 - val_loss: 0.1853 - val_acc: 0.9461\n",
      "Epoch 191/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1850 - acc: 0.9469 - val_loss: 0.1835 - val_acc: 0.9453\n",
      "Epoch 192/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1844 - acc: 0.9439 - val_loss: 0.1812 - val_acc: 0.9467\n",
      "Epoch 193/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1836 - acc: 0.9476 - val_loss: 0.1808 - val_acc: 0.9461\n",
      "Epoch 194/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1821 - acc: 0.9461 - val_loss: 0.1855 - val_acc: 0.9538\n",
      "Epoch 195/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1812 - acc: 0.9454 - val_loss: 0.1793 - val_acc: 0.9491\n",
      "Epoch 196/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1781 - acc: 0.9490 - val_loss: 0.1774 - val_acc: 0.9474\n",
      "Epoch 197/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1777 - acc: 0.9490 - val_loss: 0.1757 - val_acc: 0.9492\n",
      "Epoch 198/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1773 - acc: 0.9467 - val_loss: 0.1758 - val_acc: 0.9470\n",
      "Epoch 199/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1769 - acc: 0.9469 - val_loss: 0.1765 - val_acc: 0.9434\n",
      "Epoch 200/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1761 - acc: 0.9492 - val_loss: 0.1738 - val_acc: 0.9489\n",
      "Epoch 201/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1756 - acc: 0.9480 - val_loss: 0.1724 - val_acc: 0.9488\n",
      "Epoch 202/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1756 - acc: 0.9484 - val_loss: 0.1715 - val_acc: 0.9490\n",
      "Epoch 203/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1727 - acc: 0.9525 - val_loss: 0.1726 - val_acc: 0.9560\n",
      "Epoch 204/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1724 - acc: 0.9502 - val_loss: 0.1723 - val_acc: 0.9517\n",
      "Epoch 205/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1716 - acc: 0.9513 - val_loss: 0.1708 - val_acc: 0.9555\n",
      "Epoch 206/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1694 - acc: 0.9508 - val_loss: 0.1699 - val_acc: 0.9490\n",
      "Epoch 207/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1688 - acc: 0.9496 - val_loss: 0.1681 - val_acc: 0.9569\n",
      "Epoch 208/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1687 - acc: 0.9515 - val_loss: 0.1702 - val_acc: 0.9587\n",
      "Epoch 209/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1678 - acc: 0.9504 - val_loss: 0.1648 - val_acc: 0.9500\n",
      "Epoch 210/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1666 - acc: 0.9525 - val_loss: 0.1679 - val_acc: 0.9560\n",
      "Epoch 211/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1665 - acc: 0.9521 - val_loss: 0.1681 - val_acc: 0.9472\n",
      "Epoch 212/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1645 - acc: 0.9525 - val_loss: 0.1624 - val_acc: 0.9490\n",
      "Epoch 213/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1647 - acc: 0.9506 - val_loss: 0.1624 - val_acc: 0.9525\n",
      "Epoch 214/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1627 - acc: 0.9518 - val_loss: 0.1605 - val_acc: 0.9498\n",
      "Epoch 215/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1635 - acc: 0.9515 - val_loss: 0.1630 - val_acc: 0.9575\n",
      "Epoch 216/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1616 - acc: 0.9535 - val_loss: 0.1593 - val_acc: 0.9530\n",
      "Epoch 217/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1587 - acc: 0.9547 - val_loss: 0.1598 - val_acc: 0.9565\n",
      "Epoch 218/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1591 - acc: 0.9547 - val_loss: 0.1620 - val_acc: 0.9518\n",
      "Epoch 219/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1591 - acc: 0.9539 - val_loss: 0.1559 - val_acc: 0.9530\n",
      "Epoch 220/300\n",
      "17858/17858 [==============================] - ETA: 0s - loss: 0.1565 - acc: 0.956 - 0s 14us/step - loss: 0.1570 - acc: 0.9553 - val_loss: 0.1585 - val_acc: 0.9503\n",
      "Epoch 221/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1572 - acc: 0.9536 - val_loss: 0.1599 - val_acc: 0.9514\n",
      "Epoch 222/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1583 - acc: 0.9523 - val_loss: 0.1595 - val_acc: 0.9582\n",
      "Epoch 223/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1548 - acc: 0.9559 - val_loss: 0.1538 - val_acc: 0.9593\n",
      "Epoch 224/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1546 - acc: 0.9554 - val_loss: 0.1567 - val_acc: 0.9574\n",
      "Epoch 225/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1539 - acc: 0.9569 - val_loss: 0.1511 - val_acc: 0.9583\n",
      "Epoch 226/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1526 - acc: 0.9560 - val_loss: 0.1507 - val_acc: 0.9609\n",
      "Epoch 227/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1511 - acc: 0.9572 - val_loss: 0.1512 - val_acc: 0.9521\n",
      "Epoch 228/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1502 - acc: 0.9572 - val_loss: 0.1501 - val_acc: 0.9554\n",
      "Epoch 229/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1511 - acc: 0.9566 - val_loss: 0.1515 - val_acc: 0.9612\n",
      "Epoch 230/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1499 - acc: 0.9582 - val_loss: 0.1482 - val_acc: 0.9615\n",
      "Epoch 231/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1481 - acc: 0.9586 - val_loss: 0.1475 - val_acc: 0.9521\n",
      "Epoch 232/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1483 - acc: 0.9576 - val_loss: 0.1477 - val_acc: 0.9588\n",
      "Epoch 233/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1484 - acc: 0.9567 - val_loss: 0.1477 - val_acc: 0.9615\n",
      "Epoch 234/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1472 - acc: 0.9585 - val_loss: 0.1483 - val_acc: 0.9502\n",
      "Epoch 235/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1463 - acc: 0.9572 - val_loss: 0.1428 - val_acc: 0.9620\n",
      "Epoch 236/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1443 - acc: 0.9596 - val_loss: 0.1425 - val_acc: 0.9550\n",
      "Epoch 237/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1425 - acc: 0.9592 - val_loss: 0.1420 - val_acc: 0.9606\n",
      "Epoch 238/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1419 - acc: 0.9600 - val_loss: 0.1413 - val_acc: 0.9615\n",
      "Epoch 239/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1415 - acc: 0.9606 - val_loss: 0.1403 - val_acc: 0.9623\n",
      "Epoch 240/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1407 - acc: 0.9598 - val_loss: 0.1402 - val_acc: 0.9626\n",
      "Epoch 241/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1409 - acc: 0.9607 - val_loss: 0.1394 - val_acc: 0.9596\n",
      "Epoch 242/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1402 - acc: 0.9609 - val_loss: 0.1409 - val_acc: 0.9582\n",
      "Epoch 243/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1394 - acc: 0.9606 - val_loss: 0.1373 - val_acc: 0.9650\n",
      "Epoch 244/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1369 - acc: 0.9616 - val_loss: 0.1361 - val_acc: 0.9610\n",
      "Epoch 245/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1368 - acc: 0.9616 - val_loss: 0.1355 - val_acc: 0.9624\n",
      "Epoch 246/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1363 - acc: 0.9623 - val_loss: 0.1350 - val_acc: 0.9626\n",
      "Epoch 247/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1347 - acc: 0.9610 - val_loss: 0.1349 - val_acc: 0.9605\n",
      "Epoch 248/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1339 - acc: 0.9617 - val_loss: 0.1318 - val_acc: 0.9635\n",
      "Epoch 249/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1324 - acc: 0.9634 - val_loss: 0.1321 - val_acc: 0.9624\n",
      "Epoch 250/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1334 - acc: 0.9625 - val_loss: 0.1306 - val_acc: 0.9630\n",
      "Epoch 251/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1316 - acc: 0.9635 - val_loss: 0.1299 - val_acc: 0.9637\n",
      "Epoch 252/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1315 - acc: 0.9623 - val_loss: 0.1305 - val_acc: 0.9616\n",
      "Epoch 253/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1322 - acc: 0.9620 - val_loss: 0.1326 - val_acc: 0.9618\n",
      "Epoch 254/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1305 - acc: 0.9632 - val_loss: 0.1283 - val_acc: 0.9626\n",
      "Epoch 255/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1290 - acc: 0.9633 - val_loss: 0.1302 - val_acc: 0.9623\n",
      "Epoch 256/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1293 - acc: 0.9624 - val_loss: 0.1272 - val_acc: 0.9659\n",
      "Epoch 257/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1277 - acc: 0.9632 - val_loss: 0.1274 - val_acc: 0.9634\n",
      "Epoch 258/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1267 - acc: 0.9628 - val_loss: 0.1262 - val_acc: 0.9646\n",
      "Epoch 259/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1261 - acc: 0.9632 - val_loss: 0.1258 - val_acc: 0.9629\n",
      "Epoch 260/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1241 - acc: 0.9644 - val_loss: 0.1245 - val_acc: 0.9642\n",
      "Epoch 261/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1247 - acc: 0.9640 - val_loss: 0.1240 - val_acc: 0.9632\n",
      "Epoch 262/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1250 - acc: 0.9640 - val_loss: 0.1220 - val_acc: 0.9654\n",
      "Epoch 263/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1225 - acc: 0.9647 - val_loss: 0.1227 - val_acc: 0.9644\n",
      "Epoch 264/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1225 - acc: 0.9656 - val_loss: 0.1211 - val_acc: 0.9635\n",
      "Epoch 265/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1234 - acc: 0.9643 - val_loss: 0.1207 - val_acc: 0.9666\n",
      "Epoch 266/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1210 - acc: 0.9649 - val_loss: 0.1219 - val_acc: 0.9625\n",
      "Epoch 267/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1208 - acc: 0.9652 - val_loss: 0.1214 - val_acc: 0.9662\n",
      "Epoch 268/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1209 - acc: 0.9657 - val_loss: 0.1193 - val_acc: 0.9640\n",
      "Epoch 269/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1198 - acc: 0.9653 - val_loss: 0.1185 - val_acc: 0.9642\n",
      "Epoch 270/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1188 - acc: 0.9653 - val_loss: 0.1172 - val_acc: 0.9667\n",
      "Epoch 271/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1177 - acc: 0.9654 - val_loss: 0.1163 - val_acc: 0.9648\n",
      "Epoch 272/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1182 - acc: 0.9645 - val_loss: 0.1186 - val_acc: 0.9633\n",
      "Epoch 273/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1178 - acc: 0.9647 - val_loss: 0.1163 - val_acc: 0.9663\n",
      "Epoch 274/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1164 - acc: 0.9646 - val_loss: 0.1151 - val_acc: 0.9671\n",
      "Epoch 275/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1167 - acc: 0.9649 - val_loss: 0.1149 - val_acc: 0.9646\n",
      "Epoch 276/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1156 - acc: 0.9648 - val_loss: 0.1133 - val_acc: 0.9660\n",
      "Epoch 277/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1131 - acc: 0.9665 - val_loss: 0.1133 - val_acc: 0.9677\n",
      "Epoch 278/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1150 - acc: 0.9643 - val_loss: 0.1124 - val_acc: 0.9664\n",
      "Epoch 279/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1130 - acc: 0.9674 - val_loss: 0.1109 - val_acc: 0.9679\n",
      "Epoch 280/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1126 - acc: 0.9658 - val_loss: 0.1116 - val_acc: 0.9654\n",
      "Epoch 281/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1130 - acc: 0.9667 - val_loss: 0.1102 - val_acc: 0.9670\n",
      "Epoch 282/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1116 - acc: 0.9663 - val_loss: 0.1104 - val_acc: 0.9679\n",
      "Epoch 283/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1104 - acc: 0.9668 - val_loss: 0.1091 - val_acc: 0.9665\n",
      "Epoch 284/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1100 - acc: 0.9658 - val_loss: 0.1084 - val_acc: 0.9677\n",
      "Epoch 285/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1099 - acc: 0.9666 - val_loss: 0.1082 - val_acc: 0.9653\n",
      "Epoch 286/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1088 - acc: 0.9672 - val_loss: 0.1120 - val_acc: 0.9639\n",
      "Epoch 287/300\n",
      "17858/17858 [==============================] - 0s 13us/step - loss: 0.1080 - acc: 0.9683 - val_loss: 0.1066 - val_acc: 0.9682\n",
      "Epoch 288/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1078 - acc: 0.9677 - val_loss: 0.1069 - val_acc: 0.9656\n",
      "Epoch 289/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1074 - acc: 0.9671 - val_loss: 0.1061 - val_acc: 0.9675\n",
      "Epoch 290/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1076 - acc: 0.9664 - val_loss: 0.1056 - val_acc: 0.9676\n",
      "Epoch 291/300\n",
      "17858/17858 [==============================] - 0s 21us/step - loss: 0.1060 - acc: 0.9671 - val_loss: 0.1053 - val_acc: 0.9665\n",
      "Epoch 292/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1051 - acc: 0.9677 - val_loss: 0.1046 - val_acc: 0.9675\n",
      "Epoch 293/300\n",
      "17858/17858 [==============================] - 0s 22us/step - loss: 0.1054 - acc: 0.9670 - val_loss: 0.1106 - val_acc: 0.9639\n",
      "Epoch 294/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.1068 - acc: 0.9660 - val_loss: 0.1050 - val_acc: 0.9678\n",
      "Epoch 295/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1041 - acc: 0.9675 - val_loss: 0.1045 - val_acc: 0.9650\n",
      "Epoch 296/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.1044 - acc: 0.9664 - val_loss: 0.1047 - val_acc: 0.9657\n",
      "Epoch 297/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.1032 - acc: 0.9690 - val_loss: 0.1008 - val_acc: 0.9677\n",
      "Epoch 298/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.1025 - acc: 0.9683 - val_loss: 0.1004 - val_acc: 0.9678\n",
      "Epoch 299/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.1014 - acc: 0.9678 - val_loss: 0.1018 - val_acc: 0.9666\n",
      "Epoch 300/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.1020 - acc: 0.9667 - val_loss: 0.1029 - val_acc: 0.9644\n",
      "17859/17859 [==============================] - 2s 89us/step\n",
      "17858/17858 [==============================] - 1s 81us/step\n",
      "Train on 17858 samples, validate on 17858 samples\n",
      "Epoch 1/300\n",
      "17858/17858 [==============================] - 4s 225us/step - loss: 3.2958 - acc: 0.0703 - val_loss: 3.1922 - val_acc: 0.0788\n",
      "Epoch 2/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 3.0797 - acc: 0.0796 - val_loss: 2.9558 - val_acc: 0.0823\n",
      "Epoch 3/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 2.8503 - acc: 0.0965 - val_loss: 2.7453 - val_acc: 0.1254\n",
      "Epoch 4/300\n",
      "17858/17858 [==============================] - 0s 21us/step - loss: 2.6587 - acc: 0.1599 - val_loss: 2.5683 - val_acc: 0.1787\n",
      "Epoch 5/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 2.4877 - acc: 0.2149 - val_loss: 2.4010 - val_acc: 0.2168\n",
      "Epoch 6/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 2.3215 - acc: 0.2668 - val_loss: 2.2355 - val_acc: 0.2966\n",
      "Epoch 7/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 2.1598 - acc: 0.3356 - val_loss: 2.0782 - val_acc: 0.3617\n",
      "Epoch 8/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 2.0085 - acc: 0.3818 - val_loss: 1.9354 - val_acc: 0.4055\n",
      "Epoch 9/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 1.8746 - acc: 0.4143 - val_loss: 1.8103 - val_acc: 0.4437\n",
      "Epoch 10/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 1.7605 - acc: 0.4564 - val_loss: 1.7058 - val_acc: 0.4601\n",
      "Epoch 11/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 1.6616 - acc: 0.4735 - val_loss: 1.6150 - val_acc: 0.5055\n",
      "Epoch 12/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 1.5764 - acc: 0.5132 - val_loss: 1.5348 - val_acc: 0.5460\n",
      "Epoch 13/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 1.5004 - acc: 0.5383 - val_loss: 1.4630 - val_acc: 0.5465\n",
      "Epoch 14/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 1.4337 - acc: 0.5718 - val_loss: 1.3980 - val_acc: 0.5954\n",
      "Epoch 15/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 1.3725 - acc: 0.5945 - val_loss: 1.3412 - val_acc: 0.6426\n",
      "Epoch 16/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 1.3170 - acc: 0.6229 - val_loss: 1.2882 - val_acc: 0.6254\n",
      "Epoch 17/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 1.2650 - acc: 0.6398 - val_loss: 1.2385 - val_acc: 0.6522\n",
      "Epoch 18/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.2173 - acc: 0.6401 - val_loss: 1.1957 - val_acc: 0.6608\n",
      "Epoch 19/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.1743 - acc: 0.6464 - val_loss: 1.1497 - val_acc: 0.6749\n",
      "Epoch 20/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 1.1321 - acc: 0.6662 - val_loss: 1.1094 - val_acc: 0.7021\n",
      "Epoch 21/300\n",
      "17858/17858 [==============================] - 0s 21us/step - loss: 1.0924 - acc: 0.6809 - val_loss: 1.0748 - val_acc: 0.6994\n",
      "Epoch 22/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 1.0589 - acc: 0.7015 - val_loss: 1.0382 - val_acc: 0.7006\n",
      "Epoch 23/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 1.0249 - acc: 0.7079 - val_loss: 1.0094 - val_acc: 0.7322\n",
      "Epoch 24/300\n",
      "17858/17858 [==============================] - 0s 21us/step - loss: 0.9959 - acc: 0.7117 - val_loss: 0.9792 - val_acc: 0.7131\n",
      "Epoch 25/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.9668 - acc: 0.7255 - val_loss: 0.9518 - val_acc: 0.7301\n",
      "Epoch 26/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.9391 - acc: 0.7372 - val_loss: 0.9219 - val_acc: 0.7662\n",
      "Epoch 27/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.9131 - acc: 0.7505 - val_loss: 0.8982 - val_acc: 0.7778\n",
      "Epoch 28/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.8879 - acc: 0.7535 - val_loss: 0.8755 - val_acc: 0.7649\n",
      "Epoch 29/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.8658 - acc: 0.7528 - val_loss: 0.8539 - val_acc: 0.7524\n",
      "Epoch 30/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.8428 - acc: 0.7660 - val_loss: 0.8325 - val_acc: 0.7360\n",
      "Epoch 31/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.8226 - acc: 0.7748 - val_loss: 0.8110 - val_acc: 0.7570\n",
      "Epoch 32/300\n",
      "17858/17858 [==============================] - 0s 22us/step - loss: 0.8030 - acc: 0.7682 - val_loss: 0.7914 - val_acc: 0.8086\n",
      "Epoch 33/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.7836 - acc: 0.7838 - val_loss: 0.7738 - val_acc: 0.7959\n",
      "Epoch 34/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.7668 - acc: 0.7895 - val_loss: 0.7608 - val_acc: 0.7847\n",
      "Epoch 35/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.7504 - acc: 0.7842 - val_loss: 0.7427 - val_acc: 0.7830\n",
      "Epoch 36/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.7348 - acc: 0.7875 - val_loss: 0.7280 - val_acc: 0.7710\n",
      "Epoch 37/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.7182 - acc: 0.7893 - val_loss: 0.7079 - val_acc: 0.8045\n",
      "Epoch 38/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.7022 - acc: 0.8014 - val_loss: 0.6936 - val_acc: 0.8028\n",
      "Epoch 39/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.6883 - acc: 0.8022 - val_loss: 0.6828 - val_acc: 0.7953\n",
      "Epoch 40/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.6764 - acc: 0.7984 - val_loss: 0.6665 - val_acc: 0.7948\n",
      "Epoch 41/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.6635 - acc: 0.8014 - val_loss: 0.6552 - val_acc: 0.8084\n",
      "Epoch 42/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.6524 - acc: 0.8034 - val_loss: 0.6437 - val_acc: 0.8155\n",
      "Epoch 43/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.6386 - acc: 0.8122 - val_loss: 0.6332 - val_acc: 0.8236\n",
      "Epoch 44/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.6280 - acc: 0.8155 - val_loss: 0.6221 - val_acc: 0.8175\n",
      "Epoch 45/300\n",
      "17858/17858 [==============================] - 0s 22us/step - loss: 0.6180 - acc: 0.8173 - val_loss: 0.6114 - val_acc: 0.8205\n",
      "Epoch 46/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.6077 - acc: 0.8220 - val_loss: 0.5990 - val_acc: 0.8262\n",
      "Epoch 47/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.5966 - acc: 0.8197 - val_loss: 0.5936 - val_acc: 0.8019\n",
      "Epoch 48/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.5874 - acc: 0.8235 - val_loss: 0.5809 - val_acc: 0.8266\n",
      "Epoch 49/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.5788 - acc: 0.8279 - val_loss: 0.5726 - val_acc: 0.8107\n",
      "Epoch 50/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.5690 - acc: 0.8307 - val_loss: 0.5627 - val_acc: 0.8377\n",
      "Epoch 51/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5612 - acc: 0.8355 - val_loss: 0.5572 - val_acc: 0.8381\n",
      "Epoch 52/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.5539 - acc: 0.8376 - val_loss: 0.5490 - val_acc: 0.8386\n",
      "Epoch 53/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5442 - acc: 0.8387 - val_loss: 0.5395 - val_acc: 0.8246\n",
      "Epoch 54/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.5375 - acc: 0.8304 - val_loss: 0.5325 - val_acc: 0.8255\n",
      "Epoch 55/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.5283 - acc: 0.8415 - val_loss: 0.5232 - val_acc: 0.8467\n",
      "Epoch 56/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.5210 - acc: 0.8456 - val_loss: 0.5163 - val_acc: 0.8350\n",
      "Epoch 57/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.5137 - acc: 0.8397 - val_loss: 0.5096 - val_acc: 0.8407\n",
      "Epoch 58/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.5071 - acc: 0.8418 - val_loss: 0.5022 - val_acc: 0.8554\n",
      "Epoch 59/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.5003 - acc: 0.8479 - val_loss: 0.4957 - val_acc: 0.8521\n",
      "Epoch 60/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4941 - acc: 0.8522 - val_loss: 0.4882 - val_acc: 0.8569\n",
      "Epoch 61/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4887 - acc: 0.8501 - val_loss: 0.4842 - val_acc: 0.8650\n",
      "Epoch 62/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4819 - acc: 0.8516 - val_loss: 0.4772 - val_acc: 0.8501\n",
      "Epoch 63/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4777 - acc: 0.8512 - val_loss: 0.4756 - val_acc: 0.8622\n",
      "Epoch 64/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4714 - acc: 0.8568 - val_loss: 0.4646 - val_acc: 0.8578\n",
      "Epoch 65/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4638 - acc: 0.8617 - val_loss: 0.4611 - val_acc: 0.8509\n",
      "Epoch 66/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4608 - acc: 0.8559 - val_loss: 0.4572 - val_acc: 0.8470\n",
      "Epoch 67/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4557 - acc: 0.8524 - val_loss: 0.4498 - val_acc: 0.8693\n",
      "Epoch 68/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.4487 - acc: 0.8657 - val_loss: 0.4446 - val_acc: 0.8723\n",
      "Epoch 69/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.4438 - acc: 0.8664 - val_loss: 0.4406 - val_acc: 0.8551\n",
      "Epoch 70/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4386 - acc: 0.8583 - val_loss: 0.4351 - val_acc: 0.8615\n",
      "Epoch 71/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.4345 - acc: 0.8695 - val_loss: 0.4299 - val_acc: 0.8802\n",
      "Epoch 72/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.4304 - acc: 0.8699 - val_loss: 0.4244 - val_acc: 0.8662\n",
      "Epoch 73/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.4230 - acc: 0.8733 - val_loss: 0.4196 - val_acc: 0.8737\n",
      "Epoch 74/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4205 - acc: 0.8790 - val_loss: 0.4186 - val_acc: 0.8740\n",
      "Epoch 75/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4176 - acc: 0.8713 - val_loss: 0.4105 - val_acc: 0.8751\n",
      "Epoch 76/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4112 - acc: 0.8798 - val_loss: 0.4077 - val_acc: 0.8765\n",
      "Epoch 77/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4063 - acc: 0.8801 - val_loss: 0.4032 - val_acc: 0.8748\n",
      "Epoch 78/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.4021 - acc: 0.8773 - val_loss: 0.3982 - val_acc: 0.8861\n",
      "Epoch 79/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.3994 - acc: 0.8803 - val_loss: 0.3970 - val_acc: 0.8776\n",
      "Epoch 80/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3942 - acc: 0.8810 - val_loss: 0.3898 - val_acc: 0.8851\n",
      "Epoch 81/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3884 - acc: 0.8853 - val_loss: 0.3863 - val_acc: 0.8793\n",
      "Epoch 82/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.3871 - acc: 0.8827 - val_loss: 0.3883 - val_acc: 0.8879\n",
      "Epoch 83/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.3828 - acc: 0.8867 - val_loss: 0.3802 - val_acc: 0.8800\n",
      "Epoch 84/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.3784 - acc: 0.8873 - val_loss: 0.3756 - val_acc: 0.8862\n",
      "Epoch 85/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.3770 - acc: 0.8906 - val_loss: 0.3771 - val_acc: 0.8859\n",
      "Epoch 86/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.3716 - acc: 0.8914 - val_loss: 0.3671 - val_acc: 0.8911\n",
      "Epoch 87/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.3680 - acc: 0.8887 - val_loss: 0.3661 - val_acc: 0.8933\n",
      "Epoch 88/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.3640 - acc: 0.8962 - val_loss: 0.3623 - val_acc: 0.8900\n",
      "Epoch 89/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.3616 - acc: 0.8907 - val_loss: 0.3583 - val_acc: 0.9073\n",
      "Epoch 90/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.3573 - acc: 0.8965 - val_loss: 0.3534 - val_acc: 0.9075\n",
      "Epoch 91/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.3532 - acc: 0.8998 - val_loss: 0.3519 - val_acc: 0.8925\n",
      "Epoch 92/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3498 - acc: 0.9008 - val_loss: 0.3472 - val_acc: 0.8978\n",
      "Epoch 93/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.3474 - acc: 0.8991 - val_loss: 0.3444 - val_acc: 0.9013\n",
      "Epoch 94/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.3451 - acc: 0.9027 - val_loss: 0.3412 - val_acc: 0.8930\n",
      "Epoch 95/300\n",
      "17858/17858 [==============================] - 0s 18us/step - loss: 0.3416 - acc: 0.8979 - val_loss: 0.3411 - val_acc: 0.9046\n",
      "Epoch 96/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.3385 - acc: 0.9049 - val_loss: 0.3344 - val_acc: 0.9149\n",
      "Epoch 97/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.3351 - acc: 0.9071 - val_loss: 0.3310 - val_acc: 0.9089\n",
      "Epoch 98/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.3327 - acc: 0.9047 - val_loss: 0.3323 - val_acc: 0.9074\n",
      "Epoch 99/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3289 - acc: 0.9070 - val_loss: 0.3277 - val_acc: 0.9060\n",
      "Epoch 100/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3266 - acc: 0.9100 - val_loss: 0.3265 - val_acc: 0.9133\n",
      "Epoch 101/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3240 - acc: 0.9101 - val_loss: 0.3245 - val_acc: 0.9154\n",
      "Epoch 102/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3216 - acc: 0.9102 - val_loss: 0.3216 - val_acc: 0.9110\n",
      "Epoch 103/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3190 - acc: 0.9134 - val_loss: 0.3148 - val_acc: 0.9156\n",
      "Epoch 104/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.3158 - acc: 0.9121 - val_loss: 0.3160 - val_acc: 0.9005\n",
      "Epoch 105/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3152 - acc: 0.9092 - val_loss: 0.3117 - val_acc: 0.9162\n",
      "Epoch 106/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3114 - acc: 0.9157 - val_loss: 0.3115 - val_acc: 0.9012\n",
      "Epoch 107/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3081 - acc: 0.9130 - val_loss: 0.3046 - val_acc: 0.9210\n",
      "Epoch 108/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3067 - acc: 0.9137 - val_loss: 0.3040 - val_acc: 0.9117\n",
      "Epoch 109/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3024 - acc: 0.9153 - val_loss: 0.3004 - val_acc: 0.9100\n",
      "Epoch 110/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.3017 - acc: 0.9183 - val_loss: 0.3036 - val_acc: 0.9052\n",
      "Epoch 111/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2990 - acc: 0.9187 - val_loss: 0.2972 - val_acc: 0.9195\n",
      "Epoch 112/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2966 - acc: 0.9184 - val_loss: 0.2976 - val_acc: 0.9196\n",
      "Epoch 113/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2930 - acc: 0.9226 - val_loss: 0.2912 - val_acc: 0.9199\n",
      "Epoch 114/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2901 - acc: 0.9240 - val_loss: 0.2883 - val_acc: 0.9200\n",
      "Epoch 115/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2888 - acc: 0.9224 - val_loss: 0.2864 - val_acc: 0.9249\n",
      "Epoch 116/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2867 - acc: 0.9237 - val_loss: 0.2852 - val_acc: 0.9197\n",
      "Epoch 117/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2854 - acc: 0.9199 - val_loss: 0.2854 - val_acc: 0.9179\n",
      "Epoch 118/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2823 - acc: 0.9229 - val_loss: 0.2782 - val_acc: 0.9270\n",
      "Epoch 119/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.2783 - acc: 0.9272 - val_loss: 0.2766 - val_acc: 0.9257\n",
      "Epoch 120/300\n",
      "17858/17858 [==============================] - 0s 19us/step - loss: 0.2762 - acc: 0.9256 - val_loss: 0.2796 - val_acc: 0.9175\n",
      "Epoch 121/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2769 - acc: 0.9241 - val_loss: 0.2729 - val_acc: 0.9231\n",
      "Epoch 122/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2724 - acc: 0.9283 - val_loss: 0.2710 - val_acc: 0.9231\n",
      "Epoch 123/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2711 - acc: 0.9283 - val_loss: 0.2689 - val_acc: 0.9263\n",
      "Epoch 124/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2709 - acc: 0.9264 - val_loss: 0.2699 - val_acc: 0.9238\n",
      "Epoch 125/300\n",
      "17858/17858 [==============================] - ETA: 0s - loss: 0.2660 - acc: 0.928 - 0s 15us/step - loss: 0.2659 - acc: 0.9283 - val_loss: 0.2690 - val_acc: 0.9265\n",
      "Epoch 126/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2653 - acc: 0.9281 - val_loss: 0.2709 - val_acc: 0.9331\n",
      "Epoch 127/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2632 - acc: 0.9316 - val_loss: 0.2597 - val_acc: 0.9303\n",
      "Epoch 128/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2627 - acc: 0.9255 - val_loss: 0.2621 - val_acc: 0.9214\n",
      "Epoch 129/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2615 - acc: 0.9271 - val_loss: 0.2615 - val_acc: 0.9248\n",
      "Epoch 130/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2569 - acc: 0.9301 - val_loss: 0.2547 - val_acc: 0.9317\n",
      "Epoch 131/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2556 - acc: 0.9313 - val_loss: 0.2528 - val_acc: 0.9296\n",
      "Epoch 132/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2518 - acc: 0.9316 - val_loss: 0.2506 - val_acc: 0.9370\n",
      "Epoch 133/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2519 - acc: 0.9321 - val_loss: 0.2520 - val_acc: 0.9304\n",
      "Epoch 134/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2516 - acc: 0.9311 - val_loss: 0.2484 - val_acc: 0.9321\n",
      "Epoch 135/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2471 - acc: 0.9340 - val_loss: 0.2457 - val_acc: 0.9350\n",
      "Epoch 136/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2463 - acc: 0.9326 - val_loss: 0.2506 - val_acc: 0.9308\n",
      "Epoch 137/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2463 - acc: 0.9335 - val_loss: 0.2408 - val_acc: 0.9362\n",
      "Epoch 138/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2412 - acc: 0.9346 - val_loss: 0.2400 - val_acc: 0.9383\n",
      "Epoch 139/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2402 - acc: 0.9358 - val_loss: 0.2366 - val_acc: 0.9383\n",
      "Epoch 140/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2398 - acc: 0.9350 - val_loss: 0.2378 - val_acc: 0.9411\n",
      "Epoch 141/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2379 - acc: 0.9379 - val_loss: 0.2357 - val_acc: 0.9329\n",
      "Epoch 142/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2355 - acc: 0.9360 - val_loss: 0.2334 - val_acc: 0.9373\n",
      "Epoch 143/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2357 - acc: 0.9362 - val_loss: 0.2319 - val_acc: 0.9382\n",
      "Epoch 144/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2326 - acc: 0.9368 - val_loss: 0.2314 - val_acc: 0.9404\n",
      "Epoch 145/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2301 - acc: 0.9400 - val_loss: 0.2343 - val_acc: 0.9307\n",
      "Epoch 146/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2286 - acc: 0.9389 - val_loss: 0.2261 - val_acc: 0.9397\n",
      "Epoch 147/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2276 - acc: 0.9395 - val_loss: 0.2278 - val_acc: 0.9384\n",
      "Epoch 148/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2281 - acc: 0.9386 - val_loss: 0.2236 - val_acc: 0.9380\n",
      "Epoch 149/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2258 - acc: 0.9381 - val_loss: 0.2251 - val_acc: 0.9362\n",
      "Epoch 150/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2259 - acc: 0.9369 - val_loss: 0.2308 - val_acc: 0.9379\n",
      "Epoch 151/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2243 - acc: 0.9386 - val_loss: 0.2218 - val_acc: 0.9417\n",
      "Epoch 152/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2218 - acc: 0.9395 - val_loss: 0.2167 - val_acc: 0.9439\n",
      "Epoch 153/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2177 - acc: 0.9415 - val_loss: 0.2181 - val_acc: 0.9394\n",
      "Epoch 154/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2158 - acc: 0.9435 - val_loss: 0.2161 - val_acc: 0.9400\n",
      "Epoch 155/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2166 - acc: 0.9401 - val_loss: 0.2135 - val_acc: 0.9453\n",
      "Epoch 156/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2133 - acc: 0.9434 - val_loss: 0.2118 - val_acc: 0.9434\n",
      "Epoch 157/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2129 - acc: 0.9431 - val_loss: 0.2094 - val_acc: 0.9464\n",
      "Epoch 158/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2094 - acc: 0.9437 - val_loss: 0.2087 - val_acc: 0.9484\n",
      "Epoch 159/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.2100 - acc: 0.9435 - val_loss: 0.2102 - val_acc: 0.9385\n",
      "Epoch 160/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.2091 - acc: 0.9436 - val_loss: 0.2101 - val_acc: 0.9369\n",
      "Epoch 161/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2096 - acc: 0.9422 - val_loss: 0.2039 - val_acc: 0.9479\n",
      "Epoch 162/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.2057 - acc: 0.9463 - val_loss: 0.2028 - val_acc: 0.9470\n",
      "Epoch 163/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2047 - acc: 0.9438 - val_loss: 0.2023 - val_acc: 0.9452\n",
      "Epoch 164/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2022 - acc: 0.9451 - val_loss: 0.2008 - val_acc: 0.9473\n",
      "Epoch 165/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.2022 - acc: 0.9442 - val_loss: 0.2001 - val_acc: 0.9502\n",
      "Epoch 166/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1991 - acc: 0.9476 - val_loss: 0.2004 - val_acc: 0.9495\n",
      "Epoch 167/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1988 - acc: 0.9473 - val_loss: 0.1974 - val_acc: 0.9488\n",
      "Epoch 168/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1970 - acc: 0.9475 - val_loss: 0.1943 - val_acc: 0.9493\n",
      "Epoch 169/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1956 - acc: 0.9481 - val_loss: 0.1934 - val_acc: 0.9513\n",
      "Epoch 170/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1935 - acc: 0.9499 - val_loss: 0.1973 - val_acc: 0.9463\n",
      "Epoch 171/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1956 - acc: 0.9483 - val_loss: 0.1948 - val_acc: 0.9496\n",
      "Epoch 172/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1917 - acc: 0.9506 - val_loss: 0.1890 - val_acc: 0.9505\n",
      "Epoch 173/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1892 - acc: 0.9508 - val_loss: 0.1891 - val_acc: 0.9510\n",
      "Epoch 174/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1893 - acc: 0.9496 - val_loss: 0.1872 - val_acc: 0.9495\n",
      "Epoch 175/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1883 - acc: 0.9521 - val_loss: 0.1871 - val_acc: 0.9460\n",
      "Epoch 176/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1863 - acc: 0.9519 - val_loss: 0.1861 - val_acc: 0.9481\n",
      "Epoch 177/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1845 - acc: 0.9514 - val_loss: 0.1873 - val_acc: 0.9497\n",
      "Epoch 178/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1830 - acc: 0.9532 - val_loss: 0.1811 - val_acc: 0.9550\n",
      "Epoch 179/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1830 - acc: 0.9521 - val_loss: 0.1806 - val_acc: 0.9512\n",
      "Epoch 180/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1806 - acc: 0.9523 - val_loss: 0.1806 - val_acc: 0.9550\n",
      "Epoch 181/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1810 - acc: 0.9534 - val_loss: 0.1791 - val_acc: 0.9546\n",
      "Epoch 182/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1794 - acc: 0.9540 - val_loss: 0.1795 - val_acc: 0.9532\n",
      "Epoch 183/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1794 - acc: 0.9531 - val_loss: 0.1770 - val_acc: 0.9527\n",
      "Epoch 184/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1763 - acc: 0.9542 - val_loss: 0.1775 - val_acc: 0.9520\n",
      "Epoch 185/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1789 - acc: 0.9522 - val_loss: 0.1801 - val_acc: 0.9519\n",
      "Epoch 186/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1749 - acc: 0.9555 - val_loss: 0.1721 - val_acc: 0.9559\n",
      "Epoch 187/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1725 - acc: 0.9561 - val_loss: 0.1761 - val_acc: 0.9505\n",
      "Epoch 188/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1720 - acc: 0.9541 - val_loss: 0.1701 - val_acc: 0.9573\n",
      "Epoch 189/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1726 - acc: 0.9555 - val_loss: 0.1695 - val_acc: 0.9572\n",
      "Epoch 190/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1711 - acc: 0.9564 - val_loss: 0.1722 - val_acc: 0.9514\n",
      "Epoch 191/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1722 - acc: 0.9559 - val_loss: 0.1683 - val_acc: 0.9561\n",
      "Epoch 192/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1682 - acc: 0.9582 - val_loss: 0.1678 - val_acc: 0.9568\n",
      "Epoch 193/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1673 - acc: 0.9567 - val_loss: 0.1686 - val_acc: 0.9564\n",
      "Epoch 194/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1669 - acc: 0.9574 - val_loss: 0.1640 - val_acc: 0.9574\n",
      "Epoch 195/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1652 - acc: 0.9578 - val_loss: 0.1634 - val_acc: 0.9595\n",
      "Epoch 196/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1635 - acc: 0.9576 - val_loss: 0.1657 - val_acc: 0.9557\n",
      "Epoch 197/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.1628 - acc: 0.9588 - val_loss: 0.1599 - val_acc: 0.9587\n",
      "Epoch 198/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.1608 - acc: 0.9586 - val_loss: 0.1624 - val_acc: 0.9551\n",
      "Epoch 199/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1593 - acc: 0.9596 - val_loss: 0.1630 - val_acc: 0.9607\n",
      "Epoch 200/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1600 - acc: 0.9590 - val_loss: 0.1590 - val_acc: 0.9577\n",
      "Epoch 201/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1576 - acc: 0.9590 - val_loss: 0.1569 - val_acc: 0.9589\n",
      "Epoch 202/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1573 - acc: 0.9594 - val_loss: 0.1553 - val_acc: 0.9600\n",
      "Epoch 203/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1564 - acc: 0.9605 - val_loss: 0.1549 - val_acc: 0.9621\n",
      "Epoch 204/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1545 - acc: 0.9600 - val_loss: 0.1540 - val_acc: 0.9625\n",
      "Epoch 205/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1530 - acc: 0.9615 - val_loss: 0.1530 - val_acc: 0.9625\n",
      "Epoch 206/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1538 - acc: 0.9602 - val_loss: 0.1536 - val_acc: 0.9595\n",
      "Epoch 207/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1535 - acc: 0.9605 - val_loss: 0.1537 - val_acc: 0.9614\n",
      "Epoch 208/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1519 - acc: 0.9605 - val_loss: 0.1508 - val_acc: 0.9624\n",
      "Epoch 209/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1517 - acc: 0.9616 - val_loss: 0.1482 - val_acc: 0.9635\n",
      "Epoch 210/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1495 - acc: 0.9621 - val_loss: 0.1544 - val_acc: 0.9590\n",
      "Epoch 211/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1488 - acc: 0.9598 - val_loss: 0.1462 - val_acc: 0.9627\n",
      "Epoch 212/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1467 - acc: 0.9620 - val_loss: 0.1456 - val_acc: 0.9608\n",
      "Epoch 213/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1470 - acc: 0.9618 - val_loss: 0.1451 - val_acc: 0.9629\n",
      "Epoch 214/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1457 - acc: 0.9628 - val_loss: 0.1502 - val_acc: 0.9583\n",
      "Epoch 215/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1459 - acc: 0.9624 - val_loss: 0.1430 - val_acc: 0.9664\n",
      "Epoch 216/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1445 - acc: 0.9624 - val_loss: 0.1436 - val_acc: 0.9649\n",
      "Epoch 217/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1435 - acc: 0.9623 - val_loss: 0.1412 - val_acc: 0.9627\n",
      "Epoch 218/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1431 - acc: 0.9628 - val_loss: 0.1419 - val_acc: 0.9624\n",
      "Epoch 219/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1409 - acc: 0.9632 - val_loss: 0.1392 - val_acc: 0.9629\n",
      "Epoch 220/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1413 - acc: 0.9632 - val_loss: 0.1440 - val_acc: 0.9615\n",
      "Epoch 221/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1402 - acc: 0.9625 - val_loss: 0.1384 - val_acc: 0.9644\n",
      "Epoch 222/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1382 - acc: 0.9647 - val_loss: 0.1369 - val_acc: 0.9668\n",
      "Epoch 223/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1379 - acc: 0.9657 - val_loss: 0.1356 - val_acc: 0.9657\n",
      "Epoch 224/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1368 - acc: 0.9657 - val_loss: 0.1359 - val_acc: 0.9670\n",
      "Epoch 225/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1362 - acc: 0.9642 - val_loss: 0.1359 - val_acc: 0.9618\n",
      "Epoch 226/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1354 - acc: 0.9666 - val_loss: 0.1359 - val_acc: 0.9676\n",
      "Epoch 227/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1344 - acc: 0.9656 - val_loss: 0.1346 - val_acc: 0.9655\n",
      "Epoch 228/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1340 - acc: 0.9666 - val_loss: 0.1347 - val_acc: 0.9653\n",
      "Epoch 229/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1331 - acc: 0.9668 - val_loss: 0.1308 - val_acc: 0.9672\n",
      "Epoch 230/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1322 - acc: 0.9659 - val_loss: 0.1328 - val_acc: 0.9684\n",
      "Epoch 231/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1307 - acc: 0.9681 - val_loss: 0.1309 - val_acc: 0.9682\n",
      "Epoch 232/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1309 - acc: 0.9667 - val_loss: 0.1332 - val_acc: 0.9605\n",
      "Epoch 233/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1301 - acc: 0.9660 - val_loss: 0.1277 - val_acc: 0.9651\n",
      "Epoch 234/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1284 - acc: 0.9675 - val_loss: 0.1291 - val_acc: 0.9719\n",
      "Epoch 235/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1278 - acc: 0.9676 - val_loss: 0.1273 - val_acc: 0.9676\n",
      "Epoch 236/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.1268 - acc: 0.9695 - val_loss: 0.1297 - val_acc: 0.9616\n",
      "Epoch 237/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.1275 - acc: 0.9660 - val_loss: 0.1266 - val_acc: 0.9689\n",
      "Epoch 238/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1252 - acc: 0.9682 - val_loss: 0.1270 - val_acc: 0.9679\n",
      "Epoch 239/300\n",
      "17858/17858 [==============================] - ETA: 0s - loss: 0.1251 - acc: 0.968 - 0s 15us/step - loss: 0.1253 - acc: 0.9683 - val_loss: 0.1239 - val_acc: 0.9685\n",
      "Epoch 240/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1241 - acc: 0.9681 - val_loss: 0.1239 - val_acc: 0.9691\n",
      "Epoch 241/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1235 - acc: 0.9690 - val_loss: 0.1227 - val_acc: 0.9670\n",
      "Epoch 242/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1220 - acc: 0.9697 - val_loss: 0.1215 - val_acc: 0.9737\n",
      "Epoch 243/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1217 - acc: 0.9691 - val_loss: 0.1218 - val_acc: 0.9708\n",
      "Epoch 244/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1211 - acc: 0.9695 - val_loss: 0.1201 - val_acc: 0.9709\n",
      "Epoch 245/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1198 - acc: 0.9710 - val_loss: 0.1198 - val_acc: 0.9690\n",
      "Epoch 246/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1195 - acc: 0.9696 - val_loss: 0.1177 - val_acc: 0.9693\n",
      "Epoch 247/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1188 - acc: 0.9699 - val_loss: 0.1195 - val_acc: 0.9689\n",
      "Epoch 248/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1183 - acc: 0.9711 - val_loss: 0.1196 - val_acc: 0.9665\n",
      "Epoch 249/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1179 - acc: 0.9704 - val_loss: 0.1162 - val_acc: 0.9719\n",
      "Epoch 250/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1164 - acc: 0.9708 - val_loss: 0.1155 - val_acc: 0.9686\n",
      "Epoch 251/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1169 - acc: 0.9696 - val_loss: 0.1173 - val_acc: 0.9674\n",
      "Epoch 252/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1162 - acc: 0.9710 - val_loss: 0.1137 - val_acc: 0.9709\n",
      "Epoch 253/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1142 - acc: 0.9707 - val_loss: 0.1132 - val_acc: 0.9724\n",
      "Epoch 254/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1141 - acc: 0.9719 - val_loss: 0.1143 - val_acc: 0.9686\n",
      "Epoch 255/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1142 - acc: 0.9712 - val_loss: 0.1118 - val_acc: 0.9735\n",
      "Epoch 256/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1126 - acc: 0.9721 - val_loss: 0.1115 - val_acc: 0.9749\n",
      "Epoch 257/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1117 - acc: 0.9728 - val_loss: 0.1124 - val_acc: 0.9724\n",
      "Epoch 258/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1118 - acc: 0.9731 - val_loss: 0.1117 - val_acc: 0.9735\n",
      "Epoch 259/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1107 - acc: 0.9723 - val_loss: 0.1102 - val_acc: 0.9751\n",
      "Epoch 260/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1116 - acc: 0.9723 - val_loss: 0.1087 - val_acc: 0.9719\n",
      "Epoch 261/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1127 - acc: 0.9701 - val_loss: 0.1092 - val_acc: 0.9728\n",
      "Epoch 262/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1099 - acc: 0.9727 - val_loss: 0.1075 - val_acc: 0.9726\n",
      "Epoch 263/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1086 - acc: 0.9726 - val_loss: 0.1087 - val_acc: 0.9733\n",
      "Epoch 264/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1082 - acc: 0.9727 - val_loss: 0.1063 - val_acc: 0.9746\n",
      "Epoch 265/300\n",
      "17858/17858 [==============================] - ETA: 0s - loss: 0.1074 - acc: 0.972 - 0s 14us/step - loss: 0.1072 - acc: 0.9724 - val_loss: 0.1059 - val_acc: 0.9750\n",
      "Epoch 266/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1076 - acc: 0.9727 - val_loss: 0.1064 - val_acc: 0.9724\n",
      "Epoch 267/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1060 - acc: 0.9727 - val_loss: 0.1050 - val_acc: 0.9760\n",
      "Epoch 268/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1057 - acc: 0.9735 - val_loss: 0.1051 - val_acc: 0.9763\n",
      "Epoch 269/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1052 - acc: 0.9736 - val_loss: 0.1050 - val_acc: 0.9719\n",
      "Epoch 270/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1052 - acc: 0.9747 - val_loss: 0.1093 - val_acc: 0.9707\n",
      "Epoch 271/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1046 - acc: 0.9735 - val_loss: 0.1034 - val_acc: 0.9731\n",
      "Epoch 272/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1034 - acc: 0.9742 - val_loss: 0.1029 - val_acc: 0.9732\n",
      "Epoch 273/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1021 - acc: 0.9747 - val_loss: 0.1046 - val_acc: 0.9707\n",
      "Epoch 274/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1026 - acc: 0.9746 - val_loss: 0.1019 - val_acc: 0.9734\n",
      "Epoch 275/300\n",
      "17858/17858 [==============================] - 0s 16us/step - loss: 0.1013 - acc: 0.9748 - val_loss: 0.1005 - val_acc: 0.9747\n",
      "Epoch 276/300\n",
      "17858/17858 [==============================] - 0s 20us/step - loss: 0.1016 - acc: 0.9737 - val_loss: 0.1002 - val_acc: 0.9760\n",
      "Epoch 277/300\n",
      "17858/17858 [==============================] - 0s 17us/step - loss: 0.1012 - acc: 0.9738 - val_loss: 0.1018 - val_acc: 0.9735\n",
      "Epoch 278/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.0995 - acc: 0.9754 - val_loss: 0.0987 - val_acc: 0.9760\n",
      "Epoch 279/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.1006 - acc: 0.9742 - val_loss: 0.1037 - val_acc: 0.9698\n",
      "Epoch 280/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.1008 - acc: 0.9731 - val_loss: 0.1008 - val_acc: 0.9727\n",
      "Epoch 281/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0993 - acc: 0.9733 - val_loss: 0.0983 - val_acc: 0.9742\n",
      "Epoch 282/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.0971 - acc: 0.9756 - val_loss: 0.0968 - val_acc: 0.9761\n",
      "Epoch 283/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0977 - acc: 0.9756 - val_loss: 0.0978 - val_acc: 0.9755\n",
      "Epoch 284/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0972 - acc: 0.9746 - val_loss: 0.0957 - val_acc: 0.9756\n",
      "Epoch 285/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0966 - acc: 0.9759 - val_loss: 0.0946 - val_acc: 0.9759\n",
      "Epoch 286/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0955 - acc: 0.9755 - val_loss: 0.0957 - val_acc: 0.9751\n",
      "Epoch 287/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.0948 - acc: 0.9757 - val_loss: 0.0943 - val_acc: 0.9768\n",
      "Epoch 288/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.0950 - acc: 0.9758 - val_loss: 0.0934 - val_acc: 0.9759\n",
      "Epoch 289/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0945 - acc: 0.9751 - val_loss: 0.0938 - val_acc: 0.9747\n",
      "Epoch 290/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.0942 - acc: 0.9757 - val_loss: 0.0928 - val_acc: 0.9763\n",
      "Epoch 291/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.0947 - acc: 0.9744 - val_loss: 0.0966 - val_acc: 0.9757\n",
      "Epoch 292/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0932 - acc: 0.9758 - val_loss: 0.0930 - val_acc: 0.9747\n",
      "Epoch 293/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0928 - acc: 0.9756 - val_loss: 0.0916 - val_acc: 0.9771\n",
      "Epoch 294/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.0918 - acc: 0.9758 - val_loss: 0.0946 - val_acc: 0.9709\n",
      "Epoch 295/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0917 - acc: 0.9765 - val_loss: 0.0920 - val_acc: 0.9759\n",
      "Epoch 296/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.0932 - acc: 0.9744 - val_loss: 0.0915 - val_acc: 0.9761\n",
      "Epoch 297/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0924 - acc: 0.9754 - val_loss: 0.0907 - val_acc: 0.9770\n",
      "Epoch 298/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0899 - acc: 0.9761 - val_loss: 0.0909 - val_acc: 0.9751\n",
      "Epoch 299/300\n",
      "17858/17858 [==============================] - 0s 14us/step - loss: 0.0894 - acc: 0.9766 - val_loss: 0.0900 - val_acc: 0.9766\n",
      "Epoch 300/300\n",
      "17858/17858 [==============================] - 0s 15us/step - loss: 0.0898 - acc: 0.9766 - val_loss: 0.0878 - val_acc: 0.9768\n",
      "17859/17859 [==============================] - 1s 68us/step\n",
      "17858/17858 [==============================] - 1s 68us/step\n",
      "Train on 7143 samples, validate on 7143 samples\n",
      "Epoch 1/300\n",
      "7143/7143 [==============================] - 3s 424us/step - loss: 3.3457 - acc: 0.0549 - val_loss: 3.2988 - val_acc: 0.0756\n",
      "Epoch 2/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7143/7143 [==============================] - 0s 16us/step - loss: 3.2582 - acc: 0.0825 - val_loss: 3.2088 - val_acc: 0.0881\n",
      "Epoch 3/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 3.1633 - acc: 0.0962 - val_loss: 3.1054 - val_acc: 0.1089\n",
      "Epoch 4/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 3.0533 - acc: 0.1176 - val_loss: 2.9914 - val_acc: 0.1222\n",
      "Epoch 5/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.9395 - acc: 0.1184 - val_loss: 2.8806 - val_acc: 0.1100\n",
      "Epoch 6/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.8347 - acc: 0.1074 - val_loss: 2.7840 - val_acc: 0.1072\n",
      "Epoch 7/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.7461 - acc: 0.1092 - val_loss: 2.7028 - val_acc: 0.1120\n",
      "Epoch 8/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.6702 - acc: 0.1512 - val_loss: 2.6320 - val_acc: 0.1744\n",
      "Epoch 9/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.6020 - acc: 0.1876 - val_loss: 2.5655 - val_acc: 0.1950\n",
      "Epoch 10/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 2.5365 - acc: 0.2078 - val_loss: 2.5012 - val_acc: 0.2283\n",
      "Epoch 11/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.4719 - acc: 0.2443 - val_loss: 2.4355 - val_acc: 0.2570\n",
      "Epoch 12/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.4051 - acc: 0.2645 - val_loss: 2.3674 - val_acc: 0.2680\n",
      "Epoch 13/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 2.3370 - acc: 0.2705 - val_loss: 2.2995 - val_acc: 0.2975\n",
      "Epoch 14/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.2691 - acc: 0.3251 - val_loss: 2.2322 - val_acc: 0.3458\n",
      "Epoch 15/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 2.2027 - acc: 0.3441 - val_loss: 2.1669 - val_acc: 0.3532\n",
      "Epoch 16/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.1393 - acc: 0.3515 - val_loss: 2.1045 - val_acc: 0.3553\n",
      "Epoch 17/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.0783 - acc: 0.3567 - val_loss: 2.0457 - val_acc: 0.3725\n",
      "Epoch 18/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 2.0215 - acc: 0.3851 - val_loss: 1.9908 - val_acc: 0.4033\n",
      "Epoch 19/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.9688 - acc: 0.4073 - val_loss: 1.9397 - val_acc: 0.3983\n",
      "Epoch 20/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.9189 - acc: 0.4101 - val_loss: 1.8917 - val_acc: 0.4120\n",
      "Epoch 21/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.8727 - acc: 0.4005 - val_loss: 1.8473 - val_acc: 0.4196\n",
      "Epoch 22/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.8293 - acc: 0.4180 - val_loss: 1.8055 - val_acc: 0.4344\n",
      "Epoch 23/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.7884 - acc: 0.4308 - val_loss: 1.7652 - val_acc: 0.4407\n",
      "Epoch 24/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.7500 - acc: 0.4439 - val_loss: 1.7278 - val_acc: 0.4886\n",
      "Epoch 25/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.7134 - acc: 0.4880 - val_loss: 1.6930 - val_acc: 0.5048\n",
      "Epoch 26/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.6789 - acc: 0.5016 - val_loss: 1.6598 - val_acc: 0.4976\n",
      "Epoch 27/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.6469 - acc: 0.4971 - val_loss: 1.6272 - val_acc: 0.4983\n",
      "Epoch 28/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.6155 - acc: 0.5076 - val_loss: 1.5969 - val_acc: 0.5192\n",
      "Epoch 29/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.5865 - acc: 0.5092 - val_loss: 1.5681 - val_acc: 0.5169\n",
      "Epoch 30/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 1.5581 - acc: 0.5174 - val_loss: 1.5401 - val_acc: 0.5692\n",
      "Epoch 31/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.5297 - acc: 0.5460 - val_loss: 1.5137 - val_acc: 0.5408\n",
      "Epoch 32/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.5042 - acc: 0.5436 - val_loss: 1.4879 - val_acc: 0.5484\n",
      "Epoch 33/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.4777 - acc: 0.5537 - val_loss: 1.4625 - val_acc: 0.5660\n",
      "Epoch 34/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.4547 - acc: 0.5800 - val_loss: 1.4397 - val_acc: 0.5610\n",
      "Epoch 35/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.4315 - acc: 0.5696 - val_loss: 1.4163 - val_acc: 0.5902\n",
      "Epoch 36/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.4088 - acc: 0.5663 - val_loss: 1.3940 - val_acc: 0.5705\n",
      "Epoch 37/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.3871 - acc: 0.5937 - val_loss: 1.3721 - val_acc: 0.5887\n",
      "Epoch 38/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.3649 - acc: 0.5884 - val_loss: 1.3523 - val_acc: 0.6030\n",
      "Epoch 39/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.3450 - acc: 0.5975 - val_loss: 1.3321 - val_acc: 0.5948\n",
      "Epoch 40/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.3250 - acc: 0.5891 - val_loss: 1.3120 - val_acc: 0.6128\n",
      "Epoch 41/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.3070 - acc: 0.6095 - val_loss: 1.2939 - val_acc: 0.6077\n",
      "Epoch 42/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.2882 - acc: 0.6048 - val_loss: 1.2757 - val_acc: 0.6018\n",
      "Epoch 43/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.2691 - acc: 0.6135 - val_loss: 1.2570 - val_acc: 0.6164\n",
      "Epoch 44/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 1.2515 - acc: 0.6279 - val_loss: 1.2397 - val_acc: 0.6573\n",
      "Epoch 45/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 1.2346 - acc: 0.6513 - val_loss: 1.2234 - val_acc: 0.6514\n",
      "Epoch 46/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.2176 - acc: 0.6367 - val_loss: 1.2056 - val_acc: 0.6375\n",
      "Epoch 47/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 1.2006 - acc: 0.6416 - val_loss: 1.1896 - val_acc: 0.6980\n",
      "Epoch 48/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.1848 - acc: 0.6690 - val_loss: 1.1739 - val_acc: 0.6704\n",
      "Epoch 49/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.1687 - acc: 0.6563 - val_loss: 1.1593 - val_acc: 0.6585\n",
      "Epoch 50/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.1547 - acc: 0.6662 - val_loss: 1.1440 - val_acc: 0.6706\n",
      "Epoch 51/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.1397 - acc: 0.6874 - val_loss: 1.1280 - val_acc: 0.7032\n",
      "Epoch 52/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.1253 - acc: 0.6858 - val_loss: 1.1152 - val_acc: 0.6808\n",
      "Epoch 53/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.1114 - acc: 0.6823 - val_loss: 1.1009 - val_acc: 0.6924\n",
      "Epoch 54/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.0959 - acc: 0.6837 - val_loss: 1.0843 - val_acc: 0.7259\n",
      "Epoch 55/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.0804 - acc: 0.7283 - val_loss: 1.0713 - val_acc: 0.7231\n",
      "Epoch 56/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.0672 - acc: 0.6972 - val_loss: 1.0573 - val_acc: 0.7098\n",
      "Epoch 57/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.0548 - acc: 0.7320 - val_loss: 1.0440 - val_acc: 0.7397\n",
      "Epoch 58/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.0408 - acc: 0.7113 - val_loss: 1.0320 - val_acc: 0.7325\n",
      "Epoch 59/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.0279 - acc: 0.7395 - val_loss: 1.0191 - val_acc: 0.7193\n",
      "Epoch 60/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.0156 - acc: 0.7262 - val_loss: 1.0050 - val_acc: 0.7561\n",
      "Epoch 61/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.0021 - acc: 0.7378 - val_loss: 0.9926 - val_acc: 0.7603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.9897 - acc: 0.7504 - val_loss: 0.9804 - val_acc: 0.7568\n",
      "Epoch 63/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.9781 - acc: 0.7473 - val_loss: 0.9691 - val_acc: 0.7360\n",
      "Epoch 64/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.9649 - acc: 0.7574 - val_loss: 0.9565 - val_acc: 0.7687\n",
      "Epoch 65/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.9537 - acc: 0.7610 - val_loss: 0.9465 - val_acc: 0.7588\n",
      "Epoch 66/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.9420 - acc: 0.7612 - val_loss: 0.9339 - val_acc: 0.7717\n",
      "Epoch 67/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.9325 - acc: 0.7764 - val_loss: 0.9234 - val_acc: 0.7586\n",
      "Epoch 68/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.9206 - acc: 0.7641 - val_loss: 0.9123 - val_acc: 0.7766\n",
      "Epoch 69/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.9098 - acc: 0.7703 - val_loss: 0.9008 - val_acc: 0.7711\n",
      "Epoch 70/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.8992 - acc: 0.7686 - val_loss: 0.8922 - val_acc: 0.7759\n",
      "Epoch 71/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.8893 - acc: 0.7819 - val_loss: 0.8795 - val_acc: 0.7843\n",
      "Epoch 72/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.8789 - acc: 0.7768 - val_loss: 0.8702 - val_acc: 0.7868\n",
      "Epoch 73/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.8691 - acc: 0.7861 - val_loss: 0.8608 - val_acc: 0.7756\n",
      "Epoch 74/300\n",
      "7143/7143 [==============================] - 0s 23us/step - loss: 0.8590 - acc: 0.7789 - val_loss: 0.8510 - val_acc: 0.7896\n",
      "Epoch 75/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.8490 - acc: 0.7903 - val_loss: 0.8424 - val_acc: 0.7780\n",
      "Epoch 76/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.8405 - acc: 0.7894 - val_loss: 0.8322 - val_acc: 0.7908\n",
      "Epoch 77/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.8295 - acc: 0.7847 - val_loss: 0.8221 - val_acc: 0.7931\n",
      "Epoch 78/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.8210 - acc: 0.8012 - val_loss: 0.8132 - val_acc: 0.7915\n",
      "Epoch 79/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.8119 - acc: 0.7831 - val_loss: 0.8061 - val_acc: 0.7872\n",
      "Epoch 80/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.8056 - acc: 0.7966 - val_loss: 0.7988 - val_acc: 0.7830\n",
      "Epoch 81/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.7958 - acc: 0.7885 - val_loss: 0.7888 - val_acc: 0.7990\n",
      "Epoch 82/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.7865 - acc: 0.7880 - val_loss: 0.7801 - val_acc: 0.7963\n",
      "Epoch 83/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.7784 - acc: 0.7988 - val_loss: 0.7718 - val_acc: 0.8079\n",
      "Epoch 84/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.7705 - acc: 0.8027 - val_loss: 0.7664 - val_acc: 0.8011\n",
      "Epoch 85/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.7651 - acc: 0.7984 - val_loss: 0.7558 - val_acc: 0.7971\n",
      "Epoch 86/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.7573 - acc: 0.7987 - val_loss: 0.7511 - val_acc: 0.7872\n",
      "Epoch 87/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.7492 - acc: 0.7990 - val_loss: 0.7422 - val_acc: 0.8047\n",
      "Epoch 88/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.7404 - acc: 0.7983 - val_loss: 0.7356 - val_acc: 0.8110\n",
      "Epoch 89/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.7358 - acc: 0.8020 - val_loss: 0.7274 - val_acc: 0.8261\n",
      "Epoch 90/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.7288 - acc: 0.8111 - val_loss: 0.7216 - val_acc: 0.8023\n",
      "Epoch 91/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.7206 - acc: 0.8109 - val_loss: 0.7146 - val_acc: 0.7969\n",
      "Epoch 92/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.7128 - acc: 0.7994 - val_loss: 0.7080 - val_acc: 0.8167\n",
      "Epoch 93/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.7063 - acc: 0.8127 - val_loss: 0.7025 - val_acc: 0.7918\n",
      "Epoch 94/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.7000 - acc: 0.8025 - val_loss: 0.6951 - val_acc: 0.8236\n",
      "Epoch 95/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.6954 - acc: 0.7980 - val_loss: 0.6916 - val_acc: 0.8134\n",
      "Epoch 96/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6865 - acc: 0.8211 - val_loss: 0.6820 - val_acc: 0.7946\n",
      "Epoch 97/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6810 - acc: 0.8061 - val_loss: 0.6751 - val_acc: 0.8261\n",
      "Epoch 98/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.6733 - acc: 0.8200 - val_loss: 0.6695 - val_acc: 0.8095\n",
      "Epoch 99/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6690 - acc: 0.8117 - val_loss: 0.6632 - val_acc: 0.8306\n",
      "Epoch 100/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6644 - acc: 0.8120 - val_loss: 0.6587 - val_acc: 0.8216\n",
      "Epoch 101/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.6600 - acc: 0.8247 - val_loss: 0.6548 - val_acc: 0.8086\n",
      "Epoch 102/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6527 - acc: 0.8125 - val_loss: 0.6474 - val_acc: 0.8229\n",
      "Epoch 103/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.6471 - acc: 0.8247 - val_loss: 0.6417 - val_acc: 0.8190\n",
      "Epoch 104/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.6425 - acc: 0.8173 - val_loss: 0.6373 - val_acc: 0.8305\n",
      "Epoch 105/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.6368 - acc: 0.8254 - val_loss: 0.6319 - val_acc: 0.8235\n",
      "Epoch 106/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6318 - acc: 0.8166 - val_loss: 0.6279 - val_acc: 0.8356\n",
      "Epoch 107/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.6281 - acc: 0.8275 - val_loss: 0.6222 - val_acc: 0.8190\n",
      "Epoch 108/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6225 - acc: 0.8281 - val_loss: 0.6164 - val_acc: 0.8342\n",
      "Epoch 109/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6171 - acc: 0.8319 - val_loss: 0.6122 - val_acc: 0.8282\n",
      "Epoch 110/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.6145 - acc: 0.8225 - val_loss: 0.6105 - val_acc: 0.8286\n",
      "Epoch 111/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.6095 - acc: 0.8284 - val_loss: 0.6045 - val_acc: 0.8354\n",
      "Epoch 112/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6042 - acc: 0.8249 - val_loss: 0.5987 - val_acc: 0.8239\n",
      "Epoch 113/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5989 - acc: 0.8285 - val_loss: 0.5952 - val_acc: 0.8369\n",
      "Epoch 114/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5952 - acc: 0.8310 - val_loss: 0.5914 - val_acc: 0.8355\n",
      "Epoch 115/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5903 - acc: 0.8326 - val_loss: 0.5852 - val_acc: 0.8356\n",
      "Epoch 116/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5855 - acc: 0.8320 - val_loss: 0.5819 - val_acc: 0.8097\n",
      "Epoch 117/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5814 - acc: 0.8235 - val_loss: 0.5812 - val_acc: 0.8386\n",
      "Epoch 118/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5787 - acc: 0.8317 - val_loss: 0.5748 - val_acc: 0.8223\n",
      "Epoch 119/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5753 - acc: 0.8338 - val_loss: 0.5715 - val_acc: 0.8281\n",
      "Epoch 120/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5696 - acc: 0.8310 - val_loss: 0.5653 - val_acc: 0.8349\n",
      "Epoch 121/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5678 - acc: 0.8383 - val_loss: 0.5634 - val_acc: 0.8449\n",
      "Epoch 122/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5633 - acc: 0.8382 - val_loss: 0.5583 - val_acc: 0.8396\n",
      "Epoch 123/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5577 - acc: 0.8426 - val_loss: 0.5545 - val_acc: 0.8366\n",
      "Epoch 124/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5543 - acc: 0.8368 - val_loss: 0.5501 - val_acc: 0.8408\n",
      "Epoch 125/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5512 - acc: 0.8411 - val_loss: 0.5493 - val_acc: 0.8288\n",
      "Epoch 126/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5479 - acc: 0.8316 - val_loss: 0.5433 - val_acc: 0.8438\n",
      "Epoch 127/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5445 - acc: 0.8410 - val_loss: 0.5400 - val_acc: 0.8438\n",
      "Epoch 128/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5409 - acc: 0.8421 - val_loss: 0.5371 - val_acc: 0.8447\n",
      "Epoch 129/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5373 - acc: 0.8394 - val_loss: 0.5336 - val_acc: 0.8459\n",
      "Epoch 130/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5331 - acc: 0.8439 - val_loss: 0.5312 - val_acc: 0.8438\n",
      "Epoch 131/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5320 - acc: 0.8397 - val_loss: 0.5291 - val_acc: 0.8480\n",
      "Epoch 132/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5288 - acc: 0.8415 - val_loss: 0.5260 - val_acc: 0.8419\n",
      "Epoch 133/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5272 - acc: 0.8407 - val_loss: 0.5248 - val_acc: 0.8307\n",
      "Epoch 134/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5233 - acc: 0.8306 - val_loss: 0.5194 - val_acc: 0.8428\n",
      "Epoch 135/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5201 - acc: 0.8398 - val_loss: 0.5189 - val_acc: 0.8313\n",
      "Epoch 136/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5170 - acc: 0.8393 - val_loss: 0.5152 - val_acc: 0.8419\n",
      "Epoch 137/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5142 - acc: 0.8456 - val_loss: 0.5102 - val_acc: 0.8467\n",
      "Epoch 138/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5109 - acc: 0.8432 - val_loss: 0.5067 - val_acc: 0.8459\n",
      "Epoch 139/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5065 - acc: 0.8414 - val_loss: 0.5071 - val_acc: 0.8509\n",
      "Epoch 140/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5076 - acc: 0.8396 - val_loss: 0.5022 - val_acc: 0.8341\n",
      "Epoch 141/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5018 - acc: 0.8440 - val_loss: 0.4987 - val_acc: 0.8417\n",
      "Epoch 142/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4994 - acc: 0.8456 - val_loss: 0.4945 - val_acc: 0.8498\n",
      "Epoch 143/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4958 - acc: 0.8440 - val_loss: 0.4940 - val_acc: 0.8506\n",
      "Epoch 144/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4952 - acc: 0.8475 - val_loss: 0.4951 - val_acc: 0.8398\n",
      "Epoch 145/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4908 - acc: 0.8463 - val_loss: 0.4870 - val_acc: 0.8498\n",
      "Epoch 146/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4896 - acc: 0.8428 - val_loss: 0.4859 - val_acc: 0.8526\n",
      "Epoch 147/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4890 - acc: 0.8498 - val_loss: 0.4921 - val_acc: 0.8572\n",
      "Epoch 148/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4855 - acc: 0.8461 - val_loss: 0.4806 - val_acc: 0.8502\n",
      "Epoch 149/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4825 - acc: 0.8464 - val_loss: 0.4784 - val_acc: 0.8502\n",
      "Epoch 150/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.4781 - acc: 0.8477 - val_loss: 0.4757 - val_acc: 0.8482\n",
      "Epoch 151/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.4767 - acc: 0.8489 - val_loss: 0.4731 - val_acc: 0.8571\n",
      "Epoch 152/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.4728 - acc: 0.8499 - val_loss: 0.4693 - val_acc: 0.8495\n",
      "Epoch 153/300\n",
      "7143/7143 [==============================] - 0s 23us/step - loss: 0.4696 - acc: 0.8470 - val_loss: 0.4675 - val_acc: 0.8550\n",
      "Epoch 154/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.4688 - acc: 0.8512 - val_loss: 0.4651 - val_acc: 0.8545\n",
      "Epoch 155/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.4660 - acc: 0.8516 - val_loss: 0.4626 - val_acc: 0.8527\n",
      "Epoch 156/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.4636 - acc: 0.8572 - val_loss: 0.4625 - val_acc: 0.8541\n",
      "Epoch 157/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.4632 - acc: 0.8524 - val_loss: 0.4588 - val_acc: 0.8551\n",
      "Epoch 158/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4588 - acc: 0.8559 - val_loss: 0.4570 - val_acc: 0.8543\n",
      "Epoch 159/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.4560 - acc: 0.8540 - val_loss: 0.4551 - val_acc: 0.8585\n",
      "Epoch 160/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4530 - acc: 0.8568 - val_loss: 0.4518 - val_acc: 0.8561\n",
      "Epoch 161/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4526 - acc: 0.8548 - val_loss: 0.4492 - val_acc: 0.8583\n",
      "Epoch 162/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4518 - acc: 0.8526 - val_loss: 0.4476 - val_acc: 0.8558\n",
      "Epoch 163/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4488 - acc: 0.8558 - val_loss: 0.4466 - val_acc: 0.8554\n",
      "Epoch 164/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4483 - acc: 0.8578 - val_loss: 0.4433 - val_acc: 0.8578\n",
      "Epoch 165/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4442 - acc: 0.8578 - val_loss: 0.4405 - val_acc: 0.8652\n",
      "Epoch 166/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4421 - acc: 0.8617 - val_loss: 0.4376 - val_acc: 0.8604\n",
      "Epoch 167/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4395 - acc: 0.8566 - val_loss: 0.4380 - val_acc: 0.8634\n",
      "Epoch 168/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4394 - acc: 0.8592 - val_loss: 0.4356 - val_acc: 0.8600\n",
      "Epoch 169/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4349 - acc: 0.8592 - val_loss: 0.4334 - val_acc: 0.8629\n",
      "Epoch 170/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4345 - acc: 0.8597 - val_loss: 0.4303 - val_acc: 0.8702\n",
      "Epoch 171/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4314 - acc: 0.8613 - val_loss: 0.4304 - val_acc: 0.8645\n",
      "Epoch 172/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4307 - acc: 0.8635 - val_loss: 0.4287 - val_acc: 0.8653\n",
      "Epoch 173/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4298 - acc: 0.8613 - val_loss: 0.4271 - val_acc: 0.8666\n",
      "Epoch 174/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4287 - acc: 0.8610 - val_loss: 0.4253 - val_acc: 0.8628\n",
      "Epoch 175/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4243 - acc: 0.8627 - val_loss: 0.4207 - val_acc: 0.8615\n",
      "Epoch 176/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4221 - acc: 0.8667 - val_loss: 0.4210 - val_acc: 0.8648\n",
      "Epoch 177/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4217 - acc: 0.8662 - val_loss: 0.4198 - val_acc: 0.8645\n",
      "Epoch 178/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4193 - acc: 0.8662 - val_loss: 0.4168 - val_acc: 0.8670\n",
      "Epoch 179/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4180 - acc: 0.8632 - val_loss: 0.4126 - val_acc: 0.8691\n",
      "Epoch 180/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4149 - acc: 0.8669 - val_loss: 0.4132 - val_acc: 0.8701\n",
      "Epoch 181/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4145 - acc: 0.8674 - val_loss: 0.4122 - val_acc: 0.8706\n",
      "Epoch 182/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4127 - acc: 0.8663 - val_loss: 0.4087 - val_acc: 0.8741\n",
      "Epoch 183/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4102 - acc: 0.8676 - val_loss: 0.4075 - val_acc: 0.8685\n",
      "Epoch 184/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4095 - acc: 0.8698 - val_loss: 0.4057 - val_acc: 0.8708\n",
      "Epoch 185/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4071 - acc: 0.8669 - val_loss: 0.4059 - val_acc: 0.8744\n",
      "Epoch 186/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4045 - acc: 0.8726 - val_loss: 0.4006 - val_acc: 0.8732\n",
      "Epoch 187/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4018 - acc: 0.8740 - val_loss: 0.4000 - val_acc: 0.8750\n",
      "Epoch 188/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4003 - acc: 0.8719 - val_loss: 0.4009 - val_acc: 0.8722\n",
      "Epoch 189/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4015 - acc: 0.8723 - val_loss: 0.3993 - val_acc: 0.8778\n",
      "Epoch 190/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3989 - acc: 0.8713 - val_loss: 0.3971 - val_acc: 0.8754\n",
      "Epoch 191/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3966 - acc: 0.8685 - val_loss: 0.3936 - val_acc: 0.8723\n",
      "Epoch 192/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3943 - acc: 0.8754 - val_loss: 0.3924 - val_acc: 0.8753\n",
      "Epoch 193/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3938 - acc: 0.8733 - val_loss: 0.3930 - val_acc: 0.8664\n",
      "Epoch 194/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3953 - acc: 0.8718 - val_loss: 0.3904 - val_acc: 0.8796\n",
      "Epoch 195/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3907 - acc: 0.8754 - val_loss: 0.3901 - val_acc: 0.8782\n",
      "Epoch 196/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3888 - acc: 0.8774 - val_loss: 0.3868 - val_acc: 0.8744\n",
      "Epoch 197/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3875 - acc: 0.8767 - val_loss: 0.3843 - val_acc: 0.8768\n",
      "Epoch 198/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3859 - acc: 0.8779 - val_loss: 0.3835 - val_acc: 0.8795\n",
      "Epoch 199/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3842 - acc: 0.8788 - val_loss: 0.3831 - val_acc: 0.8734\n",
      "Epoch 200/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3816 - acc: 0.8761 - val_loss: 0.3789 - val_acc: 0.8788\n",
      "Epoch 201/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3808 - acc: 0.8757 - val_loss: 0.3774 - val_acc: 0.8782\n",
      "Epoch 202/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3784 - acc: 0.8751 - val_loss: 0.3810 - val_acc: 0.8797\n",
      "Epoch 203/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3793 - acc: 0.8803 - val_loss: 0.3792 - val_acc: 0.8807\n",
      "Epoch 204/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3776 - acc: 0.8797 - val_loss: 0.3772 - val_acc: 0.8741\n",
      "Epoch 205/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3762 - acc: 0.8733 - val_loss: 0.3774 - val_acc: 0.8800\n",
      "Epoch 206/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3746 - acc: 0.8807 - val_loss: 0.3723 - val_acc: 0.8816\n",
      "Epoch 207/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3726 - acc: 0.8818 - val_loss: 0.3732 - val_acc: 0.8803\n",
      "Epoch 208/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3727 - acc: 0.8811 - val_loss: 0.3694 - val_acc: 0.8806\n",
      "Epoch 209/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.3705 - acc: 0.8827 - val_loss: 0.3723 - val_acc: 0.8821\n",
      "Epoch 210/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3713 - acc: 0.8772 - val_loss: 0.3684 - val_acc: 0.8807\n",
      "Epoch 211/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3684 - acc: 0.8775 - val_loss: 0.3660 - val_acc: 0.8802\n",
      "Epoch 212/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3664 - acc: 0.8802 - val_loss: 0.3661 - val_acc: 0.8817\n",
      "Epoch 213/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3660 - acc: 0.8811 - val_loss: 0.3609 - val_acc: 0.8852\n",
      "Epoch 214/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3634 - acc: 0.8806 - val_loss: 0.3653 - val_acc: 0.8824\n",
      "Epoch 215/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3640 - acc: 0.8810 - val_loss: 0.3647 - val_acc: 0.8845\n",
      "Epoch 216/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3634 - acc: 0.8795 - val_loss: 0.3609 - val_acc: 0.8830\n",
      "Epoch 217/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3608 - acc: 0.8788 - val_loss: 0.3559 - val_acc: 0.8855\n",
      "Epoch 218/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3580 - acc: 0.8835 - val_loss: 0.3547 - val_acc: 0.8813\n",
      "Epoch 219/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3561 - acc: 0.8830 - val_loss: 0.3539 - val_acc: 0.8838\n",
      "Epoch 220/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3546 - acc: 0.8834 - val_loss: 0.3524 - val_acc: 0.8851\n",
      "Epoch 221/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3532 - acc: 0.8851 - val_loss: 0.3518 - val_acc: 0.8846\n",
      "Epoch 222/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3518 - acc: 0.8832 - val_loss: 0.3495 - val_acc: 0.8849\n",
      "Epoch 223/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3515 - acc: 0.8838 - val_loss: 0.3483 - val_acc: 0.8837\n",
      "Epoch 224/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3501 - acc: 0.8841 - val_loss: 0.3480 - val_acc: 0.8855\n",
      "Epoch 225/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.3484 - acc: 0.8851 - val_loss: 0.3484 - val_acc: 0.8865\n",
      "Epoch 226/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3485 - acc: 0.8838 - val_loss: 0.3469 - val_acc: 0.8870\n",
      "Epoch 227/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3460 - acc: 0.8841 - val_loss: 0.3431 - val_acc: 0.8873\n",
      "Epoch 228/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3448 - acc: 0.8855 - val_loss: 0.3423 - val_acc: 0.8863\n",
      "Epoch 229/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3454 - acc: 0.8848 - val_loss: 0.3425 - val_acc: 0.8914\n",
      "Epoch 230/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3454 - acc: 0.8858 - val_loss: 0.3424 - val_acc: 0.8872\n",
      "Epoch 231/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3432 - acc: 0.8863 - val_loss: 0.3384 - val_acc: 0.8886\n",
      "Epoch 232/300\n",
      "7143/7143 [==============================] - 0s 14us/step - loss: 0.3396 - acc: 0.8888 - val_loss: 0.3380 - val_acc: 0.8890\n",
      "Epoch 233/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3386 - acc: 0.8870 - val_loss: 0.3372 - val_acc: 0.8914\n",
      "Epoch 234/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3384 - acc: 0.8873 - val_loss: 0.3352 - val_acc: 0.8908\n",
      "Epoch 235/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3366 - acc: 0.8907 - val_loss: 0.3354 - val_acc: 0.8877\n",
      "Epoch 236/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3349 - acc: 0.8902 - val_loss: 0.3359 - val_acc: 0.8918\n",
      "Epoch 237/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3343 - acc: 0.8886 - val_loss: 0.3348 - val_acc: 0.8839\n",
      "Epoch 238/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3342 - acc: 0.8928 - val_loss: 0.3334 - val_acc: 0.8880\n",
      "Epoch 239/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3355 - acc: 0.8876 - val_loss: 0.3351 - val_acc: 0.8877\n",
      "Epoch 240/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3347 - acc: 0.8901 - val_loss: 0.3305 - val_acc: 0.8894\n",
      "Epoch 241/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.3315 - acc: 0.8888 - val_loss: 0.3294 - val_acc: 0.8855\n",
      "Epoch 242/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3285 - acc: 0.8937 - val_loss: 0.3252 - val_acc: 0.8923\n",
      "Epoch 243/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.3280 - acc: 0.8898 - val_loss: 0.3276 - val_acc: 0.8876\n",
      "Epoch 244/300\n",
      "7143/7143 [==============================] - 0s 23us/step - loss: 0.3276 - acc: 0.8879 - val_loss: 0.3242 - val_acc: 0.8886\n",
      "Epoch 245/300\n",
      "7143/7143 [==============================] - 0s 25us/step - loss: 0.3274 - acc: 0.8879 - val_loss: 0.3263 - val_acc: 0.8919\n",
      "Epoch 246/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.3251 - acc: 0.8921 - val_loss: 0.3228 - val_acc: 0.8930\n",
      "Epoch 247/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.3248 - acc: 0.8921 - val_loss: 0.3246 - val_acc: 0.8897\n",
      "Epoch 248/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3222 - acc: 0.8935 - val_loss: 0.3228 - val_acc: 0.8958\n",
      "Epoch 249/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3218 - acc: 0.8923 - val_loss: 0.3182 - val_acc: 0.8895\n",
      "Epoch 250/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.3213 - acc: 0.8926 - val_loss: 0.3205 - val_acc: 0.8991\n",
      "Epoch 251/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.3202 - acc: 0.8908 - val_loss: 0.3171 - val_acc: 0.9016\n",
      "Epoch 252/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.3176 - acc: 0.8961 - val_loss: 0.3148 - val_acc: 0.8894\n",
      "Epoch 253/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.3155 - acc: 0.8929 - val_loss: 0.3148 - val_acc: 0.8953\n",
      "Epoch 254/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.3162 - acc: 0.8926 - val_loss: 0.3168 - val_acc: 0.8944\n",
      "Epoch 255/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3153 - acc: 0.8937 - val_loss: 0.3136 - val_acc: 0.8975\n",
      "Epoch 256/300\n",
      "7143/7143 [==============================] - 0s 23us/step - loss: 0.3148 - acc: 0.8958 - val_loss: 0.3119 - val_acc: 0.8974\n",
      "Epoch 257/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.3144 - acc: 0.8958 - val_loss: 0.3134 - val_acc: 0.9021\n",
      "Epoch 258/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3149 - acc: 0.8929 - val_loss: 0.3139 - val_acc: 0.8902\n",
      "Epoch 259/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3144 - acc: 0.8918 - val_loss: 0.3137 - val_acc: 0.8895\n",
      "Epoch 260/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3128 - acc: 0.8932 - val_loss: 0.3088 - val_acc: 0.8982\n",
      "Epoch 261/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3143 - acc: 0.8895 - val_loss: 0.3099 - val_acc: 0.9012\n",
      "Epoch 262/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3122 - acc: 0.8922 - val_loss: 0.3127 - val_acc: 0.8988\n",
      "Epoch 263/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3088 - acc: 0.8956 - val_loss: 0.3041 - val_acc: 0.8968\n",
      "Epoch 264/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3060 - acc: 0.8993 - val_loss: 0.3044 - val_acc: 0.9038\n",
      "Epoch 265/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3054 - acc: 0.8984 - val_loss: 0.3025 - val_acc: 0.8981\n",
      "Epoch 266/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3038 - acc: 0.9017 - val_loss: 0.3049 - val_acc: 0.8881\n",
      "Epoch 267/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3055 - acc: 0.8940 - val_loss: 0.3024 - val_acc: 0.9006\n",
      "Epoch 268/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3037 - acc: 0.8958 - val_loss: 0.3033 - val_acc: 0.9006\n",
      "Epoch 269/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3019 - acc: 0.8988 - val_loss: 0.3017 - val_acc: 0.8925\n",
      "Epoch 270/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3033 - acc: 0.8984 - val_loss: 0.3016 - val_acc: 0.8897\n",
      "Epoch 271/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3006 - acc: 0.8975 - val_loss: 0.2983 - val_acc: 0.8902\n",
      "Epoch 272/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3007 - acc: 0.8970 - val_loss: 0.2991 - val_acc: 0.8954\n",
      "Epoch 273/300\n",
      "7143/7143 [==============================] - 0s 14us/step - loss: 0.2999 - acc: 0.8956 - val_loss: 0.2990 - val_acc: 0.8967\n",
      "Epoch 274/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2988 - acc: 0.8946 - val_loss: 0.2951 - val_acc: 0.8972\n",
      "Epoch 275/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2992 - acc: 0.9006 - val_loss: 0.2984 - val_acc: 0.8977\n",
      "Epoch 276/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.2961 - acc: 0.9002 - val_loss: 0.2937 - val_acc: 0.9100\n",
      "Epoch 277/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.2950 - acc: 0.8999 - val_loss: 0.2932 - val_acc: 0.9110\n",
      "Epoch 278/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2934 - acc: 0.9003 - val_loss: 0.2929 - val_acc: 0.9035\n",
      "Epoch 279/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2926 - acc: 0.9016 - val_loss: 0.2900 - val_acc: 0.9038\n",
      "Epoch 280/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2928 - acc: 0.9005 - val_loss: 0.2903 - val_acc: 0.8953\n",
      "Epoch 281/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2921 - acc: 0.9012 - val_loss: 0.2905 - val_acc: 0.9072\n",
      "Epoch 282/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2917 - acc: 0.9027 - val_loss: 0.2877 - val_acc: 0.8974\n",
      "Epoch 283/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.2894 - acc: 0.9040 - val_loss: 0.2879 - val_acc: 0.8961\n",
      "Epoch 284/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2874 - acc: 0.9026 - val_loss: 0.2852 - val_acc: 0.8986\n",
      "Epoch 285/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2867 - acc: 0.9010 - val_loss: 0.2848 - val_acc: 0.9055\n",
      "Epoch 286/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2868 - acc: 0.9054 - val_loss: 0.2854 - val_acc: 0.8972\n",
      "Epoch 287/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2855 - acc: 0.9056 - val_loss: 0.2852 - val_acc: 0.9055\n",
      "Epoch 288/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2839 - acc: 0.9016 - val_loss: 0.2846 - val_acc: 0.9080\n",
      "Epoch 289/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2831 - acc: 0.9072 - val_loss: 0.2823 - val_acc: 0.8964\n",
      "Epoch 290/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2830 - acc: 0.9031 - val_loss: 0.2813 - val_acc: 0.9069\n",
      "Epoch 291/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2828 - acc: 0.9028 - val_loss: 0.2801 - val_acc: 0.8996\n",
      "Epoch 292/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2825 - acc: 0.9072 - val_loss: 0.2805 - val_acc: 0.9076\n",
      "Epoch 293/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2808 - acc: 0.9041 - val_loss: 0.2785 - val_acc: 0.9047\n",
      "Epoch 294/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2783 - acc: 0.9077 - val_loss: 0.2807 - val_acc: 0.9065\n",
      "Epoch 295/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2797 - acc: 0.9082 - val_loss: 0.2768 - val_acc: 0.9083\n",
      "Epoch 296/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2797 - acc: 0.9094 - val_loss: 0.2814 - val_acc: 0.9006\n",
      "Epoch 297/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2805 - acc: 0.9033 - val_loss: 0.2782 - val_acc: 0.9084\n",
      "Epoch 298/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2785 - acc: 0.9058 - val_loss: 0.2747 - val_acc: 0.9107\n",
      "Epoch 299/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2769 - acc: 0.9066 - val_loss: 0.2743 - val_acc: 0.9101\n",
      "Epoch 300/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2769 - acc: 0.9023 - val_loss: 0.2723 - val_acc: 0.9157\n",
      "28574/28574 [==============================] - 2s 67us/step\n",
      "7143/7143 [==============================] - 0s 67us/step\n",
      "Train on 7143 samples, validate on 7143 samples\n",
      "Epoch 1/300\n",
      "7143/7143 [==============================] - 3s 434us/step - loss: 3.3789 - acc: 0.0627 - val_loss: 3.3402 - val_acc: 0.0687\n",
      "Epoch 2/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 3.3049 - acc: 0.0795 - val_loss: 3.2616 - val_acc: 0.0944\n",
      "Epoch 3/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 3.2210 - acc: 0.1154 - val_loss: 3.1703 - val_acc: 0.1246\n",
      "Epoch 4/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 3.1218 - acc: 0.1212 - val_loss: 3.0629 - val_acc: 0.1194\n",
      "Epoch 5/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 3.0105 - acc: 0.1225 - val_loss: 2.9497 - val_acc: 0.1259\n",
      "Epoch 6/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.8998 - acc: 0.1204 - val_loss: 2.8430 - val_acc: 0.1261\n",
      "Epoch 7/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.7992 - acc: 0.1322 - val_loss: 2.7489 - val_acc: 0.1294\n",
      "Epoch 8/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.7113 - acc: 0.1424 - val_loss: 2.6677 - val_acc: 0.1655\n",
      "Epoch 9/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.6339 - acc: 0.1932 - val_loss: 2.5940 - val_acc: 0.2183\n",
      "Epoch 10/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.5636 - acc: 0.2185 - val_loss: 2.5262 - val_acc: 0.2239\n",
      "Epoch 11/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 2.4958 - acc: 0.2437 - val_loss: 2.4583 - val_acc: 0.2684\n",
      "Epoch 12/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.4284 - acc: 0.2740 - val_loss: 2.3905 - val_acc: 0.2859\n",
      "Epoch 13/300\n",
      "7143/7143 [==============================] - 0s 14us/step - loss: 2.3595 - acc: 0.3002 - val_loss: 2.3222 - val_acc: 0.3000\n",
      "Epoch 14/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 2.2920 - acc: 0.3093 - val_loss: 2.2552 - val_acc: 0.3144\n",
      "Epoch 15/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.2266 - acc: 0.3276 - val_loss: 2.1911 - val_acc: 0.3290\n",
      "Epoch 16/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 2.1637 - acc: 0.3259 - val_loss: 2.1304 - val_acc: 0.3305\n",
      "Epoch 17/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.1045 - acc: 0.3307 - val_loss: 2.0723 - val_acc: 0.3420\n",
      "Epoch 18/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.0488 - acc: 0.3503 - val_loss: 2.0181 - val_acc: 0.3501\n",
      "Epoch 19/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.9967 - acc: 0.3689 - val_loss: 1.9675 - val_acc: 0.3944\n",
      "Epoch 20/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.9464 - acc: 0.3833 - val_loss: 1.9196 - val_acc: 0.3993\n",
      "Epoch 21/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.9002 - acc: 0.4155 - val_loss: 1.8746 - val_acc: 0.4283\n",
      "Epoch 22/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.8562 - acc: 0.4197 - val_loss: 1.8318 - val_acc: 0.4165\n",
      "Epoch 23/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.8144 - acc: 0.4329 - val_loss: 1.7913 - val_acc: 0.4479\n",
      "Epoch 24/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.7750 - acc: 0.4500 - val_loss: 1.7526 - val_acc: 0.4592\n",
      "Epoch 25/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.7371 - acc: 0.4645 - val_loss: 1.7159 - val_acc: 0.4665\n",
      "Epoch 26/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.7015 - acc: 0.4732 - val_loss: 1.6799 - val_acc: 0.4799\n",
      "Epoch 27/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.6665 - acc: 0.4980 - val_loss: 1.6463 - val_acc: 0.5181\n",
      "Epoch 28/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.6323 - acc: 0.5073 - val_loss: 1.6126 - val_acc: 0.5118\n",
      "Epoch 29/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.6004 - acc: 0.5197 - val_loss: 1.5813 - val_acc: 0.5362\n",
      "Epoch 30/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.5697 - acc: 0.5384 - val_loss: 1.5506 - val_acc: 0.5437\n",
      "Epoch 31/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.5400 - acc: 0.5659 - val_loss: 1.5220 - val_acc: 0.5598\n",
      "Epoch 32/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.5105 - acc: 0.5582 - val_loss: 1.4942 - val_acc: 0.5752\n",
      "Epoch 33/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.4838 - acc: 0.5790 - val_loss: 1.4678 - val_acc: 0.5810\n",
      "Epoch 34/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.4588 - acc: 0.5853 - val_loss: 1.4419 - val_acc: 0.5846\n",
      "Epoch 35/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.4332 - acc: 0.5955 - val_loss: 1.4170 - val_acc: 0.6135\n",
      "Epoch 36/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.4087 - acc: 0.6042 - val_loss: 1.3932 - val_acc: 0.6178\n",
      "Epoch 37/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.3858 - acc: 0.5958 - val_loss: 1.3706 - val_acc: 0.6210\n",
      "Epoch 38/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.3635 - acc: 0.6083 - val_loss: 1.3484 - val_acc: 0.6275\n",
      "Epoch 39/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.3407 - acc: 0.6224 - val_loss: 1.3268 - val_acc: 0.6293\n",
      "Epoch 40/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.3200 - acc: 0.6202 - val_loss: 1.3064 - val_acc: 0.6305\n",
      "Epoch 41/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 1.2996 - acc: 0.6359 - val_loss: 1.2862 - val_acc: 0.6553\n",
      "Epoch 42/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.2796 - acc: 0.6378 - val_loss: 1.2676 - val_acc: 0.6594\n",
      "Epoch 43/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.2609 - acc: 0.6367 - val_loss: 1.2489 - val_acc: 0.6527\n",
      "Epoch 44/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.2419 - acc: 0.6676 - val_loss: 1.2300 - val_acc: 0.6660\n",
      "Epoch 45/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.2250 - acc: 0.6688 - val_loss: 1.2129 - val_acc: 0.6857\n",
      "Epoch 46/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.2077 - acc: 0.6772 - val_loss: 1.1961 - val_acc: 0.6576\n",
      "Epoch 47/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.1906 - acc: 0.6622 - val_loss: 1.1792 - val_acc: 0.6821\n",
      "Epoch 48/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.1750 - acc: 0.6711 - val_loss: 1.1640 - val_acc: 0.6788\n",
      "Epoch 49/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.1603 - acc: 0.6808 - val_loss: 1.1471 - val_acc: 0.7042\n",
      "Epoch 50/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.1433 - acc: 0.6725 - val_loss: 1.1315 - val_acc: 0.7014\n",
      "Epoch 51/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.1280 - acc: 0.6989 - val_loss: 1.1170 - val_acc: 0.7064\n",
      "Epoch 52/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.1128 - acc: 0.7123 - val_loss: 1.1030 - val_acc: 0.7115\n",
      "Epoch 53/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.0976 - acc: 0.7039 - val_loss: 1.0873 - val_acc: 0.7040\n",
      "Epoch 54/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.0838 - acc: 0.6913 - val_loss: 1.0742 - val_acc: 0.7414\n",
      "Epoch 55/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.0699 - acc: 0.7267 - val_loss: 1.0606 - val_acc: 0.7182\n",
      "Epoch 56/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.0564 - acc: 0.7151 - val_loss: 1.0468 - val_acc: 0.7367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.0418 - acc: 0.7379 - val_loss: 1.0332 - val_acc: 0.7353\n",
      "Epoch 58/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.0294 - acc: 0.7322 - val_loss: 1.0206 - val_acc: 0.7388\n",
      "Epoch 59/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.0170 - acc: 0.7411 - val_loss: 1.0079 - val_acc: 0.7466\n",
      "Epoch 60/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.0052 - acc: 0.7347 - val_loss: 0.9963 - val_acc: 0.7379\n",
      "Epoch 61/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.9918 - acc: 0.7375 - val_loss: 0.9831 - val_acc: 0.7612\n",
      "Epoch 62/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.9798 - acc: 0.7546 - val_loss: 0.9701 - val_acc: 0.7543\n",
      "Epoch 63/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.9682 - acc: 0.7544 - val_loss: 0.9581 - val_acc: 0.7677\n",
      "Epoch 64/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.9553 - acc: 0.7484 - val_loss: 0.9472 - val_acc: 0.7498\n",
      "Epoch 65/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.9450 - acc: 0.7575 - val_loss: 0.9348 - val_acc: 0.7736\n",
      "Epoch 66/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.9333 - acc: 0.7698 - val_loss: 0.9252 - val_acc: 0.7628\n",
      "Epoch 67/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.9238 - acc: 0.7553 - val_loss: 0.9145 - val_acc: 0.7700\n",
      "Epoch 68/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.9118 - acc: 0.7781 - val_loss: 0.9035 - val_acc: 0.7841\n",
      "Epoch 69/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.9018 - acc: 0.7655 - val_loss: 0.8940 - val_acc: 0.7768\n",
      "Epoch 70/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.8908 - acc: 0.7792 - val_loss: 0.8830 - val_acc: 0.7719\n",
      "Epoch 71/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.8811 - acc: 0.7696 - val_loss: 0.8721 - val_acc: 0.7868\n",
      "Epoch 72/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.8710 - acc: 0.7654 - val_loss: 0.8638 - val_acc: 0.7844\n",
      "Epoch 73/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.8610 - acc: 0.7824 - val_loss: 0.8529 - val_acc: 0.7910\n",
      "Epoch 74/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.8518 - acc: 0.7736 - val_loss: 0.8468 - val_acc: 0.7864\n",
      "Epoch 75/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.8437 - acc: 0.7743 - val_loss: 0.8354 - val_acc: 0.7704\n",
      "Epoch 76/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.8327 - acc: 0.7866 - val_loss: 0.8248 - val_acc: 0.7991\n",
      "Epoch 77/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.8238 - acc: 0.7995 - val_loss: 0.8141 - val_acc: 0.7983\n",
      "Epoch 78/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.8125 - acc: 0.8004 - val_loss: 0.8055 - val_acc: 0.8057\n",
      "Epoch 79/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.8055 - acc: 0.8005 - val_loss: 0.7978 - val_acc: 0.8026\n",
      "Epoch 80/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.7976 - acc: 0.8050 - val_loss: 0.7899 - val_acc: 0.7998\n",
      "Epoch 81/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.7877 - acc: 0.7950 - val_loss: 0.7809 - val_acc: 0.8008\n",
      "Epoch 82/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.7802 - acc: 0.7974 - val_loss: 0.7725 - val_acc: 0.8047\n",
      "Epoch 83/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.7708 - acc: 0.8062 - val_loss: 0.7636 - val_acc: 0.8041\n",
      "Epoch 84/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.7630 - acc: 0.8018 - val_loss: 0.7576 - val_acc: 0.7984\n",
      "Epoch 85/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.7552 - acc: 0.7939 - val_loss: 0.7502 - val_acc: 0.8057\n",
      "Epoch 86/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.7477 - acc: 0.8097 - val_loss: 0.7408 - val_acc: 0.8090\n",
      "Epoch 87/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.7386 - acc: 0.8075 - val_loss: 0.7327 - val_acc: 0.8085\n",
      "Epoch 88/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.7327 - acc: 0.8027 - val_loss: 0.7258 - val_acc: 0.8086\n",
      "Epoch 89/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.7253 - acc: 0.8054 - val_loss: 0.7203 - val_acc: 0.8099\n",
      "Epoch 90/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.7192 - acc: 0.8076 - val_loss: 0.7139 - val_acc: 0.8102\n",
      "Epoch 91/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.7133 - acc: 0.8100 - val_loss: 0.7054 - val_acc: 0.8075\n",
      "Epoch 92/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.7031 - acc: 0.8162 - val_loss: 0.6978 - val_acc: 0.8106\n",
      "Epoch 93/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.6980 - acc: 0.8125 - val_loss: 0.6925 - val_acc: 0.8096\n",
      "Epoch 94/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6918 - acc: 0.8102 - val_loss: 0.6877 - val_acc: 0.8163\n",
      "Epoch 95/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6857 - acc: 0.8118 - val_loss: 0.6820 - val_acc: 0.8137\n",
      "Epoch 96/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6797 - acc: 0.8099 - val_loss: 0.6720 - val_acc: 0.8144\n",
      "Epoch 97/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6738 - acc: 0.8124 - val_loss: 0.6692 - val_acc: 0.8165\n",
      "Epoch 98/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.6669 - acc: 0.8172 - val_loss: 0.6634 - val_acc: 0.8237\n",
      "Epoch 99/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.6620 - acc: 0.8158 - val_loss: 0.6556 - val_acc: 0.8155\n",
      "Epoch 100/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6565 - acc: 0.8215 - val_loss: 0.6495 - val_acc: 0.8179\n",
      "Epoch 101/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.6489 - acc: 0.8148 - val_loss: 0.6451 - val_acc: 0.8165\n",
      "Epoch 102/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.6442 - acc: 0.8181 - val_loss: 0.6368 - val_acc: 0.8153\n",
      "Epoch 103/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.6393 - acc: 0.8109 - val_loss: 0.6341 - val_acc: 0.8103\n",
      "Epoch 104/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.6315 - acc: 0.8097 - val_loss: 0.6279 - val_acc: 0.8247\n",
      "Epoch 105/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6276 - acc: 0.8186 - val_loss: 0.6223 - val_acc: 0.8277\n",
      "Epoch 106/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6227 - acc: 0.8200 - val_loss: 0.6187 - val_acc: 0.8141\n",
      "Epoch 107/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.6170 - acc: 0.8244 - val_loss: 0.6119 - val_acc: 0.8244\n",
      "Epoch 108/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6107 - acc: 0.8198 - val_loss: 0.6062 - val_acc: 0.8233\n",
      "Epoch 109/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6055 - acc: 0.8228 - val_loss: 0.6038 - val_acc: 0.8242\n",
      "Epoch 110/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.6025 - acc: 0.8250 - val_loss: 0.5969 - val_acc: 0.8214\n",
      "Epoch 111/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5973 - acc: 0.8272 - val_loss: 0.5929 - val_acc: 0.8300\n",
      "Epoch 112/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5932 - acc: 0.8225 - val_loss: 0.5884 - val_acc: 0.8286\n",
      "Epoch 113/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5892 - acc: 0.8229 - val_loss: 0.5840 - val_acc: 0.8369\n",
      "Epoch 114/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5833 - acc: 0.8372 - val_loss: 0.5792 - val_acc: 0.8298\n",
      "Epoch 115/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5794 - acc: 0.8334 - val_loss: 0.5747 - val_acc: 0.8233\n",
      "Epoch 116/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5754 - acc: 0.8300 - val_loss: 0.5696 - val_acc: 0.8309\n",
      "Epoch 117/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5709 - acc: 0.8291 - val_loss: 0.5660 - val_acc: 0.8368\n",
      "Epoch 118/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5664 - acc: 0.8312 - val_loss: 0.5615 - val_acc: 0.8368\n",
      "Epoch 119/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5619 - acc: 0.8348 - val_loss: 0.5593 - val_acc: 0.8263\n",
      "Epoch 120/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5574 - acc: 0.8326 - val_loss: 0.5536 - val_acc: 0.8342\n",
      "Epoch 121/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5538 - acc: 0.8384 - val_loss: 0.5514 - val_acc: 0.8323\n",
      "Epoch 122/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5503 - acc: 0.8342 - val_loss: 0.5460 - val_acc: 0.8383\n",
      "Epoch 123/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5447 - acc: 0.8426 - val_loss: 0.5421 - val_acc: 0.8468\n",
      "Epoch 124/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5407 - acc: 0.8464 - val_loss: 0.5393 - val_acc: 0.8397\n",
      "Epoch 125/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5414 - acc: 0.8391 - val_loss: 0.5373 - val_acc: 0.8323\n",
      "Epoch 126/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.5369 - acc: 0.8334 - val_loss: 0.5332 - val_acc: 0.8363\n",
      "Epoch 127/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5342 - acc: 0.8365 - val_loss: 0.5275 - val_acc: 0.8393\n",
      "Epoch 128/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.5277 - acc: 0.8450 - val_loss: 0.5269 - val_acc: 0.8377\n",
      "Epoch 129/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.5260 - acc: 0.8438 - val_loss: 0.5214 - val_acc: 0.8438\n",
      "Epoch 130/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.5196 - acc: 0.8412 - val_loss: 0.5174 - val_acc: 0.8531\n",
      "Epoch 131/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.5170 - acc: 0.8467 - val_loss: 0.5140 - val_acc: 0.8330\n",
      "Epoch 132/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5140 - acc: 0.8426 - val_loss: 0.5098 - val_acc: 0.8527\n",
      "Epoch 133/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.5108 - acc: 0.8481 - val_loss: 0.5066 - val_acc: 0.8417\n",
      "Epoch 134/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.5064 - acc: 0.8457 - val_loss: 0.5045 - val_acc: 0.8457\n",
      "Epoch 135/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5049 - acc: 0.8461 - val_loss: 0.5012 - val_acc: 0.8419\n",
      "Epoch 136/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5013 - acc: 0.8468 - val_loss: 0.4972 - val_acc: 0.8482\n",
      "Epoch 137/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4979 - acc: 0.8478 - val_loss: 0.4937 - val_acc: 0.8450\n",
      "Epoch 138/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4954 - acc: 0.8468 - val_loss: 0.4949 - val_acc: 0.8449\n",
      "Epoch 139/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4945 - acc: 0.8457 - val_loss: 0.4900 - val_acc: 0.8445\n",
      "Epoch 140/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.4881 - acc: 0.8494 - val_loss: 0.4869 - val_acc: 0.8540\n",
      "Epoch 141/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4867 - acc: 0.8534 - val_loss: 0.4835 - val_acc: 0.8551\n",
      "Epoch 142/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4841 - acc: 0.8509 - val_loss: 0.4796 - val_acc: 0.8545\n",
      "Epoch 143/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4807 - acc: 0.8536 - val_loss: 0.4774 - val_acc: 0.8583\n",
      "Epoch 144/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.4789 - acc: 0.8513 - val_loss: 0.4744 - val_acc: 0.8482\n",
      "Epoch 145/300\n",
      "7143/7143 [==============================] - 0s 14us/step - loss: 0.4767 - acc: 0.8523 - val_loss: 0.4754 - val_acc: 0.8417\n",
      "Epoch 146/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4735 - acc: 0.8485 - val_loss: 0.4708 - val_acc: 0.8484\n",
      "Epoch 147/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4690 - acc: 0.8537 - val_loss: 0.4676 - val_acc: 0.8554\n",
      "Epoch 148/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.4666 - acc: 0.8515 - val_loss: 0.4673 - val_acc: 0.8578\n",
      "Epoch 149/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4659 - acc: 0.8550 - val_loss: 0.4643 - val_acc: 0.8611\n",
      "Epoch 150/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4648 - acc: 0.8548 - val_loss: 0.4618 - val_acc: 0.8583\n",
      "Epoch 151/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.4598 - acc: 0.8568 - val_loss: 0.4571 - val_acc: 0.8519\n",
      "Epoch 152/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4582 - acc: 0.8554 - val_loss: 0.4539 - val_acc: 0.8566\n",
      "Epoch 153/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4542 - acc: 0.8583 - val_loss: 0.4520 - val_acc: 0.8627\n",
      "Epoch 154/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4545 - acc: 0.8559 - val_loss: 0.4536 - val_acc: 0.8559\n",
      "Epoch 155/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.4496 - acc: 0.8573 - val_loss: 0.4512 - val_acc: 0.8496\n",
      "Epoch 156/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4504 - acc: 0.8566 - val_loss: 0.4449 - val_acc: 0.8554\n",
      "Epoch 157/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4459 - acc: 0.8558 - val_loss: 0.4439 - val_acc: 0.8641\n",
      "Epoch 158/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4435 - acc: 0.8564 - val_loss: 0.4449 - val_acc: 0.8470\n",
      "Epoch 159/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4421 - acc: 0.8538 - val_loss: 0.4391 - val_acc: 0.8572\n",
      "Epoch 160/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4386 - acc: 0.8578 - val_loss: 0.4364 - val_acc: 0.8625\n",
      "Epoch 161/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4363 - acc: 0.8632 - val_loss: 0.4327 - val_acc: 0.8603\n",
      "Epoch 162/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4331 - acc: 0.8607 - val_loss: 0.4302 - val_acc: 0.8669\n",
      "Epoch 163/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4319 - acc: 0.8641 - val_loss: 0.4280 - val_acc: 0.8624\n",
      "Epoch 164/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4297 - acc: 0.8638 - val_loss: 0.4290 - val_acc: 0.8594\n",
      "Epoch 165/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4279 - acc: 0.8629 - val_loss: 0.4254 - val_acc: 0.8669\n",
      "Epoch 166/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4261 - acc: 0.8621 - val_loss: 0.4234 - val_acc: 0.8676\n",
      "Epoch 167/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4245 - acc: 0.8641 - val_loss: 0.4204 - val_acc: 0.8642\n",
      "Epoch 168/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4234 - acc: 0.8635 - val_loss: 0.4177 - val_acc: 0.8678\n",
      "Epoch 169/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4205 - acc: 0.8656 - val_loss: 0.4161 - val_acc: 0.8664\n",
      "Epoch 170/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4168 - acc: 0.8657 - val_loss: 0.4142 - val_acc: 0.8688\n",
      "Epoch 171/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4153 - acc: 0.8673 - val_loss: 0.4121 - val_acc: 0.8670\n",
      "Epoch 172/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4113 - acc: 0.8680 - val_loss: 0.4096 - val_acc: 0.8687\n",
      "Epoch 173/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4113 - acc: 0.8676 - val_loss: 0.4088 - val_acc: 0.8666\n",
      "Epoch 174/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.4093 - acc: 0.8701 - val_loss: 0.4067 - val_acc: 0.8680\n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4067 - acc: 0.8660 - val_loss: 0.4059 - val_acc: 0.8739\n",
      "Epoch 176/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4052 - acc: 0.8708 - val_loss: 0.4017 - val_acc: 0.8660\n",
      "Epoch 177/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4044 - acc: 0.8653 - val_loss: 0.4031 - val_acc: 0.8657\n",
      "Epoch 178/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.4019 - acc: 0.8628 - val_loss: 0.3973 - val_acc: 0.8723\n",
      "Epoch 179/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3981 - acc: 0.8706 - val_loss: 0.3951 - val_acc: 0.8709\n",
      "Epoch 180/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3962 - acc: 0.8690 - val_loss: 0.3931 - val_acc: 0.8713\n",
      "Epoch 181/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3952 - acc: 0.8730 - val_loss: 0.3933 - val_acc: 0.8706\n",
      "Epoch 182/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3941 - acc: 0.8705 - val_loss: 0.3912 - val_acc: 0.8713\n",
      "Epoch 183/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3904 - acc: 0.8691 - val_loss: 0.3904 - val_acc: 0.8701\n",
      "Epoch 184/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3905 - acc: 0.8716 - val_loss: 0.3863 - val_acc: 0.8719\n",
      "Epoch 185/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3885 - acc: 0.8741 - val_loss: 0.3861 - val_acc: 0.8683\n",
      "Epoch 186/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3870 - acc: 0.8719 - val_loss: 0.3832 - val_acc: 0.8747\n",
      "Epoch 187/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3851 - acc: 0.8706 - val_loss: 0.3836 - val_acc: 0.8740\n",
      "Epoch 188/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3829 - acc: 0.8722 - val_loss: 0.3836 - val_acc: 0.8676\n",
      "Epoch 189/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3831 - acc: 0.8746 - val_loss: 0.3804 - val_acc: 0.8694\n",
      "Epoch 190/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3817 - acc: 0.8720 - val_loss: 0.3806 - val_acc: 0.8740\n",
      "Epoch 191/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3793 - acc: 0.8743 - val_loss: 0.3792 - val_acc: 0.8739\n",
      "Epoch 192/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3770 - acc: 0.8760 - val_loss: 0.3758 - val_acc: 0.8765\n",
      "Epoch 193/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3773 - acc: 0.8729 - val_loss: 0.3761 - val_acc: 0.8753\n",
      "Epoch 194/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3757 - acc: 0.8734 - val_loss: 0.3697 - val_acc: 0.8743\n",
      "Epoch 195/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3702 - acc: 0.8776 - val_loss: 0.3692 - val_acc: 0.8778\n",
      "Epoch 196/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3695 - acc: 0.8769 - val_loss: 0.3664 - val_acc: 0.8778\n",
      "Epoch 197/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3694 - acc: 0.8748 - val_loss: 0.3642 - val_acc: 0.8779\n",
      "Epoch 198/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3684 - acc: 0.8747 - val_loss: 0.3677 - val_acc: 0.8718\n",
      "Epoch 199/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3675 - acc: 0.8754 - val_loss: 0.3655 - val_acc: 0.8730\n",
      "Epoch 200/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3638 - acc: 0.8775 - val_loss: 0.3604 - val_acc: 0.8774\n",
      "Epoch 201/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3622 - acc: 0.8757 - val_loss: 0.3617 - val_acc: 0.8809\n",
      "Epoch 202/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3612 - acc: 0.8767 - val_loss: 0.3567 - val_acc: 0.8788\n",
      "Epoch 203/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3596 - acc: 0.8776 - val_loss: 0.3584 - val_acc: 0.8789\n",
      "Epoch 204/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3582 - acc: 0.8792 - val_loss: 0.3556 - val_acc: 0.8800\n",
      "Epoch 205/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3576 - acc: 0.8799 - val_loss: 0.3547 - val_acc: 0.8785\n",
      "Epoch 206/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3543 - acc: 0.8768 - val_loss: 0.3527 - val_acc: 0.8832\n",
      "Epoch 207/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3529 - acc: 0.8796 - val_loss: 0.3497 - val_acc: 0.8788\n",
      "Epoch 208/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3516 - acc: 0.8802 - val_loss: 0.3495 - val_acc: 0.8802\n",
      "Epoch 209/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3496 - acc: 0.8793 - val_loss: 0.3477 - val_acc: 0.8823\n",
      "Epoch 210/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3475 - acc: 0.8806 - val_loss: 0.3479 - val_acc: 0.8918\n",
      "Epoch 211/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3481 - acc: 0.8804 - val_loss: 0.3459 - val_acc: 0.8807\n",
      "Epoch 212/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3468 - acc: 0.8851 - val_loss: 0.3455 - val_acc: 0.8793\n",
      "Epoch 213/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3436 - acc: 0.8835 - val_loss: 0.3414 - val_acc: 0.8790\n",
      "Epoch 214/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3432 - acc: 0.8800 - val_loss: 0.3426 - val_acc: 0.8862\n",
      "Epoch 215/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3430 - acc: 0.8813 - val_loss: 0.3388 - val_acc: 0.8859\n",
      "Epoch 216/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3403 - acc: 0.8866 - val_loss: 0.3393 - val_acc: 0.8783\n",
      "Epoch 217/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3406 - acc: 0.8837 - val_loss: 0.3397 - val_acc: 0.8793\n",
      "Epoch 218/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3387 - acc: 0.8803 - val_loss: 0.3339 - val_acc: 0.8830\n",
      "Epoch 219/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3356 - acc: 0.8816 - val_loss: 0.3342 - val_acc: 0.8865\n",
      "Epoch 220/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3360 - acc: 0.8825 - val_loss: 0.3354 - val_acc: 0.8754\n",
      "Epoch 221/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3345 - acc: 0.8818 - val_loss: 0.3311 - val_acc: 0.8816\n",
      "Epoch 222/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3339 - acc: 0.8792 - val_loss: 0.3369 - val_acc: 0.8855\n",
      "Epoch 223/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3336 - acc: 0.8842 - val_loss: 0.3293 - val_acc: 0.8831\n",
      "Epoch 224/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3289 - acc: 0.8860 - val_loss: 0.3290 - val_acc: 0.8891\n",
      "Epoch 225/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.3299 - acc: 0.8853 - val_loss: 0.3336 - val_acc: 0.8772\n",
      "Epoch 226/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3284 - acc: 0.8844 - val_loss: 0.3268 - val_acc: 0.8858\n",
      "Epoch 227/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3278 - acc: 0.8856 - val_loss: 0.3276 - val_acc: 0.8786\n",
      "Epoch 228/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3267 - acc: 0.8874 - val_loss: 0.3245 - val_acc: 0.8830\n",
      "Epoch 229/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3230 - acc: 0.8869 - val_loss: 0.3210 - val_acc: 0.8848\n",
      "Epoch 230/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3229 - acc: 0.8853 - val_loss: 0.3206 - val_acc: 0.8851\n",
      "Epoch 231/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3227 - acc: 0.8818 - val_loss: 0.3205 - val_acc: 0.8947\n",
      "Epoch 232/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3206 - acc: 0.8900 - val_loss: 0.3193 - val_acc: 0.8835\n",
      "Epoch 233/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3194 - acc: 0.8858 - val_loss: 0.3161 - val_acc: 0.8873\n",
      "Epoch 234/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3156 - acc: 0.8880 - val_loss: 0.3145 - val_acc: 0.8872\n",
      "Epoch 235/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3161 - acc: 0.8886 - val_loss: 0.3130 - val_acc: 0.8842\n",
      "Epoch 236/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3155 - acc: 0.8888 - val_loss: 0.3128 - val_acc: 0.8876\n",
      "Epoch 237/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3134 - acc: 0.8846 - val_loss: 0.3106 - val_acc: 0.8905\n",
      "Epoch 238/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3144 - acc: 0.8897 - val_loss: 0.3108 - val_acc: 0.8887\n",
      "Epoch 239/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3120 - acc: 0.8894 - val_loss: 0.3082 - val_acc: 0.8939\n",
      "Epoch 240/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.3108 - acc: 0.8879 - val_loss: 0.3108 - val_acc: 0.8895\n",
      "Epoch 241/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.3146 - acc: 0.8884 - val_loss: 0.3105 - val_acc: 0.8876\n",
      "Epoch 242/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.3087 - acc: 0.8898 - val_loss: 0.3067 - val_acc: 0.8895\n",
      "Epoch 243/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3064 - acc: 0.8905 - val_loss: 0.3074 - val_acc: 0.8922\n",
      "Epoch 244/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3079 - acc: 0.8946 - val_loss: 0.3060 - val_acc: 0.8874\n",
      "Epoch 245/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3051 - acc: 0.8923 - val_loss: 0.3032 - val_acc: 0.8907\n",
      "Epoch 246/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3039 - acc: 0.8932 - val_loss: 0.3032 - val_acc: 0.8929\n",
      "Epoch 247/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3030 - acc: 0.8940 - val_loss: 0.2993 - val_acc: 0.8907\n",
      "Epoch 248/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3006 - acc: 0.8946 - val_loss: 0.3004 - val_acc: 0.9045\n",
      "Epoch 249/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3005 - acc: 0.8965 - val_loss: 0.2976 - val_acc: 0.8930\n",
      "Epoch 250/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.3003 - acc: 0.8919 - val_loss: 0.2985 - val_acc: 0.8901\n",
      "Epoch 251/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.3004 - acc: 0.8933 - val_loss: 0.2967 - val_acc: 0.8916\n",
      "Epoch 252/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2973 - acc: 0.8977 - val_loss: 0.2959 - val_acc: 0.8911\n",
      "Epoch 253/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2955 - acc: 0.8947 - val_loss: 0.2935 - val_acc: 0.8932\n",
      "Epoch 254/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2949 - acc: 0.8928 - val_loss: 0.2932 - val_acc: 0.8947\n",
      "Epoch 255/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2949 - acc: 0.8926 - val_loss: 0.2942 - val_acc: 0.8960\n",
      "Epoch 256/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2937 - acc: 0.8939 - val_loss: 0.2930 - val_acc: 0.8930\n",
      "Epoch 257/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2930 - acc: 0.8947 - val_loss: 0.2890 - val_acc: 0.8926\n",
      "Epoch 258/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2904 - acc: 0.8947 - val_loss: 0.2899 - val_acc: 0.8956\n",
      "Epoch 259/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2905 - acc: 0.8979 - val_loss: 0.2879 - val_acc: 0.8936\n",
      "Epoch 260/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2890 - acc: 0.8986 - val_loss: 0.2878 - val_acc: 0.8950\n",
      "Epoch 261/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2900 - acc: 0.9002 - val_loss: 0.2926 - val_acc: 0.8930\n",
      "Epoch 262/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2891 - acc: 0.8949 - val_loss: 0.2851 - val_acc: 0.9041\n",
      "Epoch 263/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2868 - acc: 0.8943 - val_loss: 0.2844 - val_acc: 0.9058\n",
      "Epoch 264/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2865 - acc: 0.8951 - val_loss: 0.2858 - val_acc: 0.9049\n",
      "Epoch 265/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2851 - acc: 0.9007 - val_loss: 0.2827 - val_acc: 0.8940\n",
      "Epoch 266/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2830 - acc: 0.9002 - val_loss: 0.2845 - val_acc: 0.8974\n",
      "Epoch 267/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2857 - acc: 0.8979 - val_loss: 0.2837 - val_acc: 0.9118\n",
      "Epoch 268/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2824 - acc: 0.9003 - val_loss: 0.2830 - val_acc: 0.8991\n",
      "Epoch 269/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2820 - acc: 0.9024 - val_loss: 0.2770 - val_acc: 0.9072\n",
      "Epoch 270/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2800 - acc: 0.9005 - val_loss: 0.2771 - val_acc: 0.9009\n",
      "Epoch 271/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.2786 - acc: 0.9002 - val_loss: 0.2765 - val_acc: 0.8988\n",
      "Epoch 272/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2770 - acc: 0.9006 - val_loss: 0.2759 - val_acc: 0.9037\n",
      "Epoch 273/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2756 - acc: 0.9016 - val_loss: 0.2767 - val_acc: 0.9040\n",
      "Epoch 274/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2760 - acc: 0.8999 - val_loss: 0.2745 - val_acc: 0.9111\n",
      "Epoch 275/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2753 - acc: 0.9033 - val_loss: 0.2737 - val_acc: 0.9014\n",
      "Epoch 276/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2738 - acc: 0.9020 - val_loss: 0.2711 - val_acc: 0.8999\n",
      "Epoch 277/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2730 - acc: 0.9024 - val_loss: 0.2728 - val_acc: 0.8992\n",
      "Epoch 278/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2731 - acc: 0.9072 - val_loss: 0.2694 - val_acc: 0.8979\n",
      "Epoch 279/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2715 - acc: 0.9047 - val_loss: 0.2708 - val_acc: 0.9126\n",
      "Epoch 280/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2704 - acc: 0.9061 - val_loss: 0.2682 - val_acc: 0.9041\n",
      "Epoch 281/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2708 - acc: 0.9055 - val_loss: 0.2701 - val_acc: 0.9000\n",
      "Epoch 282/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2696 - acc: 0.9059 - val_loss: 0.2668 - val_acc: 0.9033\n",
      "Epoch 283/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2694 - acc: 0.9045 - val_loss: 0.2685 - val_acc: 0.8984\n",
      "Epoch 284/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2670 - acc: 0.9054 - val_loss: 0.2651 - val_acc: 0.9089\n",
      "Epoch 285/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2664 - acc: 0.9051 - val_loss: 0.2643 - val_acc: 0.9104\n",
      "Epoch 286/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2652 - acc: 0.9073 - val_loss: 0.2642 - val_acc: 0.9027\n",
      "Epoch 287/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2643 - acc: 0.9059 - val_loss: 0.2635 - val_acc: 0.9016\n",
      "Epoch 288/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2638 - acc: 0.9080 - val_loss: 0.2626 - val_acc: 0.9080\n",
      "Epoch 289/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2629 - acc: 0.9066 - val_loss: 0.2613 - val_acc: 0.9072\n",
      "Epoch 290/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2619 - acc: 0.9075 - val_loss: 0.2613 - val_acc: 0.9110\n",
      "Epoch 291/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.2610 - acc: 0.9126 - val_loss: 0.2603 - val_acc: 0.9002\n",
      "Epoch 292/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2598 - acc: 0.9069 - val_loss: 0.2572 - val_acc: 0.9124\n",
      "Epoch 293/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2590 - acc: 0.9082 - val_loss: 0.2575 - val_acc: 0.9107\n",
      "Epoch 294/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2581 - acc: 0.9104 - val_loss: 0.2565 - val_acc: 0.9188\n",
      "Epoch 295/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2580 - acc: 0.9098 - val_loss: 0.2598 - val_acc: 0.9171\n",
      "Epoch 296/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2600 - acc: 0.9065 - val_loss: 0.2568 - val_acc: 0.9101\n",
      "Epoch 297/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2566 - acc: 0.9093 - val_loss: 0.2542 - val_acc: 0.9129\n",
      "Epoch 298/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2555 - acc: 0.9087 - val_loss: 0.2522 - val_acc: 0.9139\n",
      "Epoch 299/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2545 - acc: 0.9090 - val_loss: 0.2524 - val_acc: 0.9119\n",
      "Epoch 300/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2557 - acc: 0.9133 - val_loss: 0.2525 - val_acc: 0.9107\n",
      "28574/28574 [==============================] - 2s 68us/step\n",
      "7143/7143 [==============================] - 0s 70us/step\n",
      "Train on 7143 samples, validate on 7143 samples\n",
      "Epoch 1/300\n",
      "7143/7143 [==============================] - 3s 462us/step - loss: 3.3685 - acc: 0.0119 - val_loss: 3.3369 - val_acc: 0.0139\n",
      "Epoch 2/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 3.3104 - acc: 0.0255 - val_loss: 3.2776 - val_acc: 0.0221\n",
      "Epoch 3/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 3.2450 - acc: 0.0790 - val_loss: 3.2043 - val_acc: 0.1204\n",
      "Epoch 4/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 3.1642 - acc: 0.1057 - val_loss: 3.1143 - val_acc: 0.1030\n",
      "Epoch 5/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 3.0682 - acc: 0.1049 - val_loss: 3.0125 - val_acc: 0.1130\n",
      "Epoch 6/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 2.9631 - acc: 0.1232 - val_loss: 2.9041 - val_acc: 0.1516\n",
      "Epoch 7/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 2.8546 - acc: 0.1753 - val_loss: 2.7966 - val_acc: 0.1922\n",
      "Epoch 8/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 2.7483 - acc: 0.1998 - val_loss: 2.6918 - val_acc: 0.2079\n",
      "Epoch 9/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 2.6458 - acc: 0.2153 - val_loss: 2.5918 - val_acc: 0.2188\n",
      "Epoch 10/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 2.5473 - acc: 0.2132 - val_loss: 2.4948 - val_acc: 0.2135\n",
      "Epoch 11/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.4524 - acc: 0.2393 - val_loss: 2.4015 - val_acc: 0.2533\n",
      "Epoch 12/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 2.3610 - acc: 0.2535 - val_loss: 2.3124 - val_acc: 0.2552\n",
      "Epoch 13/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.2739 - acc: 0.2778 - val_loss: 2.2280 - val_acc: 0.3048\n",
      "Epoch 14/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 2.1929 - acc: 0.3081 - val_loss: 2.1500 - val_acc: 0.3209\n",
      "Epoch 15/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 2.1177 - acc: 0.3657 - val_loss: 2.0787 - val_acc: 0.3965\n",
      "Epoch 16/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 2.0491 - acc: 0.3935 - val_loss: 2.0133 - val_acc: 0.3907\n",
      "Epoch 17/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.9866 - acc: 0.3954 - val_loss: 1.9539 - val_acc: 0.4053\n",
      "Epoch 18/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.9295 - acc: 0.4131 - val_loss: 1.8994 - val_acc: 0.4326\n",
      "Epoch 19/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 1.8772 - acc: 0.4372 - val_loss: 1.8492 - val_acc: 0.4504\n",
      "Epoch 20/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 1.8292 - acc: 0.4536 - val_loss: 1.8028 - val_acc: 0.4638\n",
      "Epoch 21/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 1.7841 - acc: 0.4427 - val_loss: 1.7592 - val_acc: 0.4476\n",
      "Epoch 22/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 1.7416 - acc: 0.4508 - val_loss: 1.7182 - val_acc: 0.4817\n",
      "Epoch 23/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 1.7023 - acc: 0.4907 - val_loss: 1.6797 - val_acc: 0.4969\n",
      "Epoch 24/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.6649 - acc: 0.4733 - val_loss: 1.6435 - val_acc: 0.4750\n",
      "Epoch 25/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.6295 - acc: 0.4974 - val_loss: 1.6087 - val_acc: 0.5201\n",
      "Epoch 26/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.5951 - acc: 0.5288 - val_loss: 1.5762 - val_acc: 0.5261\n",
      "Epoch 27/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 1.5631 - acc: 0.5327 - val_loss: 1.5443 - val_acc: 0.5387\n",
      "Epoch 28/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 1.5319 - acc: 0.5491 - val_loss: 1.5148 - val_acc: 0.5547\n",
      "Epoch 29/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.5028 - acc: 0.5773 - val_loss: 1.4853 - val_acc: 0.5885\n",
      "Epoch 30/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 1.4746 - acc: 0.5775 - val_loss: 1.4574 - val_acc: 0.5990\n",
      "Epoch 31/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 1.4473 - acc: 0.6028 - val_loss: 1.4316 - val_acc: 0.6402\n",
      "Epoch 32/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 1.4219 - acc: 0.5979 - val_loss: 1.4056 - val_acc: 0.6168\n",
      "Epoch 33/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 1.3959 - acc: 0.6282 - val_loss: 1.3807 - val_acc: 0.6314\n",
      "Epoch 34/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.3713 - acc: 0.6244 - val_loss: 1.3569 - val_acc: 0.6378\n",
      "Epoch 35/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 1.3476 - acc: 0.6177 - val_loss: 1.3336 - val_acc: 0.6371\n",
      "Epoch 36/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 1.3250 - acc: 0.6282 - val_loss: 1.3110 - val_acc: 0.6550\n",
      "Epoch 37/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.3032 - acc: 0.6567 - val_loss: 1.2898 - val_acc: 0.6338\n",
      "Epoch 38/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.2820 - acc: 0.6280 - val_loss: 1.2678 - val_acc: 0.6723\n",
      "Epoch 39/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.2606 - acc: 0.6793 - val_loss: 1.2467 - val_acc: 0.6885\n",
      "Epoch 40/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.2402 - acc: 0.6545 - val_loss: 1.2267 - val_acc: 0.6842\n",
      "Epoch 41/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 1.2206 - acc: 0.6836 - val_loss: 1.2067 - val_acc: 0.6777\n",
      "Epoch 42/300\n",
      "7143/7143 [==============================] - 0s 24us/step - loss: 1.1998 - acc: 0.6580 - val_loss: 1.1883 - val_acc: 0.6857\n",
      "Epoch 43/300\n",
      "7143/7143 [==============================] - 0s 23us/step - loss: 1.1814 - acc: 0.6864 - val_loss: 1.1688 - val_acc: 0.6955\n",
      "Epoch 44/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 1.1636 - acc: 0.6850 - val_loss: 1.1518 - val_acc: 0.6991\n",
      "Epoch 45/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 1.1453 - acc: 0.7123 - val_loss: 1.1341 - val_acc: 0.7036\n",
      "Epoch 46/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 1.1278 - acc: 0.6905 - val_loss: 1.1168 - val_acc: 0.7059\n",
      "Epoch 47/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 1.1123 - acc: 0.7064 - val_loss: 1.1009 - val_acc: 0.7127\n",
      "Epoch 48/300\n",
      "7143/7143 [==============================] - 0s 24us/step - loss: 1.0962 - acc: 0.7172 - val_loss: 1.0849 - val_acc: 0.7042\n",
      "Epoch 49/300\n",
      "7143/7143 [==============================] - 0s 37us/step - loss: 1.0804 - acc: 0.7089 - val_loss: 1.0690 - val_acc: 0.7197\n",
      "Epoch 50/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.0642 - acc: 0.7231 - val_loss: 1.0540 - val_acc: 0.7193\n",
      "Epoch 51/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 1.0504 - acc: 0.7311 - val_loss: 1.0395 - val_acc: 0.7367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/300\n",
      "7143/7143 [==============================] - 0s 14us/step - loss: 1.0347 - acc: 0.7262 - val_loss: 1.0249 - val_acc: 0.7287\n",
      "Epoch 53/300\n",
      "7143/7143 [==============================] - 0s 14us/step - loss: 1.0211 - acc: 0.7442 - val_loss: 1.0104 - val_acc: 0.7271\n",
      "Epoch 54/300\n",
      "7143/7143 [==============================] - 0s 22us/step - loss: 1.0073 - acc: 0.7204 - val_loss: 0.9978 - val_acc: 0.7428\n",
      "Epoch 55/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.9944 - acc: 0.7446 - val_loss: 0.9851 - val_acc: 0.7458\n",
      "Epoch 56/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.9804 - acc: 0.7459 - val_loss: 0.9709 - val_acc: 0.7395\n",
      "Epoch 57/300\n",
      "7143/7143 [==============================] - 0s 36us/step - loss: 0.9683 - acc: 0.7389 - val_loss: 0.9584 - val_acc: 0.7437\n",
      "Epoch 58/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.9554 - acc: 0.7472 - val_loss: 0.9461 - val_acc: 0.7558\n",
      "Epoch 59/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.9434 - acc: 0.7551 - val_loss: 0.9353 - val_acc: 0.7595\n",
      "Epoch 60/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.9314 - acc: 0.7605 - val_loss: 0.9223 - val_acc: 0.7567\n",
      "Epoch 61/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.9194 - acc: 0.7599 - val_loss: 0.9126 - val_acc: 0.7546\n",
      "Epoch 62/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.9084 - acc: 0.7623 - val_loss: 0.9016 - val_acc: 0.7570\n",
      "Epoch 63/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.8972 - acc: 0.7620 - val_loss: 0.8908 - val_acc: 0.7561\n",
      "Epoch 64/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.8873 - acc: 0.7588 - val_loss: 0.8793 - val_acc: 0.7683\n",
      "Epoch 65/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.8772 - acc: 0.7722 - val_loss: 0.8684 - val_acc: 0.7754\n",
      "Epoch 66/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.8672 - acc: 0.7718 - val_loss: 0.8590 - val_acc: 0.7683\n",
      "Epoch 67/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.8563 - acc: 0.7726 - val_loss: 0.8488 - val_acc: 0.7857\n",
      "Epoch 68/300\n",
      "7143/7143 [==============================] - 0s 29us/step - loss: 0.8464 - acc: 0.7813 - val_loss: 0.8385 - val_acc: 0.7726\n",
      "Epoch 69/300\n",
      "7143/7143 [==============================] - 0s 23us/step - loss: 0.8370 - acc: 0.7711 - val_loss: 0.8296 - val_acc: 0.7808\n",
      "Epoch 70/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.8287 - acc: 0.7817 - val_loss: 0.8197 - val_acc: 0.7782\n",
      "Epoch 71/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.8184 - acc: 0.7794 - val_loss: 0.8129 - val_acc: 0.7859\n",
      "Epoch 72/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.8086 - acc: 0.7787 - val_loss: 0.8037 - val_acc: 0.7718\n",
      "Epoch 73/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.8009 - acc: 0.7845 - val_loss: 0.7964 - val_acc: 0.7869\n",
      "Epoch 74/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.7935 - acc: 0.7952 - val_loss: 0.7875 - val_acc: 0.7857\n",
      "Epoch 75/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.7844 - acc: 0.7815 - val_loss: 0.7788 - val_acc: 0.7857\n",
      "Epoch 76/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.7767 - acc: 0.7931 - val_loss: 0.7710 - val_acc: 0.8026\n",
      "Epoch 77/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.7694 - acc: 0.7886 - val_loss: 0.7624 - val_acc: 0.7826\n",
      "Epoch 78/300\n",
      "7143/7143 [==============================] - 0s 22us/step - loss: 0.7626 - acc: 0.7920 - val_loss: 0.7554 - val_acc: 0.7970\n",
      "Epoch 79/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.7541 - acc: 0.7959 - val_loss: 0.7485 - val_acc: 0.7833\n",
      "Epoch 80/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.7470 - acc: 0.7922 - val_loss: 0.7424 - val_acc: 0.7976\n",
      "Epoch 81/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.7396 - acc: 0.7970 - val_loss: 0.7333 - val_acc: 0.8027\n",
      "Epoch 82/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.7325 - acc: 0.7945 - val_loss: 0.7259 - val_acc: 0.8121\n",
      "Epoch 83/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.7253 - acc: 0.8092 - val_loss: 0.7197 - val_acc: 0.8050\n",
      "Epoch 84/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.7194 - acc: 0.8036 - val_loss: 0.7131 - val_acc: 0.8195\n",
      "Epoch 85/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.7116 - acc: 0.8148 - val_loss: 0.7064 - val_acc: 0.8121\n",
      "Epoch 86/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.7056 - acc: 0.8092 - val_loss: 0.6996 - val_acc: 0.8228\n",
      "Epoch 87/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.6980 - acc: 0.8184 - val_loss: 0.6940 - val_acc: 0.8102\n",
      "Epoch 88/300\n",
      "7143/7143 [==============================] - 0s 22us/step - loss: 0.6941 - acc: 0.8149 - val_loss: 0.6870 - val_acc: 0.8116\n",
      "Epoch 89/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.6859 - acc: 0.8127 - val_loss: 0.6817 - val_acc: 0.8194\n",
      "Epoch 90/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.6797 - acc: 0.8174 - val_loss: 0.6765 - val_acc: 0.8176\n",
      "Epoch 91/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.6751 - acc: 0.8186 - val_loss: 0.6690 - val_acc: 0.8226\n",
      "Epoch 92/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.6698 - acc: 0.8058 - val_loss: 0.6633 - val_acc: 0.8221\n",
      "Epoch 93/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.6639 - acc: 0.8184 - val_loss: 0.6589 - val_acc: 0.8260\n",
      "Epoch 94/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.6583 - acc: 0.8205 - val_loss: 0.6528 - val_acc: 0.8166\n",
      "Epoch 95/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.6520 - acc: 0.8219 - val_loss: 0.6479 - val_acc: 0.8242\n",
      "Epoch 96/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.6470 - acc: 0.8243 - val_loss: 0.6425 - val_acc: 0.8250\n",
      "Epoch 97/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.6412 - acc: 0.8232 - val_loss: 0.6374 - val_acc: 0.8193\n",
      "Epoch 98/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.6371 - acc: 0.8222 - val_loss: 0.6311 - val_acc: 0.8289\n",
      "Epoch 99/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.6311 - acc: 0.8242 - val_loss: 0.6262 - val_acc: 0.8302\n",
      "Epoch 100/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.6269 - acc: 0.8278 - val_loss: 0.6226 - val_acc: 0.8230\n",
      "Epoch 101/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.6217 - acc: 0.8235 - val_loss: 0.6175 - val_acc: 0.8155\n",
      "Epoch 102/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.6180 - acc: 0.8229 - val_loss: 0.6139 - val_acc: 0.8268\n",
      "Epoch 103/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.6138 - acc: 0.8229 - val_loss: 0.6091 - val_acc: 0.8344\n",
      "Epoch 104/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.6079 - acc: 0.8271 - val_loss: 0.6067 - val_acc: 0.8286\n",
      "Epoch 105/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.6043 - acc: 0.8284 - val_loss: 0.5987 - val_acc: 0.8317\n",
      "Epoch 106/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.5989 - acc: 0.8258 - val_loss: 0.5943 - val_acc: 0.8292\n",
      "Epoch 107/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.5960 - acc: 0.8228 - val_loss: 0.5909 - val_acc: 0.8216\n",
      "Epoch 108/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5905 - acc: 0.8251 - val_loss: 0.5857 - val_acc: 0.8316\n",
      "Epoch 109/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.5864 - acc: 0.8330 - val_loss: 0.5834 - val_acc: 0.8299\n",
      "Epoch 110/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.5831 - acc: 0.8271 - val_loss: 0.5797 - val_acc: 0.8305\n",
      "Epoch 111/300\n",
      "7143/7143 [==============================] - 0s 22us/step - loss: 0.5778 - acc: 0.8328 - val_loss: 0.5747 - val_acc: 0.8306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.5741 - acc: 0.8307 - val_loss: 0.5703 - val_acc: 0.8243\n",
      "Epoch 113/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.5710 - acc: 0.8296 - val_loss: 0.5674 - val_acc: 0.8324\n",
      "Epoch 114/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.5661 - acc: 0.8354 - val_loss: 0.5608 - val_acc: 0.8358\n",
      "Epoch 115/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.5618 - acc: 0.8324 - val_loss: 0.5575 - val_acc: 0.8348\n",
      "Epoch 116/300\n",
      "7143/7143 [==============================] - 0s 23us/step - loss: 0.5593 - acc: 0.8365 - val_loss: 0.5554 - val_acc: 0.8333\n",
      "Epoch 117/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.5536 - acc: 0.8345 - val_loss: 0.5501 - val_acc: 0.8387\n",
      "Epoch 118/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.5508 - acc: 0.8359 - val_loss: 0.5466 - val_acc: 0.8379\n",
      "Epoch 119/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.5482 - acc: 0.8373 - val_loss: 0.5449 - val_acc: 0.8278\n",
      "Epoch 120/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.5449 - acc: 0.8355 - val_loss: 0.5424 - val_acc: 0.8389\n",
      "Epoch 121/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.5416 - acc: 0.8331 - val_loss: 0.5363 - val_acc: 0.8400\n",
      "Epoch 122/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.5369 - acc: 0.8379 - val_loss: 0.5341 - val_acc: 0.8331\n",
      "Epoch 123/300\n",
      "7143/7143 [==============================] - 0s 22us/step - loss: 0.5333 - acc: 0.8319 - val_loss: 0.5297 - val_acc: 0.8405\n",
      "Epoch 124/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.5309 - acc: 0.8380 - val_loss: 0.5263 - val_acc: 0.8366\n",
      "Epoch 125/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.5275 - acc: 0.8370 - val_loss: 0.5248 - val_acc: 0.8342\n",
      "Epoch 126/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.5261 - acc: 0.8324 - val_loss: 0.5232 - val_acc: 0.8405\n",
      "Epoch 127/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.5223 - acc: 0.8411 - val_loss: 0.5176 - val_acc: 0.8410\n",
      "Epoch 128/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.5174 - acc: 0.8404 - val_loss: 0.5143 - val_acc: 0.8419\n",
      "Epoch 129/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.5141 - acc: 0.8442 - val_loss: 0.5101 - val_acc: 0.8442\n",
      "Epoch 130/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.5108 - acc: 0.8438 - val_loss: 0.5082 - val_acc: 0.8442\n",
      "Epoch 131/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.5090 - acc: 0.8428 - val_loss: 0.5045 - val_acc: 0.8461\n",
      "Epoch 132/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.5058 - acc: 0.8425 - val_loss: 0.5031 - val_acc: 0.8513\n",
      "Epoch 133/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.5049 - acc: 0.8421 - val_loss: 0.5018 - val_acc: 0.8431\n",
      "Epoch 134/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.4990 - acc: 0.8442 - val_loss: 0.4958 - val_acc: 0.8475\n",
      "Epoch 135/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.4959 - acc: 0.8463 - val_loss: 0.4932 - val_acc: 0.8410\n",
      "Epoch 136/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.4941 - acc: 0.8421 - val_loss: 0.4918 - val_acc: 0.8491\n",
      "Epoch 137/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4948 - acc: 0.8461 - val_loss: 0.4887 - val_acc: 0.8478\n",
      "Epoch 138/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.4890 - acc: 0.8481 - val_loss: 0.4858 - val_acc: 0.8447\n",
      "Epoch 139/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4849 - acc: 0.8487 - val_loss: 0.4826 - val_acc: 0.8534\n",
      "Epoch 140/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.4845 - acc: 0.8460 - val_loss: 0.4806 - val_acc: 0.8446\n",
      "Epoch 141/300\n",
      "7143/7143 [==============================] - 0s 40us/step - loss: 0.4808 - acc: 0.8470 - val_loss: 0.4766 - val_acc: 0.8426\n",
      "Epoch 142/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.4772 - acc: 0.8470 - val_loss: 0.4723 - val_acc: 0.8488\n",
      "Epoch 143/300\n",
      "7143/7143 [==============================] - 0s 31us/step - loss: 0.4745 - acc: 0.8503 - val_loss: 0.4694 - val_acc: 0.8550\n",
      "Epoch 144/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.4706 - acc: 0.8489 - val_loss: 0.4675 - val_acc: 0.8508\n",
      "Epoch 145/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.4686 - acc: 0.8512 - val_loss: 0.4664 - val_acc: 0.8527\n",
      "Epoch 146/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.4662 - acc: 0.8537 - val_loss: 0.4637 - val_acc: 0.8520\n",
      "Epoch 147/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.4637 - acc: 0.8512 - val_loss: 0.4605 - val_acc: 0.8573\n",
      "Epoch 148/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.4609 - acc: 0.8545 - val_loss: 0.4594 - val_acc: 0.8494\n",
      "Epoch 149/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.4601 - acc: 0.8527 - val_loss: 0.4570 - val_acc: 0.8607\n",
      "Epoch 150/300\n",
      "7143/7143 [==============================] - 0s 22us/step - loss: 0.4562 - acc: 0.8557 - val_loss: 0.4552 - val_acc: 0.8571\n",
      "Epoch 151/300\n",
      "7143/7143 [==============================] - 0s 35us/step - loss: 0.4556 - acc: 0.8534 - val_loss: 0.4526 - val_acc: 0.8524\n",
      "Epoch 152/300\n",
      "7143/7143 [==============================] - 0s 25us/step - loss: 0.4526 - acc: 0.8552 - val_loss: 0.4488 - val_acc: 0.8578\n",
      "Epoch 153/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.4504 - acc: 0.8533 - val_loss: 0.4479 - val_acc: 0.8561\n",
      "Epoch 154/300\n",
      "7143/7143 [==============================] - 0s 26us/step - loss: 0.4475 - acc: 0.8530 - val_loss: 0.4456 - val_acc: 0.8568\n",
      "Epoch 155/300\n",
      "7143/7143 [==============================] - 0s 30us/step - loss: 0.4446 - acc: 0.8575 - val_loss: 0.4407 - val_acc: 0.8576\n",
      "Epoch 156/300\n",
      "7143/7143 [==============================] - 0s 44us/step - loss: 0.4416 - acc: 0.8568 - val_loss: 0.4394 - val_acc: 0.8589\n",
      "Epoch 157/300\n",
      "7143/7143 [==============================] - 0s 26us/step - loss: 0.4407 - acc: 0.8606 - val_loss: 0.4374 - val_acc: 0.8600\n",
      "Epoch 158/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.4382 - acc: 0.8559 - val_loss: 0.4348 - val_acc: 0.8617\n",
      "Epoch 159/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.4386 - acc: 0.8575 - val_loss: 0.4364 - val_acc: 0.8586\n",
      "Epoch 160/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.4375 - acc: 0.8587 - val_loss: 0.4343 - val_acc: 0.8639\n",
      "Epoch 161/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.4331 - acc: 0.8615 - val_loss: 0.4291 - val_acc: 0.8596\n",
      "Epoch 162/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.4322 - acc: 0.8607 - val_loss: 0.4297 - val_acc: 0.8590\n",
      "Epoch 163/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.4302 - acc: 0.8582 - val_loss: 0.4268 - val_acc: 0.8614\n",
      "Epoch 164/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.4260 - acc: 0.8613 - val_loss: 0.4229 - val_acc: 0.8642\n",
      "Epoch 165/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.4241 - acc: 0.8646 - val_loss: 0.4205 - val_acc: 0.8625\n",
      "Epoch 166/300\n",
      "7143/7143 [==============================] - 0s 33us/step - loss: 0.4201 - acc: 0.8666 - val_loss: 0.4181 - val_acc: 0.8642\n",
      "Epoch 167/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.4184 - acc: 0.8652 - val_loss: 0.4169 - val_acc: 0.8656\n",
      "Epoch 168/300\n",
      "7143/7143 [==============================] - 0s 28us/step - loss: 0.4174 - acc: 0.8670 - val_loss: 0.4153 - val_acc: 0.8669\n",
      "Epoch 169/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.4154 - acc: 0.8649 - val_loss: 0.4133 - val_acc: 0.8677\n",
      "Epoch 170/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.4154 - acc: 0.8639 - val_loss: 0.4118 - val_acc: 0.8655\n",
      "Epoch 171/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.4134 - acc: 0.8666 - val_loss: 0.4083 - val_acc: 0.8670\n",
      "Epoch 172/300\n",
      "7143/7143 [==============================] - 0s 22us/step - loss: 0.4080 - acc: 0.8673 - val_loss: 0.4051 - val_acc: 0.8662\n",
      "Epoch 173/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.4064 - acc: 0.8690 - val_loss: 0.4054 - val_acc: 0.8708\n",
      "Epoch 174/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.4062 - acc: 0.8680 - val_loss: 0.4020 - val_acc: 0.8680\n",
      "Epoch 175/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.4045 - acc: 0.8690 - val_loss: 0.4028 - val_acc: 0.8692\n",
      "Epoch 176/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.4013 - acc: 0.8711 - val_loss: 0.4015 - val_acc: 0.8634\n",
      "Epoch 177/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.4030 - acc: 0.8681 - val_loss: 0.3983 - val_acc: 0.8761\n",
      "Epoch 178/300\n",
      "7143/7143 [==============================] - 0s 23us/step - loss: 0.3989 - acc: 0.8698 - val_loss: 0.3966 - val_acc: 0.8701\n",
      "Epoch 179/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.3971 - acc: 0.8711 - val_loss: 0.3932 - val_acc: 0.8723\n",
      "Epoch 180/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.3954 - acc: 0.8702 - val_loss: 0.3933 - val_acc: 0.8687\n",
      "Epoch 181/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.3943 - acc: 0.8704 - val_loss: 0.3903 - val_acc: 0.8725\n",
      "Epoch 182/300\n",
      "7143/7143 [==============================] - 0s 24us/step - loss: 0.3922 - acc: 0.8713 - val_loss: 0.3880 - val_acc: 0.8713\n",
      "Epoch 183/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.3891 - acc: 0.8727 - val_loss: 0.3874 - val_acc: 0.8736\n",
      "Epoch 184/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.3882 - acc: 0.8725 - val_loss: 0.3842 - val_acc: 0.8751\n",
      "Epoch 185/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.3864 - acc: 0.8729 - val_loss: 0.3827 - val_acc: 0.8768\n",
      "Epoch 186/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.3849 - acc: 0.8748 - val_loss: 0.3828 - val_acc: 0.8712\n",
      "Epoch 187/300\n",
      "7143/7143 [==============================] - 0s 22us/step - loss: 0.3844 - acc: 0.8746 - val_loss: 0.3846 - val_acc: 0.8747\n",
      "Epoch 188/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.3827 - acc: 0.8754 - val_loss: 0.3796 - val_acc: 0.8741\n",
      "Epoch 189/300\n",
      "7143/7143 [==============================] - 0s 22us/step - loss: 0.3796 - acc: 0.8764 - val_loss: 0.3761 - val_acc: 0.8803\n",
      "Epoch 190/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.3785 - acc: 0.8786 - val_loss: 0.3750 - val_acc: 0.8806\n",
      "Epoch 191/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.3753 - acc: 0.8747 - val_loss: 0.3738 - val_acc: 0.8785\n",
      "Epoch 192/300\n",
      "7143/7143 [==============================] - 0s 28us/step - loss: 0.3734 - acc: 0.8793 - val_loss: 0.3738 - val_acc: 0.8838\n",
      "Epoch 193/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.3734 - acc: 0.8797 - val_loss: 0.3718 - val_acc: 0.8778\n",
      "Epoch 194/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.3728 - acc: 0.8776 - val_loss: 0.3705 - val_acc: 0.8818\n",
      "Epoch 195/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3706 - acc: 0.8793 - val_loss: 0.3667 - val_acc: 0.8824\n",
      "Epoch 196/300\n",
      "7143/7143 [==============================] - 0s 29us/step - loss: 0.3682 - acc: 0.8803 - val_loss: 0.3645 - val_acc: 0.8820\n",
      "Epoch 197/300\n",
      "7143/7143 [==============================] - 0s 63us/step - loss: 0.3646 - acc: 0.8817 - val_loss: 0.3641 - val_acc: 0.8890\n",
      "Epoch 198/300\n",
      "7143/7143 [==============================] - 0s 37us/step - loss: 0.3631 - acc: 0.8838 - val_loss: 0.3616 - val_acc: 0.8818\n",
      "Epoch 199/300\n",
      "7143/7143 [==============================] - 0s 36us/step - loss: 0.3619 - acc: 0.8851 - val_loss: 0.3599 - val_acc: 0.8839\n",
      "Epoch 200/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.3606 - acc: 0.8806 - val_loss: 0.3585 - val_acc: 0.8862\n",
      "Epoch 201/300\n",
      "7143/7143 [==============================] - 0s 23us/step - loss: 0.3585 - acc: 0.8837 - val_loss: 0.3588 - val_acc: 0.8841\n",
      "Epoch 202/300\n",
      "7143/7143 [==============================] - 0s 22us/step - loss: 0.3585 - acc: 0.8827 - val_loss: 0.3550 - val_acc: 0.8827\n",
      "Epoch 203/300\n",
      "7143/7143 [==============================] - 0s 27us/step - loss: 0.3562 - acc: 0.8832 - val_loss: 0.3549 - val_acc: 0.8838\n",
      "Epoch 204/300\n",
      "7143/7143 [==============================] - 0s 28us/step - loss: 0.3570 - acc: 0.8807 - val_loss: 0.3559 - val_acc: 0.8835\n",
      "Epoch 205/300\n",
      "7143/7143 [==============================] - 0s 31us/step - loss: 0.3537 - acc: 0.8814 - val_loss: 0.3535 - val_acc: 0.8904\n",
      "Epoch 206/300\n",
      "7143/7143 [==============================] - 0s 29us/step - loss: 0.3534 - acc: 0.8842 - val_loss: 0.3495 - val_acc: 0.8859\n",
      "Epoch 207/300\n",
      "7143/7143 [==============================] - 0s 29us/step - loss: 0.3510 - acc: 0.8867 - val_loss: 0.3487 - val_acc: 0.8853\n",
      "Epoch 208/300\n",
      "7143/7143 [==============================] - 0s 26us/step - loss: 0.3488 - acc: 0.8852 - val_loss: 0.3451 - val_acc: 0.8887\n",
      "Epoch 209/300\n",
      "7143/7143 [==============================] - 0s 29us/step - loss: 0.3470 - acc: 0.8874 - val_loss: 0.3454 - val_acc: 0.8865\n",
      "Epoch 210/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.3449 - acc: 0.8860 - val_loss: 0.3426 - val_acc: 0.8950\n",
      "Epoch 211/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.3447 - acc: 0.8902 - val_loss: 0.3460 - val_acc: 0.8823\n",
      "Epoch 212/300\n",
      "7143/7143 [==============================] - 0s 23us/step - loss: 0.3439 - acc: 0.8900 - val_loss: 0.3415 - val_acc: 0.8908\n",
      "Epoch 213/300\n",
      "7143/7143 [==============================] - 0s 28us/step - loss: 0.3421 - acc: 0.8901 - val_loss: 0.3385 - val_acc: 0.8911\n",
      "Epoch 214/300\n",
      "7143/7143 [==============================] - 0s 28us/step - loss: 0.3388 - acc: 0.8888 - val_loss: 0.3357 - val_acc: 0.8936\n",
      "Epoch 215/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.3377 - acc: 0.8936 - val_loss: 0.3357 - val_acc: 0.8884\n",
      "Epoch 216/300\n",
      "7143/7143 [==============================] - 0s 22us/step - loss: 0.3378 - acc: 0.8887 - val_loss: 0.3355 - val_acc: 0.8912\n",
      "Epoch 217/300\n",
      "7143/7143 [==============================] - 0s 24us/step - loss: 0.3353 - acc: 0.8908 - val_loss: 0.3323 - val_acc: 0.8936\n",
      "Epoch 218/300\n",
      "7143/7143 [==============================] - 0s 23us/step - loss: 0.3336 - acc: 0.8904 - val_loss: 0.3329 - val_acc: 0.8954\n",
      "Epoch 219/300\n",
      "7143/7143 [==============================] - 0s 25us/step - loss: 0.3319 - acc: 0.8918 - val_loss: 0.3307 - val_acc: 0.8888\n",
      "Epoch 220/300\n",
      "7143/7143 [==============================] - 0s 25us/step - loss: 0.3300 - acc: 0.8942 - val_loss: 0.3321 - val_acc: 0.8881\n",
      "Epoch 221/300\n",
      "7143/7143 [==============================] - 0s 23us/step - loss: 0.3321 - acc: 0.8926 - val_loss: 0.3292 - val_acc: 0.8922\n",
      "Epoch 222/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.3279 - acc: 0.8935 - val_loss: 0.3245 - val_acc: 0.8954\n",
      "Epoch 223/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.3255 - acc: 0.8939 - val_loss: 0.3234 - val_acc: 0.8936\n",
      "Epoch 224/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3248 - acc: 0.8943 - val_loss: 0.3227 - val_acc: 0.8935\n",
      "Epoch 225/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.3237 - acc: 0.8901 - val_loss: 0.3207 - val_acc: 0.8972\n",
      "Epoch 226/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.3211 - acc: 0.8961 - val_loss: 0.3193 - val_acc: 0.8923\n",
      "Epoch 227/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.3219 - acc: 0.8949 - val_loss: 0.3173 - val_acc: 0.8942\n",
      "Epoch 228/300\n",
      "7143/7143 [==============================] - 0s 22us/step - loss: 0.3194 - acc: 0.8926 - val_loss: 0.3204 - val_acc: 0.8986\n",
      "Epoch 229/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.3183 - acc: 0.8944 - val_loss: 0.3150 - val_acc: 0.8974\n",
      "Epoch 230/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3186 - acc: 0.8916 - val_loss: 0.3162 - val_acc: 0.9016\n",
      "Epoch 231/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.3177 - acc: 0.8953 - val_loss: 0.3130 - val_acc: 0.9041\n",
      "Epoch 232/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.3137 - acc: 0.8995 - val_loss: 0.3120 - val_acc: 0.8933\n",
      "Epoch 233/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.3121 - acc: 0.8986 - val_loss: 0.3125 - val_acc: 0.8970\n",
      "Epoch 234/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.3132 - acc: 0.8954 - val_loss: 0.3108 - val_acc: 0.9079\n",
      "Epoch 235/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.3105 - acc: 0.8991 - val_loss: 0.3100 - val_acc: 0.8985\n",
      "Epoch 236/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.3110 - acc: 0.8957 - val_loss: 0.3075 - val_acc: 0.9002\n",
      "Epoch 237/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.3088 - acc: 0.8989 - val_loss: 0.3076 - val_acc: 0.8965\n",
      "Epoch 238/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.3083 - acc: 0.9006 - val_loss: 0.3063 - val_acc: 0.8929\n",
      "Epoch 239/300\n",
      "7143/7143 [==============================] - 0s 22us/step - loss: 0.3058 - acc: 0.8989 - val_loss: 0.3047 - val_acc: 0.9075\n",
      "Epoch 240/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.3037 - acc: 0.8982 - val_loss: 0.3020 - val_acc: 0.8985\n",
      "Epoch 241/300\n",
      "7143/7143 [==============================] - 0s 28us/step - loss: 0.3038 - acc: 0.9028 - val_loss: 0.3030 - val_acc: 0.9031\n",
      "Epoch 242/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.3010 - acc: 0.9003 - val_loss: 0.3011 - val_acc: 0.9024\n",
      "Epoch 243/300\n",
      "7143/7143 [==============================] - 0s 22us/step - loss: 0.3009 - acc: 0.8972 - val_loss: 0.3017 - val_acc: 0.9075\n",
      "Epoch 244/300\n",
      "7143/7143 [==============================] - 0s 22us/step - loss: 0.3031 - acc: 0.8988 - val_loss: 0.2986 - val_acc: 0.8961\n",
      "Epoch 245/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.2986 - acc: 0.9012 - val_loss: 0.2980 - val_acc: 0.8935\n",
      "Epoch 246/300\n",
      "7143/7143 [==============================] - 0s 22us/step - loss: 0.2984 - acc: 0.8993 - val_loss: 0.2947 - val_acc: 0.9010\n",
      "Epoch 247/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.2959 - acc: 0.9056 - val_loss: 0.2942 - val_acc: 0.8939\n",
      "Epoch 248/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.2950 - acc: 0.9055 - val_loss: 0.2935 - val_acc: 0.9056\n",
      "Epoch 249/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.2962 - acc: 0.9028 - val_loss: 0.2949 - val_acc: 0.9021\n",
      "Epoch 250/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.2947 - acc: 0.9052 - val_loss: 0.2905 - val_acc: 0.9086\n",
      "Epoch 251/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.2927 - acc: 0.9006 - val_loss: 0.2888 - val_acc: 0.9013\n",
      "Epoch 252/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.2891 - acc: 0.9100 - val_loss: 0.2907 - val_acc: 0.8944\n",
      "Epoch 253/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.2902 - acc: 0.9013 - val_loss: 0.2898 - val_acc: 0.9037\n",
      "Epoch 254/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.2896 - acc: 0.9014 - val_loss: 0.2912 - val_acc: 0.9112\n",
      "Epoch 255/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.2895 - acc: 0.9047 - val_loss: 0.2852 - val_acc: 0.9126\n",
      "Epoch 256/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.2861 - acc: 0.9073 - val_loss: 0.2859 - val_acc: 0.8970\n",
      "Epoch 257/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.2864 - acc: 0.9049 - val_loss: 0.2819 - val_acc: 0.9084\n",
      "Epoch 258/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.2852 - acc: 0.9107 - val_loss: 0.2832 - val_acc: 0.9181\n",
      "Epoch 259/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2831 - acc: 0.9068 - val_loss: 0.2801 - val_acc: 0.9133\n",
      "Epoch 260/300\n",
      "7143/7143 [==============================] - 0s 15us/step - loss: 0.2828 - acc: 0.9097 - val_loss: 0.2818 - val_acc: 0.9068\n",
      "Epoch 261/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2817 - acc: 0.9079 - val_loss: 0.2814 - val_acc: 0.8996\n",
      "Epoch 262/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2807 - acc: 0.9087 - val_loss: 0.2790 - val_acc: 0.9089\n",
      "Epoch 263/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2792 - acc: 0.9101 - val_loss: 0.2781 - val_acc: 0.9082\n",
      "Epoch 264/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.2806 - acc: 0.9079 - val_loss: 0.2757 - val_acc: 0.9089\n",
      "Epoch 265/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.2768 - acc: 0.9083 - val_loss: 0.2764 - val_acc: 0.9035\n",
      "Epoch 266/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.2758 - acc: 0.9097 - val_loss: 0.2728 - val_acc: 0.9145\n",
      "Epoch 267/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2742 - acc: 0.9122 - val_loss: 0.2731 - val_acc: 0.9153\n",
      "Epoch 268/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.2742 - acc: 0.9114 - val_loss: 0.2724 - val_acc: 0.9013\n",
      "Epoch 269/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.2723 - acc: 0.9076 - val_loss: 0.2751 - val_acc: 0.9094\n",
      "Epoch 270/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.2745 - acc: 0.9100 - val_loss: 0.2724 - val_acc: 0.9117\n",
      "Epoch 271/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.2716 - acc: 0.9096 - val_loss: 0.2704 - val_acc: 0.9231\n",
      "Epoch 272/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2701 - acc: 0.9098 - val_loss: 0.2692 - val_acc: 0.9245\n",
      "Epoch 273/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.2691 - acc: 0.9139 - val_loss: 0.2655 - val_acc: 0.9138\n",
      "Epoch 274/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.2675 - acc: 0.9122 - val_loss: 0.2702 - val_acc: 0.9153\n",
      "Epoch 275/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.2685 - acc: 0.9126 - val_loss: 0.2654 - val_acc: 0.9160\n",
      "Epoch 276/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2658 - acc: 0.9124 - val_loss: 0.2643 - val_acc: 0.9213\n",
      "Epoch 277/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.2662 - acc: 0.9143 - val_loss: 0.2639 - val_acc: 0.9191\n",
      "Epoch 278/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.2653 - acc: 0.9117 - val_loss: 0.2619 - val_acc: 0.9145\n",
      "Epoch 279/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.2636 - acc: 0.9166 - val_loss: 0.2619 - val_acc: 0.9042\n",
      "Epoch 280/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.2630 - acc: 0.9149 - val_loss: 0.2610 - val_acc: 0.9087\n",
      "Epoch 281/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.2608 - acc: 0.9128 - val_loss: 0.2588 - val_acc: 0.9170\n",
      "Epoch 282/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.2613 - acc: 0.9159 - val_loss: 0.2583 - val_acc: 0.9196\n",
      "Epoch 283/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.2603 - acc: 0.9131 - val_loss: 0.2597 - val_acc: 0.9240\n",
      "Epoch 284/300\n",
      "7143/7143 [==============================] - 0s 23us/step - loss: 0.2575 - acc: 0.9188 - val_loss: 0.2565 - val_acc: 0.9118\n",
      "Epoch 285/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.2584 - acc: 0.9178 - val_loss: 0.2589 - val_acc: 0.9171\n",
      "Epoch 286/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2568 - acc: 0.9153 - val_loss: 0.2550 - val_acc: 0.9205\n",
      "Epoch 287/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.2564 - acc: 0.9206 - val_loss: 0.2549 - val_acc: 0.9237\n",
      "Epoch 288/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.2581 - acc: 0.9182 - val_loss: 0.2552 - val_acc: 0.9079\n",
      "Epoch 289/300\n",
      "7143/7143 [==============================] - 0s 17us/step - loss: 0.2579 - acc: 0.9191 - val_loss: 0.2527 - val_acc: 0.9133\n",
      "Epoch 290/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.2538 - acc: 0.9185 - val_loss: 0.2547 - val_acc: 0.9187\n",
      "Epoch 291/300\n",
      "7143/7143 [==============================] - 0s 16us/step - loss: 0.2524 - acc: 0.9173 - val_loss: 0.2503 - val_acc: 0.9234\n",
      "Epoch 292/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.2542 - acc: 0.9153 - val_loss: 0.2503 - val_acc: 0.9216\n",
      "Epoch 293/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.2549 - acc: 0.9140 - val_loss: 0.2490 - val_acc: 0.9212\n",
      "Epoch 294/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.2514 - acc: 0.9167 - val_loss: 0.2476 - val_acc: 0.9230\n",
      "Epoch 295/300\n",
      "7143/7143 [==============================] - 0s 21us/step - loss: 0.2490 - acc: 0.9205 - val_loss: 0.2475 - val_acc: 0.9156\n",
      "Epoch 296/300\n",
      "7143/7143 [==============================] - 0s 22us/step - loss: 0.2483 - acc: 0.9184 - val_loss: 0.2484 - val_acc: 0.9202\n",
      "Epoch 297/300\n",
      "7143/7143 [==============================] - 0s 18us/step - loss: 0.2481 - acc: 0.9205 - val_loss: 0.2459 - val_acc: 0.9257\n",
      "Epoch 298/300\n",
      "7143/7143 [==============================] - 0s 23us/step - loss: 0.2477 - acc: 0.9199 - val_loss: 0.2494 - val_acc: 0.9308\n",
      "Epoch 299/300\n",
      "7143/7143 [==============================] - 0s 19us/step - loss: 0.2468 - acc: 0.9206 - val_loss: 0.2455 - val_acc: 0.9252\n",
      "Epoch 300/300\n",
      "7143/7143 [==============================] - 0s 20us/step - loss: 0.2460 - acc: 0.9217 - val_loss: 0.2456 - val_acc: 0.9208\n",
      "28574/28574 [==============================] - 2s 87us/step\n",
      "7143/7143 [==============================] - 1s 94us/step\n",
      "[0.9878219484882419, 0.971778934990761, 0.9121345745493942]\n",
      "[0.9880189922824995, 0.9724493224325231, 0.9157216855690701]\n"
     ]
    }
   ],
   "source": [
    "ave_acc_parking_ann=[]\n",
    "ave_acc_parking_ann_train=[]\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(parking_x, parking_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        model = create_model(X_train1.shape[1],y_train1.shape[1])\n",
    "        history = model.fit(X_train1, y_train1,validation_data=(X_train1,y_train1),batch_size=512,epochs=300)\n",
    "        score2 += model.evaluate(X_test1,y_test1,verbose=1)[1]\n",
    "        score1 += model.evaluate(X_train1,y_train1,verbose=1)[1]\n",
    "    ave_acc_parking_ann.append(score2/3.0)\n",
    "    ave_acc_parking_ann_train.append(score1/3.0)\n",
    "    \n",
    "print ave_acc_parking_ann \n",
    "print ave_acc_parking_ann_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6514 samples, validate on 6514 samples\n",
      "Epoch 1/50\n",
      "6514/6514 [==============================] - 10s 2ms/step - loss: 0.6700 - acc: 0.5940 - val_loss: 0.4733 - val_acc: 0.9088\n",
      "Epoch 2/50\n",
      "6514/6514 [==============================] - 1s 212us/step - loss: 0.3507 - acc: 0.9372 - val_loss: 0.2552 - val_acc: 0.9553\n",
      "Epoch 3/50\n",
      "6514/6514 [==============================] - 1s 202us/step - loss: 0.1997 - acc: 0.9619 - val_loss: 0.1554 - val_acc: 0.9691\n",
      "Epoch 4/50\n",
      "6514/6514 [==============================] - 1s 185us/step - loss: 0.1282 - acc: 0.9725 - val_loss: 0.1057 - val_acc: 0.9757\n",
      "Epoch 5/50\n",
      "6514/6514 [==============================] - 1s 193us/step - loss: 0.0922 - acc: 0.9785 - val_loss: 0.0809 - val_acc: 0.9814\n",
      "Epoch 6/50\n",
      "6514/6514 [==============================] - 1s 190us/step - loss: 0.0741 - acc: 0.9819 - val_loss: 0.0682 - val_acc: 0.9836\n",
      "Epoch 7/50\n",
      "6514/6514 [==============================] - 1s 218us/step - loss: 0.0646 - acc: 0.9837 - val_loss: 0.0613 - val_acc: 0.9845\n",
      "Epoch 8/50\n",
      "6514/6514 [==============================] - 1s 210us/step - loss: 0.0592 - acc: 0.9848 - val_loss: 0.0572 - val_acc: 0.9851\n",
      "Epoch 9/50\n",
      "6514/6514 [==============================] - 1s 212us/step - loss: 0.0560 - acc: 0.9856 - val_loss: 0.0547 - val_acc: 0.9857\n",
      "Epoch 10/50\n",
      "6514/6514 [==============================] - 1s 215us/step - loss: 0.0540 - acc: 0.9857 - val_loss: 0.0529 - val_acc: 0.9859\n",
      "Epoch 11/50\n",
      "6514/6514 [==============================] - 1s 206us/step - loss: 0.0524 - acc: 0.9857 - val_loss: 0.0517 - val_acc: 0.9865\n",
      "Epoch 12/50\n",
      "6514/6514 [==============================] - 1s 173us/step - loss: 0.0514 - acc: 0.9860 - val_loss: 0.0509 - val_acc: 0.9866\n",
      "Epoch 13/50\n",
      "6514/6514 [==============================] - 1s 195us/step - loss: 0.0507 - acc: 0.9860 - val_loss: 0.0502 - val_acc: 0.9860\n",
      "Epoch 14/50\n",
      "6514/6514 [==============================] - 1s 178us/step - loss: 0.0502 - acc: 0.9862 - val_loss: 0.0497 - val_acc: 0.9860\n",
      "Epoch 15/50\n",
      "6514/6514 [==============================] - 1s 217us/step - loss: 0.0497 - acc: 0.9860 - val_loss: 0.0493 - val_acc: 0.9860\n",
      "Epoch 16/50\n",
      "6514/6514 [==============================] - 1s 191us/step - loss: 0.0494 - acc: 0.9860 - val_loss: 0.0489 - val_acc: 0.9860\n",
      "Epoch 17/50\n",
      "6514/6514 [==============================] - 1s 188us/step - loss: 0.0490 - acc: 0.9859 - val_loss: 0.0485 - val_acc: 0.9860\n",
      "Epoch 18/50\n",
      "6514/6514 [==============================] - 1s 189us/step - loss: 0.0487 - acc: 0.9860 - val_loss: 0.0483 - val_acc: 0.9860\n",
      "Epoch 19/50\n",
      "6514/6514 [==============================] - 1s 174us/step - loss: 0.0483 - acc: 0.9860 - val_loss: 0.0479 - val_acc: 0.9860\n",
      "Epoch 20/50\n",
      "6514/6514 [==============================] - 1s 191us/step - loss: 0.0479 - acc: 0.9860 - val_loss: 0.0477 - val_acc: 0.9860\n",
      "Epoch 21/50\n",
      "6514/6514 [==============================] - 1s 190us/step - loss: 0.0478 - acc: 0.9860 - val_loss: 0.0474 - val_acc: 0.9860\n",
      "Epoch 22/50\n",
      "6514/6514 [==============================] - 1s 199us/step - loss: 0.0476 - acc: 0.9860 - val_loss: 0.0472 - val_acc: 0.9860\n",
      "Epoch 23/50\n",
      "6514/6514 [==============================] - 1s 213us/step - loss: 0.0474 - acc: 0.9860 - val_loss: 0.0470 - val_acc: 0.9860\n",
      "Epoch 24/50\n",
      "6514/6514 [==============================] - 1s 176us/step - loss: 0.0470 - acc: 0.9860 - val_loss: 0.0466 - val_acc: 0.9860\n",
      "Epoch 25/50\n",
      "6514/6514 [==============================] - 1s 188us/step - loss: 0.0467 - acc: 0.9860 - val_loss: 0.0464 - val_acc: 0.9860\n",
      "Epoch 26/50\n",
      "6514/6514 [==============================] - 1s 181us/step - loss: 0.0465 - acc: 0.9860 - val_loss: 0.0461 - val_acc: 0.9860\n",
      "Epoch 27/50\n",
      "6514/6514 [==============================] - 1s 188us/step - loss: 0.0463 - acc: 0.9860 - val_loss: 0.0459 - val_acc: 0.9860\n",
      "Epoch 28/50\n",
      "6514/6514 [==============================] - 1s 186us/step - loss: 0.0460 - acc: 0.9860 - val_loss: 0.0457 - val_acc: 0.9860\n",
      "Epoch 29/50\n",
      "6514/6514 [==============================] - 1s 186us/step - loss: 0.0457 - acc: 0.9860 - val_loss: 0.0454 - val_acc: 0.9860\n",
      "Epoch 30/50\n",
      "6514/6514 [==============================] - 1s 163us/step - loss: 0.0455 - acc: 0.9860 - val_loss: 0.0451 - val_acc: 0.9860\n",
      "Epoch 31/50\n",
      "6514/6514 [==============================] - 1s 199us/step - loss: 0.0453 - acc: 0.9860 - val_loss: 0.0448 - val_acc: 0.9860\n",
      "Epoch 32/50\n",
      "6514/6514 [==============================] - 2s 250us/step - loss: 0.0447 - acc: 0.9862 - val_loss: 0.0448 - val_acc: 0.9862\n",
      "Epoch 33/50\n",
      "6514/6514 [==============================] - 1s 200us/step - loss: 0.0448 - acc: 0.9862 - val_loss: 0.0443 - val_acc: 0.9862\n",
      "Epoch 34/50\n",
      "6514/6514 [==============================] - 1s 227us/step - loss: 0.0444 - acc: 0.9862 - val_loss: 0.0440 - val_acc: 0.9862\n",
      "Epoch 35/50\n",
      "6514/6514 [==============================] - 1s 184us/step - loss: 0.0441 - acc: 0.9862 - val_loss: 0.0438 - val_acc: 0.9862\n",
      "Epoch 36/50\n",
      "6514/6514 [==============================] - 1s 176us/step - loss: 0.0440 - acc: 0.9862 - val_loss: 0.0435 - val_acc: 0.9862\n",
      "Epoch 37/50\n",
      "6514/6514 [==============================] - 1s 204us/step - loss: 0.0436 - acc: 0.9862 - val_loss: 0.0432 - val_acc: 0.9862\n",
      "Epoch 38/50\n",
      "6514/6514 [==============================] - 1s 175us/step - loss: 0.0434 - acc: 0.9862 - val_loss: 0.0430 - val_acc: 0.9862\n",
      "Epoch 39/50\n",
      "6514/6514 [==============================] - 1s 221us/step - loss: 0.0431 - acc: 0.9862 - val_loss: 0.0427 - val_acc: 0.9862\n",
      "Epoch 40/50\n",
      "6514/6514 [==============================] - 1s 192us/step - loss: 0.0428 - acc: 0.9862 - val_loss: 0.0424 - val_acc: 0.9862\n",
      "Epoch 41/50\n",
      "6514/6514 [==============================] - 1s 185us/step - loss: 0.0425 - acc: 0.9862 - val_loss: 0.0421 - val_acc: 0.9862\n",
      "Epoch 42/50\n",
      "6514/6514 [==============================] - 1s 187us/step - loss: 0.0423 - acc: 0.9862 - val_loss: 0.0418 - val_acc: 0.9862\n",
      "Epoch 43/50\n",
      "6514/6514 [==============================] - 1s 189us/step - loss: 0.0419 - acc: 0.9862 - val_loss: 0.0416 - val_acc: 0.9862\n",
      "Epoch 44/50\n",
      "6514/6514 [==============================] - 1s 195us/step - loss: 0.0416 - acc: 0.9862 - val_loss: 0.0412 - val_acc: 0.9862\n",
      "Epoch 45/50\n",
      "6514/6514 [==============================] - 1s 204us/step - loss: 0.0414 - acc: 0.9862 - val_loss: 0.0410 - val_acc: 0.9862\n",
      "Epoch 46/50\n",
      "6514/6514 [==============================] - 1s 195us/step - loss: 0.0410 - acc: 0.9862 - val_loss: 0.0408 - val_acc: 0.9862\n",
      "Epoch 47/50\n",
      "6514/6514 [==============================] - 1s 198us/step - loss: 0.0409 - acc: 0.9862 - val_loss: 0.0405 - val_acc: 0.9862\n",
      "Epoch 48/50\n",
      "6514/6514 [==============================] - 1s 207us/step - loss: 0.0406 - acc: 0.9862 - val_loss: 0.0402 - val_acc: 0.9863\n",
      "Epoch 49/50\n",
      "6514/6514 [==============================] - 1s 186us/step - loss: 0.0404 - acc: 0.9862 - val_loss: 0.0399 - val_acc: 0.9863\n",
      "Epoch 50/50\n",
      "6514/6514 [==============================] - 1s 208us/step - loss: 0.0400 - acc: 0.9862 - val_loss: 0.0398 - val_acc: 0.9862\n",
      "1629/1629 [==============================] - 0s 85us/step\n",
      "6514/6514 [==============================] - 1s 90us/step\n",
      "Train on 6514 samples, validate on 6514 samples\n",
      "Epoch 1/50\n",
      "6514/6514 [==============================] - 1s 184us/step - loss: 0.0439 - acc: 0.9846 - val_loss: 0.0433 - val_acc: 0.9846\n",
      "Epoch 2/50\n",
      "6514/6514 [==============================] - 1s 188us/step - loss: 0.0434 - acc: 0.9846 - val_loss: 0.0433 - val_acc: 0.9845\n",
      "Epoch 3/50\n",
      "6514/6514 [==============================] - 1s 206us/step - loss: 0.0430 - acc: 0.9843 - val_loss: 0.0429 - val_acc: 0.9846\n",
      "Epoch 4/50\n",
      "6514/6514 [==============================] - 1s 230us/step - loss: 0.0428 - acc: 0.9846 - val_loss: 0.0423 - val_acc: 0.9846\n",
      "Epoch 5/50\n",
      "6514/6514 [==============================] - 1s 190us/step - loss: 0.0425 - acc: 0.9846 - val_loss: 0.0420 - val_acc: 0.9846\n",
      "Epoch 6/50\n",
      "6514/6514 [==============================] - 1s 179us/step - loss: 0.0423 - acc: 0.9846 - val_loss: 0.0417 - val_acc: 0.9846\n",
      "Epoch 7/50\n",
      "6514/6514 [==============================] - 1s 177us/step - loss: 0.0418 - acc: 0.9845 - val_loss: 0.0414 - val_acc: 0.9846\n",
      "Epoch 8/50\n",
      "6514/6514 [==============================] - 1s 181us/step - loss: 0.0415 - acc: 0.9845 - val_loss: 0.0413 - val_acc: 0.9848\n",
      "Epoch 9/50\n",
      "6514/6514 [==============================] - 1s 180us/step - loss: 0.0414 - acc: 0.9846 - val_loss: 0.0408 - val_acc: 0.9848\n",
      "Epoch 10/50\n",
      "6514/6514 [==============================] - 1s 177us/step - loss: 0.0410 - acc: 0.9848 - val_loss: 0.0405 - val_acc: 0.9848\n",
      "Epoch 11/50\n",
      "6514/6514 [==============================] - 1s 183us/step - loss: 0.0406 - acc: 0.9848 - val_loss: 0.0403 - val_acc: 0.9848\n",
      "Epoch 12/50\n",
      "6514/6514 [==============================] - 2s 232us/step - loss: 0.0404 - acc: 0.9848 - val_loss: 0.0399 - val_acc: 0.9846\n",
      "Epoch 13/50\n",
      "6514/6514 [==============================] - 1s 205us/step - loss: 0.0401 - acc: 0.9848 - val_loss: 0.0396 - val_acc: 0.9848\n",
      "Epoch 14/50\n",
      "6514/6514 [==============================] - 1s 180us/step - loss: 0.0399 - acc: 0.9848 - val_loss: 0.0393 - val_acc: 0.9848\n",
      "Epoch 15/50\n",
      "6514/6514 [==============================] - 1s 210us/step - loss: 0.0396 - acc: 0.9848 - val_loss: 0.0391 - val_acc: 0.9848\n",
      "Epoch 16/50\n",
      "6514/6514 [==============================] - 1s 191us/step - loss: 0.0393 - acc: 0.9848 - val_loss: 0.0388 - val_acc: 0.9848\n",
      "Epoch 17/50\n",
      "6514/6514 [==============================] - 1s 184us/step - loss: 0.0390 - acc: 0.9846 - val_loss: 0.0388 - val_acc: 0.9848\n",
      "Epoch 18/50\n",
      "6514/6514 [==============================] - 1s 168us/step - loss: 0.0388 - acc: 0.9848 - val_loss: 0.0384 - val_acc: 0.9848\n",
      "Epoch 19/50\n",
      "6514/6514 [==============================] - 1s 163us/step - loss: 0.0384 - acc: 0.9846 - val_loss: 0.0380 - val_acc: 0.9848\n",
      "Epoch 20/50\n",
      "6514/6514 [==============================] - 1s 198us/step - loss: 0.0382 - acc: 0.9848 - val_loss: 0.0378 - val_acc: 0.9848\n",
      "Epoch 21/50\n",
      "6514/6514 [==============================] - 1s 170us/step - loss: 0.0380 - acc: 0.9848 - val_loss: 0.0376 - val_acc: 0.9848\n",
      "Epoch 22/50\n",
      "6514/6514 [==============================] - 1s 165us/step - loss: 0.0378 - acc: 0.9848 - val_loss: 0.0374 - val_acc: 0.9848\n",
      "Epoch 23/50\n",
      "6514/6514 [==============================] - 1s 180us/step - loss: 0.0375 - acc: 0.9848 - val_loss: 0.0370 - val_acc: 0.9848\n",
      "Epoch 24/50\n",
      "6514/6514 [==============================] - 1s 163us/step - loss: 0.0372 - acc: 0.9848 - val_loss: 0.0369 - val_acc: 0.9848\n",
      "Epoch 25/50\n",
      "6514/6514 [==============================] - 1s 176us/step - loss: 0.0370 - acc: 0.9848 - val_loss: 0.0365 - val_acc: 0.9848\n",
      "Epoch 26/50\n",
      "6514/6514 [==============================] - 1s 167us/step - loss: 0.0368 - acc: 0.9848 - val_loss: 0.0363 - val_acc: 0.9848\n",
      "Epoch 27/50\n",
      "6514/6514 [==============================] - 1s 182us/step - loss: 0.0367 - acc: 0.9846 - val_loss: 0.0361 - val_acc: 0.9848\n",
      "Epoch 28/50\n",
      "6514/6514 [==============================] - 1s 173us/step - loss: 0.0363 - acc: 0.9848 - val_loss: 0.0358 - val_acc: 0.9848\n",
      "Epoch 29/50\n",
      "6514/6514 [==============================] - 1s 210us/step - loss: 0.0361 - acc: 0.9850 - val_loss: 0.0356 - val_acc: 0.9848\n",
      "Epoch 30/50\n",
      "6514/6514 [==============================] - 1s 188us/step - loss: 0.0358 - acc: 0.9848 - val_loss: 0.0354 - val_acc: 0.9848\n",
      "Epoch 31/50\n",
      "6514/6514 [==============================] - 1s 211us/step - loss: 0.0357 - acc: 0.9848 - val_loss: 0.0354 - val_acc: 0.9848\n",
      "Epoch 32/50\n",
      "6514/6514 [==============================] - 1s 189us/step - loss: 0.0354 - acc: 0.9850 - val_loss: 0.0349 - val_acc: 0.9848\n",
      "Epoch 33/50\n",
      "6514/6514 [==============================] - 1s 177us/step - loss: 0.0352 - acc: 0.9848 - val_loss: 0.0347 - val_acc: 0.9848\n",
      "Epoch 34/50\n",
      "6514/6514 [==============================] - 1s 162us/step - loss: 0.0350 - acc: 0.9848 - val_loss: 0.0346 - val_acc: 0.9848\n",
      "Epoch 35/50\n",
      "6514/6514 [==============================] - 1s 168us/step - loss: 0.0348 - acc: 0.9848 - val_loss: 0.0343 - val_acc: 0.9848\n",
      "Epoch 36/50\n",
      "6514/6514 [==============================] - 1s 185us/step - loss: 0.0348 - acc: 0.9848 - val_loss: 0.0343 - val_acc: 0.9848\n",
      "Epoch 37/50\n",
      "6514/6514 [==============================] - 1s 159us/step - loss: 0.0344 - acc: 0.9848 - val_loss: 0.0341 - val_acc: 0.9848\n",
      "Epoch 38/50\n",
      "6514/6514 [==============================] - 1s 201us/step - loss: 0.0342 - acc: 0.9848 - val_loss: 0.0341 - val_acc: 0.9848\n",
      "Epoch 39/50\n",
      "6514/6514 [==============================] - 1s 161us/step - loss: 0.0340 - acc: 0.9848 - val_loss: 0.0337 - val_acc: 0.9850\n",
      "Epoch 40/50\n",
      "6514/6514 [==============================] - 1s 164us/step - loss: 0.0339 - acc: 0.9850 - val_loss: 0.0337 - val_acc: 0.9851\n",
      "Epoch 41/50\n",
      "6514/6514 [==============================] - 1s 177us/step - loss: 0.0338 - acc: 0.9846 - val_loss: 0.0334 - val_acc: 0.9851\n",
      "Epoch 42/50\n",
      "6514/6514 [==============================] - 1s 163us/step - loss: 0.0337 - acc: 0.9848 - val_loss: 0.0332 - val_acc: 0.9850\n",
      "Epoch 43/50\n",
      "6514/6514 [==============================] - 1s 172us/step - loss: 0.0336 - acc: 0.9851 - val_loss: 0.0333 - val_acc: 0.9860\n",
      "Epoch 44/50\n",
      "6514/6514 [==============================] - 1s 173us/step - loss: 0.0335 - acc: 0.9854 - val_loss: 0.0330 - val_acc: 0.9853\n",
      "Epoch 45/50\n",
      "6514/6514 [==============================] - 1s 186us/step - loss: 0.0333 - acc: 0.9851 - val_loss: 0.0328 - val_acc: 0.9853\n",
      "Epoch 46/50\n",
      "6514/6514 [==============================] - 1s 194us/step - loss: 0.0331 - acc: 0.9853 - val_loss: 0.0328 - val_acc: 0.9851\n",
      "Epoch 47/50\n",
      "6514/6514 [==============================] - 1s 192us/step - loss: 0.0329 - acc: 0.9856 - val_loss: 0.0329 - val_acc: 0.9854\n",
      "Epoch 48/50\n",
      "6514/6514 [==============================] - 1s 167us/step - loss: 0.0331 - acc: 0.9854 - val_loss: 0.0325 - val_acc: 0.9853\n",
      "Epoch 49/50\n",
      "6514/6514 [==============================] - 1s 184us/step - loss: 0.0327 - acc: 0.9853 - val_loss: 0.0324 - val_acc: 0.9851\n",
      "Epoch 50/50\n",
      "6514/6514 [==============================] - 1s 166us/step - loss: 0.0326 - acc: 0.9853 - val_loss: 0.0323 - val_acc: 0.9862\n",
      "1629/1629 [==============================] - 0s 80us/step\n",
      "6514/6514 [==============================] - 1s 83us/step\n",
      "Train on 6514 samples, validate on 6514 samples\n",
      "Epoch 1/50\n",
      "6514/6514 [==============================] - 1s 188us/step - loss: 0.0284 - acc: 0.9885 - val_loss: 0.0280 - val_acc: 0.9896\n",
      "Epoch 2/50\n",
      "6514/6514 [==============================] - 1s 181us/step - loss: 0.0283 - acc: 0.9893 - val_loss: 0.0278 - val_acc: 0.9891\n",
      "Epoch 3/50\n",
      "6514/6514 [==============================] - 1s 190us/step - loss: 0.0281 - acc: 0.9889 - val_loss: 0.0277 - val_acc: 0.9897\n",
      "Epoch 4/50\n",
      "6514/6514 [==============================] - 2s 232us/step - loss: 0.0280 - acc: 0.9897 - val_loss: 0.0276 - val_acc: 0.9897\n",
      "Epoch 5/50\n",
      "6514/6514 [==============================] - 1s 211us/step - loss: 0.0280 - acc: 0.9893 - val_loss: 0.0276 - val_acc: 0.9897\n",
      "Epoch 6/50\n",
      "6514/6514 [==============================] - 1s 193us/step - loss: 0.0279 - acc: 0.9894 - val_loss: 0.0275 - val_acc: 0.9897\n",
      "Epoch 7/50\n",
      "6514/6514 [==============================] - 1s 182us/step - loss: 0.0277 - acc: 0.9894 - val_loss: 0.0275 - val_acc: 0.9897\n",
      "Epoch 8/50\n",
      "6514/6514 [==============================] - 1s 174us/step - loss: 0.0277 - acc: 0.9897 - val_loss: 0.0273 - val_acc: 0.9897\n",
      "Epoch 9/50\n",
      "6514/6514 [==============================] - 1s 183us/step - loss: 0.0275 - acc: 0.9894 - val_loss: 0.0272 - val_acc: 0.9897\n",
      "Epoch 10/50\n",
      "6514/6514 [==============================] - 1s 192us/step - loss: 0.0275 - acc: 0.9894 - val_loss: 0.0272 - val_acc: 0.9902\n",
      "Epoch 11/50\n",
      "6514/6514 [==============================] - 1s 211us/step - loss: 0.0273 - acc: 0.9899 - val_loss: 0.0271 - val_acc: 0.9902\n",
      "Epoch 12/50\n",
      "6514/6514 [==============================] - 1s 194us/step - loss: 0.0273 - acc: 0.9894 - val_loss: 0.0272 - val_acc: 0.9889\n",
      "Epoch 13/50\n",
      "6514/6514 [==============================] - 1s 175us/step - loss: 0.0273 - acc: 0.9902 - val_loss: 0.0270 - val_acc: 0.9897\n",
      "Epoch 14/50\n",
      "6514/6514 [==============================] - 1s 171us/step - loss: 0.0273 - acc: 0.9900 - val_loss: 0.0269 - val_acc: 0.9902\n",
      "Epoch 15/50\n",
      "6514/6514 [==============================] - 1s 180us/step - loss: 0.0271 - acc: 0.9902 - val_loss: 0.0268 - val_acc: 0.9902\n",
      "Epoch 16/50\n",
      "6514/6514 [==============================] - 1s 211us/step - loss: 0.0272 - acc: 0.9900 - val_loss: 0.0268 - val_acc: 0.9900\n",
      "Epoch 17/50\n",
      "6514/6514 [==============================] - 1s 163us/step - loss: 0.0271 - acc: 0.9902 - val_loss: 0.0268 - val_acc: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "6514/6514 [==============================] - 1s 171us/step - loss: 0.0270 - acc: 0.9897 - val_loss: 0.0267 - val_acc: 0.9900\n",
      "Epoch 19/50\n",
      "6514/6514 [==============================] - 1s 173us/step - loss: 0.0270 - acc: 0.9897 - val_loss: 0.0270 - val_acc: 0.9893\n",
      "Epoch 20/50\n",
      "6514/6514 [==============================] - 1s 174us/step - loss: 0.0269 - acc: 0.9897 - val_loss: 0.0266 - val_acc: 0.9902\n",
      "Epoch 21/50\n",
      "6514/6514 [==============================] - 1s 189us/step - loss: 0.0269 - acc: 0.9899 - val_loss: 0.0266 - val_acc: 0.9902\n",
      "Epoch 22/50\n",
      "6514/6514 [==============================] - 1s 177us/step - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0265 - val_acc: 0.9900\n",
      "Epoch 23/50\n",
      "6514/6514 [==============================] - 1s 177us/step - loss: 0.0269 - acc: 0.9900 - val_loss: 0.0264 - val_acc: 0.9902\n",
      "Epoch 24/50\n",
      "6514/6514 [==============================] - 1s 166us/step - loss: 0.0265 - acc: 0.9900 - val_loss: 0.0264 - val_acc: 0.9900\n",
      "Epoch 25/50\n",
      "6514/6514 [==============================] - 1s 173us/step - loss: 0.0268 - acc: 0.9900 - val_loss: 0.0263 - val_acc: 0.9906\n",
      "Epoch 26/50\n",
      "6514/6514 [==============================] - 1s 172us/step - loss: 0.0266 - acc: 0.9903 - val_loss: 0.0263 - val_acc: 0.9899\n",
      "Epoch 27/50\n",
      "6514/6514 [==============================] - 1s 161us/step - loss: 0.0266 - acc: 0.9902 - val_loss: 0.0262 - val_acc: 0.9900\n",
      "Epoch 28/50\n",
      "6514/6514 [==============================] - 1s 196us/step - loss: 0.0264 - acc: 0.9897 - val_loss: 0.0265 - val_acc: 0.9899\n",
      "Epoch 29/50\n",
      "6514/6514 [==============================] - 1s 193us/step - loss: 0.0265 - acc: 0.9897 - val_loss: 0.0264 - val_acc: 0.9900\n",
      "Epoch 30/50\n",
      "6514/6514 [==============================] - 1s 196us/step - loss: 0.0265 - acc: 0.9902 - val_loss: 0.0261 - val_acc: 0.9899\n",
      "Epoch 31/50\n",
      "6514/6514 [==============================] - 1s 179us/step - loss: 0.0263 - acc: 0.9900 - val_loss: 0.0264 - val_acc: 0.9899\n",
      "Epoch 32/50\n",
      "6514/6514 [==============================] - 1s 162us/step - loss: 0.0264 - acc: 0.9902 - val_loss: 0.0261 - val_acc: 0.9900\n",
      "Epoch 33/50\n",
      "6514/6514 [==============================] - 1s 156us/step - loss: 0.0262 - acc: 0.9902 - val_loss: 0.0260 - val_acc: 0.9899\n",
      "Epoch 34/50\n",
      "6514/6514 [==============================] - 1s 176us/step - loss: 0.0264 - acc: 0.9905 - val_loss: 0.0259 - val_acc: 0.9902\n",
      "Epoch 35/50\n",
      "6514/6514 [==============================] - 1s 168us/step - loss: 0.0263 - acc: 0.9897 - val_loss: 0.0261 - val_acc: 0.9900\n",
      "Epoch 36/50\n",
      "6514/6514 [==============================] - 1s 181us/step - loss: 0.0263 - acc: 0.9899 - val_loss: 0.0261 - val_acc: 0.9905\n",
      "Epoch 37/50\n",
      "6514/6514 [==============================] - 1s 161us/step - loss: 0.0263 - acc: 0.9905 - val_loss: 0.0259 - val_acc: 0.9899\n",
      "Epoch 38/50\n",
      "6514/6514 [==============================] - 1s 180us/step - loss: 0.0262 - acc: 0.9897 - val_loss: 0.0258 - val_acc: 0.9902\n",
      "Epoch 39/50\n",
      "6514/6514 [==============================] - 1s 160us/step - loss: 0.0261 - acc: 0.9900 - val_loss: 0.0258 - val_acc: 0.9902\n",
      "Epoch 40/50\n",
      "6514/6514 [==============================] - 1s 174us/step - loss: 0.0263 - acc: 0.9899 - val_loss: 0.0258 - val_acc: 0.9900\n",
      "Epoch 41/50\n",
      "6514/6514 [==============================] - 1s 184us/step - loss: 0.0262 - acc: 0.9902 - val_loss: 0.0258 - val_acc: 0.9900\n",
      "Epoch 42/50\n",
      "6514/6514 [==============================] - 1s 167us/step - loss: 0.0261 - acc: 0.9906 - val_loss: 0.0257 - val_acc: 0.9902\n",
      "Epoch 43/50\n",
      "6514/6514 [==============================] - 1s 166us/step - loss: 0.0262 - acc: 0.9899 - val_loss: 0.0256 - val_acc: 0.9902\n",
      "Epoch 44/50\n",
      "6514/6514 [==============================] - 1s 157us/step - loss: 0.0260 - acc: 0.9899 - val_loss: 0.0257 - val_acc: 0.9900\n",
      "Epoch 45/50\n",
      "6514/6514 [==============================] - 1s 165us/step - loss: 0.0260 - acc: 0.9900 - val_loss: 0.0255 - val_acc: 0.9902\n",
      "Epoch 46/50\n",
      "6514/6514 [==============================] - 1s 171us/step - loss: 0.0260 - acc: 0.9902 - val_loss: 0.0256 - val_acc: 0.9900\n",
      "Epoch 47/50\n",
      "6514/6514 [==============================] - 1s 155us/step - loss: 0.0258 - acc: 0.9902 - val_loss: 0.0256 - val_acc: 0.9902\n",
      "Epoch 48/50\n",
      "6514/6514 [==============================] - 1s 187us/step - loss: 0.0258 - acc: 0.9900 - val_loss: 0.0255 - val_acc: 0.9906\n",
      "Epoch 49/50\n",
      "6514/6514 [==============================] - 1s 172us/step - loss: 0.0258 - acc: 0.9902 - val_loss: 0.0254 - val_acc: 0.9900\n",
      "Epoch 50/50\n",
      "6514/6514 [==============================] - 1s 165us/step - loss: 0.0257 - acc: 0.9900 - val_loss: 0.0254 - val_acc: 0.9903\n",
      "1629/1629 [==============================] - 0s 73us/step\n",
      "6514/6514 [==============================] - 1s 78us/step\n",
      "Train on 4071 samples, validate on 4071 samples\n",
      "Epoch 1/50\n",
      "4071/4071 [==============================] - 1s 173us/step - loss: 0.0262 - acc: 0.9904 - val_loss: 0.0258 - val_acc: 0.9902\n",
      "Epoch 2/50\n",
      "4071/4071 [==============================] - 1s 181us/step - loss: 0.0261 - acc: 0.9904 - val_loss: 0.0256 - val_acc: 0.9904\n",
      "Epoch 3/50\n",
      "4071/4071 [==============================] - 1s 191us/step - loss: 0.0260 - acc: 0.9899 - val_loss: 0.0256 - val_acc: 0.9904\n",
      "Epoch 4/50\n",
      "4071/4071 [==============================] - 1s 164us/step - loss: 0.0259 - acc: 0.9902 - val_loss: 0.0255 - val_acc: 0.9904\n",
      "Epoch 5/50\n",
      "4071/4071 [==============================] - 1s 184us/step - loss: 0.0258 - acc: 0.9907 - val_loss: 0.0255 - val_acc: 0.9904\n",
      "Epoch 6/50\n",
      "4071/4071 [==============================] - 1s 186us/step - loss: 0.0260 - acc: 0.9907 - val_loss: 0.0254 - val_acc: 0.9904\n",
      "Epoch 7/50\n",
      "4071/4071 [==============================] - 1s 175us/step - loss: 0.0257 - acc: 0.9904 - val_loss: 0.0256 - val_acc: 0.9904\n",
      "Epoch 8/50\n",
      "4071/4071 [==============================] - 1s 190us/step - loss: 0.0258 - acc: 0.9907 - val_loss: 0.0253 - val_acc: 0.9904\n",
      "Epoch 9/50\n",
      "4071/4071 [==============================] - 1s 198us/step - loss: 0.0257 - acc: 0.9902 - val_loss: 0.0252 - val_acc: 0.9904\n",
      "Epoch 10/50\n",
      "4071/4071 [==============================] - 1s 162us/step - loss: 0.0255 - acc: 0.9904 - val_loss: 0.0252 - val_acc: 0.9904\n",
      "Epoch 11/50\n",
      "4071/4071 [==============================] - 1s 180us/step - loss: 0.0257 - acc: 0.9902 - val_loss: 0.0252 - val_acc: 0.9907\n",
      "Epoch 12/50\n",
      "4071/4071 [==============================] - 1s 270us/step - loss: 0.0255 - acc: 0.9904 - val_loss: 0.0251 - val_acc: 0.9904\n",
      "Epoch 13/50\n",
      "4071/4071 [==============================] - 1s 262us/step - loss: 0.0254 - acc: 0.9909 - val_loss: 0.0251 - val_acc: 0.9904\n",
      "Epoch 14/50\n",
      "4071/4071 [==============================] - 1s 304us/step - loss: 0.0257 - acc: 0.9902 - val_loss: 0.0251 - val_acc: 0.9902\n",
      "Epoch 15/50\n",
      "4071/4071 [==============================] - 1s 205us/step - loss: 0.0255 - acc: 0.9912 - val_loss: 0.0251 - val_acc: 0.9904\n",
      "Epoch 16/50\n",
      "4071/4071 [==============================] - 1s 306us/step - loss: 0.0254 - acc: 0.9902 - val_loss: 0.0250 - val_acc: 0.9904\n",
      "Epoch 17/50\n",
      "4071/4071 [==============================] - 1s 160us/step - loss: 0.0254 - acc: 0.9907 - val_loss: 0.0251 - val_acc: 0.9909\n",
      "Epoch 18/50\n",
      "4071/4071 [==============================] - 1s 165us/step - loss: 0.0254 - acc: 0.9904 - val_loss: 0.0250 - val_acc: 0.9907\n",
      "Epoch 19/50\n",
      "4071/4071 [==============================] - 1s 192us/step - loss: 0.0252 - acc: 0.9904 - val_loss: 0.0250 - val_acc: 0.9904\n",
      "Epoch 20/50\n",
      "4071/4071 [==============================] - 1s 214us/step - loss: 0.0253 - acc: 0.9904 - val_loss: 0.0249 - val_acc: 0.9902\n",
      "Epoch 21/50\n",
      "4071/4071 [==============================] - 1s 178us/step - loss: 0.0253 - acc: 0.9904 - val_loss: 0.0249 - val_acc: 0.9909\n",
      "Epoch 22/50\n",
      "4071/4071 [==============================] - 1s 199us/step - loss: 0.0252 - acc: 0.9909 - val_loss: 0.0249 - val_acc: 0.9907\n",
      "Epoch 23/50\n",
      "4071/4071 [==============================] - 1s 187us/step - loss: 0.0252 - acc: 0.9904 - val_loss: 0.0248 - val_acc: 0.9904\n",
      "Epoch 24/50\n",
      "4071/4071 [==============================] - 1s 176us/step - loss: 0.0253 - acc: 0.9907 - val_loss: 0.0249 - val_acc: 0.9909\n",
      "Epoch 25/50\n",
      "4071/4071 [==============================] - 1s 180us/step - loss: 0.0252 - acc: 0.9909 - val_loss: 0.0249 - val_acc: 0.9909\n",
      "Epoch 26/50\n",
      "4071/4071 [==============================] - 1s 172us/step - loss: 0.0253 - acc: 0.9904 - val_loss: 0.0248 - val_acc: 0.9907\n",
      "Epoch 27/50\n",
      "4071/4071 [==============================] - 1s 159us/step - loss: 0.0251 - acc: 0.9904 - val_loss: 0.0248 - val_acc: 0.9909\n",
      "Epoch 28/50\n",
      "4071/4071 [==============================] - 1s 167us/step - loss: 0.0252 - acc: 0.9912 - val_loss: 0.0248 - val_acc: 0.9909\n",
      "Epoch 29/50\n",
      "4071/4071 [==============================] - 1s 174us/step - loss: 0.0251 - acc: 0.9902 - val_loss: 0.0248 - val_acc: 0.9907\n",
      "Epoch 30/50\n",
      "4071/4071 [==============================] - 1s 160us/step - loss: 0.0251 - acc: 0.9907 - val_loss: 0.0250 - val_acc: 0.9914\n",
      "Epoch 31/50\n",
      "4071/4071 [==============================] - 1s 164us/step - loss: 0.0252 - acc: 0.9907 - val_loss: 0.0247 - val_acc: 0.9902\n",
      "Epoch 32/50\n",
      "4071/4071 [==============================] - 1s 164us/step - loss: 0.0250 - acc: 0.9907 - val_loss: 0.0247 - val_acc: 0.9907\n",
      "Epoch 33/50\n",
      "4071/4071 [==============================] - 1s 220us/step - loss: 0.0250 - acc: 0.9904 - val_loss: 0.0246 - val_acc: 0.9907\n",
      "Epoch 34/50\n",
      "4071/4071 [==============================] - 1s 196us/step - loss: 0.0250 - acc: 0.9907 - val_loss: 0.0246 - val_acc: 0.9909\n",
      "Epoch 35/50\n",
      "4071/4071 [==============================] - 1s 168us/step - loss: 0.0249 - acc: 0.9907 - val_loss: 0.0246 - val_acc: 0.9907\n",
      "Epoch 36/50\n",
      "4071/4071 [==============================] - 1s 175us/step - loss: 0.0251 - acc: 0.9907 - val_loss: 0.0247 - val_acc: 0.9904\n",
      "Epoch 37/50\n",
      "4071/4071 [==============================] - 1s 184us/step - loss: 0.0249 - acc: 0.9902 - val_loss: 0.0246 - val_acc: 0.9909\n",
      "Epoch 38/50\n",
      "4071/4071 [==============================] - 1s 197us/step - loss: 0.0250 - acc: 0.9909 - val_loss: 0.0247 - val_acc: 0.9912\n",
      "Epoch 39/50\n",
      "4071/4071 [==============================] - 1s 153us/step - loss: 0.0250 - acc: 0.9912 - val_loss: 0.0246 - val_acc: 0.9904\n",
      "Epoch 40/50\n",
      "4071/4071 [==============================] - 1s 156us/step - loss: 0.0249 - acc: 0.9904 - val_loss: 0.0245 - val_acc: 0.9907\n",
      "Epoch 41/50\n",
      "4071/4071 [==============================] - 1s 156us/step - loss: 0.0250 - acc: 0.9909 - val_loss: 0.0248 - val_acc: 0.9902\n",
      "Epoch 42/50\n",
      "4071/4071 [==============================] - 1s 155us/step - loss: 0.0249 - acc: 0.9902 - val_loss: 0.0246 - val_acc: 0.9912\n",
      "Epoch 43/50\n",
      "4071/4071 [==============================] - 1s 158us/step - loss: 0.0249 - acc: 0.9907 - val_loss: 0.0245 - val_acc: 0.9904\n",
      "Epoch 44/50\n",
      "4071/4071 [==============================] - 1s 168us/step - loss: 0.0248 - acc: 0.9902 - val_loss: 0.0245 - val_acc: 0.9904\n",
      "Epoch 45/50\n",
      "4071/4071 [==============================] - 1s 164us/step - loss: 0.0249 - acc: 0.9909 - val_loss: 0.0246 - val_acc: 0.9912\n",
      "Epoch 46/50\n",
      "4071/4071 [==============================] - 1s 162us/step - loss: 0.0250 - acc: 0.9907 - val_loss: 0.0246 - val_acc: 0.9909\n",
      "Epoch 47/50\n",
      "4071/4071 [==============================] - 1s 183us/step - loss: 0.0249 - acc: 0.9904 - val_loss: 0.0245 - val_acc: 0.9909\n",
      "Epoch 48/50\n",
      "4071/4071 [==============================] - 1s 191us/step - loss: 0.0249 - acc: 0.9907 - val_loss: 0.0244 - val_acc: 0.9904\n",
      "Epoch 49/50\n",
      "4071/4071 [==============================] - 1s 166us/step - loss: 0.0248 - acc: 0.9904 - val_loss: 0.0244 - val_acc: 0.9912\n",
      "Epoch 50/50\n",
      "4071/4071 [==============================] - 1s 231us/step - loss: 0.0248 - acc: 0.9902 - val_loss: 0.0244 - val_acc: 0.9912\n",
      "4072/4072 [==============================] - 0s 115us/step\n",
      "4071/4071 [==============================] - 0s 81us/step\n",
      "Train on 4071 samples, validate on 4071 samples\n",
      "Epoch 1/50\n",
      "4071/4071 [==============================] - 1s 169us/step - loss: 0.0285 - acc: 0.9907 - val_loss: 0.0280 - val_acc: 0.9909\n",
      "Epoch 2/50\n",
      "4071/4071 [==============================] - 1s 190us/step - loss: 0.0284 - acc: 0.9909 - val_loss: 0.0277 - val_acc: 0.9909\n",
      "Epoch 3/50\n",
      "4071/4071 [==============================] - 1s 167us/step - loss: 0.0283 - acc: 0.9909 - val_loss: 0.0276 - val_acc: 0.9909\n",
      "Epoch 4/50\n",
      "4071/4071 [==============================] - 1s 161us/step - loss: 0.0278 - acc: 0.9909 - val_loss: 0.0275 - val_acc: 0.9904\n",
      "Epoch 5/50\n",
      "4071/4071 [==============================] - 1s 163us/step - loss: 0.0279 - acc: 0.9904 - val_loss: 0.0275 - val_acc: 0.9904\n",
      "Epoch 6/50\n",
      "4071/4071 [==============================] - 1s 165us/step - loss: 0.0278 - acc: 0.9904 - val_loss: 0.0274 - val_acc: 0.9904\n",
      "Epoch 7/50\n",
      "4071/4071 [==============================] - 1s 198us/step - loss: 0.0277 - acc: 0.9902 - val_loss: 0.0273 - val_acc: 0.9904\n",
      "Epoch 8/50\n",
      "4071/4071 [==============================] - 1s 164us/step - loss: 0.0276 - acc: 0.9902 - val_loss: 0.0272 - val_acc: 0.9904\n",
      "Epoch 9/50\n",
      "4071/4071 [==============================] - 1s 214us/step - loss: 0.0274 - acc: 0.9904 - val_loss: 0.0273 - val_acc: 0.9904\n",
      "Epoch 10/50\n",
      "4071/4071 [==============================] - 1s 196us/step - loss: 0.0275 - acc: 0.9904 - val_loss: 0.0272 - val_acc: 0.9904\n",
      "Epoch 11/50\n",
      "4071/4071 [==============================] - 1s 163us/step - loss: 0.0275 - acc: 0.9904 - val_loss: 0.0271 - val_acc: 0.9904\n",
      "Epoch 12/50\n",
      "4071/4071 [==============================] - 1s 191us/step - loss: 0.0276 - acc: 0.9902 - val_loss: 0.0270 - val_acc: 0.9904\n",
      "Epoch 13/50\n",
      "4071/4071 [==============================] - 1s 179us/step - loss: 0.0273 - acc: 0.9907 - val_loss: 0.0271 - val_acc: 0.9904\n",
      "Epoch 14/50\n",
      "4071/4071 [==============================] - 1s 176us/step - loss: 0.0273 - acc: 0.9907 - val_loss: 0.0270 - val_acc: 0.9904\n",
      "Epoch 15/50\n",
      "4071/4071 [==============================] - 1s 184us/step - loss: 0.0274 - acc: 0.9904 - val_loss: 0.0270 - val_acc: 0.9904\n",
      "Epoch 16/50\n",
      "4071/4071 [==============================] - 1s 182us/step - loss: 0.0272 - acc: 0.9904 - val_loss: 0.0270 - val_acc: 0.9904\n",
      "Epoch 17/50\n",
      "4071/4071 [==============================] - 1s 175us/step - loss: 0.0272 - acc: 0.9907 - val_loss: 0.0269 - val_acc: 0.9904\n",
      "Epoch 18/50\n",
      "4071/4071 [==============================] - 1s 177us/step - loss: 0.0271 - acc: 0.9904 - val_loss: 0.0269 - val_acc: 0.9904\n",
      "Epoch 19/50\n",
      "4071/4071 [==============================] - 1s 177us/step - loss: 0.0271 - acc: 0.9907 - val_loss: 0.0268 - val_acc: 0.9904\n",
      "Epoch 20/50\n",
      "4071/4071 [==============================] - 1s 177us/step - loss: 0.0274 - acc: 0.9904 - val_loss: 0.0268 - val_acc: 0.9904\n",
      "Epoch 21/50\n",
      "4071/4071 [==============================] - 1s 184us/step - loss: 0.0270 - acc: 0.9902 - val_loss: 0.0267 - val_acc: 0.9904\n",
      "Epoch 22/50\n",
      "4071/4071 [==============================] - 1s 170us/step - loss: 0.0271 - acc: 0.9904 - val_loss: 0.0267 - val_acc: 0.9904\n",
      "Epoch 23/50\n",
      "4071/4071 [==============================] - 1s 189us/step - loss: 0.0271 - acc: 0.9902 - val_loss: 0.0267 - val_acc: 0.9904\n",
      "Epoch 24/50\n",
      "4071/4071 [==============================] - 1s 192us/step - loss: 0.0272 - acc: 0.9904 - val_loss: 0.0267 - val_acc: 0.9904\n",
      "Epoch 25/50\n",
      "4071/4071 [==============================] - 1s 173us/step - loss: 0.0271 - acc: 0.9904 - val_loss: 0.0266 - val_acc: 0.9904\n",
      "Epoch 26/50\n",
      "4071/4071 [==============================] - 1s 178us/step - loss: 0.0271 - acc: 0.9902 - val_loss: 0.0267 - val_acc: 0.9904\n",
      "Epoch 27/50\n",
      "4071/4071 [==============================] - 1s 181us/step - loss: 0.0271 - acc: 0.9904 - val_loss: 0.0266 - val_acc: 0.9904\n",
      "Epoch 28/50\n",
      "4071/4071 [==============================] - 1s 162us/step - loss: 0.0271 - acc: 0.9904 - val_loss: 0.0266 - val_acc: 0.9904\n",
      "Epoch 29/50\n",
      "4071/4071 [==============================] - 1s 227us/step - loss: 0.0268 - acc: 0.9904 - val_loss: 0.0266 - val_acc: 0.9904\n",
      "Epoch 30/50\n",
      "4071/4071 [==============================] - 1s 276us/step - loss: 0.0268 - acc: 0.9909 - val_loss: 0.0268 - val_acc: 0.9904\n",
      "Epoch 31/50\n",
      "4071/4071 [==============================] - 1s 246us/step - loss: 0.0269 - acc: 0.9907 - val_loss: 0.0267 - val_acc: 0.9904\n",
      "Epoch 32/50\n",
      "4071/4071 [==============================] - 1s 251us/step - loss: 0.0268 - acc: 0.9904 - val_loss: 0.0266 - val_acc: 0.9904\n",
      "Epoch 33/50\n",
      "4071/4071 [==============================] - 1s 252us/step - loss: 0.0268 - acc: 0.9904 - val_loss: 0.0267 - val_acc: 0.9904\n",
      "Epoch 34/50\n",
      "4071/4071 [==============================] - 1s 269us/step - loss: 0.0270 - acc: 0.9904 - val_loss: 0.0265 - val_acc: 0.9904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "4071/4071 [==============================] - 1s 193us/step - loss: 0.0270 - acc: 0.9902 - val_loss: 0.0265 - val_acc: 0.9904\n",
      "Epoch 36/50\n",
      "4071/4071 [==============================] - 1s 212us/step - loss: 0.0268 - acc: 0.9902 - val_loss: 0.0267 - val_acc: 0.9904\n",
      "Epoch 37/50\n",
      "4071/4071 [==============================] - 1s 189us/step - loss: 0.0267 - acc: 0.9907 - val_loss: 0.0265 - val_acc: 0.9904\n",
      "Epoch 38/50\n",
      "4071/4071 [==============================] - 1s 206us/step - loss: 0.0268 - acc: 0.9902 - val_loss: 0.0266 - val_acc: 0.9904\n",
      "Epoch 39/50\n",
      "4071/4071 [==============================] - 1s 181us/step - loss: 0.0269 - acc: 0.9904 - val_loss: 0.0264 - val_acc: 0.9904\n",
      "Epoch 40/50\n",
      "4071/4071 [==============================] - 1s 192us/step - loss: 0.0267 - acc: 0.9902 - val_loss: 0.0264 - val_acc: 0.9902\n",
      "Epoch 41/50\n",
      "4071/4071 [==============================] - 1s 179us/step - loss: 0.0268 - acc: 0.9904 - val_loss: 0.0264 - val_acc: 0.9904\n",
      "Epoch 42/50\n",
      "4071/4071 [==============================] - 1s 184us/step - loss: 0.0269 - acc: 0.9902 - val_loss: 0.0264 - val_acc: 0.9904\n",
      "Epoch 43/50\n",
      "4071/4071 [==============================] - 1s 192us/step - loss: 0.0268 - acc: 0.9907 - val_loss: 0.0264 - val_acc: 0.9904\n",
      "Epoch 44/50\n",
      "4071/4071 [==============================] - 1s 186us/step - loss: 0.0268 - acc: 0.9902 - val_loss: 0.0266 - val_acc: 0.9904\n",
      "Epoch 45/50\n",
      "4071/4071 [==============================] - 1s 173us/step - loss: 0.0268 - acc: 0.9907 - val_loss: 0.0264 - val_acc: 0.9904\n",
      "Epoch 46/50\n",
      "4071/4071 [==============================] - 1s 222us/step - loss: 0.0268 - acc: 0.9902 - val_loss: 0.0263 - val_acc: 0.9902\n",
      "Epoch 47/50\n",
      "4071/4071 [==============================] - 1s 196us/step - loss: 0.0269 - acc: 0.9902 - val_loss: 0.0264 - val_acc: 0.9904\n",
      "Epoch 48/50\n",
      "4071/4071 [==============================] - 1s 219us/step - loss: 0.0268 - acc: 0.9902 - val_loss: 0.0263 - val_acc: 0.9904\n",
      "Epoch 49/50\n",
      "4071/4071 [==============================] - 1s 193us/step - loss: 0.0267 - acc: 0.9902 - val_loss: 0.0263 - val_acc: 0.9904\n",
      "Epoch 50/50\n",
      "4071/4071 [==============================] - 1s 174us/step - loss: 0.0266 - acc: 0.9907 - val_loss: 0.0265 - val_acc: 0.9904\n",
      "4072/4072 [==============================] - 0s 88us/step\n",
      "4071/4071 [==============================] - 0s 79us/step\n",
      "Train on 4071 samples, validate on 4071 samples\n",
      "Epoch 1/50\n",
      "4071/4071 [==============================] - 1s 190us/step - loss: 0.0290 - acc: 0.9897 - val_loss: 0.0283 - val_acc: 0.9897\n",
      "Epoch 2/50\n",
      "4071/4071 [==============================] - 1s 190us/step - loss: 0.0289 - acc: 0.9897 - val_loss: 0.0283 - val_acc: 0.9899\n",
      "Epoch 3/50\n",
      "4071/4071 [==============================] - 1s 205us/step - loss: 0.0285 - acc: 0.9897 - val_loss: 0.0281 - val_acc: 0.9899\n",
      "Epoch 4/50\n",
      "4071/4071 [==============================] - 1s 168us/step - loss: 0.0285 - acc: 0.9897 - val_loss: 0.0280 - val_acc: 0.9897\n",
      "Epoch 5/50\n",
      "4071/4071 [==============================] - 1s 164us/step - loss: 0.0285 - acc: 0.9899 - val_loss: 0.0279 - val_acc: 0.9897\n",
      "Epoch 6/50\n",
      "4071/4071 [==============================] - 1s 171us/step - loss: 0.0284 - acc: 0.9897 - val_loss: 0.0278 - val_acc: 0.9897\n",
      "Epoch 7/50\n",
      "4071/4071 [==============================] - 1s 200us/step - loss: 0.0282 - acc: 0.9899 - val_loss: 0.0277 - val_acc: 0.9899\n",
      "Epoch 8/50\n",
      "4071/4071 [==============================] - 1s 189us/step - loss: 0.0280 - acc: 0.9899 - val_loss: 0.0277 - val_acc: 0.9899\n",
      "Epoch 9/50\n",
      "4071/4071 [==============================] - 1s 186us/step - loss: 0.0280 - acc: 0.9897 - val_loss: 0.0276 - val_acc: 0.9897\n",
      "Epoch 10/50\n",
      "4071/4071 [==============================] - 1s 170us/step - loss: 0.0280 - acc: 0.9899 - val_loss: 0.0276 - val_acc: 0.9899\n",
      "Epoch 11/50\n",
      "4071/4071 [==============================] - 1s 165us/step - loss: 0.0281 - acc: 0.9897 - val_loss: 0.0276 - val_acc: 0.9897\n",
      "Epoch 12/50\n",
      "4071/4071 [==============================] - 1s 162us/step - loss: 0.0279 - acc: 0.9894 - val_loss: 0.0275 - val_acc: 0.9899\n",
      "Epoch 13/50\n",
      "4071/4071 [==============================] - 1s 166us/step - loss: 0.0280 - acc: 0.9894 - val_loss: 0.0274 - val_acc: 0.9897\n",
      "Epoch 14/50\n",
      "4071/4071 [==============================] - 1s 170us/step - loss: 0.0277 - acc: 0.9897 - val_loss: 0.0274 - val_acc: 0.9897\n",
      "Epoch 15/50\n",
      "4071/4071 [==============================] - 1s 187us/step - loss: 0.0278 - acc: 0.9892 - val_loss: 0.0273 - val_acc: 0.9899\n",
      "Epoch 16/50\n",
      "4071/4071 [==============================] - 1s 185us/step - loss: 0.0278 - acc: 0.9897 - val_loss: 0.0273 - val_acc: 0.9894\n",
      "Epoch 17/50\n",
      "4071/4071 [==============================] - 1s 208us/step - loss: 0.0275 - acc: 0.9897 - val_loss: 0.0274 - val_acc: 0.9894\n",
      "Epoch 18/50\n",
      "4071/4071 [==============================] - 1s 219us/step - loss: 0.0276 - acc: 0.9894 - val_loss: 0.0273 - val_acc: 0.9894\n",
      "Epoch 19/50\n",
      "4071/4071 [==============================] - 1s 223us/step - loss: 0.0274 - acc: 0.9897 - val_loss: 0.0271 - val_acc: 0.9897\n",
      "Epoch 20/50\n",
      "4071/4071 [==============================] - 1s 205us/step - loss: 0.0276 - acc: 0.9894 - val_loss: 0.0271 - val_acc: 0.9894\n",
      "Epoch 21/50\n",
      "4071/4071 [==============================] - 1s 201us/step - loss: 0.0274 - acc: 0.9892 - val_loss: 0.0273 - val_acc: 0.9897\n",
      "Epoch 22/50\n",
      "4071/4071 [==============================] - 1s 187us/step - loss: 0.0275 - acc: 0.9897 - val_loss: 0.0270 - val_acc: 0.9894\n",
      "Epoch 23/50\n",
      "4071/4071 [==============================] - 1s 159us/step - loss: 0.0275 - acc: 0.9897 - val_loss: 0.0270 - val_acc: 0.9892\n",
      "Epoch 24/50\n",
      "4071/4071 [==============================] - 1s 195us/step - loss: 0.0274 - acc: 0.9894 - val_loss: 0.0270 - val_acc: 0.9894\n",
      "Epoch 25/50\n",
      "4071/4071 [==============================] - 1s 211us/step - loss: 0.0276 - acc: 0.9894 - val_loss: 0.0270 - val_acc: 0.9894\n",
      "Epoch 26/50\n",
      "4071/4071 [==============================] - 1s 197us/step - loss: 0.0271 - acc: 0.9897 - val_loss: 0.0270 - val_acc: 0.9897\n",
      "Epoch 27/50\n",
      "4071/4071 [==============================] - 1s 170us/step - loss: 0.0273 - acc: 0.9897 - val_loss: 0.0269 - val_acc: 0.9894\n",
      "Epoch 28/50\n",
      "4071/4071 [==============================] - 1s 172us/step - loss: 0.0274 - acc: 0.9894 - val_loss: 0.0268 - val_acc: 0.9894\n",
      "Epoch 29/50\n",
      "4071/4071 [==============================] - 1s 191us/step - loss: 0.0274 - acc: 0.9892 - val_loss: 0.0268 - val_acc: 0.9897\n",
      "Epoch 30/50\n",
      "4071/4071 [==============================] - 1s 184us/step - loss: 0.0271 - acc: 0.9897 - val_loss: 0.0268 - val_acc: 0.9894\n",
      "Epoch 31/50\n",
      "4071/4071 [==============================] - 1s 189us/step - loss: 0.0272 - acc: 0.9897 - val_loss: 0.0267 - val_acc: 0.9894\n",
      "Epoch 32/50\n",
      "4071/4071 [==============================] - 1s 197us/step - loss: 0.0271 - acc: 0.9897 - val_loss: 0.0267 - val_acc: 0.9894\n",
      "Epoch 33/50\n",
      "4071/4071 [==============================] - 1s 208us/step - loss: 0.0273 - acc: 0.9894 - val_loss: 0.0268 - val_acc: 0.9894\n",
      "Epoch 34/50\n",
      "4071/4071 [==============================] - 1s 214us/step - loss: 0.0269 - acc: 0.9897 - val_loss: 0.0272 - val_acc: 0.9892\n",
      "Epoch 35/50\n",
      "4071/4071 [==============================] - 1s 250us/step - loss: 0.0273 - acc: 0.9897 - val_loss: 0.0266 - val_acc: 0.9894\n",
      "Epoch 36/50\n",
      "4071/4071 [==============================] - 1s 189us/step - loss: 0.0273 - acc: 0.9894 - val_loss: 0.0266 - val_acc: 0.9892\n",
      "Epoch 37/50\n",
      "4071/4071 [==============================] - 1s 187us/step - loss: 0.0269 - acc: 0.9894 - val_loss: 0.0267 - val_acc: 0.9897\n",
      "Epoch 38/50\n",
      "4071/4071 [==============================] - 1s 194us/step - loss: 0.0270 - acc: 0.9897 - val_loss: 0.0267 - val_acc: 0.9892\n",
      "Epoch 39/50\n",
      "4071/4071 [==============================] - 1s 199us/step - loss: 0.0271 - acc: 0.9894 - val_loss: 0.0265 - val_acc: 0.9894\n",
      "Epoch 40/50\n",
      "4071/4071 [==============================] - 1s 203us/step - loss: 0.0269 - acc: 0.9892 - val_loss: 0.0265 - val_acc: 0.9894\n",
      "Epoch 41/50\n",
      "4071/4071 [==============================] - 1s 190us/step - loss: 0.0269 - acc: 0.9892 - val_loss: 0.0266 - val_acc: 0.9897\n",
      "Epoch 42/50\n",
      "4071/4071 [==============================] - 1s 194us/step - loss: 0.0268 - acc: 0.9892 - val_loss: 0.0265 - val_acc: 0.9897\n",
      "Epoch 43/50\n",
      "4071/4071 [==============================] - 1s 210us/step - loss: 0.0271 - acc: 0.9894 - val_loss: 0.0265 - val_acc: 0.9894\n",
      "Epoch 44/50\n",
      "4071/4071 [==============================] - 1s 216us/step - loss: 0.0270 - acc: 0.9892 - val_loss: 0.0265 - val_acc: 0.9894\n",
      "Epoch 45/50\n",
      "4071/4071 [==============================] - 1s 202us/step - loss: 0.0268 - acc: 0.9897 - val_loss: 0.0266 - val_acc: 0.9894\n",
      "Epoch 46/50\n",
      "4071/4071 [==============================] - 1s 190us/step - loss: 0.0266 - acc: 0.9889 - val_loss: 0.0266 - val_acc: 0.9897\n",
      "Epoch 47/50\n",
      "4071/4071 [==============================] - 1s 215us/step - loss: 0.0269 - acc: 0.9897 - val_loss: 0.0264 - val_acc: 0.9894\n",
      "Epoch 48/50\n",
      "4071/4071 [==============================] - 1s 199us/step - loss: 0.0268 - acc: 0.9892 - val_loss: 0.0265 - val_acc: 0.9897\n",
      "Epoch 49/50\n",
      "4071/4071 [==============================] - 1s 218us/step - loss: 0.0268 - acc: 0.9894 - val_loss: 0.0264 - val_acc: 0.9894\n",
      "Epoch 50/50\n",
      "4071/4071 [==============================] - 1s 190us/step - loss: 0.0269 - acc: 0.9892 - val_loss: 0.0264 - val_acc: 0.9897\n",
      "4072/4072 [==============================] - 0s 86us/step\n",
      "4071/4071 [==============================] - 0s 87us/step\n",
      "Train on 1628 samples, validate on 1628 samples\n",
      "Epoch 1/50\n",
      "1628/1628 [==============================] - 0s 168us/step - loss: 0.0321 - acc: 0.9883 - val_loss: 0.0304 - val_acc: 0.9883\n",
      "Epoch 2/50\n",
      "1628/1628 [==============================] - 0s 177us/step - loss: 0.0300 - acc: 0.9889 - val_loss: 0.0294 - val_acc: 0.9889\n",
      "Epoch 3/50\n",
      "1628/1628 [==============================] - 0s 183us/step - loss: 0.0295 - acc: 0.9889 - val_loss: 0.0286 - val_acc: 0.9889\n",
      "Epoch 4/50\n",
      "1628/1628 [==============================] - 0s 189us/step - loss: 0.0287 - acc: 0.9889 - val_loss: 0.0282 - val_acc: 0.9883\n",
      "Epoch 5/50\n",
      "1628/1628 [==============================] - 0s 161us/step - loss: 0.0284 - acc: 0.9877 - val_loss: 0.0276 - val_acc: 0.9889\n",
      "Epoch 6/50\n",
      "1628/1628 [==============================] - 0s 175us/step - loss: 0.0279 - acc: 0.9889 - val_loss: 0.0272 - val_acc: 0.9889\n",
      "Epoch 7/50\n",
      "1628/1628 [==============================] - 0s 171us/step - loss: 0.0278 - acc: 0.9883 - val_loss: 0.0268 - val_acc: 0.9883\n",
      "Epoch 8/50\n",
      "1628/1628 [==============================] - 0s 196us/step - loss: 0.0274 - acc: 0.9883 - val_loss: 0.0264 - val_acc: 0.9889\n",
      "Epoch 9/50\n",
      "1628/1628 [==============================] - 0s 185us/step - loss: 0.0269 - acc: 0.9896 - val_loss: 0.0262 - val_acc: 0.9889\n",
      "Epoch 10/50\n",
      "1628/1628 [==============================] - 0s 177us/step - loss: 0.0264 - acc: 0.9889 - val_loss: 0.0259 - val_acc: 0.9896\n",
      "Epoch 11/50\n",
      "1628/1628 [==============================] - 0s 228us/step - loss: 0.0264 - acc: 0.9889 - val_loss: 0.0257 - val_acc: 0.9889\n",
      "Epoch 12/50\n",
      "1628/1628 [==============================] - 0s 206us/step - loss: 0.0258 - acc: 0.9883 - val_loss: 0.0255 - val_acc: 0.9896\n",
      "Epoch 13/50\n",
      "1628/1628 [==============================] - 0s 190us/step - loss: 0.0256 - acc: 0.9896 - val_loss: 0.0252 - val_acc: 0.9896\n",
      "Epoch 14/50\n",
      "1628/1628 [==============================] - 0s 223us/step - loss: 0.0255 - acc: 0.9896 - val_loss: 0.0251 - val_acc: 0.9896\n",
      "Epoch 15/50\n",
      "1628/1628 [==============================] - 0s 215us/step - loss: 0.0253 - acc: 0.9896 - val_loss: 0.0249 - val_acc: 0.9896\n",
      "Epoch 16/50\n",
      "1628/1628 [==============================] - 0s 197us/step - loss: 0.0252 - acc: 0.9896 - val_loss: 0.0248 - val_acc: 0.9896\n",
      "Epoch 17/50\n",
      "1628/1628 [==============================] - 0s 200us/step - loss: 0.0249 - acc: 0.9902 - val_loss: 0.0246 - val_acc: 0.9902\n",
      "Epoch 18/50\n",
      "1628/1628 [==============================] - 0s 174us/step - loss: 0.0250 - acc: 0.9902 - val_loss: 0.0245 - val_acc: 0.9914\n",
      "Epoch 19/50\n",
      "1628/1628 [==============================] - 0s 198us/step - loss: 0.0251 - acc: 0.9914 - val_loss: 0.0244 - val_acc: 0.9920\n",
      "Epoch 20/50\n",
      "1628/1628 [==============================] - 0s 195us/step - loss: 0.0247 - acc: 0.9914 - val_loss: 0.0243 - val_acc: 0.9920\n",
      "Epoch 21/50\n",
      "1628/1628 [==============================] - 0s 233us/step - loss: 0.0245 - acc: 0.9920 - val_loss: 0.0242 - val_acc: 0.9920\n",
      "Epoch 22/50\n",
      "1628/1628 [==============================] - 0s 229us/step - loss: 0.0245 - acc: 0.9908 - val_loss: 0.0241 - val_acc: 0.9920\n",
      "Epoch 23/50\n",
      "1628/1628 [==============================] - 0s 201us/step - loss: 0.0244 - acc: 0.9920 - val_loss: 0.0240 - val_acc: 0.9920\n",
      "Epoch 24/50\n",
      "1628/1628 [==============================] - 0s 170us/step - loss: 0.0242 - acc: 0.9920 - val_loss: 0.0239 - val_acc: 0.9926\n",
      "Epoch 25/50\n",
      "1628/1628 [==============================] - 0s 228us/step - loss: 0.0241 - acc: 0.9932 - val_loss: 0.0238 - val_acc: 0.9926\n",
      "Epoch 26/50\n",
      "1628/1628 [==============================] - 0s 242us/step - loss: 0.0242 - acc: 0.9926 - val_loss: 0.0237 - val_acc: 0.9926\n",
      "Epoch 27/50\n",
      "1628/1628 [==============================] - 0s 191us/step - loss: 0.0240 - acc: 0.9926 - val_loss: 0.0237 - val_acc: 0.9932\n",
      "Epoch 28/50\n",
      "1628/1628 [==============================] - 0s 227us/step - loss: 0.0238 - acc: 0.9920 - val_loss: 0.0236 - val_acc: 0.9932\n",
      "Epoch 29/50\n",
      "1628/1628 [==============================] - 0s 200us/step - loss: 0.0241 - acc: 0.9926 - val_loss: 0.0235 - val_acc: 0.9926\n",
      "Epoch 30/50\n",
      "1628/1628 [==============================] - 0s 246us/step - loss: 0.0239 - acc: 0.9920 - val_loss: 0.0234 - val_acc: 0.9926\n",
      "Epoch 31/50\n",
      "1628/1628 [==============================] - 0s 203us/step - loss: 0.0237 - acc: 0.9926 - val_loss: 0.0234 - val_acc: 0.9932\n",
      "Epoch 32/50\n",
      "1628/1628 [==============================] - 0s 170us/step - loss: 0.0236 - acc: 0.9932 - val_loss: 0.0233 - val_acc: 0.9932\n",
      "Epoch 33/50\n",
      "1628/1628 [==============================] - 0s 237us/step - loss: 0.0234 - acc: 0.9926 - val_loss: 0.0232 - val_acc: 0.9932\n",
      "Epoch 34/50\n",
      "1628/1628 [==============================] - 0s 187us/step - loss: 0.0234 - acc: 0.9939 - val_loss: 0.0232 - val_acc: 0.9939\n",
      "Epoch 35/50\n",
      "1628/1628 [==============================] - 0s 224us/step - loss: 0.0235 - acc: 0.9926 - val_loss: 0.0232 - val_acc: 0.9926\n",
      "Epoch 36/50\n",
      "1628/1628 [==============================] - 0s 209us/step - loss: 0.0234 - acc: 0.9926 - val_loss: 0.0231 - val_acc: 0.9932\n",
      "Epoch 37/50\n",
      "1628/1628 [==============================] - 0s 217us/step - loss: 0.0232 - acc: 0.9939 - val_loss: 0.0230 - val_acc: 0.9939\n",
      "Epoch 38/50\n",
      "1628/1628 [==============================] - 0s 170us/step - loss: 0.0231 - acc: 0.9939 - val_loss: 0.0229 - val_acc: 0.9939\n",
      "Epoch 39/50\n",
      "1628/1628 [==============================] - 0s 178us/step - loss: 0.0232 - acc: 0.9932 - val_loss: 0.0229 - val_acc: 0.9939\n",
      "Epoch 40/50\n",
      "1628/1628 [==============================] - 0s 176us/step - loss: 0.0231 - acc: 0.9945 - val_loss: 0.0229 - val_acc: 0.9945\n",
      "Epoch 41/50\n",
      "1628/1628 [==============================] - 0s 226us/step - loss: 0.0234 - acc: 0.9926 - val_loss: 0.0228 - val_acc: 0.9939\n",
      "Epoch 42/50\n",
      "1628/1628 [==============================] - 0s 241us/step - loss: 0.0231 - acc: 0.9945 - val_loss: 0.0228 - val_acc: 0.9951\n",
      "Epoch 43/50\n",
      "1628/1628 [==============================] - 0s 182us/step - loss: 0.0234 - acc: 0.9926 - val_loss: 0.0228 - val_acc: 0.9945\n",
      "Epoch 44/50\n",
      "1628/1628 [==============================] - 0s 185us/step - loss: 0.0233 - acc: 0.9932 - val_loss: 0.0228 - val_acc: 0.9945\n",
      "Epoch 45/50\n",
      "1628/1628 [==============================] - 0s 183us/step - loss: 0.0229 - acc: 0.9945 - val_loss: 0.0226 - val_acc: 0.9939\n",
      "Epoch 46/50\n",
      "1628/1628 [==============================] - 0s 175us/step - loss: 0.0230 - acc: 0.9945 - val_loss: 0.0226 - val_acc: 0.9951\n",
      "Epoch 47/50\n",
      "1628/1628 [==============================] - 0s 170us/step - loss: 0.0228 - acc: 0.9939 - val_loss: 0.0225 - val_acc: 0.9951\n",
      "Epoch 48/50\n",
      "1628/1628 [==============================] - 0s 245us/step - loss: 0.0229 - acc: 0.9939 - val_loss: 0.0225 - val_acc: 0.9945\n",
      "Epoch 49/50\n",
      "1628/1628 [==============================] - 0s 181us/step - loss: 0.0228 - acc: 0.9945 - val_loss: 0.0225 - val_acc: 0.9951\n",
      "Epoch 50/50\n",
      "1628/1628 [==============================] - 0s 272us/step - loss: 0.0228 - acc: 0.9945 - val_loss: 0.0224 - val_acc: 0.9951\n",
      "6515/6515 [==============================] - 1s 87us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1628/1628 [==============================] - 0s 80us/step\n",
      "Train on 1628 samples, validate on 1628 samples\n",
      "Epoch 1/50\n",
      "1628/1628 [==============================] - 0s 188us/step - loss: 0.0240 - acc: 0.9914 - val_loss: 0.0231 - val_acc: 0.9902\n",
      "Epoch 2/50\n",
      "1628/1628 [==============================] - 0s 172us/step - loss: 0.0234 - acc: 0.9902 - val_loss: 0.0229 - val_acc: 0.9902\n",
      "Epoch 3/50\n",
      "1628/1628 [==============================] - 0s 167us/step - loss: 0.0233 - acc: 0.9914 - val_loss: 0.0227 - val_acc: 0.9902\n",
      "Epoch 4/50\n",
      "1628/1628 [==============================] - 0s 181us/step - loss: 0.0230 - acc: 0.9908 - val_loss: 0.0226 - val_acc: 0.9902\n",
      "Epoch 5/50\n",
      "1628/1628 [==============================] - 0s 183us/step - loss: 0.0228 - acc: 0.9914 - val_loss: 0.0225 - val_acc: 0.9908\n",
      "Epoch 6/50\n",
      "1628/1628 [==============================] - 0s 172us/step - loss: 0.0229 - acc: 0.9908 - val_loss: 0.0224 - val_acc: 0.9908\n",
      "Epoch 7/50\n",
      "1628/1628 [==============================] - 0s 172us/step - loss: 0.0227 - acc: 0.9902 - val_loss: 0.0225 - val_acc: 0.9914\n",
      "Epoch 8/50\n",
      "1628/1628 [==============================] - 0s 163us/step - loss: 0.0227 - acc: 0.9908 - val_loss: 0.0223 - val_acc: 0.9908\n",
      "Epoch 9/50\n",
      "1628/1628 [==============================] - 0s 251us/step - loss: 0.0227 - acc: 0.9914 - val_loss: 0.0223 - val_acc: 0.9914\n",
      "Epoch 10/50\n",
      "1628/1628 [==============================] - 0s 235us/step - loss: 0.0227 - acc: 0.9908 - val_loss: 0.0223 - val_acc: 0.9914\n",
      "Epoch 11/50\n",
      "1628/1628 [==============================] - 0s 163us/step - loss: 0.0226 - acc: 0.9908 - val_loss: 0.0223 - val_acc: 0.9914\n",
      "Epoch 12/50\n",
      "1628/1628 [==============================] - 0s 227us/step - loss: 0.0227 - acc: 0.9902 - val_loss: 0.0223 - val_acc: 0.9908\n",
      "Epoch 13/50\n",
      "1628/1628 [==============================] - 0s 266us/step - loss: 0.0226 - acc: 0.9908 - val_loss: 0.0223 - val_acc: 0.9920\n",
      "Epoch 14/50\n",
      "1628/1628 [==============================] - 0s 196us/step - loss: 0.0225 - acc: 0.9908 - val_loss: 0.0222 - val_acc: 0.9914\n",
      "Epoch 15/50\n",
      "1628/1628 [==============================] - 0s 168us/step - loss: 0.0225 - acc: 0.9920 - val_loss: 0.0221 - val_acc: 0.9908\n",
      "Epoch 16/50\n",
      "1628/1628 [==============================] - 0s 246us/step - loss: 0.0225 - acc: 0.9914 - val_loss: 0.0221 - val_acc: 0.9908\n",
      "Epoch 17/50\n",
      "1628/1628 [==============================] - 0s 201us/step - loss: 0.0223 - acc: 0.9908 - val_loss: 0.0221 - val_acc: 0.9908\n",
      "Epoch 18/50\n",
      "1628/1628 [==============================] - 0s 225us/step - loss: 0.0225 - acc: 0.9920 - val_loss: 0.0221 - val_acc: 0.9908\n",
      "Epoch 19/50\n",
      "1628/1628 [==============================] - 0s 200us/step - loss: 0.0223 - acc: 0.9908 - val_loss: 0.0221 - val_acc: 0.9908\n",
      "Epoch 20/50\n",
      "1628/1628 [==============================] - 0s 253us/step - loss: 0.0223 - acc: 0.9908 - val_loss: 0.0221 - val_acc: 0.9914\n",
      "Epoch 21/50\n",
      "1628/1628 [==============================] - 0s 187us/step - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0221 - val_acc: 0.9920\n",
      "Epoch 22/50\n",
      "1628/1628 [==============================] - 0s 193us/step - loss: 0.0223 - acc: 0.9914 - val_loss: 0.0220 - val_acc: 0.9914\n",
      "Epoch 23/50\n",
      "1628/1628 [==============================] - 0s 249us/step - loss: 0.0223 - acc: 0.9908 - val_loss: 0.0220 - val_acc: 0.9914\n",
      "Epoch 24/50\n",
      "1628/1628 [==============================] - 0s 203us/step - loss: 0.0224 - acc: 0.9914 - val_loss: 0.0220 - val_acc: 0.9914\n",
      "Epoch 25/50\n",
      "1628/1628 [==============================] - 0s 216us/step - loss: 0.0223 - acc: 0.9902 - val_loss: 0.0220 - val_acc: 0.9908\n",
      "Epoch 26/50\n",
      "1628/1628 [==============================] - 0s 189us/step - loss: 0.0222 - acc: 0.9914 - val_loss: 0.0220 - val_acc: 0.9920\n",
      "Epoch 27/50\n",
      "1628/1628 [==============================] - 0s 168us/step - loss: 0.0223 - acc: 0.9914 - val_loss: 0.0219 - val_acc: 0.9908\n",
      "Epoch 28/50\n",
      "1628/1628 [==============================] - 0s 181us/step - loss: 0.0225 - acc: 0.9902 - val_loss: 0.0220 - val_acc: 0.9908\n",
      "Epoch 29/50\n",
      "1628/1628 [==============================] - 0s 177us/step - loss: 0.0225 - acc: 0.9920 - val_loss: 0.0219 - val_acc: 0.9908\n",
      "Epoch 30/50\n",
      "1628/1628 [==============================] - 0s 171us/step - loss: 0.0223 - acc: 0.9902 - val_loss: 0.0219 - val_acc: 0.9908\n",
      "Epoch 31/50\n",
      "1628/1628 [==============================] - 0s 205us/step - loss: 0.0221 - acc: 0.9920 - val_loss: 0.0219 - val_acc: 0.9920\n",
      "Epoch 32/50\n",
      "1628/1628 [==============================] - ETA: 0s - loss: 0.0215 - acc: 0.990 - 0s 190us/step - loss: 0.0222 - acc: 0.9914 - val_loss: 0.0219 - val_acc: 0.9920\n",
      "Epoch 33/50\n",
      "1628/1628 [==============================] - 0s 218us/step - loss: 0.0221 - acc: 0.9908 - val_loss: 0.0219 - val_acc: 0.9908\n",
      "Epoch 34/50\n",
      "1628/1628 [==============================] - 0s 172us/step - loss: 0.0224 - acc: 0.9914 - val_loss: 0.0219 - val_acc: 0.9908\n",
      "Epoch 35/50\n",
      "1628/1628 [==============================] - 0s 256us/step - loss: 0.0221 - acc: 0.9908 - val_loss: 0.0218 - val_acc: 0.9908\n",
      "Epoch 36/50\n",
      "1628/1628 [==============================] - 0s 233us/step - loss: 0.0220 - acc: 0.9914 - val_loss: 0.0218 - val_acc: 0.9914\n",
      "Epoch 37/50\n",
      "1628/1628 [==============================] - 0s 174us/step - loss: 0.0227 - acc: 0.9914 - val_loss: 0.0218 - val_acc: 0.9914\n",
      "Epoch 38/50\n",
      "1628/1628 [==============================] - 0s 214us/step - loss: 0.0222 - acc: 0.9908 - val_loss: 0.0218 - val_acc: 0.9908\n",
      "Epoch 39/50\n",
      "1628/1628 [==============================] - 0s 184us/step - loss: 0.0221 - acc: 0.9914 - val_loss: 0.0218 - val_acc: 0.9920\n",
      "Epoch 40/50\n",
      "1628/1628 [==============================] - 0s 172us/step - loss: 0.0223 - acc: 0.9908 - val_loss: 0.0218 - val_acc: 0.9908\n",
      "Epoch 41/50\n",
      "1628/1628 [==============================] - 0s 220us/step - loss: 0.0220 - acc: 0.9920 - val_loss: 0.0218 - val_acc: 0.9920\n",
      "Epoch 42/50\n",
      "1628/1628 [==============================] - 0s 176us/step - loss: 0.0222 - acc: 0.9920 - val_loss: 0.0218 - val_acc: 0.9914\n",
      "Epoch 43/50\n",
      "1628/1628 [==============================] - 0s 229us/step - loss: 0.0224 - acc: 0.9908 - val_loss: 0.0217 - val_acc: 0.9920\n",
      "Epoch 44/50\n",
      "1628/1628 [==============================] - 0s 192us/step - loss: 0.0221 - acc: 0.9914 - val_loss: 0.0217 - val_acc: 0.9920\n",
      "Epoch 45/50\n",
      "1628/1628 [==============================] - 0s 173us/step - loss: 0.0219 - acc: 0.9914 - val_loss: 0.0217 - val_acc: 0.9914\n",
      "Epoch 46/50\n",
      "1628/1628 [==============================] - 0s 246us/step - loss: 0.0219 - acc: 0.9914 - val_loss: 0.0217 - val_acc: 0.9920\n",
      "Epoch 47/50\n",
      "1628/1628 [==============================] - 0s 203us/step - loss: 0.0221 - acc: 0.9920 - val_loss: 0.0218 - val_acc: 0.9920\n",
      "Epoch 48/50\n",
      "1628/1628 [==============================] - 0s 195us/step - loss: 0.0222 - acc: 0.9908 - val_loss: 0.0217 - val_acc: 0.9914\n",
      "Epoch 49/50\n",
      "1628/1628 [==============================] - 0s 192us/step - loss: 0.0219 - acc: 0.9920 - val_loss: 0.0217 - val_acc: 0.9908\n",
      "Epoch 50/50\n",
      "1628/1628 [==============================] - 0s 205us/step - loss: 0.0221 - acc: 0.9914 - val_loss: 0.0217 - val_acc: 0.9920\n",
      "6515/6515 [==============================] - 1s 99us/step\n",
      "1628/1628 [==============================] - 0s 94us/step\n",
      "Train on 1628 samples, validate on 1628 samples\n",
      "Epoch 1/50\n",
      "1628/1628 [==============================] - 0s 203us/step - loss: 0.0243 - acc: 0.9908 - val_loss: 0.0228 - val_acc: 0.9926\n",
      "Epoch 2/50\n",
      "1628/1628 [==============================] - 0s 244us/step - loss: 0.0229 - acc: 0.9932 - val_loss: 0.0222 - val_acc: 0.9932\n",
      "Epoch 3/50\n",
      "1628/1628 [==============================] - 0s 186us/step - loss: 0.0226 - acc: 0.9926 - val_loss: 0.0221 - val_acc: 0.9932\n",
      "Epoch 4/50\n",
      "1628/1628 [==============================] - 0s 233us/step - loss: 0.0225 - acc: 0.9926 - val_loss: 0.0220 - val_acc: 0.9939\n",
      "Epoch 5/50\n",
      "1628/1628 [==============================] - 0s 190us/step - loss: 0.0222 - acc: 0.9932 - val_loss: 0.0219 - val_acc: 0.9932\n",
      "Epoch 6/50\n",
      "1628/1628 [==============================] - 0s 250us/step - loss: 0.0222 - acc: 0.9932 - val_loss: 0.0218 - val_acc: 0.9939\n",
      "Epoch 7/50\n",
      "1628/1628 [==============================] - 0s 227us/step - loss: 0.0224 - acc: 0.9926 - val_loss: 0.0218 - val_acc: 0.9932\n",
      "Epoch 8/50\n",
      "1628/1628 [==============================] - 0s 252us/step - loss: 0.0221 - acc: 0.9945 - val_loss: 0.0218 - val_acc: 0.9939\n",
      "Epoch 9/50\n",
      "1628/1628 [==============================] - 0s 182us/step - loss: 0.0220 - acc: 0.9939 - val_loss: 0.0217 - val_acc: 0.9939\n",
      "Epoch 10/50\n",
      "1628/1628 [==============================] - 0s 173us/step - loss: 0.0222 - acc: 0.9932 - val_loss: 0.0217 - val_acc: 0.9939\n",
      "Epoch 11/50\n",
      "1628/1628 [==============================] - 0s 170us/step - loss: 0.0222 - acc: 0.9939 - val_loss: 0.0217 - val_acc: 0.9932\n",
      "Epoch 12/50\n",
      "1628/1628 [==============================] - 0s 192us/step - loss: 0.0222 - acc: 0.9926 - val_loss: 0.0217 - val_acc: 0.9932\n",
      "Epoch 13/50\n",
      "1628/1628 [==============================] - 0s 214us/step - loss: 0.0220 - acc: 0.9939 - val_loss: 0.0217 - val_acc: 0.9932\n",
      "Epoch 14/50\n",
      "1628/1628 [==============================] - 0s 181us/step - loss: 0.0219 - acc: 0.9939 - val_loss: 0.0216 - val_acc: 0.9939\n",
      "Epoch 15/50\n",
      "1628/1628 [==============================] - 0s 178us/step - loss: 0.0219 - acc: 0.9939 - val_loss: 0.0216 - val_acc: 0.9939\n",
      "Epoch 16/50\n",
      "1628/1628 [==============================] - 0s 186us/step - loss: 0.0218 - acc: 0.9932 - val_loss: 0.0216 - val_acc: 0.9939\n",
      "Epoch 17/50\n",
      "1628/1628 [==============================] - 0s 185us/step - loss: 0.0220 - acc: 0.9939 - val_loss: 0.0216 - val_acc: 0.9939\n",
      "Epoch 18/50\n",
      "1628/1628 [==============================] - 0s 168us/step - loss: 0.0218 - acc: 0.9932 - val_loss: 0.0215 - val_acc: 0.9939\n",
      "Epoch 19/50\n",
      "1628/1628 [==============================] - 0s 229us/step - loss: 0.0219 - acc: 0.9932 - val_loss: 0.0215 - val_acc: 0.9939\n",
      "Epoch 20/50\n",
      "1628/1628 [==============================] - 0s 194us/step - loss: 0.0222 - acc: 0.9920 - val_loss: 0.0215 - val_acc: 0.9939\n",
      "Epoch 21/50\n",
      "1628/1628 [==============================] - 0s 196us/step - loss: 0.0219 - acc: 0.9939 - val_loss: 0.0215 - val_acc: 0.9939\n",
      "Epoch 22/50\n",
      "1628/1628 [==============================] - 0s 174us/step - loss: 0.0220 - acc: 0.9932 - val_loss: 0.0215 - val_acc: 0.9932\n",
      "Epoch 23/50\n",
      "1628/1628 [==============================] - 0s 234us/step - loss: 0.0217 - acc: 0.9932 - val_loss: 0.0215 - val_acc: 0.9932\n",
      "Epoch 24/50\n",
      "1628/1628 [==============================] - 0s 228us/step - loss: 0.0218 - acc: 0.9932 - val_loss: 0.0214 - val_acc: 0.9939\n",
      "Epoch 25/50\n",
      "1628/1628 [==============================] - 0s 203us/step - loss: 0.0220 - acc: 0.9932 - val_loss: 0.0215 - val_acc: 0.9939\n",
      "Epoch 26/50\n",
      "1628/1628 [==============================] - 0s 276us/step - loss: 0.0218 - acc: 0.9920 - val_loss: 0.0214 - val_acc: 0.9939\n",
      "Epoch 27/50\n",
      "1628/1628 [==============================] - 0s 258us/step - loss: 0.0218 - acc: 0.9926 - val_loss: 0.0215 - val_acc: 0.9926\n",
      "Epoch 28/50\n",
      "1628/1628 [==============================] - 0s 179us/step - loss: 0.0218 - acc: 0.9932 - val_loss: 0.0214 - val_acc: 0.9932\n",
      "Epoch 29/50\n",
      "1628/1628 [==============================] - 0s 206us/step - loss: 0.0218 - acc: 0.9920 - val_loss: 0.0214 - val_acc: 0.9932\n",
      "Epoch 30/50\n",
      "1628/1628 [==============================] - 0s 205us/step - loss: 0.0218 - acc: 0.9939 - val_loss: 0.0214 - val_acc: 0.9932\n",
      "Epoch 31/50\n",
      "1628/1628 [==============================] - 0s 175us/step - loss: 0.0217 - acc: 0.9932 - val_loss: 0.0214 - val_acc: 0.9939\n",
      "Epoch 32/50\n",
      "1628/1628 [==============================] - 0s 163us/step - loss: 0.0218 - acc: 0.9932 - val_loss: 0.0213 - val_acc: 0.9939\n",
      "Epoch 33/50\n",
      "1628/1628 [==============================] - 0s 166us/step - loss: 0.0218 - acc: 0.9926 - val_loss: 0.0213 - val_acc: 0.9939\n",
      "Epoch 34/50\n",
      "1628/1628 [==============================] - 0s 166us/step - loss: 0.0219 - acc: 0.9914 - val_loss: 0.0214 - val_acc: 0.9926\n",
      "Epoch 35/50\n",
      "1628/1628 [==============================] - 0s 169us/step - loss: 0.0220 - acc: 0.9926 - val_loss: 0.0213 - val_acc: 0.9932\n",
      "Epoch 36/50\n",
      "1628/1628 [==============================] - 0s 167us/step - loss: 0.0217 - acc: 0.9920 - val_loss: 0.0213 - val_acc: 0.9932\n",
      "Epoch 37/50\n",
      "1628/1628 [==============================] - 0s 192us/step - loss: 0.0218 - acc: 0.9926 - val_loss: 0.0213 - val_acc: 0.9939\n",
      "Epoch 38/50\n",
      "1628/1628 [==============================] - 0s 209us/step - loss: 0.0218 - acc: 0.9932 - val_loss: 0.0213 - val_acc: 0.9932\n",
      "Epoch 39/50\n",
      "1628/1628 [==============================] - 0s 212us/step - loss: 0.0217 - acc: 0.9926 - val_loss: 0.0213 - val_acc: 0.9932\n",
      "Epoch 40/50\n",
      "1628/1628 [==============================] - 0s 233us/step - loss: 0.0215 - acc: 0.9926 - val_loss: 0.0213 - val_acc: 0.9939\n",
      "Epoch 41/50\n",
      "1628/1628 [==============================] - 0s 266us/step - loss: 0.0217 - acc: 0.9932 - val_loss: 0.0212 - val_acc: 0.9939\n",
      "Epoch 42/50\n",
      "1628/1628 [==============================] - 0s 261us/step - loss: 0.0217 - acc: 0.9926 - val_loss: 0.0213 - val_acc: 0.9926\n",
      "Epoch 43/50\n",
      "1628/1628 [==============================] - 0s 268us/step - loss: 0.0216 - acc: 0.9926 - val_loss: 0.0212 - val_acc: 0.9932\n",
      "Epoch 44/50\n",
      "1628/1628 [==============================] - 0s 212us/step - loss: 0.0216 - acc: 0.9939 - val_loss: 0.0213 - val_acc: 0.9926\n",
      "Epoch 45/50\n",
      "1628/1628 [==============================] - 0s 171us/step - loss: 0.0219 - acc: 0.9920 - val_loss: 0.0212 - val_acc: 0.9932\n",
      "Epoch 46/50\n",
      "1628/1628 [==============================] - 0s 225us/step - loss: 0.0217 - acc: 0.9926 - val_loss: 0.0212 - val_acc: 0.9932\n",
      "Epoch 47/50\n",
      "1628/1628 [==============================] - 0s 269us/step - loss: 0.0215 - acc: 0.9939 - val_loss: 0.0212 - val_acc: 0.9932\n",
      "Epoch 48/50\n",
      "1628/1628 [==============================] - 0s 252us/step - loss: 0.0217 - acc: 0.9926 - val_loss: 0.0212 - val_acc: 0.9932\n",
      "Epoch 49/50\n",
      "1628/1628 [==============================] - 0s 192us/step - loss: 0.0218 - acc: 0.9932 - val_loss: 0.0212 - val_acc: 0.9939\n",
      "Epoch 50/50\n",
      "1628/1628 [==============================] - 0s 236us/step - loss: 0.0215 - acc: 0.9920 - val_loss: 0.0212 - val_acc: 0.9926\n",
      "6515/6515 [==============================] - 1s 77us/step\n",
      "1628/1628 [==============================] - 0s 110us/step\n",
      "[0.9895641497851443, 0.9896856581532415, 0.9909439754412893]\n",
      "[0.9875652440652525, 0.9904200442151806, 0.9932432432432433]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8,activation='relu',input_dim=5))\n",
    "#model.add(Dense(units = 32, activation = 'relu'))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "ave_acc_occ_ann=[]\n",
    "ave_acc_occ_ann_train=[]\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(occ_x, occ_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        history = model.fit(X_train1, y_train1,validation_data=(X_train1,y_train1),batch_size=32,epochs=50)\n",
    "        score2 += model.evaluate(X_test1,y_test1,verbose=1)[1]\n",
    "        score1 += model.evaluate(X_train1,y_train1,verbose=1)[1]\n",
    "    ave_acc_occ_ann.append(score2/3.0)\n",
    "    ave_acc_occ_ann_train.append(score1/3.0)\n",
    "    \n",
    "print ave_acc_occ_ann  \n",
    "print ave_acc_occ_ann_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:14: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 130000 samples, validate on 130000 samples\n",
      "Epoch 1/100\n",
      "130000/130000 [==============================] - 6s 47us/step - loss: 0.2552 - acc: 0.9624 - val_loss: 0.1409 - val_acc: 0.9749\n",
      "Epoch 2/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.1223 - acc: 0.9749 - val_loss: 0.1102 - val_acc: 0.9749\n",
      "Epoch 3/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.1041 - acc: 0.9749 - val_loss: 0.0994 - val_acc: 0.9749\n",
      "Epoch 4/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0969 - acc: 0.9750 - val_loss: 0.0948 - val_acc: 0.9750\n",
      "Epoch 5/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0937 - acc: 0.9752 - val_loss: 0.0926 - val_acc: 0.9752\n",
      "Epoch 6/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0919 - acc: 0.9754 - val_loss: 0.0912 - val_acc: 0.9754\n",
      "Epoch 7/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0907 - acc: 0.9754 - val_loss: 0.0901 - val_acc: 0.9757\n",
      "Epoch 8/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0898 - acc: 0.9755 - val_loss: 0.0892 - val_acc: 0.9756\n",
      "Epoch 9/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0889 - acc: 0.9758 - val_loss: 0.0886 - val_acc: 0.9758\n",
      "Epoch 10/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0882 - acc: 0.9757 - val_loss: 0.0878 - val_acc: 0.9757\n",
      "Epoch 11/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0876 - acc: 0.9758 - val_loss: 0.0873 - val_acc: 0.9759\n",
      "Epoch 12/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0870 - acc: 0.9758 - val_loss: 0.0866 - val_acc: 0.9759\n",
      "Epoch 13/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0865 - acc: 0.9759 - val_loss: 0.0862 - val_acc: 0.9759\n",
      "Epoch 14/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0860 - acc: 0.9760 - val_loss: 0.0857 - val_acc: 0.9760\n",
      "Epoch 15/100\n",
      "130000/130000 [==============================] - 1s 12us/step - loss: 0.0855 - acc: 0.9760 - val_loss: 0.0853 - val_acc: 0.9759\n",
      "Epoch 16/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0850 - acc: 0.9759 - val_loss: 0.0847 - val_acc: 0.9760\n",
      "Epoch 17/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0847 - acc: 0.9760 - val_loss: 0.0845 - val_acc: 0.9759\n",
      "Epoch 18/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0843 - acc: 0.9760 - val_loss: 0.0840 - val_acc: 0.9760\n",
      "Epoch 19/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0840 - acc: 0.9760 - val_loss: 0.0840 - val_acc: 0.9759\n",
      "Epoch 20/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0837 - acc: 0.9761 - val_loss: 0.0834 - val_acc: 0.9760\n",
      "Epoch 21/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0834 - acc: 0.9760 - val_loss: 0.0836 - val_acc: 0.9761\n",
      "Epoch 22/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0833 - acc: 0.9760 - val_loss: 0.0830 - val_acc: 0.9762\n",
      "Epoch 23/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0830 - acc: 0.9760 - val_loss: 0.0829 - val_acc: 0.9761\n",
      "Epoch 24/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0829 - acc: 0.9761 - val_loss: 0.0826 - val_acc: 0.9761\n",
      "Epoch 25/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0827 - acc: 0.9761 - val_loss: 0.0827 - val_acc: 0.9760\n",
      "Epoch 26/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0826 - acc: 0.9760 - val_loss: 0.0824 - val_acc: 0.9760\n",
      "Epoch 27/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0825 - acc: 0.9761 - val_loss: 0.0823 - val_acc: 0.9762\n",
      "Epoch 28/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0823 - acc: 0.9762 - val_loss: 0.0822 - val_acc: 0.9761\n",
      "Epoch 29/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0822 - acc: 0.9761 - val_loss: 0.0821 - val_acc: 0.9763\n",
      "Epoch 30/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0822 - acc: 0.9762 - val_loss: 0.0819 - val_acc: 0.9762\n",
      "Epoch 31/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0820 - acc: 0.9762 - val_loss: 0.0818 - val_acc: 0.9761\n",
      "Epoch 32/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0820 - acc: 0.9762 - val_loss: 0.0818 - val_acc: 0.9762\n",
      "Epoch 33/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0818 - acc: 0.9763 - val_loss: 0.0818 - val_acc: 0.9760\n",
      "Epoch 34/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0817 - acc: 0.9763 - val_loss: 0.0818 - val_acc: 0.9763\n",
      "Epoch 35/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0817 - acc: 0.9762 - val_loss: 0.0815 - val_acc: 0.9763\n",
      "Epoch 36/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0817 - acc: 0.9763 - val_loss: 0.0814 - val_acc: 0.9762\n",
      "Epoch 37/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0815 - acc: 0.9762 - val_loss: 0.0814 - val_acc: 0.9763\n",
      "Epoch 38/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0816 - acc: 0.9762 - val_loss: 0.0814 - val_acc: 0.9762\n",
      "Epoch 39/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0814 - acc: 0.9762 - val_loss: 0.0817 - val_acc: 0.9764\n",
      "Epoch 40/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0814 - acc: 0.9763 - val_loss: 0.0815 - val_acc: 0.9763\n",
      "Epoch 41/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0814 - acc: 0.9762 - val_loss: 0.0812 - val_acc: 0.9765\n",
      "Epoch 42/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0813 - acc: 0.9763 - val_loss: 0.0813 - val_acc: 0.9762\n",
      "Epoch 43/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0812 - acc: 0.9762 - val_loss: 0.0810 - val_acc: 0.9764\n",
      "Epoch 44/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0812 - acc: 0.9763 - val_loss: 0.0812 - val_acc: 0.9762\n",
      "Epoch 45/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0811 - acc: 0.9764 - val_loss: 0.0811 - val_acc: 0.9763\n",
      "Epoch 46/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0812 - acc: 0.9764 - val_loss: 0.0808 - val_acc: 0.9764\n",
      "Epoch 47/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0810 - acc: 0.9764 - val_loss: 0.0809 - val_acc: 0.9763\n",
      "Epoch 48/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0810 - acc: 0.9763 - val_loss: 0.0810 - val_acc: 0.9763\n",
      "Epoch 49/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0810 - acc: 0.9764 - val_loss: 0.0810 - val_acc: 0.9765\n",
      "Epoch 50/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0809 - acc: 0.9764 - val_loss: 0.0808 - val_acc: 0.9764\n",
      "Epoch 51/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0809 - acc: 0.9764 - val_loss: 0.0807 - val_acc: 0.9765\n",
      "Epoch 52/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0809 - acc: 0.9763 - val_loss: 0.0807 - val_acc: 0.9765\n",
      "Epoch 53/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0809 - acc: 0.9764 - val_loss: 0.0808 - val_acc: 0.9764\n",
      "Epoch 54/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0808 - acc: 0.9764 - val_loss: 0.0806 - val_acc: 0.9764\n",
      "Epoch 55/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0808 - acc: 0.9766 - val_loss: 0.0807 - val_acc: 0.9765\n",
      "Epoch 56/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0808 - acc: 0.9765 - val_loss: 0.0806 - val_acc: 0.9765\n",
      "Epoch 57/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0807 - acc: 0.9766 - val_loss: 0.0807 - val_acc: 0.9765\n",
      "Epoch 58/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0807 - acc: 0.9764 - val_loss: 0.0807 - val_acc: 0.9765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0807 - acc: 0.9764 - val_loss: 0.0805 - val_acc: 0.9765\n",
      "Epoch 60/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0807 - acc: 0.9765 - val_loss: 0.0805 - val_acc: 0.9764\n",
      "Epoch 61/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0806 - acc: 0.9764 - val_loss: 0.0804 - val_acc: 0.9765\n",
      "Epoch 62/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0807 - acc: 0.9764 - val_loss: 0.0806 - val_acc: 0.9765\n",
      "Epoch 63/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0806 - acc: 0.9764 - val_loss: 0.0803 - val_acc: 0.9766\n",
      "Epoch 64/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0805 - acc: 0.9766 - val_loss: 0.0807 - val_acc: 0.9763\n",
      "Epoch 65/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0805 - acc: 0.9765 - val_loss: 0.0803 - val_acc: 0.9766\n",
      "Epoch 66/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0804 - acc: 0.9765 - val_loss: 0.0807 - val_acc: 0.9764\n",
      "Epoch 67/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0805 - acc: 0.9764 - val_loss: 0.0804 - val_acc: 0.9765\n",
      "Epoch 68/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0805 - acc: 0.9764 - val_loss: 0.0803 - val_acc: 0.9764\n",
      "Epoch 69/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0804 - acc: 0.9764 - val_loss: 0.0802 - val_acc: 0.9765\n",
      "Epoch 70/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0804 - acc: 0.9765 - val_loss: 0.0802 - val_acc: 0.9764\n",
      "Epoch 71/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0803 - acc: 0.9765 - val_loss: 0.0805 - val_acc: 0.9763\n",
      "Epoch 72/100\n",
      "130000/130000 [==============================] - 2s 17us/step - loss: 0.0804 - acc: 0.9765 - val_loss: 0.0803 - val_acc: 0.9765\n",
      "Epoch 73/100\n",
      "130000/130000 [==============================] - 3s 24us/step - loss: 0.0803 - acc: 0.9765 - val_loss: 0.0802 - val_acc: 0.9765\n",
      "Epoch 74/100\n",
      "130000/130000 [==============================] - 3s 22us/step - loss: 0.0803 - acc: 0.9765 - val_loss: 0.0801 - val_acc: 0.9764\n",
      "Epoch 75/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0803 - acc: 0.9764 - val_loss: 0.0800 - val_acc: 0.9765\n",
      "Epoch 76/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0802 - acc: 0.9766 - val_loss: 0.0801 - val_acc: 0.9764\n",
      "Epoch 77/100\n",
      "130000/130000 [==============================] - 2s 18us/step - loss: 0.0803 - acc: 0.9764 - val_loss: 0.0800 - val_acc: 0.9765\n",
      "Epoch 78/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0802 - acc: 0.9765 - val_loss: 0.0801 - val_acc: 0.9764\n",
      "Epoch 79/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0802 - acc: 0.9764 - val_loss: 0.0801 - val_acc: 0.9764\n",
      "Epoch 80/100\n",
      "130000/130000 [==============================] - 2s 15us/step - loss: 0.0801 - acc: 0.9765 - val_loss: 0.0799 - val_acc: 0.9764\n",
      "Epoch 81/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0802 - acc: 0.9765 - val_loss: 0.0799 - val_acc: 0.9765\n",
      "Epoch 82/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0801 - acc: 0.9764 - val_loss: 0.0799 - val_acc: 0.9764\n",
      "Epoch 83/100\n",
      "130000/130000 [==============================] - 3s 20us/step - loss: 0.0801 - acc: 0.9765 - val_loss: 0.0799 - val_acc: 0.9766\n",
      "Epoch 84/100\n",
      "130000/130000 [==============================] - 2s 16us/step - loss: 0.0801 - acc: 0.9764 - val_loss: 0.0799 - val_acc: 0.9764\n",
      "Epoch 85/100\n",
      "130000/130000 [==============================] - 4s 33us/step - loss: 0.0801 - acc: 0.9764 - val_loss: 0.0799 - val_acc: 0.9765\n",
      "Epoch 86/100\n",
      "130000/130000 [==============================] - 2s 18us/step - loss: 0.0800 - acc: 0.9765 - val_loss: 0.0798 - val_acc: 0.9765\n",
      "Epoch 87/100\n",
      "130000/130000 [==============================] - 3s 20us/step - loss: 0.0800 - acc: 0.9765 - val_loss: 0.0800 - val_acc: 0.9764\n",
      "Epoch 88/100\n",
      "130000/130000 [==============================] - 2s 15us/step - loss: 0.0800 - acc: 0.9765 - val_loss: 0.0798 - val_acc: 0.9765\n",
      "Epoch 89/100\n",
      "130000/130000 [==============================] - 2s 18us/step - loss: 0.0800 - acc: 0.9765 - val_loss: 0.0802 - val_acc: 0.9767\n",
      "Epoch 90/100\n",
      "130000/130000 [==============================] - 3s 20us/step - loss: 0.0800 - acc: 0.9766 - val_loss: 0.0800 - val_acc: 0.9764\n",
      "Epoch 91/100\n",
      "130000/130000 [==============================] - 2s 18us/step - loss: 0.0800 - acc: 0.9765 - val_loss: 0.0799 - val_acc: 0.9765\n",
      "Epoch 92/100\n",
      "130000/130000 [==============================] - 2s 15us/step - loss: 0.0799 - acc: 0.9765 - val_loss: 0.0798 - val_acc: 0.9763\n",
      "Epoch 93/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0799 - acc: 0.9764 - val_loss: 0.0798 - val_acc: 0.9767\n",
      "Epoch 94/100\n",
      "130000/130000 [==============================] - 1s 12us/step - loss: 0.0798 - acc: 0.9766 - val_loss: 0.0797 - val_acc: 0.9764\n",
      "Epoch 95/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0799 - acc: 0.9765 - val_loss: 0.0797 - val_acc: 0.9766\n",
      "Epoch 96/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0798 - acc: 0.9764 - val_loss: 0.0797 - val_acc: 0.9767\n",
      "Epoch 97/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0798 - acc: 0.9765 - val_loss: 0.0797 - val_acc: 0.9764\n",
      "Epoch 98/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0798 - acc: 0.9764 - val_loss: 0.0796 - val_acc: 0.9765\n",
      "Epoch 99/100\n",
      "130000/130000 [==============================] - 2s 15us/step - loss: 0.0798 - acc: 0.9764 - val_loss: 0.0797 - val_acc: 0.9764\n",
      "Epoch 100/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0799 - acc: 0.9765 - val_loss: 0.0796 - val_acc: 0.9765\n",
      "32501/32501 [==============================] - 3s 87us/step\n",
      "130000/130000 [==============================] - 11s 87us/step\n",
      "Train on 130000 samples, validate on 130000 samples\n",
      "Epoch 1/100\n",
      "130000/130000 [==============================] - 2s 15us/step - loss: 0.0798 - acc: 0.9763 - val_loss: 0.0796 - val_acc: 0.9763\n",
      "Epoch 2/100\n",
      "130000/130000 [==============================] - 2s 16us/step - loss: 0.0798 - acc: 0.9764 - val_loss: 0.0798 - val_acc: 0.9764\n",
      "Epoch 3/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0798 - acc: 0.9764 - val_loss: 0.0796 - val_acc: 0.9764\n",
      "Epoch 4/100\n",
      "130000/130000 [==============================] - 3s 20us/step - loss: 0.0797 - acc: 0.9763 - val_loss: 0.0796 - val_acc: 0.9765\n",
      "Epoch 5/100\n",
      "130000/130000 [==============================] - 2s 16us/step - loss: 0.0797 - acc: 0.9765 - val_loss: 0.0798 - val_acc: 0.9765\n",
      "Epoch 6/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0797 - acc: 0.9763 - val_loss: 0.0795 - val_acc: 0.9765\n",
      "Epoch 7/100\n",
      "130000/130000 [==============================] - 2s 16us/step - loss: 0.0797 - acc: 0.9763 - val_loss: 0.0795 - val_acc: 0.9763\n",
      "Epoch 8/100\n",
      "130000/130000 [==============================] - 3s 20us/step - loss: 0.0796 - acc: 0.9764 - val_loss: 0.0794 - val_acc: 0.9763\n",
      "Epoch 9/100\n",
      "130000/130000 [==============================] - 3s 21us/step - loss: 0.0796 - acc: 0.9765 - val_loss: 0.0794 - val_acc: 0.9765\n",
      "Epoch 10/100\n",
      "130000/130000 [==============================] - 4s 33us/step - loss: 0.0797 - acc: 0.9764 - val_loss: 0.0793 - val_acc: 0.9764\n",
      "Epoch 11/100\n",
      "130000/130000 [==============================] - 2s 19us/step - loss: 0.0796 - acc: 0.9765 - val_loss: 0.0795 - val_acc: 0.9765\n",
      "Epoch 12/100\n",
      "130000/130000 [==============================] - 3s 20us/step - loss: 0.0796 - acc: 0.9765 - val_loss: 0.0796 - val_acc: 0.9764\n",
      "Epoch 13/100\n",
      "130000/130000 [==============================] - 3s 19us/step - loss: 0.0796 - acc: 0.9765 - val_loss: 0.0793 - val_acc: 0.9764\n",
      "Epoch 14/100\n",
      "130000/130000 [==============================] - 2s 19us/step - loss: 0.0795 - acc: 0.9764 - val_loss: 0.0794 - val_acc: 0.9764\n",
      "Epoch 15/100\n",
      "130000/130000 [==============================] - 3s 22us/step - loss: 0.0795 - acc: 0.9765 - val_loss: 0.0794 - val_acc: 0.9764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "130000/130000 [==============================] - 2s 19us/step - loss: 0.0794 - acc: 0.9763 - val_loss: 0.0794 - val_acc: 0.9766\n",
      "Epoch 17/100\n",
      "130000/130000 [==============================] - 2s 16us/step - loss: 0.0794 - acc: 0.9764 - val_loss: 0.0792 - val_acc: 0.9764\n",
      "Epoch 18/100\n",
      "130000/130000 [==============================] - 2s 19us/step - loss: 0.0794 - acc: 0.9764 - val_loss: 0.0793 - val_acc: 0.9764\n",
      "Epoch 19/100\n",
      "130000/130000 [==============================] - 2s 16us/step - loss: 0.0794 - acc: 0.9763 - val_loss: 0.0792 - val_acc: 0.9765\n",
      "Epoch 20/100\n",
      "130000/130000 [==============================] - 2s 17us/step - loss: 0.0793 - acc: 0.9764 - val_loss: 0.0793 - val_acc: 0.9765\n",
      "Epoch 21/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0794 - acc: 0.9765 - val_loss: 0.0795 - val_acc: 0.9766\n",
      "Epoch 22/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0793 - acc: 0.9764 - val_loss: 0.0793 - val_acc: 0.9765\n",
      "Epoch 23/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0793 - acc: 0.9763 - val_loss: 0.0793 - val_acc: 0.9765\n",
      "Epoch 24/100\n",
      "130000/130000 [==============================] - 2s 15us/step - loss: 0.0792 - acc: 0.9764 - val_loss: 0.0791 - val_acc: 0.9765\n",
      "Epoch 25/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0794 - acc: 0.9765 - val_loss: 0.0790 - val_acc: 0.9764\n",
      "Epoch 26/100\n",
      "130000/130000 [==============================] - 2s 15us/step - loss: 0.0792 - acc: 0.9764 - val_loss: 0.0794 - val_acc: 0.9764\n",
      "Epoch 27/100\n",
      "130000/130000 [==============================] - 2s 15us/step - loss: 0.0792 - acc: 0.9764 - val_loss: 0.0796 - val_acc: 0.9762\n",
      "Epoch 28/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0792 - acc: 0.9764 - val_loss: 0.0790 - val_acc: 0.9764\n",
      "Epoch 29/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0792 - acc: 0.9765 - val_loss: 0.0791 - val_acc: 0.9765\n",
      "Epoch 30/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0793 - acc: 0.9765 - val_loss: 0.0790 - val_acc: 0.9765\n",
      "Epoch 31/100\n",
      "130000/130000 [==============================] - 2s 17us/step - loss: 0.0792 - acc: 0.9764 - val_loss: 0.0795 - val_acc: 0.9764\n",
      "Epoch 32/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0792 - acc: 0.9764 - val_loss: 0.0791 - val_acc: 0.9765\n",
      "Epoch 33/100\n",
      "130000/130000 [==============================] - 2s 16us/step - loss: 0.0792 - acc: 0.9764 - val_loss: 0.0792 - val_acc: 0.9763\n",
      "Epoch 34/100\n",
      "130000/130000 [==============================] - 2s 17us/step - loss: 0.0792 - acc: 0.9764 - val_loss: 0.0790 - val_acc: 0.9765\n",
      "Epoch 35/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0792 - acc: 0.9764 - val_loss: 0.0790 - val_acc: 0.9766\n",
      "Epoch 36/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0792 - acc: 0.9765 - val_loss: 0.0793 - val_acc: 0.9765\n",
      "Epoch 37/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0791 - acc: 0.9765 - val_loss: 0.0789 - val_acc: 0.9766\n",
      "Epoch 38/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0791 - acc: 0.9765 - val_loss: 0.0788 - val_acc: 0.9765\n",
      "Epoch 39/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0791 - acc: 0.9764 - val_loss: 0.0789 - val_acc: 0.9765\n",
      "Epoch 40/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0791 - acc: 0.9765 - val_loss: 0.0789 - val_acc: 0.9765\n",
      "Epoch 41/100\n",
      "130000/130000 [==============================] - 2s 17us/step - loss: 0.0790 - acc: 0.9765 - val_loss: 0.0789 - val_acc: 0.9766\n",
      "Epoch 42/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0790 - acc: 0.9764 - val_loss: 0.0788 - val_acc: 0.9766\n",
      "Epoch 43/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0790 - acc: 0.9764 - val_loss: 0.0790 - val_acc: 0.9766\n",
      "Epoch 44/100\n",
      "130000/130000 [==============================] - 2s 16us/step - loss: 0.0790 - acc: 0.9765 - val_loss: 0.0788 - val_acc: 0.9766\n",
      "Epoch 45/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0790 - acc: 0.9765 - val_loss: 0.0790 - val_acc: 0.9766\n",
      "Epoch 46/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0791 - acc: 0.9765 - val_loss: 0.0788 - val_acc: 0.9765\n",
      "Epoch 47/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0790 - acc: 0.9766 - val_loss: 0.0789 - val_acc: 0.9764\n",
      "Epoch 48/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0789 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9765\n",
      "Epoch 49/100\n",
      "130000/130000 [==============================] - 3s 22us/step - loss: 0.0789 - acc: 0.9766 - val_loss: 0.0787 - val_acc: 0.9765\n",
      "Epoch 50/100\n",
      "130000/130000 [==============================] - 2s 18us/step - loss: 0.0789 - acc: 0.9766 - val_loss: 0.0788 - val_acc: 0.9767\n",
      "Epoch 51/100\n",
      "130000/130000 [==============================] - 3s 21us/step - loss: 0.0790 - acc: 0.9765 - val_loss: 0.0788 - val_acc: 0.9765\n",
      "Epoch 52/100\n",
      "130000/130000 [==============================] - 2s 17us/step - loss: 0.0789 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9767\n",
      "Epoch 53/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0789 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9764\n",
      "Epoch 54/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0789 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9765\n",
      "Epoch 55/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0790 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9765\n",
      "Epoch 56/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0789 - acc: 0.9764 - val_loss: 0.0787 - val_acc: 0.9765\n",
      "Epoch 57/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0789 - acc: 0.9765 - val_loss: 0.0786 - val_acc: 0.9765\n",
      "Epoch 58/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0792 - val_acc: 0.9763\n",
      "Epoch 59/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0789 - acc: 0.9765 - val_loss: 0.0786 - val_acc: 0.9766\n",
      "Epoch 60/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9765\n",
      "Epoch 61/100\n",
      "130000/130000 [==============================] - 2s 16us/step - loss: 0.0788 - acc: 0.9766 - val_loss: 0.0787 - val_acc: 0.9766\n",
      "Epoch 62/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0788 - acc: 0.9766 - val_loss: 0.0787 - val_acc: 0.9767\n",
      "Epoch 63/100\n",
      "130000/130000 [==============================] - 2s 16us/step - loss: 0.0788 - acc: 0.9767 - val_loss: 0.0788 - val_acc: 0.9764\n",
      "Epoch 64/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9766\n",
      "Epoch 65/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0786 - val_acc: 0.9766\n",
      "Epoch 66/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0786 - val_acc: 0.9767\n",
      "Epoch 67/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0788 - acc: 0.9764 - val_loss: 0.0792 - val_acc: 0.9764\n",
      "Epoch 68/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0785 - val_acc: 0.9765\n",
      "Epoch 69/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0787 - acc: 0.9765 - val_loss: 0.0790 - val_acc: 0.9766\n",
      "Epoch 70/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0787 - acc: 0.9766 - val_loss: 0.0786 - val_acc: 0.9765\n",
      "Epoch 71/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0787 - acc: 0.9766 - val_loss: 0.0786 - val_acc: 0.9766\n",
      "Epoch 72/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0787 - acc: 0.9766 - val_loss: 0.0786 - val_acc: 0.9764\n",
      "Epoch 73/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0787 - acc: 0.9765 - val_loss: 0.0789 - val_acc: 0.9765\n",
      "Epoch 74/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0787 - acc: 0.9766 - val_loss: 0.0785 - val_acc: 0.9766\n",
      "Epoch 75/100\n",
      "130000/130000 [==============================] - 2s 15us/step - loss: 0.0787 - acc: 0.9766 - val_loss: 0.0787 - val_acc: 0.9764\n",
      "Epoch 76/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0786 - acc: 0.9764 - val_loss: 0.0785 - val_acc: 0.9766\n",
      "Epoch 77/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0786 - acc: 0.9766 - val_loss: 0.0785 - val_acc: 0.9765\n",
      "Epoch 78/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0787 - acc: 0.9765 - val_loss: 0.0785 - val_acc: 0.9764\n",
      "Epoch 79/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0786 - acc: 0.9766 - val_loss: 0.0788 - val_acc: 0.9764\n",
      "Epoch 80/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0786 - acc: 0.9764 - val_loss: 0.0784 - val_acc: 0.9765\n",
      "Epoch 81/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0785 - acc: 0.9765 - val_loss: 0.0784 - val_acc: 0.9765\n",
      "Epoch 82/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0786 - acc: 0.9767 - val_loss: 0.0783 - val_acc: 0.9766\n",
      "Epoch 83/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0786 - acc: 0.9764 - val_loss: 0.0784 - val_acc: 0.9766\n",
      "Epoch 84/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0786 - acc: 0.9766 - val_loss: 0.0784 - val_acc: 0.9766\n",
      "Epoch 85/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0786 - acc: 0.9765 - val_loss: 0.0789 - val_acc: 0.9765\n",
      "Epoch 86/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0786 - acc: 0.9765 - val_loss: 0.0788 - val_acc: 0.9765\n",
      "Epoch 87/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0786 - acc: 0.9766 - val_loss: 0.0783 - val_acc: 0.9766\n",
      "Epoch 88/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0785 - acc: 0.9766 - val_loss: 0.0784 - val_acc: 0.9765\n",
      "Epoch 89/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0786 - acc: 0.9765 - val_loss: 0.0785 - val_acc: 0.9767\n",
      "Epoch 90/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0785 - acc: 0.9766 - val_loss: 0.0785 - val_acc: 0.9767\n",
      "Epoch 91/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0785 - acc: 0.9766 - val_loss: 0.0786 - val_acc: 0.9765\n",
      "Epoch 92/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0785 - acc: 0.9765 - val_loss: 0.0783 - val_acc: 0.9765\n",
      "Epoch 93/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0785 - acc: 0.9765 - val_loss: 0.0785 - val_acc: 0.9764\n",
      "Epoch 94/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0785 - acc: 0.9765 - val_loss: 0.0784 - val_acc: 0.9766\n",
      "Epoch 95/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0785 - acc: 0.9767 - val_loss: 0.0783 - val_acc: 0.9765\n",
      "Epoch 96/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0785 - acc: 0.9766 - val_loss: 0.0782 - val_acc: 0.9765\n",
      "Epoch 97/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0784 - acc: 0.9765 - val_loss: 0.0782 - val_acc: 0.9767\n",
      "Epoch 98/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0786 - acc: 0.9764 - val_loss: 0.0784 - val_acc: 0.9764\n",
      "Epoch 99/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0785 - acc: 0.9766 - val_loss: 0.0783 - val_acc: 0.9766\n",
      "Epoch 100/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0785 - acc: 0.9765 - val_loss: 0.0782 - val_acc: 0.9767\n",
      "32501/32501 [==============================] - 3s 85us/step\n",
      "130000/130000 [==============================] - 10s 78us/step\n",
      "Train on 130000 samples, validate on 130000 samples\n",
      "Epoch 1/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0790 - acc: 0.9764 - val_loss: 0.0787 - val_acc: 0.9766\n",
      "Epoch 2/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0790 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9765\n",
      "Epoch 3/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0789 - acc: 0.9763 - val_loss: 0.0788 - val_acc: 0.9766\n",
      "Epoch 4/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0790 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9764\n",
      "Epoch 5/100\n",
      "130000/130000 [==============================] - 2s 15us/step - loss: 0.0789 - acc: 0.9764 - val_loss: 0.0787 - val_acc: 0.9764\n",
      "Epoch 6/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0789 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9765\n",
      "Epoch 7/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9765\n",
      "Epoch 8/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0788 - acc: 0.9764 - val_loss: 0.0792 - val_acc: 0.9762\n",
      "Epoch 9/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9765\n",
      "Epoch 10/100\n",
      "130000/130000 [==============================] - 2s 15us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9764\n",
      "Epoch 11/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0789 - acc: 0.9765 - val_loss: 0.0790 - val_acc: 0.9765\n",
      "Epoch 12/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0788 - acc: 0.9764 - val_loss: 0.0786 - val_acc: 0.9766\n",
      "Epoch 13/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9765\n",
      "Epoch 14/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0786 - val_acc: 0.9764\n",
      "Epoch 15/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0786 - val_acc: 0.9766\n",
      "Epoch 16/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0786 - val_acc: 0.9765\n",
      "Epoch 17/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0785 - val_acc: 0.9764\n",
      "Epoch 18/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9764\n",
      "Epoch 19/100\n",
      "130000/130000 [==============================] - 2s 15us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0785 - val_acc: 0.9765\n",
      "Epoch 20/100\n",
      "130000/130000 [==============================] - 2s 15us/step - loss: 0.0788 - acc: 0.9764 - val_loss: 0.0789 - val_acc: 0.9764\n",
      "Epoch 21/100\n",
      "130000/130000 [==============================] - 2s 17us/step - loss: 0.0789 - acc: 0.9765 - val_loss: 0.0786 - val_acc: 0.9766\n",
      "Epoch 22/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0787 - acc: 0.9765 - val_loss: 0.0786 - val_acc: 0.9764\n",
      "Epoch 23/100\n",
      "130000/130000 [==============================] - 2s 15us/step - loss: 0.0788 - acc: 0.9764 - val_loss: 0.0789 - val_acc: 0.9767\n",
      "Epoch 24/100\n",
      "130000/130000 [==============================] - 2s 15us/step - loss: 0.0788 - acc: 0.9767 - val_loss: 0.0786 - val_acc: 0.9765\n",
      "Epoch 25/100\n",
      "130000/130000 [==============================] - 2s 17us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0786 - val_acc: 0.9764\n",
      "Epoch 26/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0787 - acc: 0.9764 - val_loss: 0.0786 - val_acc: 0.9767\n",
      "Epoch 27/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0787 - acc: 0.9765 - val_loss: 0.0786 - val_acc: 0.9764\n",
      "Epoch 28/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0788 - acc: 0.9764 - val_loss: 0.0784 - val_acc: 0.9765\n",
      "Epoch 29/100\n",
      "130000/130000 [==============================] - 2s 15us/step - loss: 0.0787 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9765\n",
      "Epoch 30/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0786 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9765\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0786 - acc: 0.9765 - val_loss: 0.0785 - val_acc: 0.9768\n",
      "Epoch 32/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0787 - acc: 0.9766 - val_loss: 0.0786 - val_acc: 0.9764\n",
      "Epoch 33/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0787 - acc: 0.9766 - val_loss: 0.0786 - val_acc: 0.9767\n",
      "Epoch 34/100\n",
      "130000/130000 [==============================] - 2s 15us/step - loss: 0.0786 - acc: 0.9766 - val_loss: 0.0785 - val_acc: 0.9767\n",
      "Epoch 35/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0786 - val_acc: 0.9764\n",
      "Epoch 36/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0786 - acc: 0.9765 - val_loss: 0.0786 - val_acc: 0.9765\n",
      "Epoch 37/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0787 - acc: 0.9766 - val_loss: 0.0784 - val_acc: 0.9765\n",
      "Epoch 38/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0785 - acc: 0.9765 - val_loss: 0.0785 - val_acc: 0.9765\n",
      "Epoch 39/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0786 - acc: 0.9766 - val_loss: 0.0785 - val_acc: 0.9766\n",
      "Epoch 40/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0786 - acc: 0.9766 - val_loss: 0.0784 - val_acc: 0.9767\n",
      "Epoch 41/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0786 - acc: 0.9765 - val_loss: 0.0785 - val_acc: 0.9765\n",
      "Epoch 42/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0787 - acc: 0.9766 - val_loss: 0.0784 - val_acc: 0.9765\n",
      "Epoch 43/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0786 - acc: 0.9764 - val_loss: 0.0784 - val_acc: 0.9765\n",
      "Epoch 44/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0786 - acc: 0.9764 - val_loss: 0.0784 - val_acc: 0.9767\n",
      "Epoch 45/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0785 - acc: 0.9765 - val_loss: 0.0788 - val_acc: 0.9764\n",
      "Epoch 46/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0787 - acc: 0.9765 - val_loss: 0.0784 - val_acc: 0.9766\n",
      "Epoch 47/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0786 - acc: 0.9765 - val_loss: 0.0783 - val_acc: 0.9765\n",
      "Epoch 48/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0785 - acc: 0.9766 - val_loss: 0.0783 - val_acc: 0.9766\n",
      "Epoch 49/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0785 - acc: 0.9766 - val_loss: 0.0785 - val_acc: 0.9766\n",
      "Epoch 50/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0787 - acc: 0.9765 - val_loss: 0.0786 - val_acc: 0.9764\n",
      "Epoch 51/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0785 - acc: 0.9766 - val_loss: 0.0784 - val_acc: 0.9765\n",
      "Epoch 52/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0786 - acc: 0.9765 - val_loss: 0.0784 - val_acc: 0.9766\n",
      "Epoch 53/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0785 - acc: 0.9765 - val_loss: 0.0783 - val_acc: 0.9766\n",
      "Epoch 54/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0784 - acc: 0.9766 - val_loss: 0.0783 - val_acc: 0.9765\n",
      "Epoch 55/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0786 - acc: 0.9765 - val_loss: 0.0788 - val_acc: 0.9765\n",
      "Epoch 56/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0785 - acc: 0.9766 - val_loss: 0.0783 - val_acc: 0.9766\n",
      "Epoch 57/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0785 - acc: 0.9766 - val_loss: 0.0783 - val_acc: 0.9765\n",
      "Epoch 58/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0785 - acc: 0.9765 - val_loss: 0.0782 - val_acc: 0.9765\n",
      "Epoch 59/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0785 - acc: 0.9764 - val_loss: 0.0785 - val_acc: 0.9766\n",
      "Epoch 60/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0785 - acc: 0.9766 - val_loss: 0.0786 - val_acc: 0.9765\n",
      "Epoch 61/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0785 - acc: 0.9766 - val_loss: 0.0785 - val_acc: 0.9766\n",
      "Epoch 62/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0785 - acc: 0.9766 - val_loss: 0.0785 - val_acc: 0.9765\n",
      "Epoch 63/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0785 - acc: 0.9764 - val_loss: 0.0786 - val_acc: 0.9764\n",
      "Epoch 64/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0785 - acc: 0.9765 - val_loss: 0.0785 - val_acc: 0.9763\n",
      "Epoch 65/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0785 - acc: 0.9764 - val_loss: 0.0783 - val_acc: 0.9766\n",
      "Epoch 66/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0784 - acc: 0.9766 - val_loss: 0.0783 - val_acc: 0.9765\n",
      "Epoch 67/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0785 - acc: 0.9765 - val_loss: 0.0783 - val_acc: 0.9765\n",
      "Epoch 68/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0785 - acc: 0.9764 - val_loss: 0.0784 - val_acc: 0.9767\n",
      "Epoch 69/100\n",
      "130000/130000 [==============================] - 2s 13us/step - loss: 0.0785 - acc: 0.9766 - val_loss: 0.0784 - val_acc: 0.9765\n",
      "Epoch 70/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0785 - acc: 0.9765 - val_loss: 0.0782 - val_acc: 0.9767\n",
      "Epoch 71/100\n",
      "130000/130000 [==============================] - 2s 14us/step - loss: 0.0785 - acc: 0.9765 - val_loss: 0.0782 - val_acc: 0.9765\n",
      "Epoch 72/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0785 - acc: 0.9765 - val_loss: 0.0782 - val_acc: 0.9766\n",
      "Epoch 73/100\n",
      "130000/130000 [==============================] - 2s 16us/step - loss: 0.0784 - acc: 0.9764 - val_loss: 0.0782 - val_acc: 0.9766\n",
      "Epoch 74/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0784 - acc: 0.9765 - val_loss: 0.0783 - val_acc: 0.9766\n",
      "Epoch 75/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0784 - acc: 0.9765 - val_loss: 0.0786 - val_acc: 0.9767\n",
      "Epoch 76/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0785 - acc: 0.9764 - val_loss: 0.0782 - val_acc: 0.9766\n",
      "Epoch 77/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0784 - acc: 0.9765 - val_loss: 0.0783 - val_acc: 0.9766\n",
      "Epoch 78/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0784 - acc: 0.9765 - val_loss: 0.0783 - val_acc: 0.9765\n",
      "Epoch 79/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0783 - acc: 0.9765 - val_loss: 0.0783 - val_acc: 0.9765\n",
      "Epoch 80/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0783 - acc: 0.9767 - val_loss: 0.0782 - val_acc: 0.9766\n",
      "Epoch 81/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0783 - acc: 0.9765 - val_loss: 0.0785 - val_acc: 0.9767\n",
      "Epoch 82/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0784 - acc: 0.9765 - val_loss: 0.0782 - val_acc: 0.9766\n",
      "Epoch 83/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0784 - acc: 0.9765 - val_loss: 0.0781 - val_acc: 0.9765\n",
      "Epoch 84/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0785 - acc: 0.9764 - val_loss: 0.0782 - val_acc: 0.9766\n",
      "Epoch 85/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0784 - acc: 0.9764 - val_loss: 0.0783 - val_acc: 0.9765\n",
      "Epoch 86/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0784 - acc: 0.9766 - val_loss: 0.0785 - val_acc: 0.9767\n",
      "Epoch 87/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0784 - acc: 0.9766 - val_loss: 0.0788 - val_acc: 0.9764\n",
      "Epoch 88/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0784 - acc: 0.9764 - val_loss: 0.0782 - val_acc: 0.9765\n",
      "Epoch 89/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0783 - acc: 0.9765 - val_loss: 0.0781 - val_acc: 0.9764\n",
      "Epoch 90/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0784 - acc: 0.9766 - val_loss: 0.0782 - val_acc: 0.9765\n",
      "Epoch 91/100\n",
      "130000/130000 [==============================] - 1s 10us/step - loss: 0.0784 - acc: 0.9764 - val_loss: 0.0781 - val_acc: 0.9766\n",
      "Epoch 92/100\n",
      "130000/130000 [==============================] - 1s 11us/step - loss: 0.0783 - acc: 0.9765 - val_loss: 0.0781 - val_acc: 0.9765\n",
      "Epoch 93/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0784 - acc: 0.9765 - val_loss: 0.0781 - val_acc: 0.9764\n",
      "Epoch 94/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0784 - acc: 0.9765 - val_loss: 0.0781 - val_acc: 0.9765\n",
      "Epoch 95/100\n",
      "130000/130000 [==============================] - 2s 12us/step - loss: 0.0782 - acc: 0.9766 - val_loss: 0.0781 - val_acc: 0.9765\n",
      "Epoch 96/100\n",
      "130000/130000 [==============================] - 3s 23us/step - loss: 0.0784 - acc: 0.9765 - val_loss: 0.0781 - val_acc: 0.9766\n",
      "Epoch 97/100\n",
      "130000/130000 [==============================] - 3s 21us/step - loss: 0.0783 - acc: 0.9765 - val_loss: 0.0781 - val_acc: 0.9766\n",
      "Epoch 98/100\n",
      "130000/130000 [==============================] - 3s 24us/step - loss: 0.0784 - acc: 0.9766 - val_loss: 0.0783 - val_acc: 0.9765\n",
      "Epoch 99/100\n",
      "130000/130000 [==============================] - 3s 25us/step - loss: 0.0783 - acc: 0.9765 - val_loss: 0.0781 - val_acc: 0.9766\n",
      "Epoch 100/100\n",
      "130000/130000 [==============================] - 3s 19us/step - loss: 0.0783 - acc: 0.9766 - val_loss: 0.0784 - val_acc: 0.9765\n",
      "32501/32501 [==============================] - 3s 89us/step\n",
      "130000/130000 [==============================] - 11s 84us/step\n",
      "Train on 81250 samples, validate on 81250 samples\n",
      "Epoch 1/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0804 - acc: 0.9758 - val_loss: 0.0800 - val_acc: 0.9759\n",
      "Epoch 2/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0803 - acc: 0.9757 - val_loss: 0.0800 - val_acc: 0.9757\n",
      "Epoch 3/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0803 - acc: 0.9756 - val_loss: 0.0801 - val_acc: 0.9761\n",
      "Epoch 4/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0801 - acc: 0.9760 - val_loss: 0.0800 - val_acc: 0.9760\n",
      "Epoch 5/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0801 - acc: 0.9758 - val_loss: 0.0810 - val_acc: 0.9759\n",
      "Epoch 6/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0802 - acc: 0.9758 - val_loss: 0.0799 - val_acc: 0.9758\n",
      "Epoch 7/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0801 - acc: 0.9757 - val_loss: 0.0799 - val_acc: 0.9760\n",
      "Epoch 8/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0801 - acc: 0.9759 - val_loss: 0.0798 - val_acc: 0.9759\n",
      "Epoch 9/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0802 - acc: 0.9757 - val_loss: 0.0801 - val_acc: 0.9755\n",
      "Epoch 10/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0801 - acc: 0.9758 - val_loss: 0.0799 - val_acc: 0.9756\n",
      "Epoch 11/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9757 - val_loss: 0.0803 - val_acc: 0.9762\n",
      "Epoch 12/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0801 - acc: 0.9759 - val_loss: 0.0802 - val_acc: 0.9762\n",
      "Epoch 13/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0801 - acc: 0.9759 - val_loss: 0.0799 - val_acc: 0.9758\n",
      "Epoch 14/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0801 - acc: 0.9758 - val_loss: 0.0800 - val_acc: 0.9758\n",
      "Epoch 15/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0801 - acc: 0.9757 - val_loss: 0.0800 - val_acc: 0.9762\n",
      "Epoch 16/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0801 - acc: 0.9759 - val_loss: 0.0801 - val_acc: 0.9760\n",
      "Epoch 17/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0801 - acc: 0.9758 - val_loss: 0.0799 - val_acc: 0.9761\n",
      "Epoch 18/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0800 - acc: 0.9758 - val_loss: 0.0799 - val_acc: 0.9760\n",
      "Epoch 19/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0801 - acc: 0.9757 - val_loss: 0.0798 - val_acc: 0.9759\n",
      "Epoch 20/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9757 - val_loss: 0.0799 - val_acc: 0.9759\n",
      "Epoch 21/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0801 - acc: 0.9759 - val_loss: 0.0799 - val_acc: 0.9759\n",
      "Epoch 22/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9757 - val_loss: 0.0798 - val_acc: 0.9760\n",
      "Epoch 23/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9757 - val_loss: 0.0798 - val_acc: 0.9759\n",
      "Epoch 24/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0799 - acc: 0.9761 - val_loss: 0.0800 - val_acc: 0.9757\n",
      "Epoch 25/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9757 - val_loss: 0.0797 - val_acc: 0.9760\n",
      "Epoch 26/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9760 - val_loss: 0.0798 - val_acc: 0.9759\n",
      "Epoch 27/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0799 - acc: 0.9759 - val_loss: 0.0800 - val_acc: 0.9757\n",
      "Epoch 28/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0800 - acc: 0.9759 - val_loss: 0.0798 - val_acc: 0.9758\n",
      "Epoch 29/100\n",
      "81250/81250 [==============================] - 1s 14us/step - loss: 0.0799 - acc: 0.9757 - val_loss: 0.0800 - val_acc: 0.9755\n",
      "Epoch 30/100\n",
      "81250/81250 [==============================] - 1s 16us/step - loss: 0.0800 - acc: 0.9757 - val_loss: 0.0798 - val_acc: 0.9757\n",
      "Epoch 31/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0800 - acc: 0.9759 - val_loss: 0.0797 - val_acc: 0.9759\n",
      "Epoch 32/100\n",
      "81250/81250 [==============================] - 1s 14us/step - loss: 0.0800 - acc: 0.9757 - val_loss: 0.0797 - val_acc: 0.9761\n",
      "Epoch 33/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0800 - acc: 0.9760 - val_loss: 0.0798 - val_acc: 0.9756\n",
      "Epoch 34/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0799 - acc: 0.9758 - val_loss: 0.0799 - val_acc: 0.9758\n",
      "Epoch 35/100\n",
      "81250/81250 [==============================] - 1s 16us/step - loss: 0.0799 - acc: 0.9758 - val_loss: 0.0799 - val_acc: 0.9757\n",
      "Epoch 36/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0799 - acc: 0.9759 - val_loss: 0.0799 - val_acc: 0.9762\n",
      "Epoch 37/100\n",
      "81250/81250 [==============================] - 1s 14us/step - loss: 0.0799 - acc: 0.9760 - val_loss: 0.0801 - val_acc: 0.9756\n",
      "Epoch 38/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0800 - acc: 0.9758 - val_loss: 0.0797 - val_acc: 0.9759\n",
      "Epoch 39/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0799 - acc: 0.9758 - val_loss: 0.0797 - val_acc: 0.9759\n",
      "Epoch 40/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0799 - acc: 0.9759 - val_loss: 0.0797 - val_acc: 0.9760\n",
      "Epoch 41/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0798 - acc: 0.9760 - val_loss: 0.0803 - val_acc: 0.9757\n",
      "Epoch 42/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0800 - acc: 0.9760 - val_loss: 0.0797 - val_acc: 0.9760\n",
      "Epoch 43/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9760 - val_loss: 0.0796 - val_acc: 0.9761\n",
      "Epoch 44/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0800 - acc: 0.9758 - val_loss: 0.0804 - val_acc: 0.9757\n",
      "Epoch 45/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0799 - acc: 0.9759 - val_loss: 0.0796 - val_acc: 0.9759\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81250/81250 [==============================] - 1s 18us/step - loss: 0.0800 - acc: 0.9760 - val_loss: 0.0797 - val_acc: 0.9759\n",
      "Epoch 47/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0799 - acc: 0.9759 - val_loss: 0.0799 - val_acc: 0.9759\n",
      "Epoch 48/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0800 - acc: 0.9759 - val_loss: 0.0803 - val_acc: 0.9760\n",
      "Epoch 49/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0799 - acc: 0.9760 - val_loss: 0.0799 - val_acc: 0.9759\n",
      "Epoch 50/100\n",
      "81250/81250 [==============================] - 1s 14us/step - loss: 0.0798 - acc: 0.9759 - val_loss: 0.0797 - val_acc: 0.9761\n",
      "Epoch 51/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0798 - acc: 0.9758 - val_loss: 0.0799 - val_acc: 0.9759\n",
      "Epoch 52/100\n",
      "81250/81250 [==============================] - 1s 14us/step - loss: 0.0800 - acc: 0.9759 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 53/100\n",
      "81250/81250 [==============================] - 1s 14us/step - loss: 0.0799 - acc: 0.9758 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 54/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0799 - acc: 0.9759 - val_loss: 0.0796 - val_acc: 0.9761\n",
      "Epoch 55/100\n",
      "81250/81250 [==============================] - 1s 17us/step - loss: 0.0799 - acc: 0.9758 - val_loss: 0.0797 - val_acc: 0.9761\n",
      "Epoch 56/100\n",
      "81250/81250 [==============================] - 1s 14us/step - loss: 0.0799 - acc: 0.9758 - val_loss: 0.0797 - val_acc: 0.9759\n",
      "Epoch 57/100\n",
      "81250/81250 [==============================] - 1s 16us/step - loss: 0.0799 - acc: 0.9758 - val_loss: 0.0797 - val_acc: 0.9757\n",
      "Epoch 58/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0799 - acc: 0.9758 - val_loss: 0.0796 - val_acc: 0.9758\n",
      "Epoch 59/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0799 - acc: 0.9758 - val_loss: 0.0799 - val_acc: 0.9757\n",
      "Epoch 60/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0799 - acc: 0.9758 - val_loss: 0.0796 - val_acc: 0.9759\n",
      "Epoch 61/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0799 - acc: 0.9759 - val_loss: 0.0797 - val_acc: 0.9757\n",
      "Epoch 62/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0798 - acc: 0.9760 - val_loss: 0.0796 - val_acc: 0.9759\n",
      "Epoch 63/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0798 - acc: 0.9759 - val_loss: 0.0796 - val_acc: 0.9760\n",
      "Epoch 64/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0798 - acc: 0.9759 - val_loss: 0.0798 - val_acc: 0.9759\n",
      "Epoch 65/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0799 - acc: 0.9759 - val_loss: 0.0796 - val_acc: 0.9759\n",
      "Epoch 66/100\n",
      "81250/81250 [==============================] - 1s 14us/step - loss: 0.0798 - acc: 0.9759 - val_loss: 0.0797 - val_acc: 0.9758\n",
      "Epoch 67/100\n",
      "81250/81250 [==============================] - 1s 15us/step - loss: 0.0799 - acc: 0.9762 - val_loss: 0.0798 - val_acc: 0.9758\n",
      "Epoch 68/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0798 - acc: 0.9758 - val_loss: 0.0798 - val_acc: 0.9758\n",
      "Epoch 69/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0799 - acc: 0.9758 - val_loss: 0.0800 - val_acc: 0.9760\n",
      "Epoch 70/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0799 - acc: 0.9759 - val_loss: 0.0797 - val_acc: 0.9759\n",
      "Epoch 71/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0799 - acc: 0.9760 - val_loss: 0.0798 - val_acc: 0.9755\n",
      "Epoch 72/100\n",
      "81250/81250 [==============================] - 1s 16us/step - loss: 0.0798 - acc: 0.9761 - val_loss: 0.0796 - val_acc: 0.9759\n",
      "Epoch 73/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0798 - acc: 0.9759 - val_loss: 0.0795 - val_acc: 0.9760\n",
      "Epoch 74/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0799 - acc: 0.9760 - val_loss: 0.0795 - val_acc: 0.9761\n",
      "Epoch 75/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0798 - acc: 0.9760 - val_loss: 0.0797 - val_acc: 0.9759\n",
      "Epoch 76/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0799 - acc: 0.9759 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 77/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0798 - acc: 0.9758 - val_loss: 0.0796 - val_acc: 0.9758\n",
      "Epoch 78/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0799 - acc: 0.9759 - val_loss: 0.0796 - val_acc: 0.9758\n",
      "Epoch 79/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0798 - acc: 0.9760 - val_loss: 0.0797 - val_acc: 0.9758\n",
      "Epoch 80/100\n",
      "81250/81250 [==============================] - 1s 14us/step - loss: 0.0798 - acc: 0.9761 - val_loss: 0.0795 - val_acc: 0.9760\n",
      "Epoch 81/100\n",
      "81250/81250 [==============================] - 1s 17us/step - loss: 0.0798 - acc: 0.9759 - val_loss: 0.0797 - val_acc: 0.9758\n",
      "Epoch 82/100\n",
      "81250/81250 [==============================] - 1s 15us/step - loss: 0.0798 - acc: 0.9759 - val_loss: 0.0795 - val_acc: 0.9760\n",
      "Epoch 83/100\n",
      "81250/81250 [==============================] - 1s 15us/step - loss: 0.0797 - acc: 0.9758 - val_loss: 0.0795 - val_acc: 0.9759\n",
      "Epoch 84/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0797 - acc: 0.9758 - val_loss: 0.0797 - val_acc: 0.9761\n",
      "Epoch 85/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0797 - acc: 0.9759 - val_loss: 0.0798 - val_acc: 0.9760\n",
      "Epoch 86/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0798 - acc: 0.9759 - val_loss: 0.0801 - val_acc: 0.9757\n",
      "Epoch 87/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0797 - acc: 0.9758 - val_loss: 0.0795 - val_acc: 0.9760\n",
      "Epoch 88/100\n",
      "81250/81250 [==============================] - 1s 15us/step - loss: 0.0798 - acc: 0.9759 - val_loss: 0.0796 - val_acc: 0.9759\n",
      "Epoch 89/100\n",
      "81250/81250 [==============================] - 1s 18us/step - loss: 0.0797 - acc: 0.9758 - val_loss: 0.0795 - val_acc: 0.9761\n",
      "Epoch 90/100\n",
      "81250/81250 [==============================] - 1s 18us/step - loss: 0.0798 - acc: 0.9760 - val_loss: 0.0796 - val_acc: 0.9760\n",
      "Epoch 91/100\n",
      "81250/81250 [==============================] - 1s 15us/step - loss: 0.0797 - acc: 0.9759 - val_loss: 0.0796 - val_acc: 0.9762\n",
      "Epoch 92/100\n",
      "81250/81250 [==============================] - 2s 19us/step - loss: 0.0798 - acc: 0.9758 - val_loss: 0.0797 - val_acc: 0.9758\n",
      "Epoch 93/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0796 - acc: 0.9759 - val_loss: 0.0796 - val_acc: 0.9759\n",
      "Epoch 94/100\n",
      "81250/81250 [==============================] - 1s 15us/step - loss: 0.0797 - acc: 0.9759 - val_loss: 0.0795 - val_acc: 0.9760\n",
      "Epoch 95/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0798 - acc: 0.9758 - val_loss: 0.0796 - val_acc: 0.9760\n",
      "Epoch 96/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0798 - acc: 0.9758 - val_loss: 0.0797 - val_acc: 0.9758\n",
      "Epoch 97/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0797 - acc: 0.9760 - val_loss: 0.0796 - val_acc: 0.9759\n",
      "Epoch 98/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0797 - acc: 0.9759 - val_loss: 0.0795 - val_acc: 0.9760\n",
      "Epoch 99/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0797 - acc: 0.9759 - val_loss: 0.0799 - val_acc: 0.9761\n",
      "Epoch 100/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0798 - acc: 0.9759 - val_loss: 0.0797 - val_acc: 0.9760\n",
      "81251/81251 [==============================] - 10s 123us/step\n",
      "81250/81250 [==============================] - 9s 106us/step\n",
      "Train on 81250 samples, validate on 81250 samples\n",
      "Epoch 1/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0801 - acc: 0.9763 - val_loss: 0.0801 - val_acc: 0.9761\n",
      "Epoch 2/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0801 - acc: 0.9764 - val_loss: 0.0801 - val_acc: 0.9762\n",
      "Epoch 3/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0801 - acc: 0.9762 - val_loss: 0.0798 - val_acc: 0.9762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0801 - acc: 0.9763 - val_loss: 0.0799 - val_acc: 0.9763\n",
      "Epoch 5/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0800 - acc: 0.9763 - val_loss: 0.0798 - val_acc: 0.9762\n",
      "Epoch 6/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0800 - acc: 0.9760 - val_loss: 0.0797 - val_acc: 0.9762\n",
      "Epoch 7/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9762 - val_loss: 0.0797 - val_acc: 0.9762\n",
      "Epoch 8/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9762 - val_loss: 0.0798 - val_acc: 0.9762\n",
      "Epoch 9/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0799 - acc: 0.9762 - val_loss: 0.0803 - val_acc: 0.9760\n",
      "Epoch 10/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0799 - acc: 0.9763 - val_loss: 0.0796 - val_acc: 0.9761\n",
      "Epoch 11/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0797 - val_acc: 0.9762\n",
      "Epoch 12/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0799 - acc: 0.9763 - val_loss: 0.0796 - val_acc: 0.9762\n",
      "Epoch 13/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0799 - acc: 0.9763 - val_loss: 0.0801 - val_acc: 0.9761\n",
      "Epoch 14/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0799 - acc: 0.9762 - val_loss: 0.0799 - val_acc: 0.9761\n",
      "Epoch 15/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0798 - acc: 0.9763 - val_loss: 0.0799 - val_acc: 0.9761\n",
      "Epoch 16/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9763 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 17/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0798 - acc: 0.9762 - val_loss: 0.0797 - val_acc: 0.9763\n",
      "Epoch 18/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0800 - acc: 0.9762 - val_loss: 0.0797 - val_acc: 0.9763\n",
      "Epoch 19/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0799 - acc: 0.9762 - val_loss: 0.0796 - val_acc: 0.9762\n",
      "Epoch 20/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9763 - val_loss: 0.0796 - val_acc: 0.9761\n",
      "Epoch 21/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0798 - acc: 0.9762 - val_loss: 0.0796 - val_acc: 0.9762\n",
      "Epoch 22/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0799 - acc: 0.9762 - val_loss: 0.0797 - val_acc: 0.9763\n",
      "Epoch 23/100\n",
      "81250/81250 [==============================] - 1s 14us/step - loss: 0.0799 - acc: 0.9761 - val_loss: 0.0802 - val_acc: 0.9761\n",
      "Epoch 24/100\n",
      "81250/81250 [==============================] - 1s 16us/step - loss: 0.0798 - acc: 0.9763 - val_loss: 0.0799 - val_acc: 0.9760\n",
      "Epoch 25/100\n",
      "81250/81250 [==============================] - 2s 21us/step - loss: 0.0798 - acc: 0.9762 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 26/100\n",
      "81250/81250 [==============================] - 2s 19us/step - loss: 0.0798 - acc: 0.9763 - val_loss: 0.0796 - val_acc: 0.9761\n",
      "Epoch 27/100\n",
      "81250/81250 [==============================] - 2s 21us/step - loss: 0.0797 - acc: 0.9762 - val_loss: 0.0797 - val_acc: 0.9762\n",
      "Epoch 28/100\n",
      "81250/81250 [==============================] - 2s 26us/step - loss: 0.0798 - acc: 0.9763 - val_loss: 0.0799 - val_acc: 0.9761\n",
      "Epoch 29/100\n",
      "81250/81250 [==============================] - 2s 21us/step - loss: 0.0798 - acc: 0.9762 - val_loss: 0.0796 - val_acc: 0.9762\n",
      "Epoch 30/100\n",
      "81250/81250 [==============================] - 1s 17us/step - loss: 0.0798 - acc: 0.9763 - val_loss: 0.0795 - val_acc: 0.9763\n",
      "Epoch 31/100\n",
      "81250/81250 [==============================] - 1s 14us/step - loss: 0.0798 - acc: 0.9762 - val_loss: 0.0796 - val_acc: 0.9764\n",
      "Epoch 32/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0799 - acc: 0.9761 - val_loss: 0.0795 - val_acc: 0.9763\n",
      "Epoch 33/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0798 - acc: 0.9763 - val_loss: 0.0795 - val_acc: 0.9763\n",
      "Epoch 34/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0797 - acc: 0.9761 - val_loss: 0.0796 - val_acc: 0.9763\n",
      "Epoch 35/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0798 - acc: 0.9765 - val_loss: 0.0795 - val_acc: 0.9763\n",
      "Epoch 36/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0796 - acc: 0.9763 - val_loss: 0.0797 - val_acc: 0.9764\n",
      "Epoch 37/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0798 - acc: 0.9761 - val_loss: 0.0795 - val_acc: 0.9762\n",
      "Epoch 38/100\n",
      "81250/81250 [==============================] - 1s 14us/step - loss: 0.0798 - acc: 0.9762 - val_loss: 0.0795 - val_acc: 0.9763\n",
      "Epoch 39/100\n",
      "81250/81250 [==============================] - 1s 15us/step - loss: 0.0798 - acc: 0.9762 - val_loss: 0.0795 - val_acc: 0.9761\n",
      "Epoch 40/100\n",
      "81250/81250 [==============================] - 1s 14us/step - loss: 0.0796 - acc: 0.9762 - val_loss: 0.0795 - val_acc: 0.9762\n",
      "Epoch 41/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0797 - acc: 0.9763 - val_loss: 0.0795 - val_acc: 0.9763\n",
      "Epoch 42/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0798 - acc: 0.9763 - val_loss: 0.0796 - val_acc: 0.9763\n",
      "Epoch 43/100\n",
      "81250/81250 [==============================] - 1s 15us/step - loss: 0.0798 - acc: 0.9762 - val_loss: 0.0794 - val_acc: 0.9763\n",
      "Epoch 44/100\n",
      "81250/81250 [==============================] - 1s 14us/step - loss: 0.0797 - acc: 0.9762 - val_loss: 0.0797 - val_acc: 0.9764\n",
      "Epoch 45/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0797 - acc: 0.9763 - val_loss: 0.0794 - val_acc: 0.9763\n",
      "Epoch 46/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0798 - acc: 0.9762 - val_loss: 0.0794 - val_acc: 0.9763\n",
      "Epoch 47/100\n",
      "81250/81250 [==============================] - 1s 17us/step - loss: 0.0798 - acc: 0.9761 - val_loss: 0.0796 - val_acc: 0.9762\n",
      "Epoch 48/100\n",
      "81250/81250 [==============================] - 2s 29us/step - loss: 0.0796 - acc: 0.9762 - val_loss: 0.0795 - val_acc: 0.9762\n",
      "Epoch 49/100\n",
      "81250/81250 [==============================] - 2s 20us/step - loss: 0.0798 - acc: 0.9763 - val_loss: 0.0794 - val_acc: 0.9763\n",
      "Epoch 50/100\n",
      "81250/81250 [==============================] - 1s 16us/step - loss: 0.0798 - acc: 0.9761 - val_loss: 0.0794 - val_acc: 0.9763\n",
      "Epoch 51/100\n",
      "81250/81250 [==============================] - 1s 18us/step - loss: 0.0796 - acc: 0.9762 - val_loss: 0.0795 - val_acc: 0.9762\n",
      "Epoch 52/100\n",
      "81250/81250 [==============================] - 2s 19us/step - loss: 0.0796 - acc: 0.9764 - val_loss: 0.0799 - val_acc: 0.9765\n",
      "Epoch 53/100\n",
      "81250/81250 [==============================] - 2s 18us/step - loss: 0.0797 - acc: 0.9763 - val_loss: 0.0794 - val_acc: 0.9762\n",
      "Epoch 54/100\n",
      "81250/81250 [==============================] - 2s 19us/step - loss: 0.0797 - acc: 0.9762 - val_loss: 0.0795 - val_acc: 0.9763\n",
      "Epoch 55/100\n",
      "81250/81250 [==============================] - 1s 16us/step - loss: 0.0797 - acc: 0.9762 - val_loss: 0.0795 - val_acc: 0.9762\n",
      "Epoch 56/100\n",
      "81250/81250 [==============================] - 1s 17us/step - loss: 0.0797 - acc: 0.9764 - val_loss: 0.0794 - val_acc: 0.9764\n",
      "Epoch 57/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0796 - acc: 0.9764 - val_loss: 0.0799 - val_acc: 0.9760\n",
      "Epoch 58/100\n",
      "81250/81250 [==============================] - 1s 15us/step - loss: 0.0798 - acc: 0.9761 - val_loss: 0.0794 - val_acc: 0.9763\n",
      "Epoch 59/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0796 - acc: 0.9763 - val_loss: 0.0797 - val_acc: 0.9763\n",
      "Epoch 60/100\n",
      "81250/81250 [==============================] - 1s 14us/step - loss: 0.0797 - acc: 0.9762 - val_loss: 0.0796 - val_acc: 0.9762\n",
      "Epoch 61/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0797 - acc: 0.9763 - val_loss: 0.0796 - val_acc: 0.9762\n",
      "Epoch 62/100\n",
      "81250/81250 [==============================] - 1s 14us/step - loss: 0.0796 - acc: 0.9762 - val_loss: 0.0795 - val_acc: 0.9762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0796 - acc: 0.9761 - val_loss: 0.0794 - val_acc: 0.9763\n",
      "Epoch 64/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0797 - acc: 0.9761 - val_loss: 0.0794 - val_acc: 0.9763\n",
      "Epoch 65/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0797 - acc: 0.9762 - val_loss: 0.0794 - val_acc: 0.9764\n",
      "Epoch 66/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0796 - acc: 0.9761 - val_loss: 0.0796 - val_acc: 0.9762\n",
      "Epoch 67/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0796 - acc: 0.9762 - val_loss: 0.0797 - val_acc: 0.9764\n",
      "Epoch 68/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0796 - acc: 0.9764 - val_loss: 0.0793 - val_acc: 0.9764\n",
      "Epoch 69/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0796 - acc: 0.9764 - val_loss: 0.0793 - val_acc: 0.9763\n",
      "Epoch 70/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0795 - acc: 0.9762 - val_loss: 0.0802 - val_acc: 0.9761\n",
      "Epoch 71/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0796 - acc: 0.9762 - val_loss: 0.0794 - val_acc: 0.9764\n",
      "Epoch 72/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0796 - acc: 0.9762 - val_loss: 0.0796 - val_acc: 0.9760\n",
      "Epoch 73/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0797 - acc: 0.9762 - val_loss: 0.0798 - val_acc: 0.9762\n",
      "Epoch 74/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0796 - acc: 0.9764 - val_loss: 0.0798 - val_acc: 0.9760\n",
      "Epoch 75/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0796 - acc: 0.9762 - val_loss: 0.0793 - val_acc: 0.9764\n",
      "Epoch 76/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0797 - acc: 0.9765 - val_loss: 0.0793 - val_acc: 0.9761\n",
      "Epoch 77/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0796 - acc: 0.9762 - val_loss: 0.0793 - val_acc: 0.9763\n",
      "Epoch 78/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0795 - acc: 0.9763 - val_loss: 0.0794 - val_acc: 0.9764\n",
      "Epoch 79/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0795 - acc: 0.9763 - val_loss: 0.0795 - val_acc: 0.9760\n",
      "Epoch 80/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0795 - acc: 0.9763 - val_loss: 0.0793 - val_acc: 0.9763\n",
      "Epoch 81/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0795 - acc: 0.9762 - val_loss: 0.0793 - val_acc: 0.9763\n",
      "Epoch 82/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0796 - acc: 0.9763 - val_loss: 0.0793 - val_acc: 0.9763\n",
      "Epoch 83/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0796 - acc: 0.9763 - val_loss: 0.0796 - val_acc: 0.9762\n",
      "Epoch 84/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0795 - acc: 0.9760 - val_loss: 0.0796 - val_acc: 0.9763\n",
      "Epoch 85/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0796 - acc: 0.9764 - val_loss: 0.0794 - val_acc: 0.9761\n",
      "Epoch 86/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0796 - acc: 0.9762 - val_loss: 0.0793 - val_acc: 0.9763\n",
      "Epoch 87/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0796 - acc: 0.9764 - val_loss: 0.0793 - val_acc: 0.9762\n",
      "Epoch 88/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0796 - acc: 0.9761 - val_loss: 0.0798 - val_acc: 0.9760\n",
      "Epoch 89/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0796 - acc: 0.9762 - val_loss: 0.0798 - val_acc: 0.9763\n",
      "Epoch 90/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0795 - acc: 0.9764 - val_loss: 0.0793 - val_acc: 0.9762\n",
      "Epoch 91/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0794 - acc: 0.9762 - val_loss: 0.0794 - val_acc: 0.9763\n",
      "Epoch 92/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0795 - acc: 0.9762 - val_loss: 0.0793 - val_acc: 0.9765\n",
      "Epoch 93/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0795 - acc: 0.9763 - val_loss: 0.0792 - val_acc: 0.9763\n",
      "Epoch 94/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0795 - acc: 0.9764 - val_loss: 0.0793 - val_acc: 0.9761\n",
      "Epoch 95/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0796 - acc: 0.9761 - val_loss: 0.0793 - val_acc: 0.9765\n",
      "Epoch 96/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0796 - acc: 0.9765 - val_loss: 0.0793 - val_acc: 0.9764\n",
      "Epoch 97/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0794 - acc: 0.9763 - val_loss: 0.0794 - val_acc: 0.9763\n",
      "Epoch 98/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0796 - acc: 0.9761 - val_loss: 0.0793 - val_acc: 0.9762\n",
      "Epoch 99/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0794 - acc: 0.9763 - val_loss: 0.0793 - val_acc: 0.9762\n",
      "Epoch 100/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0795 - acc: 0.9762 - val_loss: 0.0793 - val_acc: 0.9764\n",
      "81251/81251 [==============================] - 5s 61us/step\n",
      "81250/81250 [==============================] - 5s 62us/step\n",
      "Train on 81250 samples, validate on 81250 samples\n",
      "Epoch 1/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0806 - acc: 0.9759 - val_loss: 0.0808 - val_acc: 0.9763\n",
      "Epoch 2/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0806 - acc: 0.9761 - val_loss: 0.0802 - val_acc: 0.9760\n",
      "Epoch 3/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0804 - acc: 0.9761 - val_loss: 0.0805 - val_acc: 0.9759\n",
      "Epoch 4/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0805 - acc: 0.9759 - val_loss: 0.0803 - val_acc: 0.9761\n",
      "Epoch 5/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0805 - acc: 0.9760 - val_loss: 0.0802 - val_acc: 0.9760\n",
      "Epoch 6/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0804 - acc: 0.9760 - val_loss: 0.0808 - val_acc: 0.9756\n",
      "Epoch 7/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0804 - acc: 0.9760 - val_loss: 0.0802 - val_acc: 0.9761\n",
      "Epoch 8/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0804 - acc: 0.9760 - val_loss: 0.0801 - val_acc: 0.9760\n",
      "Epoch 9/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0803 - acc: 0.9760 - val_loss: 0.0803 - val_acc: 0.9760\n",
      "Epoch 10/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0802 - acc: 0.9761 - val_loss: 0.0804 - val_acc: 0.9761\n",
      "Epoch 11/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0804 - acc: 0.9760 - val_loss: 0.0803 - val_acc: 0.9760\n",
      "Epoch 12/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0804 - acc: 0.9760 - val_loss: 0.0802 - val_acc: 0.9762\n",
      "Epoch 13/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0803 - acc: 0.9760 - val_loss: 0.0803 - val_acc: 0.9760\n",
      "Epoch 14/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0803 - acc: 0.9759 - val_loss: 0.0805 - val_acc: 0.9760\n",
      "Epoch 15/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0803 - acc: 0.9759 - val_loss: 0.0802 - val_acc: 0.9759\n",
      "Epoch 16/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0803 - acc: 0.9759 - val_loss: 0.0800 - val_acc: 0.9762\n",
      "Epoch 17/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0803 - acc: 0.9760 - val_loss: 0.0800 - val_acc: 0.9760\n",
      "Epoch 18/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0802 - acc: 0.9760 - val_loss: 0.0802 - val_acc: 0.9758\n",
      "Epoch 19/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0802 - acc: 0.9761 - val_loss: 0.0801 - val_acc: 0.9760\n",
      "Epoch 20/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0803 - acc: 0.9760 - val_loss: 0.0800 - val_acc: 0.9760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0802 - acc: 0.9760 - val_loss: 0.0803 - val_acc: 0.9760\n",
      "Epoch 22/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0803 - acc: 0.9761 - val_loss: 0.0799 - val_acc: 0.9759\n",
      "Epoch 23/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0803 - acc: 0.9760 - val_loss: 0.0799 - val_acc: 0.9761\n",
      "Epoch 24/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0802 - acc: 0.9759 - val_loss: 0.0799 - val_acc: 0.9759\n",
      "Epoch 25/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0802 - acc: 0.9760 - val_loss: 0.0805 - val_acc: 0.9763\n",
      "Epoch 26/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0802 - acc: 0.9761 - val_loss: 0.0802 - val_acc: 0.9759\n",
      "Epoch 27/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0802 - acc: 0.9760 - val_loss: 0.0806 - val_acc: 0.9762\n",
      "Epoch 28/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0801 - acc: 0.9761 - val_loss: 0.0801 - val_acc: 0.9762\n",
      "Epoch 29/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0801 - acc: 0.9761 - val_loss: 0.0800 - val_acc: 0.9760\n",
      "Epoch 30/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0802 - acc: 0.9761 - val_loss: 0.0800 - val_acc: 0.9761\n",
      "Epoch 31/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0801 - acc: 0.9760 - val_loss: 0.0803 - val_acc: 0.9763\n",
      "Epoch 32/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0802 - acc: 0.9759 - val_loss: 0.0804 - val_acc: 0.9761\n",
      "Epoch 33/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0802 - acc: 0.9760 - val_loss: 0.0799 - val_acc: 0.9760\n",
      "Epoch 34/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0802 - acc: 0.9761 - val_loss: 0.0799 - val_acc: 0.9760\n",
      "Epoch 35/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0801 - acc: 0.9760 - val_loss: 0.0801 - val_acc: 0.9761\n",
      "Epoch 36/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0802 - acc: 0.9760 - val_loss: 0.0798 - val_acc: 0.9762\n",
      "Epoch 37/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0802 - acc: 0.9762 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 38/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0801 - acc: 0.9760 - val_loss: 0.0804 - val_acc: 0.9763\n",
      "Epoch 39/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0801 - acc: 0.9761 - val_loss: 0.0800 - val_acc: 0.9758\n",
      "Epoch 40/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0801 - acc: 0.9762 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 41/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0801 - acc: 0.9760 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 42/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9760 - val_loss: 0.0805 - val_acc: 0.9762\n",
      "Epoch 43/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0802 - acc: 0.9760 - val_loss: 0.0799 - val_acc: 0.9760\n",
      "Epoch 44/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9762 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 45/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0799 - val_acc: 0.9761\n",
      "Epoch 46/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0801 - acc: 0.9760 - val_loss: 0.0800 - val_acc: 0.9759\n",
      "Epoch 47/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0798 - val_acc: 0.9762\n",
      "Epoch 48/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0799 - val_acc: 0.9759\n",
      "Epoch 49/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9760 - val_loss: 0.0798 - val_acc: 0.9763\n",
      "Epoch 50/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9763 - val_loss: 0.0799 - val_acc: 0.9761\n",
      "Epoch 51/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9762 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 52/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0801 - acc: 0.9760 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 53/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0803 - val_acc: 0.9761\n",
      "Epoch 54/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0799 - val_acc: 0.9762\n",
      "Epoch 55/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0801 - acc: 0.9760 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 56/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0801 - acc: 0.9760 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 57/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9760 - val_loss: 0.0797 - val_acc: 0.9760\n",
      "Epoch 58/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9762 - val_loss: 0.0797 - val_acc: 0.9761\n",
      "Epoch 59/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9763 - val_loss: 0.0799 - val_acc: 0.9760\n",
      "Epoch 60/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0801 - acc: 0.9760 - val_loss: 0.0797 - val_acc: 0.9760\n",
      "Epoch 61/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0799 - acc: 0.9760 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 62/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9760 - val_loss: 0.0801 - val_acc: 0.9762\n",
      "Epoch 63/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0801 - acc: 0.9761 - val_loss: 0.0798 - val_acc: 0.9760\n",
      "Epoch 64/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9759 - val_loss: 0.0803 - val_acc: 0.9762\n",
      "Epoch 65/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9759 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 66/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0801 - acc: 0.9760 - val_loss: 0.0798 - val_acc: 0.9763\n",
      "Epoch 67/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0799 - val_acc: 0.9761\n",
      "Epoch 68/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9762 - val_loss: 0.0801 - val_acc: 0.9760\n",
      "Epoch 69/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9760 - val_loss: 0.0800 - val_acc: 0.9762\n",
      "Epoch 70/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0799 - acc: 0.9759 - val_loss: 0.0797 - val_acc: 0.9760\n",
      "Epoch 71/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0800 - acc: 0.9760 - val_loss: 0.0797 - val_acc: 0.9761\n",
      "Epoch 72/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0802 - acc: 0.9761 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 73/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9760 - val_loss: 0.0797 - val_acc: 0.9761\n",
      "Epoch 74/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0799 - acc: 0.9761 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 75/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0801 - acc: 0.9763 - val_loss: 0.0799 - val_acc: 0.9761\n",
      "Epoch 76/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9760 - val_loss: 0.0797 - val_acc: 0.9761\n",
      "Epoch 77/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0797 - val_acc: 0.9762\n",
      "Epoch 78/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0801 - acc: 0.9759 - val_loss: 0.0801 - val_acc: 0.9761\n",
      "Epoch 79/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0800 - acc: 0.9762 - val_loss: 0.0805 - val_acc: 0.9761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 81/100\n",
      "81250/81250 [==============================] - 1s 14us/step - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0798 - val_acc: 0.9762\n",
      "Epoch 82/100\n",
      "81250/81250 [==============================] - 1s 18us/step - loss: 0.0800 - acc: 0.9760 - val_loss: 0.0799 - val_acc: 0.9763\n",
      "Epoch 83/100\n",
      "81250/81250 [==============================] - 1s 16us/step - loss: 0.0801 - acc: 0.9762 - val_loss: 0.0799 - val_acc: 0.9759\n",
      "Epoch 84/100\n",
      "81250/81250 [==============================] - 1s 17us/step - loss: 0.0800 - acc: 0.9758 - val_loss: 0.0802 - val_acc: 0.9762\n",
      "Epoch 85/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0798 - val_acc: 0.9762\n",
      "Epoch 86/100\n",
      "81250/81250 [==============================] - 1s 15us/step - loss: 0.0799 - acc: 0.9760 - val_loss: 0.0800 - val_acc: 0.9757\n",
      "Epoch 87/100\n",
      "81250/81250 [==============================] - 1s 15us/step - loss: 0.0800 - acc: 0.9760 - val_loss: 0.0797 - val_acc: 0.9761\n",
      "Epoch 88/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0799 - val_acc: 0.9760\n",
      "Epoch 89/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0801 - acc: 0.9760 - val_loss: 0.0798 - val_acc: 0.9760\n",
      "Epoch 90/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9763 - val_loss: 0.0797 - val_acc: 0.9762\n",
      "Epoch 91/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0797 - val_acc: 0.9763\n",
      "Epoch 92/100\n",
      "81250/81250 [==============================] - 1s 10us/step - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0797 - val_acc: 0.9761\n",
      "Epoch 93/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0800 - val_acc: 0.9763\n",
      "Epoch 94/100\n",
      "81250/81250 [==============================] - 1s 12us/step - loss: 0.0800 - acc: 0.9761 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 95/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0799 - acc: 0.9761 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 96/100\n",
      "81250/81250 [==============================] - 1s 11us/step - loss: 0.0800 - acc: 0.9760 - val_loss: 0.0797 - val_acc: 0.9762\n",
      "Epoch 97/100\n",
      "81250/81250 [==============================] - 1s 16us/step - loss: 0.0799 - acc: 0.9762 - val_loss: 0.0797 - val_acc: 0.9761\n",
      "Epoch 98/100\n",
      "81250/81250 [==============================] - 1s 13us/step - loss: 0.0799 - acc: 0.9761 - val_loss: 0.0797 - val_acc: 0.9763\n",
      "Epoch 99/100\n",
      "81250/81250 [==============================] - 1s 15us/step - loss: 0.0799 - acc: 0.9760 - val_loss: 0.0797 - val_acc: 0.9761\n",
      "Epoch 100/100\n",
      "81250/81250 [==============================] - 1s 16us/step - loss: 0.0799 - acc: 0.9760 - val_loss: 0.0799 - val_acc: 0.9763\n",
      "81251/81251 [==============================] - 7s 91us/step\n",
      "81250/81250 [==============================] - 7s 80us/step\n",
      "Train on 32500 samples, validate on 32500 samples\n",
      "Epoch 1/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0800 - acc: 0.9765 - val_loss: 0.0796 - val_acc: 0.9765\n",
      "Epoch 2/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0798 - acc: 0.9764 - val_loss: 0.0795 - val_acc: 0.9765\n",
      "Epoch 3/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0797 - acc: 0.9766 - val_loss: 0.0793 - val_acc: 0.9764\n",
      "Epoch 4/100\n",
      "32500/32500 [==============================] - 0s 15us/step - loss: 0.0796 - acc: 0.9765 - val_loss: 0.0792 - val_acc: 0.9767\n",
      "Epoch 5/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0794 - acc: 0.9765 - val_loss: 0.0792 - val_acc: 0.9768\n",
      "Epoch 6/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0795 - acc: 0.9768 - val_loss: 0.0793 - val_acc: 0.9768\n",
      "Epoch 7/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0795 - acc: 0.9767 - val_loss: 0.0792 - val_acc: 0.9768\n",
      "Epoch 8/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0793 - acc: 0.9766 - val_loss: 0.0795 - val_acc: 0.9765\n",
      "Epoch 9/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0795 - acc: 0.9766 - val_loss: 0.0791 - val_acc: 0.9768\n",
      "Epoch 10/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0793 - acc: 0.9768 - val_loss: 0.0790 - val_acc: 0.9766\n",
      "Epoch 11/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0795 - acc: 0.9764 - val_loss: 0.0790 - val_acc: 0.9767\n",
      "Epoch 12/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0794 - acc: 0.9764 - val_loss: 0.0790 - val_acc: 0.9768\n",
      "Epoch 13/100\n",
      "32500/32500 [==============================] - 1s 17us/step - loss: 0.0792 - acc: 0.9765 - val_loss: 0.0790 - val_acc: 0.9767\n",
      "Epoch 14/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0792 - acc: 0.9767 - val_loss: 0.0788 - val_acc: 0.9766\n",
      "Epoch 15/100\n",
      "32500/32500 [==============================] - 1s 18us/step - loss: 0.0791 - acc: 0.9768 - val_loss: 0.0790 - val_acc: 0.9768\n",
      "Epoch 16/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0790 - acc: 0.9763 - val_loss: 0.0791 - val_acc: 0.9767\n",
      "Epoch 17/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0794 - acc: 0.9765 - val_loss: 0.0789 - val_acc: 0.9768\n",
      "Epoch 18/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0790 - acc: 0.9766 - val_loss: 0.0788 - val_acc: 0.9766\n",
      "Epoch 19/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0791 - acc: 0.9767 - val_loss: 0.0790 - val_acc: 0.9768\n",
      "Epoch 20/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0791 - acc: 0.9766 - val_loss: 0.0788 - val_acc: 0.9766\n",
      "Epoch 21/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0791 - acc: 0.9768 - val_loss: 0.0789 - val_acc: 0.9769\n",
      "Epoch 22/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0791 - acc: 0.9765 - val_loss: 0.0791 - val_acc: 0.9767\n",
      "Epoch 23/100\n",
      "32500/32500 [==============================] - 0s 15us/step - loss: 0.0791 - acc: 0.9766 - val_loss: 0.0787 - val_acc: 0.9767\n",
      "Epoch 24/100\n",
      "32500/32500 [==============================] - 1s 20us/step - loss: 0.0791 - acc: 0.9766 - val_loss: 0.0787 - val_acc: 0.9765\n",
      "Epoch 25/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0789 - acc: 0.9766 - val_loss: 0.0790 - val_acc: 0.9770\n",
      "Epoch 26/100\n",
      "32500/32500 [==============================] - 1s 20us/step - loss: 0.0790 - acc: 0.9769 - val_loss: 0.0787 - val_acc: 0.9767\n",
      "Epoch 27/100\n",
      "32500/32500 [==============================] - 1s 19us/step - loss: 0.0789 - acc: 0.9766 - val_loss: 0.0786 - val_acc: 0.9765\n",
      "Epoch 28/100\n",
      "32500/32500 [==============================] - 1s 22us/step - loss: 0.0791 - acc: 0.9766 - val_loss: 0.0788 - val_acc: 0.9766\n",
      "Epoch 29/100\n",
      "32500/32500 [==============================] - 1s 18us/step - loss: 0.0789 - acc: 0.9765 - val_loss: 0.0786 - val_acc: 0.9766\n",
      "Epoch 30/100\n",
      "32500/32500 [==============================] - 1s 15us/step - loss: 0.0790 - acc: 0.9765 - val_loss: 0.0789 - val_acc: 0.9769\n",
      "Epoch 31/100\n",
      "32500/32500 [==============================] - 0s 15us/step - loss: 0.0790 - acc: 0.9766 - val_loss: 0.0787 - val_acc: 0.9769\n",
      "Epoch 32/100\n",
      "32500/32500 [==============================] - 1s 17us/step - loss: 0.0789 - acc: 0.9768 - val_loss: 0.0786 - val_acc: 0.9767\n",
      "Epoch 33/100\n",
      "32500/32500 [==============================] - 1s 18us/step - loss: 0.0789 - acc: 0.9766 - val_loss: 0.0790 - val_acc: 0.9766\n",
      "Epoch 34/100\n",
      "32500/32500 [==============================] - 1s 17us/step - loss: 0.0789 - acc: 0.9766 - val_loss: 0.0788 - val_acc: 0.9770\n",
      "Epoch 35/100\n",
      "32500/32500 [==============================] - 1s 16us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0786 - val_acc: 0.9768\n",
      "Epoch 36/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0790 - acc: 0.9767 - val_loss: 0.0786 - val_acc: 0.9768\n",
      "Epoch 37/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0787 - acc: 0.9766 - val_loss: 0.0789 - val_acc: 0.9769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0789 - acc: 0.9766 - val_loss: 0.0787 - val_acc: 0.9769\n",
      "Epoch 39/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0789 - acc: 0.9765 - val_loss: 0.0786 - val_acc: 0.9769\n",
      "Epoch 40/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0788 - acc: 0.9766 - val_loss: 0.0787 - val_acc: 0.9769\n",
      "Epoch 41/100\n",
      "32500/32500 [==============================] - 1s 18us/step - loss: 0.0789 - acc: 0.9767 - val_loss: 0.0785 - val_acc: 0.9767\n",
      "Epoch 42/100\n",
      "32500/32500 [==============================] - 1s 16us/step - loss: 0.0788 - acc: 0.9767 - val_loss: 0.0789 - val_acc: 0.9770\n",
      "Epoch 43/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0790 - acc: 0.9767 - val_loss: 0.0786 - val_acc: 0.9768\n",
      "Epoch 44/100\n",
      "32500/32500 [==============================] - 1s 15us/step - loss: 0.0790 - acc: 0.9766 - val_loss: 0.0786 - val_acc: 0.9766\n",
      "Epoch 45/100\n",
      "32500/32500 [==============================] - 1s 17us/step - loss: 0.0789 - acc: 0.9769 - val_loss: 0.0793 - val_acc: 0.9763\n",
      "Epoch 46/100\n",
      "32500/32500 [==============================] - 1s 25us/step - loss: 0.0789 - acc: 0.9767 - val_loss: 0.0785 - val_acc: 0.9768\n",
      "Epoch 47/100\n",
      "32500/32500 [==============================] - 1s 31us/step - loss: 0.0788 - acc: 0.9768 - val_loss: 0.0785 - val_acc: 0.9766\n",
      "Epoch 48/100\n",
      "32500/32500 [==============================] - 1s 16us/step - loss: 0.0788 - acc: 0.9768 - val_loss: 0.0786 - val_acc: 0.9770\n",
      "Epoch 49/100\n",
      "32500/32500 [==============================] - 1s 17us/step - loss: 0.0788 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9769\n",
      "Epoch 50/100\n",
      "32500/32500 [==============================] - 0s 15us/step - loss: 0.0789 - acc: 0.9766 - val_loss: 0.0785 - val_acc: 0.9767\n",
      "Epoch 51/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0788 - acc: 0.9767 - val_loss: 0.0786 - val_acc: 0.9766\n",
      "Epoch 52/100\n",
      "32500/32500 [==============================] - 1s 15us/step - loss: 0.0787 - acc: 0.9767 - val_loss: 0.0786 - val_acc: 0.9770\n",
      "Epoch 53/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0787 - acc: 0.9767 - val_loss: 0.0789 - val_acc: 0.9766\n",
      "Epoch 54/100\n",
      "32500/32500 [==============================] - 1s 39us/step - loss: 0.0788 - acc: 0.9766 - val_loss: 0.0786 - val_acc: 0.9766\n",
      "Epoch 55/100\n",
      "32500/32500 [==============================] - 1s 17us/step - loss: 0.0787 - acc: 0.9767 - val_loss: 0.0785 - val_acc: 0.9769\n",
      "Epoch 56/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0788 - acc: 0.9768 - val_loss: 0.0787 - val_acc: 0.9766\n",
      "Epoch 57/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0787 - acc: 0.9767 - val_loss: 0.0785 - val_acc: 0.9766\n",
      "Epoch 58/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0787 - acc: 0.9767 - val_loss: 0.0786 - val_acc: 0.9765\n",
      "Epoch 59/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0788 - acc: 0.9767 - val_loss: 0.0788 - val_acc: 0.9766\n",
      "Epoch 60/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0789 - acc: 0.9766 - val_loss: 0.0786 - val_acc: 0.9766\n",
      "Epoch 61/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0788 - acc: 0.9766 - val_loss: 0.0784 - val_acc: 0.9767\n",
      "Epoch 62/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0787 - acc: 0.9766 - val_loss: 0.0786 - val_acc: 0.9768\n",
      "Epoch 63/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0787 - acc: 0.9765 - val_loss: 0.0784 - val_acc: 0.9767\n",
      "Epoch 64/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0786 - acc: 0.9767 - val_loss: 0.0785 - val_acc: 0.9770\n",
      "Epoch 65/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0787 - acc: 0.9766 - val_loss: 0.0784 - val_acc: 0.9768\n",
      "Epoch 66/100\n",
      "32500/32500 [==============================] - 0s 15us/step - loss: 0.0787 - acc: 0.9768 - val_loss: 0.0785 - val_acc: 0.9767\n",
      "Epoch 67/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0786 - acc: 0.9767 - val_loss: 0.0784 - val_acc: 0.9767\n",
      "Epoch 68/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0786 - acc: 0.9767 - val_loss: 0.0784 - val_acc: 0.9768\n",
      "Epoch 69/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0787 - acc: 0.9768 - val_loss: 0.0787 - val_acc: 0.9770\n",
      "Epoch 70/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0787 - acc: 0.9769 - val_loss: 0.0784 - val_acc: 0.9769\n",
      "Epoch 71/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0787 - acc: 0.9767 - val_loss: 0.0783 - val_acc: 0.9766\n",
      "Epoch 72/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0786 - acc: 0.9766 - val_loss: 0.0785 - val_acc: 0.9767\n",
      "Epoch 73/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0787 - acc: 0.9764 - val_loss: 0.0789 - val_acc: 0.9765\n",
      "Epoch 74/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0787 - acc: 0.9768 - val_loss: 0.0788 - val_acc: 0.9769\n",
      "Epoch 75/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0786 - acc: 0.9769 - val_loss: 0.0785 - val_acc: 0.9768\n",
      "Epoch 76/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0786 - acc: 0.9766 - val_loss: 0.0784 - val_acc: 0.9767\n",
      "Epoch 77/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0788 - acc: 0.9767 - val_loss: 0.0786 - val_acc: 0.9770\n",
      "Epoch 78/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0788 - acc: 0.9766 - val_loss: 0.0784 - val_acc: 0.9768\n",
      "Epoch 79/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0786 - acc: 0.9769 - val_loss: 0.0789 - val_acc: 0.9765\n",
      "Epoch 80/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0786 - acc: 0.9767 - val_loss: 0.0783 - val_acc: 0.9767\n",
      "Epoch 81/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0785 - acc: 0.9768 - val_loss: 0.0787 - val_acc: 0.9769\n",
      "Epoch 82/100\n",
      "32500/32500 [==============================] - 1s 17us/step - loss: 0.0787 - acc: 0.9769 - val_loss: 0.0784 - val_acc: 0.9768\n",
      "Epoch 83/100\n",
      "32500/32500 [==============================] - 0s 15us/step - loss: 0.0786 - acc: 0.9768 - val_loss: 0.0783 - val_acc: 0.9767\n",
      "Epoch 84/100\n",
      "32500/32500 [==============================] - 1s 17us/step - loss: 0.0786 - acc: 0.9768 - val_loss: 0.0783 - val_acc: 0.9770\n",
      "Epoch 85/100\n",
      "32500/32500 [==============================] - 0s 15us/step - loss: 0.0786 - acc: 0.9769 - val_loss: 0.0785 - val_acc: 0.9771\n",
      "Epoch 86/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0787 - acc: 0.9769 - val_loss: 0.0786 - val_acc: 0.9770\n",
      "Epoch 87/100\n",
      "32500/32500 [==============================] - 1s 25us/step - loss: 0.0787 - acc: 0.9767 - val_loss: 0.0785 - val_acc: 0.9768\n",
      "Epoch 88/100\n",
      "32500/32500 [==============================] - 1s 18us/step - loss: 0.0789 - acc: 0.9767 - val_loss: 0.0783 - val_acc: 0.9767\n",
      "Epoch 89/100\n",
      "32500/32500 [==============================] - 1s 15us/step - loss: 0.0787 - acc: 0.9767 - val_loss: 0.0784 - val_acc: 0.9769\n",
      "Epoch 90/100\n",
      "32500/32500 [==============================] - 1s 18us/step - loss: 0.0785 - acc: 0.9770 - val_loss: 0.0784 - val_acc: 0.9770\n",
      "Epoch 91/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0787 - acc: 0.9769 - val_loss: 0.0783 - val_acc: 0.9766\n",
      "Epoch 92/100\n",
      "32500/32500 [==============================] - 1s 18us/step - loss: 0.0784 - acc: 0.9767 - val_loss: 0.0784 - val_acc: 0.9767\n",
      "Epoch 93/100\n",
      "32500/32500 [==============================] - 1s 16us/step - loss: 0.0786 - acc: 0.9768 - val_loss: 0.0786 - val_acc: 0.9769\n",
      "Epoch 94/100\n",
      "32500/32500 [==============================] - 0s 15us/step - loss: 0.0787 - acc: 0.9768 - val_loss: 0.0783 - val_acc: 0.9767\n",
      "Epoch 95/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0786 - acc: 0.9768 - val_loss: 0.0783 - val_acc: 0.9768\n",
      "Epoch 96/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0787 - acc: 0.9767 - val_loss: 0.0783 - val_acc: 0.9768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0786 - acc: 0.9767 - val_loss: 0.0783 - val_acc: 0.9766\n",
      "Epoch 98/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0787 - acc: 0.9767 - val_loss: 0.0783 - val_acc: 0.9769\n",
      "Epoch 99/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0787 - acc: 0.9767 - val_loss: 0.0783 - val_acc: 0.9767\n",
      "Epoch 100/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0786 - acc: 0.9767 - val_loss: 0.0784 - val_acc: 0.9767\n",
      "130001/130001 [==============================] - 12s 90us/step\n",
      "32500/32500 [==============================] - 2s 70us/step\n",
      "Train on 32500 samples, validate on 32500 samples\n",
      "Epoch 1/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0809 - acc: 0.9757 - val_loss: 0.0808 - val_acc: 0.9757\n",
      "Epoch 2/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0807 - acc: 0.9757 - val_loss: 0.0806 - val_acc: 0.9758\n",
      "Epoch 3/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0808 - acc: 0.9758 - val_loss: 0.0808 - val_acc: 0.9762\n",
      "Epoch 4/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0806 - acc: 0.9757 - val_loss: 0.0802 - val_acc: 0.9755\n",
      "Epoch 5/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0805 - acc: 0.9755 - val_loss: 0.0802 - val_acc: 0.9759\n",
      "Epoch 6/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0804 - acc: 0.9757 - val_loss: 0.0806 - val_acc: 0.9761\n",
      "Epoch 7/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0805 - acc: 0.9759 - val_loss: 0.0801 - val_acc: 0.9759\n",
      "Epoch 8/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0803 - acc: 0.9758 - val_loss: 0.0801 - val_acc: 0.9759\n",
      "Epoch 9/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0804 - acc: 0.9757 - val_loss: 0.0800 - val_acc: 0.9760\n",
      "Epoch 10/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0802 - acc: 0.9759 - val_loss: 0.0800 - val_acc: 0.9758\n",
      "Epoch 11/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0803 - acc: 0.9757 - val_loss: 0.0802 - val_acc: 0.9756\n",
      "Epoch 12/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0802 - acc: 0.9757 - val_loss: 0.0803 - val_acc: 0.9760\n",
      "Epoch 13/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0802 - acc: 0.9760 - val_loss: 0.0804 - val_acc: 0.9754\n",
      "Epoch 14/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0803 - acc: 0.9758 - val_loss: 0.0800 - val_acc: 0.9760\n",
      "Epoch 15/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0803 - acc: 0.9758 - val_loss: 0.0801 - val_acc: 0.9756\n",
      "Epoch 16/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0801 - acc: 0.9755 - val_loss: 0.0804 - val_acc: 0.9756\n",
      "Epoch 17/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0803 - acc: 0.9758 - val_loss: 0.0804 - val_acc: 0.9753\n",
      "Epoch 18/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0802 - acc: 0.9754 - val_loss: 0.0799 - val_acc: 0.9756\n",
      "Epoch 19/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0800 - acc: 0.9758 - val_loss: 0.0800 - val_acc: 0.9759\n",
      "Epoch 20/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0803 - acc: 0.9758 - val_loss: 0.0799 - val_acc: 0.9760\n",
      "Epoch 21/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0802 - acc: 0.9759 - val_loss: 0.0798 - val_acc: 0.9755\n",
      "Epoch 22/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0801 - acc: 0.9759 - val_loss: 0.0799 - val_acc: 0.9757\n",
      "Epoch 23/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0801 - acc: 0.9756 - val_loss: 0.0801 - val_acc: 0.9760\n",
      "Epoch 24/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0801 - acc: 0.9760 - val_loss: 0.0799 - val_acc: 0.9760\n",
      "Epoch 25/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0799 - acc: 0.9757 - val_loss: 0.0797 - val_acc: 0.9760\n",
      "Epoch 26/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0800 - acc: 0.9759 - val_loss: 0.0797 - val_acc: 0.9756\n",
      "Epoch 27/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0802 - acc: 0.9759 - val_loss: 0.0798 - val_acc: 0.9756\n",
      "Epoch 28/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0798 - acc: 0.9758 - val_loss: 0.0797 - val_acc: 0.9761\n",
      "Epoch 29/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0799 - acc: 0.9759 - val_loss: 0.0798 - val_acc: 0.9756\n",
      "Epoch 30/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0799 - acc: 0.9758 - val_loss: 0.0796 - val_acc: 0.9758\n",
      "Epoch 31/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0800 - acc: 0.9757 - val_loss: 0.0796 - val_acc: 0.9759\n",
      "Epoch 32/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0800 - acc: 0.9760 - val_loss: 0.0796 - val_acc: 0.9757\n",
      "Epoch 33/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0801 - acc: 0.9758 - val_loss: 0.0795 - val_acc: 0.9758\n",
      "Epoch 34/100\n",
      "32500/32500 [==============================] - 1s 16us/step - loss: 0.0799 - acc: 0.9756 - val_loss: 0.0795 - val_acc: 0.9759\n",
      "Epoch 35/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0798 - acc: 0.9757 - val_loss: 0.0796 - val_acc: 0.9756\n",
      "Epoch 36/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0798 - acc: 0.9757 - val_loss: 0.0795 - val_acc: 0.9758\n",
      "Epoch 37/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0798 - acc: 0.9758 - val_loss: 0.0801 - val_acc: 0.9760\n",
      "Epoch 38/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0800 - acc: 0.9758 - val_loss: 0.0795 - val_acc: 0.9759\n",
      "Epoch 39/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0799 - acc: 0.9760 - val_loss: 0.0795 - val_acc: 0.9760\n",
      "Epoch 40/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0796 - acc: 0.9759 - val_loss: 0.0804 - val_acc: 0.9755\n",
      "Epoch 41/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0801 - acc: 0.9760 - val_loss: 0.0795 - val_acc: 0.9756\n",
      "Epoch 42/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0798 - acc: 0.9758 - val_loss: 0.0799 - val_acc: 0.9754\n",
      "Epoch 43/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0797 - acc: 0.9759 - val_loss: 0.0801 - val_acc: 0.9757\n",
      "Epoch 44/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0801 - acc: 0.9757 - val_loss: 0.0796 - val_acc: 0.9760\n",
      "Epoch 45/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0798 - acc: 0.9756 - val_loss: 0.0797 - val_acc: 0.9761\n",
      "Epoch 46/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0801 - acc: 0.9758 - val_loss: 0.0795 - val_acc: 0.9760\n",
      "Epoch 47/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0797 - acc: 0.9757 - val_loss: 0.0795 - val_acc: 0.9759\n",
      "Epoch 48/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0798 - acc: 0.9758 - val_loss: 0.0795 - val_acc: 0.9763\n",
      "Epoch 49/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0797 - acc: 0.9759 - val_loss: 0.0802 - val_acc: 0.9759\n",
      "Epoch 50/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0798 - acc: 0.9759 - val_loss: 0.0794 - val_acc: 0.9757\n",
      "Epoch 51/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0795 - acc: 0.9760 - val_loss: 0.0794 - val_acc: 0.9758\n",
      "Epoch 52/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0796 - acc: 0.9756 - val_loss: 0.0793 - val_acc: 0.9759\n",
      "Epoch 53/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0797 - acc: 0.9759 - val_loss: 0.0796 - val_acc: 0.9757\n",
      "Epoch 54/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0795 - acc: 0.9758 - val_loss: 0.0795 - val_acc: 0.9759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0797 - acc: 0.9757 - val_loss: 0.0794 - val_acc: 0.9762\n",
      "Epoch 56/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0795 - acc: 0.9758 - val_loss: 0.0793 - val_acc: 0.9758\n",
      "Epoch 57/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0796 - acc: 0.9760 - val_loss: 0.0793 - val_acc: 0.9757\n",
      "Epoch 58/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0796 - acc: 0.9760 - val_loss: 0.0794 - val_acc: 0.9757\n",
      "Epoch 59/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0795 - acc: 0.9758 - val_loss: 0.0792 - val_acc: 0.9757\n",
      "Epoch 60/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0794 - acc: 0.9757 - val_loss: 0.0792 - val_acc: 0.9761\n",
      "Epoch 61/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0796 - acc: 0.9758 - val_loss: 0.0796 - val_acc: 0.9755\n",
      "Epoch 62/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0795 - acc: 0.9757 - val_loss: 0.0792 - val_acc: 0.9758\n",
      "Epoch 63/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0794 - acc: 0.9761 - val_loss: 0.0792 - val_acc: 0.9762\n",
      "Epoch 64/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0796 - acc: 0.9759 - val_loss: 0.0792 - val_acc: 0.9760\n",
      "Epoch 65/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0794 - acc: 0.9758 - val_loss: 0.0796 - val_acc: 0.9755\n",
      "Epoch 66/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0794 - acc: 0.9761 - val_loss: 0.0792 - val_acc: 0.9758\n",
      "Epoch 67/100\n",
      "32500/32500 [==============================] - 0s 15us/step - loss: 0.0794 - acc: 0.9758 - val_loss: 0.0792 - val_acc: 0.9761\n",
      "Epoch 68/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0795 - acc: 0.9757 - val_loss: 0.0792 - val_acc: 0.9758\n",
      "Epoch 69/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0795 - acc: 0.9758 - val_loss: 0.0793 - val_acc: 0.9757\n",
      "Epoch 70/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0796 - acc: 0.9758 - val_loss: 0.0792 - val_acc: 0.9760\n",
      "Epoch 71/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0793 - acc: 0.9757 - val_loss: 0.0795 - val_acc: 0.9758\n",
      "Epoch 72/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0793 - acc: 0.9759 - val_loss: 0.0792 - val_acc: 0.9762\n",
      "Epoch 73/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0794 - acc: 0.9758 - val_loss: 0.0793 - val_acc: 0.9756\n",
      "Epoch 74/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0794 - acc: 0.9757 - val_loss: 0.0791 - val_acc: 0.9756\n",
      "Epoch 75/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0794 - acc: 0.9758 - val_loss: 0.0791 - val_acc: 0.9760\n",
      "Epoch 76/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0794 - acc: 0.9760 - val_loss: 0.0791 - val_acc: 0.9758\n",
      "Epoch 77/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0794 - acc: 0.9758 - val_loss: 0.0793 - val_acc: 0.9756\n",
      "Epoch 78/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0794 - acc: 0.9761 - val_loss: 0.0793 - val_acc: 0.9757\n",
      "Epoch 79/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0795 - acc: 0.9757 - val_loss: 0.0792 - val_acc: 0.9758\n",
      "Epoch 80/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0793 - acc: 0.9758 - val_loss: 0.0792 - val_acc: 0.9764\n",
      "Epoch 81/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0793 - acc: 0.9757 - val_loss: 0.0794 - val_acc: 0.9763\n",
      "Epoch 82/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0795 - acc: 0.9758 - val_loss: 0.0791 - val_acc: 0.9757\n",
      "Epoch 83/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0793 - acc: 0.9756 - val_loss: 0.0791 - val_acc: 0.9763\n",
      "Epoch 84/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0794 - acc: 0.9762 - val_loss: 0.0790 - val_acc: 0.9759\n",
      "Epoch 85/100\n",
      "32500/32500 [==============================] - 0s 15us/step - loss: 0.0794 - acc: 0.9758 - val_loss: 0.0791 - val_acc: 0.9759\n",
      "Epoch 86/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0793 - acc: 0.9757 - val_loss: 0.0794 - val_acc: 0.9763\n",
      "Epoch 87/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0793 - acc: 0.9759 - val_loss: 0.0791 - val_acc: 0.9759\n",
      "Epoch 88/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0794 - acc: 0.9759 - val_loss: 0.0790 - val_acc: 0.9758\n",
      "Epoch 89/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0794 - acc: 0.9761 - val_loss: 0.0791 - val_acc: 0.9757\n",
      "Epoch 90/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0793 - acc: 0.9757 - val_loss: 0.0792 - val_acc: 0.9756\n",
      "Epoch 91/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0795 - acc: 0.9760 - val_loss: 0.0797 - val_acc: 0.9759\n",
      "Epoch 92/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0797 - acc: 0.9757 - val_loss: 0.0792 - val_acc: 0.9758\n",
      "Epoch 93/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0794 - acc: 0.9758 - val_loss: 0.0790 - val_acc: 0.9757\n",
      "Epoch 94/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0793 - acc: 0.9758 - val_loss: 0.0790 - val_acc: 0.9758\n",
      "Epoch 95/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0794 - acc: 0.9757 - val_loss: 0.0795 - val_acc: 0.9755\n",
      "Epoch 96/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0794 - acc: 0.9758 - val_loss: 0.0792 - val_acc: 0.9762\n",
      "Epoch 97/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0794 - acc: 0.9759 - val_loss: 0.0791 - val_acc: 0.9757\n",
      "Epoch 98/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0793 - acc: 0.9757 - val_loss: 0.0791 - val_acc: 0.9760\n",
      "Epoch 99/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0793 - acc: 0.9756 - val_loss: 0.0791 - val_acc: 0.9764\n",
      "Epoch 100/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0792 - acc: 0.9758 - val_loss: 0.0791 - val_acc: 0.9761\n",
      "130001/130001 [==============================] - 11s 83us/step\n",
      "32500/32500 [==============================] - 2s 67us/step\n",
      "Train on 32500 samples, validate on 32500 samples\n",
      "Epoch 1/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0785 - acc: 0.9754 - val_loss: 0.0782 - val_acc: 0.9758\n",
      "Epoch 2/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0782 - acc: 0.9756 - val_loss: 0.0783 - val_acc: 0.9758\n",
      "Epoch 3/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0782 - acc: 0.9754 - val_loss: 0.0777 - val_acc: 0.9754\n",
      "Epoch 4/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0781 - acc: 0.9754 - val_loss: 0.0778 - val_acc: 0.9754\n",
      "Epoch 5/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0779 - acc: 0.9756 - val_loss: 0.0776 - val_acc: 0.9758\n",
      "Epoch 6/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0779 - acc: 0.9753 - val_loss: 0.0776 - val_acc: 0.9754\n",
      "Epoch 7/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0777 - acc: 0.9759 - val_loss: 0.0775 - val_acc: 0.9755\n",
      "Epoch 8/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0776 - acc: 0.9755 - val_loss: 0.0773 - val_acc: 0.9759\n",
      "Epoch 9/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0776 - acc: 0.9759 - val_loss: 0.0774 - val_acc: 0.9757\n",
      "Epoch 10/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0776 - acc: 0.9759 - val_loss: 0.0773 - val_acc: 0.9757\n",
      "Epoch 11/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0775 - acc: 0.9760 - val_loss: 0.0771 - val_acc: 0.9759\n",
      "Epoch 12/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0774 - acc: 0.9755 - val_loss: 0.0774 - val_acc: 0.9757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0775 - acc: 0.9761 - val_loss: 0.0772 - val_acc: 0.9759\n",
      "Epoch 14/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0773 - acc: 0.9759 - val_loss: 0.0770 - val_acc: 0.9758\n",
      "Epoch 15/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0773 - acc: 0.9762 - val_loss: 0.0769 - val_acc: 0.9759\n",
      "Epoch 16/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0773 - acc: 0.9759 - val_loss: 0.0769 - val_acc: 0.9761\n",
      "Epoch 17/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0773 - acc: 0.9758 - val_loss: 0.0769 - val_acc: 0.9760\n",
      "Epoch 18/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0774 - acc: 0.9760 - val_loss: 0.0770 - val_acc: 0.9762\n",
      "Epoch 19/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0771 - acc: 0.9763 - val_loss: 0.0770 - val_acc: 0.9761\n",
      "Epoch 20/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0771 - acc: 0.9761 - val_loss: 0.0770 - val_acc: 0.9760\n",
      "Epoch 21/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0772 - acc: 0.9760 - val_loss: 0.0768 - val_acc: 0.9761\n",
      "Epoch 22/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0771 - acc: 0.9762 - val_loss: 0.0769 - val_acc: 0.9761\n",
      "Epoch 23/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0770 - acc: 0.9759 - val_loss: 0.0767 - val_acc: 0.9761\n",
      "Epoch 24/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0769 - acc: 0.9761 - val_loss: 0.0768 - val_acc: 0.9760\n",
      "Epoch 25/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0770 - acc: 0.9758 - val_loss: 0.0767 - val_acc: 0.9761\n",
      "Epoch 26/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0771 - acc: 0.9759 - val_loss: 0.0766 - val_acc: 0.9762\n",
      "Epoch 27/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0768 - acc: 0.9762 - val_loss: 0.0769 - val_acc: 0.9761\n",
      "Epoch 28/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0768 - acc: 0.9761 - val_loss: 0.0766 - val_acc: 0.9762\n",
      "Epoch 29/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0768 - acc: 0.9761 - val_loss: 0.0765 - val_acc: 0.9762\n",
      "Epoch 30/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0768 - acc: 0.9762 - val_loss: 0.0765 - val_acc: 0.9762\n",
      "Epoch 31/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0767 - acc: 0.9761 - val_loss: 0.0765 - val_acc: 0.9761\n",
      "Epoch 32/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0767 - acc: 0.9762 - val_loss: 0.0764 - val_acc: 0.9761\n",
      "Epoch 33/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0767 - acc: 0.9760 - val_loss: 0.0764 - val_acc: 0.9762\n",
      "Epoch 34/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0767 - acc: 0.9762 - val_loss: 0.0764 - val_acc: 0.9762\n",
      "Epoch 35/100\n",
      "32500/32500 [==============================] - 1s 18us/step - loss: 0.0767 - acc: 0.9760 - val_loss: 0.0765 - val_acc: 0.9762\n",
      "Epoch 36/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0768 - acc: 0.9758 - val_loss: 0.0767 - val_acc: 0.9758\n",
      "Epoch 37/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0767 - acc: 0.9760 - val_loss: 0.0763 - val_acc: 0.9764\n",
      "Epoch 38/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0766 - acc: 0.9761 - val_loss: 0.0763 - val_acc: 0.9762\n",
      "Epoch 39/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0766 - acc: 0.9760 - val_loss: 0.0764 - val_acc: 0.9763\n",
      "Epoch 40/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0766 - acc: 0.9762 - val_loss: 0.0763 - val_acc: 0.9762\n",
      "Epoch 41/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0766 - acc: 0.9762 - val_loss: 0.0765 - val_acc: 0.9763\n",
      "Epoch 42/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0767 - acc: 0.9761 - val_loss: 0.0763 - val_acc: 0.9763\n",
      "Epoch 43/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0767 - acc: 0.9762 - val_loss: 0.0764 - val_acc: 0.9764\n",
      "Epoch 44/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0766 - acc: 0.9760 - val_loss: 0.0772 - val_acc: 0.9758\n",
      "Epoch 45/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0766 - acc: 0.9759 - val_loss: 0.0763 - val_acc: 0.9761\n",
      "Epoch 46/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0765 - acc: 0.9762 - val_loss: 0.0762 - val_acc: 0.9764\n",
      "Epoch 47/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0767 - acc: 0.9762 - val_loss: 0.0764 - val_acc: 0.9762\n",
      "Epoch 48/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0766 - acc: 0.9762 - val_loss: 0.0765 - val_acc: 0.9761\n",
      "Epoch 49/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0766 - acc: 0.9762 - val_loss: 0.0762 - val_acc: 0.9764\n",
      "Epoch 50/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0765 - acc: 0.9762 - val_loss: 0.0763 - val_acc: 0.9763\n",
      "Epoch 51/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0764 - acc: 0.9762 - val_loss: 0.0764 - val_acc: 0.9763\n",
      "Epoch 52/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0766 - acc: 0.9761 - val_loss: 0.0764 - val_acc: 0.9761\n",
      "Epoch 53/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0765 - acc: 0.9760 - val_loss: 0.0763 - val_acc: 0.9763\n",
      "Epoch 54/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0765 - acc: 0.9761 - val_loss: 0.0765 - val_acc: 0.9762\n",
      "Epoch 55/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0764 - acc: 0.9762 - val_loss: 0.0772 - val_acc: 0.9762\n",
      "Epoch 56/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0767 - acc: 0.9761 - val_loss: 0.0765 - val_acc: 0.9760\n",
      "Epoch 57/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0764 - acc: 0.9760 - val_loss: 0.0762 - val_acc: 0.9762\n",
      "Epoch 58/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0765 - acc: 0.9762 - val_loss: 0.0761 - val_acc: 0.9762\n",
      "Epoch 59/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0764 - acc: 0.9762 - val_loss: 0.0761 - val_acc: 0.9763\n",
      "Epoch 60/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0765 - acc: 0.9763 - val_loss: 0.0764 - val_acc: 0.9761\n",
      "Epoch 61/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0765 - acc: 0.9763 - val_loss: 0.0761 - val_acc: 0.9765\n",
      "Epoch 62/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0764 - acc: 0.9762 - val_loss: 0.0761 - val_acc: 0.9764\n",
      "Epoch 63/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0763 - acc: 0.9763 - val_loss: 0.0761 - val_acc: 0.9762\n",
      "Epoch 64/100\n",
      "32500/32500 [==============================] - 0s 13us/step - loss: 0.0763 - acc: 0.9761 - val_loss: 0.0762 - val_acc: 0.9764\n",
      "Epoch 65/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0765 - acc: 0.9763 - val_loss: 0.0761 - val_acc: 0.9762\n",
      "Epoch 66/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0764 - acc: 0.9764 - val_loss: 0.0761 - val_acc: 0.9765\n",
      "Epoch 67/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0764 - acc: 0.9764 - val_loss: 0.0763 - val_acc: 0.9764\n",
      "Epoch 68/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0764 - acc: 0.9762 - val_loss: 0.0761 - val_acc: 0.9762\n",
      "Epoch 69/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0764 - acc: 0.9764 - val_loss: 0.0761 - val_acc: 0.9765\n",
      "Epoch 70/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0764 - acc: 0.9761 - val_loss: 0.0763 - val_acc: 0.9761\n",
      "Epoch 71/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0765 - acc: 0.9761 - val_loss: 0.0763 - val_acc: 0.9762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0765 - acc: 0.9764 - val_loss: 0.0762 - val_acc: 0.9762\n",
      "Epoch 73/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0764 - acc: 0.9763 - val_loss: 0.0765 - val_acc: 0.9762\n",
      "Epoch 74/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0764 - acc: 0.9762 - val_loss: 0.0761 - val_acc: 0.9762\n",
      "Epoch 75/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0764 - acc: 0.9763 - val_loss: 0.0767 - val_acc: 0.9761\n",
      "Epoch 76/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0764 - acc: 0.9761 - val_loss: 0.0762 - val_acc: 0.9762\n",
      "Epoch 77/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0763 - acc: 0.9765 - val_loss: 0.0765 - val_acc: 0.9760\n",
      "Epoch 78/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0764 - acc: 0.9763 - val_loss: 0.0760 - val_acc: 0.9764\n",
      "Epoch 79/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0763 - acc: 0.9762 - val_loss: 0.0761 - val_acc: 0.9762\n",
      "Epoch 80/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0765 - acc: 0.9766 - val_loss: 0.0761 - val_acc: 0.9764\n",
      "Epoch 81/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0764 - acc: 0.9760 - val_loss: 0.0763 - val_acc: 0.9762\n",
      "Epoch 82/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0763 - acc: 0.9765 - val_loss: 0.0760 - val_acc: 0.9764\n",
      "Epoch 83/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0763 - acc: 0.9762 - val_loss: 0.0763 - val_acc: 0.9765\n",
      "Epoch 84/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0764 - acc: 0.9763 - val_loss: 0.0761 - val_acc: 0.9762\n",
      "Epoch 85/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0765 - acc: 0.9758 - val_loss: 0.0760 - val_acc: 0.9763\n",
      "Epoch 86/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0763 - acc: 0.9762 - val_loss: 0.0761 - val_acc: 0.9763\n",
      "Epoch 87/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0762 - acc: 0.9766 - val_loss: 0.0763 - val_acc: 0.9761\n",
      "Epoch 88/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0764 - acc: 0.9763 - val_loss: 0.0761 - val_acc: 0.9762\n",
      "Epoch 89/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0763 - acc: 0.9763 - val_loss: 0.0760 - val_acc: 0.9764\n",
      "Epoch 90/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0764 - acc: 0.9762 - val_loss: 0.0760 - val_acc: 0.9764\n",
      "Epoch 91/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0765 - acc: 0.9763 - val_loss: 0.0760 - val_acc: 0.9765\n",
      "Epoch 92/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0763 - acc: 0.9762 - val_loss: 0.0761 - val_acc: 0.9764\n",
      "Epoch 93/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0763 - acc: 0.9760 - val_loss: 0.0760 - val_acc: 0.9763\n",
      "Epoch 94/100\n",
      "32500/32500 [==============================] - 0s 14us/step - loss: 0.0762 - acc: 0.9763 - val_loss: 0.0763 - val_acc: 0.9762\n",
      "Epoch 95/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0764 - acc: 0.9762 - val_loss: 0.0760 - val_acc: 0.9764\n",
      "Epoch 96/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0763 - acc: 0.9762 - val_loss: 0.0762 - val_acc: 0.9762\n",
      "Epoch 97/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0764 - acc: 0.9764 - val_loss: 0.0764 - val_acc: 0.9765\n",
      "Epoch 98/100\n",
      "32500/32500 [==============================] - 0s 11us/step - loss: 0.0762 - acc: 0.9763 - val_loss: 0.0761 - val_acc: 0.9764\n",
      "Epoch 99/100\n",
      "32500/32500 [==============================] - 0s 10us/step - loss: 0.0761 - acc: 0.9761 - val_loss: 0.0760 - val_acc: 0.9763\n",
      "Epoch 100/100\n",
      "32500/32500 [==============================] - 0s 12us/step - loss: 0.0762 - acc: 0.9764 - val_loss: 0.0762 - val_acc: 0.9763\n",
      "130001/130001 [==============================] - 9s 70us/step\n",
      "32500/32500 [==============================] - 2s 73us/step\n",
      "[0.9757033116935849, 0.9767633629124566, 0.9765181293478759]\n",
      "[0.976551282051282, 0.9762297435897436, 0.9763589743540836]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32,activation='relu',input_dim=3))\n",
    "#model.add(Dense(units = 32, activation = 'relu'))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics=['accuracy'])\n",
    "ave_acc_act_ann=[]\n",
    "ave_acc_act_ann_train=[]\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(Act_x, Act_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        history = model.fit(X_train1, y_train1,validation_data=(X_train1,y_train1),batch_size=512,epochs=100)\n",
    "        score2 += model.evaluate(X_test1,y_test1,verbose=1)[1]\n",
    "        score1 += model.evaluate(X_train1,y_train1,verbose=1)[1]\n",
    "    ave_acc_act_ann.append(score2/3.0)\n",
    "    ave_acc_act_ann_train.append(score1/3.0)\n",
    "    \n",
    "print ave_acc_act_ann  \n",
    "print ave_acc_act_ann_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss_activity_ann')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 200, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier()\n",
    "#parameter = [{'learning_rate':[0.01,0.1,0.3],'n_estimators':[100,200,500]}]\n",
    "parameter = [{'learning_rate':[0.1],'n_estimators':[100,200]}]\n",
    "search = GridSearchCV(clf,parameter,cv=3)\n",
    "search.fit(Act_x,Act_y)\n",
    "print search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=search.best_params_['learning_rate'],n_estimators=search.best_params_['n_estimators'],)\n",
    "ave_acc_activity_boo = []\n",
    "ave_acc_activity_boo_train = []\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(Act_x, Act_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1,y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_activity_boo_train.append(score1/3.0)\n",
    "    ave_acc_activity_boo.append(score2/3.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9773545429371403, 0.9768290031302179, 0.9763360794660554]\n",
      "[0.9778846153846154, 0.9784205128205129, 0.9797128205128205]\n"
     ]
    }
   ],
   "source": [
    "print ave_acc_activity_boo\n",
    "print ave_acc_activity_boo_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "search.fit(occ_x,occ_y)\n",
    "print search.best_params_\n",
    "clf = GradientBoostingClassifier(learning_rate=search.best_params_['learning_rate'],n_estimators=search.best_params_['n_estimators'])\n",
    "ave_acc_occ_boo = []\n",
    "ave_acc_occ_boo_train = []\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(occ_x, occ_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_occ_boo_train.append(score1/3.0)\n",
    "    ave_acc_occ_boo.append(score2/3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.992633517495396, 0.9939423706614275, 0.9903300076745971]\n",
      "[0.9983113294442739, 0.9986080406124621, 0.9995904995904996]\n"
     ]
    }
   ],
   "source": [
    "print ave_acc_occ_boo\n",
    "print ave_acc_occ_boo_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'learning_rate': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:12: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "search.fit(Whole_x,Whole_y)\n",
    "print search.best_params_\n",
    "clf = GradientBoostingClassifier(learning_rate=search.best_params_['learning_rate'],n_estimators=search.best_params_['n_estimators'])\n",
    "ave_acc_whole_boo = []\n",
    "ave_acc_whole_boo_train = []\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(Whole_x, Whole_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_whole_boo_train.append(score1/3.0)\n",
    "    ave_acc_whole_boo.append(score2/3.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9204545454545454, 0.9166666666666666, 0.8882575757575758]\n",
      "[0.9990530303030303, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print ave_acc_whole_boo\n",
    "print ave_acc_whole_boo_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'learning_rate': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:12: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "search.fit(eva_x,Instr)\n",
    "print search.best_params_\n",
    "clf = GradientBoostingClassifier(learning_rate=search.best_params_['learning_rate'],n_estimators=search.best_params_['n_estimators'])\n",
    "ave_acc_eva_boo=[]\n",
    "ave_acc_eva_boo_train=[]\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(eva_x, Instr, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_eva_boo_train.append(score1/3.0)\n",
    "    ave_acc_eva_boo.append(score2/3.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9836769759450172, 0.9804123711340206, 0.9817439862542955]\n",
      "[0.9864690721649486, 0.9888888888888889, 0.9905498281786942]\n"
     ]
    }
   ],
   "source": [
    "print ave_acc_eva_boo\n",
    "print ave_acc_eva_boo_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'learning_rate': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:12: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "search.fit(parking_x,parking_label)\n",
    "print search.best_params_\n",
    "clf = GradientBoostingClassifier(learning_rate=search.best_params_['learning_rate'],n_estimators=search.best_params_['n_estimators'])\n",
    "ave_acc_parking_boo=[]\n",
    "ave_acc_parking_boo_train=[]\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(parking_x, parking_label, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_parking_boo_train.append(score1/3.0)\n",
    "    ave_acc_parking_boo.append(score2/3.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0]\n",
      "[1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print ave_acc_parking_boo\n",
    "print ave_acc_parking_boo_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 100, 'algorithm': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "parameter = [{'n_neighbors':[5,100],'algorithm':['auto']}]\n",
    "search = GridSearchCV(clf,parameter,cv=3)\n",
    "search.fit(Act_x,Act_y)\n",
    "print search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=search.best_params_['n_neighbors'],algorithm=search.best_params_['algorithm'])\n",
    "ave_acc_activity_knn = []\n",
    "ave_acc_activity_knn_train = []\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(Act_x, Act_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1,y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_activity_knn_train.append(score1/3.0)\n",
    "    ave_acc_activity_knn.append(score2/3.0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9764417505102406, 0.9759879878401496, 0.9752617287559326]\n",
      "[0.9768846153846154, 0.9766276923076923, 0.9749435897435897]\n"
     ]
    }
   ],
   "source": [
    "print ave_acc_activity_knn\n",
    "print ave_acc_activity_knn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 100, 'algorithm': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "search.fit(occ_x,occ_y)\n",
    "print search.best_params_\n",
    "clf = KNeighborsClassifier(n_neighbors=search.best_params_['n_neighbors'],algorithm=search.best_params_['algorithm'])\n",
    "ave_acc_occ_knn = []\n",
    "ave_acc_occ_knn_train = []\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(occ_x, occ_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_occ_knn_train.append(score1/3.0)\n",
    "    ave_acc_occ_knn.append(score2/3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9850624104767752, 0.9873935821872953, 0.9791250959324636]\n",
      "[0.987360556749565, 0.9857528862687301, 0.9731777231777232]\n"
     ]
    }
   ],
   "source": [
    "print ave_acc_occ_knn\n",
    "print ave_acc_occ_knn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 5, 'algorithm': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:12: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "search.fit(eva_x,eva_y)\n",
    "print search.best_params_\n",
    "clf = KNeighborsClassifier(n_neighbors=search.best_params_['n_neighbors'],algorithm=search.best_params_['algorithm'])\n",
    "ave_acc_eva_knn=[]\n",
    "ave_acc_eva_knn_train=[]\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(eva_x, eva_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_eva_knn_train.append(score1/3.0)\n",
    "    ave_acc_eva_knn.append(score2/3.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.697308132875143, 0.6660939289805269, 0.5891323024054983]\n",
      "[0.7903064146620848, 0.7687285223367697, 0.718213058419244]\n"
     ]
    }
   ],
   "source": [
    "print ave_acc_eva_knn\n",
    "print ave_acc_eva_knn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 5, 'algorithm': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:12: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "search.fit(Whole_x,Whole_y)\n",
    "print search.best_params_\n",
    "clf = KNeighborsClassifier(n_neighbors=search.best_params_['n_neighbors'],algorithm=search.best_params_['algorithm'])\n",
    "ave_acc_whole_knn=[]\n",
    "ave_acc_whole_knn_train=[]\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(Whole_x, Whole_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_whole_knn_train.append(score1/3.0)\n",
    "    ave_acc_whole_knn.append(score2/3.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.912878787878788, 0.9136363636363637, 0.8835227272727274]\n",
      "[0.9299242424242425, 0.9196969696969698, 0.9204545454545454]\n"
     ]
    }
   ],
   "source": [
    "print ave_acc_whole_knn\n",
    "print ave_acc_whole_knn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 5, 'algorithm': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:12: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "search.fit(parking_x,parking_y)\n",
    "print search.best_params_\n",
    "clf = KNeighborsClassifier(n_neighbors=search.best_params_['n_neighbors'],algorithm=search.best_params_['algorithm'])\n",
    "ave_acc_parking_knn=[]\n",
    "ave_acc_parking_knn_train=[]\n",
    "for j in test_size:\n",
    "    score1=0\n",
    "    score2=0\n",
    "    for i in range(3):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(parking_x, parking_y, test_size=j) \n",
    "        X_train1 = sc.fit_transform(X_train1)\n",
    "        X_test1 = sc.transform(X_test1)\n",
    "        clf.fit(X_train1, y_train1)\n",
    "        score1 += clf.score(X_train1,y_train1)\n",
    "        score2 += clf.score(X_test1,y_test1)\n",
    "    ave_acc_parking_knn_train.append(score1/3.0)\n",
    "    ave_acc_parking_knn.append(score2/3.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9902482269503546, 0.9771170464938312, 0.934135927766501]\n",
      "[0.9947152906590139, 0.9876619255609064, 0.9661673433198003]\n"
     ]
    }
   ],
   "source": [
    "print ave_acc_parking_knn\n",
    "print ave_acc_parking_knn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
